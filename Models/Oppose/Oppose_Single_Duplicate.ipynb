{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Oppose_Single_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78ceff54979a46cea3942a575a1d9b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5eec9461d13743e8a5c5ac2defd46a5c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_022375f3f91f4af298e95df6727f9efb",
              "IPY_MODEL_b65fb6c23e3246d08f1acc244880f48c"
            ]
          }
        },
        "5eec9461d13743e8a5c5ac2defd46a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "022375f3f91f4af298e95df6727f9efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2247b758fd14ba2b54d1a7d1a95794c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc3ad92096084b189609f273e3c3af5e"
          }
        },
        "b65fb6c23e3246d08f1acc244880f48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3f3b48c070c4009801a74b9b59ecadd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:16&lt;00:00, 14.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_990b39ca9ff54ea9b5073b03f2335503"
          }
        },
        "c2247b758fd14ba2b54d1a7d1a95794c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc3ad92096084b189609f273e3c3af5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3f3b48c070c4009801a74b9b59ecadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "990b39ca9ff54ea9b5073b03f2335503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9334fa5d3d114b1aa6330d9157187b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8af0c8cbbfb34249ad6c5d994eb346a9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d147a34d6a1b41a6b4a655de4c7ba281",
              "IPY_MODEL_caa074e4b11c4c189c6eab8ec122050a"
            ]
          }
        },
        "8af0c8cbbfb34249ad6c5d994eb346a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d147a34d6a1b41a6b4a655de4c7ba281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a2dba6ce52143e58b37da928684a248",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1717,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1717,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ed1e4ebfbad4b818be4f234fe45d902"
          }
        },
        "caa074e4b11c4c189c6eab8ec122050a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eeb4484cd56b4ae3b4d82fd5e957d810",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1717/1717 [48:23&lt;00:00,  1.69s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_354092f893f849ae8b3bcb0b19470d2d"
          }
        },
        "0a2dba6ce52143e58b37da928684a248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ed1e4ebfbad4b818be4f234fe45d902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eeb4484cd56b4ae3b4d82fd5e957d810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "354092f893f849ae8b3bcb0b19470d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10c63761fea74ef1b6a8ebfdc7053a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a68bd79e24fe4a199b86a4279ca4f2eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d74c7d5eedb74ef4adafa8e76a67e9a2",
              "IPY_MODEL_954362a12a7c4d0f8b421df06fbfe885"
            ]
          }
        },
        "a68bd79e24fe4a199b86a4279ca4f2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d74c7d5eedb74ef4adafa8e76a67e9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6773823b6e8c42dd985213948031836c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1717,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1717,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa79beab787549bfa417610e53020c77"
          }
        },
        "954362a12a7c4d0f8b421df06fbfe885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5194769325594552abc9d707e518d39a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1717/1717 [15:40&lt;00:00,  1.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_964c4d1796244d48a0fecc892e3e5fd2"
          }
        },
        "6773823b6e8c42dd985213948031836c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa79beab787549bfa417610e53020c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5194769325594552abc9d707e518d39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "964c4d1796244d48a0fecc892e3e5fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "224c194f55f44836b6e002dac5a28f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e25ab7595e1c4fa99287aeb5405a2ff0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90ef2767128f4133b862874aa549ff60",
              "IPY_MODEL_d19419efbef94eeeb752ab2d7f8e7cc7"
            ]
          }
        },
        "e25ab7595e1c4fa99287aeb5405a2ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90ef2767128f4133b862874aa549ff60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03d6481e5ac4426b869e1cba7dd97119",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1717,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1717,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4c451913a6d42a1a78ba7ab33f33dd5"
          }
        },
        "d19419efbef94eeeb752ab2d7f8e7cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0609b7cf3be443bf8afce167c9f79929",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1717/1717 [15:54&lt;00:00,  1.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d53e8c5888654b739bd89b6a36cc7f42"
          }
        },
        "03d6481e5ac4426b869e1cba7dd97119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4c451913a6d42a1a78ba7ab33f33dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0609b7cf3be443bf8afce167c9f79929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d53e8c5888654b739bd89b6a36cc7f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d05b1230-8b2d-4c9b-db13-9583861002e7"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 45.33 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c5535b7-b353-4b95-9557-866b8ecd706c"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a1ee2f5-f48e-4b43-a9d7-f47c6a630f3d"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e3226cc0-d232-4889-cfbb-eec631cf97a9"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "98597ea2-78fa-4165-c136-9d2722fed703"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "cec4c497-040f-4dd9-d444-eb8eb2b6eb80"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 29.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 16.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f65879a0-58b6-4c21-95bc-ef1c41c65503"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "887d62f6-2a70-41d0-952d-4d6e533f1426"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "1758c3db-4602-4c97-bbbe-02fac3313ec4"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "084df2e4-ffc3-4f1b-9ba8-d901af8b91b1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                         How #MeToo really started!  \n",
              "1    #BIGNEWS: Soon you will find out who is behind...\n",
              "2                                        ption - no:2 \n",
              "3    All girls deserve to grow up safe, respected a...\n",
              "4    here is the link !!!!! he is not a xxxxxx fuck...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51d4ba7e-ffa8-4da2-e009-4b87aa562e95"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:10<00:00, 39980557.14B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8f77d9c-07a9-4462-9d39-1525ff049cc1"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 911658.66B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "426beced-89a5-48de-b820-f7d256e8c058"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3051bc1f-cea5-4ccc-e6d7-5ba0bbea9af0"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        df4 = df2.copy().reset_index(drop=True)\n",
        "        df5 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            # random.shuffle(text)\n",
        "            # text3 = ' '.join(text)\n",
        "            # df3['text'][i]=text3\n",
        "            # random.shuffle(text)\n",
        "            # text4 = ' '.join(text)\n",
        "            # df4['text'][i]=text4\n",
        "            # random.shuffle(text)\n",
        "            # text5 = ' '.join(text)\n",
        "            # df5['text'][i]=text5\n",
        "        self.data = self.data.append(df2, ignore_index=True)\n",
        "        # self.data = self.data.append(df3, ignore_index=True)\n",
        "        # self.data = self.data.append(df4, ignore_index=True)\n",
        "        # self.data = self.data.append(df5, ignore_index=True)\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97fe63a7-c284-4e24-ce01-4fe5f1b76a46"
      },
      "source": [
        "col_name = \"Oppose\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862,
          "referenced_widgets": [
            "78ceff54979a46cea3942a575a1d9b1e",
            "5eec9461d13743e8a5c5ac2defd46a5c",
            "022375f3f91f4af298e95df6727f9efb",
            "b65fb6c23e3246d08f1acc244880f48c",
            "c2247b758fd14ba2b54d1a7d1a95794c",
            "cc3ad92096084b189609f273e3c3af5e",
            "e3f3b48c070c4009801a74b9b59ecadd",
            "990b39ca9ff54ea9b5073b03f2335503",
            "9334fa5d3d114b1aa6330d9157187b11",
            "8af0c8cbbfb34249ad6c5d994eb346a9",
            "d147a34d6a1b41a6b4a655de4c7ba281",
            "caa074e4b11c4c189c6eab8ec122050a",
            "0a2dba6ce52143e58b37da928684a248",
            "3ed1e4ebfbad4b818be4f234fe45d902",
            "eeb4484cd56b4ae3b4d82fd5e957d810",
            "354092f893f849ae8b3bcb0b19470d2d",
            "10c63761fea74ef1b6a8ebfdc7053a87",
            "a68bd79e24fe4a199b86a4279ca4f2eb",
            "d74c7d5eedb74ef4adafa8e76a67e9a2",
            "954362a12a7c4d0f8b421df06fbfe885",
            "6773823b6e8c42dd985213948031836c",
            "aa79beab787549bfa417610e53020c77",
            "5194769325594552abc9d707e518d39a",
            "964c4d1796244d48a0fecc892e3e5fd2",
            "224c194f55f44836b6e002dac5a28f94",
            "e25ab7595e1c4fa99287aeb5405a2ff0",
            "90ef2767128f4133b862874aa549ff60",
            "d19419efbef94eeeb752ab2d7f8e7cc7",
            "03d6481e5ac4426b869e1cba7dd97119",
            "d4c451913a6d42a1a78ba7ab33f33dd5",
            "0609b7cf3be443bf8afce167c9f79929",
            "d53e8c5888654b739bd89b6a36cc7f42"
          ]
        },
        "outputId": "a219c851-1242-495f-bc86-4ecfb825f81d"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6870\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1710\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78ceff54979a46cea3942a575a1d9b1e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9334fa5d3d114b1aa6330d9157187b11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1717.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0874\n",
            "Train Losses : [0.18028885126113892, 1.0512059926986694, 1.5485037565231323, 0.3197208642959595, 0.497959166765213, 1.8060349225997925, 1.0310841798782349, 0.5987213850021362, 0.00782097689807415, 0.12365812063217163, 0.016746804118156433, 0.4512898623943329, 0.1497332900762558, 0.04544952139258385, 0.023159250617027283, 0.026285743340849876, 0.39542919397354126, 0.09766638278961182, 0.2702849209308624, 0.013420320115983486, 0.19660523533821106, 0.5051684975624084, 0.06858453899621964, 0.12147919088602066, 0.07916244864463806, 0.13617061078548431, 1.0875803232192993, 0.04756572097539902, 0.012399428524076939, 0.007552382070571184, 0.010589190758764744, 0.20540420711040497, 0.004559161141514778, 0.6919206976890564, 0.013040745630860329, 0.2276642918586731, 0.00525614432990551, 0.018246056511998177, 0.0342828631401062, 0.10944420844316483, 0.13942527770996094, 0.016560647636651993, 0.9676401615142822, 0.00682730320841074, 0.016331588849425316, 0.006153056863695383, 0.5421499013900757, 0.008088482543826103, 0.9945833086967468, 0.14243082702159882, 0.013708412647247314, 0.010995618999004364, 0.1413041055202484, 0.16345418989658356, 0.22964833676815033, 0.015292075462639332, 0.1830219179391861, 0.02181333303451538, 0.02808421105146408, 0.02013658732175827, 0.39319324493408203, 0.21328668296337128, 0.656114935874939, 1.0379825830459595, 0.5862659215927124, 0.034923966974020004, 0.03171791508793831, 0.8328577280044556, 0.07806943356990814, 0.08719664812088013, 0.03282812610268593, 0.037485431879758835, 0.03589203208684921, 0.041501447558403015, 0.11277487128973007, 0.03580266982316971, 0.0745907798409462, 0.26781171560287476, 0.03641989082098007, 0.10191566497087479, 0.1141783818602562, 0.09493424743413925, 0.027128634974360466, 0.10168082267045975, 0.15740106999874115, 0.021577933803200722, 0.18482641875743866, 0.02139291539788246, 0.23975002765655518, 0.03725321963429451, 0.14262540638446808, 0.019287079572677612, 0.04831280559301376, 0.08224217593669891, 0.21572481095790863, 0.38231727480888367, 0.011131457053124905, 0.014961891807615757, 0.016192730516195297, 0.014309665188193321, 0.013184864073991776, 0.01251291949301958, 0.4767456650733948, 0.10856027156114578, 0.12247435748577118, 0.05536568909883499, 0.0136079341173172, 0.013494465500116348, 0.011862010695040226, 0.013380098156630993, 0.15301711857318878, 0.008822057396173477, 0.008546042256057262, 0.358925998210907, 0.011941831558942795, 0.013149120844900608, 0.07322154939174652, 0.012785200960934162, 0.15374311804771423, 0.10408132523298264, 0.7448868155479431, 0.1250821053981781, 0.04616786167025566, 0.011066430248320103, 0.010668733157217503, 0.20838558673858643, 0.010583884082734585, 0.013269167393445969, 0.1617574691772461, 0.06290043145418167, 0.010825591161847115, 0.013108680956065655, 0.018114369362592697, 0.01145870704203844, 0.08705480396747589, 0.011717012152075768, 0.012278210371732712, 0.013028125278651714, 0.4495207667350769, 0.2087186723947525, 0.05537757650017738, 0.011936974711716175, 0.5860069394111633, 0.12678974866867065, 0.013617162592709064, 0.1865299493074417, 0.01386223640292883, 0.16889113187789917, 0.01464199647307396, 0.013600888662040234, 0.013484329916536808, 0.013458484783768654, 0.09652175009250641, 0.014814338646829128, 0.012777730822563171, 0.012488593347370625, 0.01580166071653366, 0.011672303080558777, 0.010862817987799644, 0.011185633018612862, 0.011097569018602371, 0.2577480971813202, 0.009265991859138012, 0.14528602361679077, 0.008714969269931316, 0.07805600017309189, 0.007814663462340832, 0.007706910837441683, 0.0628981962800026, 0.007758164778351784, 0.008337120525538921, 0.009324672631919384, 0.10656904429197311, 0.11510267108678818, 0.01129571907222271, 0.04284590110182762, 0.0075041973032057285, 0.18172849714756012, 0.2502337098121643, 0.010305684059858322, 0.2947823703289032, 0.23172451555728912, 0.01119658350944519, 0.010181954130530357, 0.03566187992691994, 0.43197759985923767, 0.012272250838577747, 0.05611486732959747, 0.016751259565353394, 0.017312807962298393, 0.6637257933616638, 0.027144763618707657, 0.02552192658185959, 0.02335045114159584, 0.021271254867315292, 0.3622913658618927, 0.02375747449696064, 0.03439898416399956, 0.26425567269325256, 0.023528603836894035, 0.41786879301071167, 0.02629643678665161, 0.04828467592597008, 0.12964804470539093, 0.03287186101078987, 0.10490620881319046, 0.06795575469732285, 0.169834166765213, 0.03595024719834328, 0.03545006364583969, 0.21861612796783447, 0.03427215293049812, 0.08302032947540283, 0.10810836404561996, 0.2542458176612854, 0.032302532345056534, 0.0998932272195816, 0.08135455846786499, 0.02470795437693596, 0.023412276059389114, 0.13071948289871216, 0.1302422732114792, 0.06269204616546631, 0.08546566963195801, 0.12272496521472931, 0.018521947786211967, 0.01761561818420887, 0.10292909294366837, 0.13366343080997467, 0.09543727338314056, 0.06798824667930603, 0.07596553862094879, 0.16789576411247253, 0.11925538629293442, 0.0940362960100174, 0.014962665736675262, 0.3693324625492096, 0.015307565219700336, 0.10194593667984009, 0.01906728371977806, 0.017870765179395676, 0.35823962092399597, 0.15180771052837372, 0.12169315665960312, 0.492055207490921, 0.020967034623026848, 0.024389833211898804, 0.025278424844145775, 0.028034700080752373, 0.027214692905545235, 0.027102002874016762, 0.031773604452610016, 0.02856641449034214, 0.3536520004272461, 0.02423964999616146, 0.041360173374414444, 0.023694762960076332, 0.14192113280296326, 0.08141851425170898, 0.02264883741736412, 0.02535257302224636, 0.08330316841602325, 0.3236217498779297, 0.020116090774536133, 0.13952785730361938, 0.01922624558210373, 0.29652005434036255, 0.019810790196061134, 0.019726915284991264, 0.06757236272096634, 0.02111138589680195, 0.12744265794754028, 0.01867706887423992, 0.1143256276845932, 0.01832175999879837, 0.01752293109893799, 0.018208637833595276, 0.2759748697280884, 0.01686725951731205, 0.018834609538316727, 0.0173097662627697, 0.01661914959549904, 0.14162494242191315, 0.01536065898835659, 0.013997790403664112, 0.013694187626242638, 0.015481379814445972, 0.013497213833034039, 0.09913518279790878, 0.010963731445372105, 0.010360958985984325, 0.19134214520454407, 0.09166456758975983, 0.16106446087360382, 0.16970929503440857, 0.009055041708052158, 0.008466136641800404, 0.008487222716212273, 0.00840636994689703, 0.00897717010229826, 0.0073972055688500404, 0.11422175168991089, 0.006959403399378061, 0.006972290575504303, 0.08392373472452164, 0.10633515566587448, 0.006320910528302193, 0.1554197072982788, 0.006338690873235464, 0.0067873685620725155, 0.006416513118892908, 0.07843147963285446, 0.006366906221956015, 0.2096310257911682, 0.1075863391160965, 0.007632764521986246, 0.0061581926420331, 0.0065004173666238785, 0.18781830370426178, 0.006179851479828358, 0.12746338546276093, 0.00708361342549324, 0.08796431869268417, 0.007975166663527489, 0.006326107308268547, 0.007622326724231243, 0.40115296840667725, 0.12697015702724457, 0.0072029209695756435, 0.09710972011089325, 0.12310270220041275, 0.008559465408325195, 0.009198140352964401, 0.0099077383056283, 0.009407923556864262, 0.009519137442111969, 0.009939094074070454, 0.11826290935277939, 0.009711557067930698, 0.009998191148042679, 0.010576353408396244, 0.1099160686135292, 0.3146435618400574, 0.10015001893043518, 0.011184644885361195, 0.10207986831665039, 0.011773317120969296, 0.011247911490499973, 0.13338452577590942, 0.012428388930857182, 0.34768155217170715, 0.012253147549927235, 0.013793284073472023, 0.013034714385867119, 0.013227925635874271, 0.013827774673700333, 0.30770742893218994, 0.014353035017848015, 0.01495734415948391, 0.1104075238108635, 0.08053243905305862, 0.12988106906414032, 0.015527774579823017, 0.016759609803557396, 0.015231404453516006, 0.015672652050852776, 0.015393474139273167, 0.04637325927615166, 0.015118532814085484, 0.013958998024463654, 0.06960772722959518, 0.11508337408304214, 0.30962029099464417, 0.013329658657312393, 0.01289032120257616, 0.013134807348251343, 0.10794223099946976, 0.493557333946228, 0.1094660684466362, 0.20620600879192352, 0.16359448432922363, 0.019009998068213463, 0.10760031640529633, 0.16787245869636536, 0.17088721692562103, 0.09193044900894165, 0.15681588649749756, 0.028689634054899216, 0.029951076954603195, 0.04783874377608299, 0.032637760043144226, 0.08795531839132309, 0.2722177803516388, 0.10842800885438919, 0.03316212445497513, 0.035575564950704575, 0.03449128940701485, 0.1402851641178131, 0.03066505864262581, 0.08400019258260727, 0.029673898592591286, 0.08569992333650589, 0.027784427627921104, 0.023498915135860443, 0.15305663645267487, 0.07611001282930374, 0.01993766985833645, 0.019576316699385643, 0.11824879795312881, 0.09021373838186264, 0.11000166088342667, 0.01594216749072075, 0.10112397372722626, 0.014116753824055195, 0.08603929728269577, 0.012814991176128387, 0.29446688294410706, 0.07312233746051788, 0.1723698526620865, 0.012816965579986572, 0.01260572113096714, 0.0853360965847969, 0.012467820197343826, 0.012668060138821602, 0.10249344259500504, 0.14995907247066498, 0.011727388016879559, 0.16465413570404053, 0.13785356283187866, 0.011088117025792599, 0.07450751215219498, 0.1648574024438858, 0.12326491624116898, 0.011158939450979233, 0.0902285948395729, 0.08888518810272217, 0.10351450741291046, 0.011581506580114365, 0.12478462606668472, 0.011455713771283627, 0.011744702234864235, 0.01191000547260046, 0.18359112739562988, 0.011962603777647018, 0.010348130017518997, 0.07349976152181625, 0.06726502627134323, 0.059492018073797226, 0.06246953457593918, 0.011026449501514435, 0.010327181778848171, 0.07891926914453506, 0.01094889547675848, 0.009534820914268494, 0.009652981534600258, 0.06576623767614365, 0.4091355502605438, 0.011668410152196884, 0.06633850187063217, 0.10202496498823166, 0.010640617460012436, 0.011080128140747547, 0.09056845307350159, 0.013021018356084824, 0.14689567685127258, 0.011946897022426128, 0.013015863485634327, 0.012351260520517826, 0.0126305241137743, 0.08121012151241302, 0.160379558801651, 0.17156767845153809, 0.01338884886354208, 0.010587818920612335, 0.010602368973195553, 0.21461164951324463, 0.10255731642246246, 0.17273403704166412, 0.010388697497546673, 0.13993528485298157, 0.010359672829508781, 0.009513811208307743, 0.3723132908344269, 0.14293867349624634, 0.0103140315040946, 0.010718286037445068, 0.01086501032114029, 0.08974739909172058, 0.011270474642515182, 0.011780730448663235, 0.011887965723872185, 0.011762312613427639, 0.31964004039764404, 0.011834380216896534, 0.012366917915642262, 0.13691575825214386, 0.09330955147743225, 0.012555429711937904, 0.013229815289378166, 0.1428249031305313, 0.013010047376155853, 0.013083786703646183, 0.17677466571331024, 0.013806615024805069, 0.012534689158201218, 0.012291685678064823, 0.012138890102505684, 0.34837576746940613, 0.012198279611766338, 0.011938001960515976, 0.012193882837891579, 0.011716227978467941, 0.012227216735482216, 0.12368875741958618, 0.01155433151870966, 0.01130559854209423, 0.01091146282851696, 0.010775389149785042, 0.010485691018402576, 0.009979283437132835, 0.009721278212964535, 0.00931861437857151, 0.09969468414783478, 0.10276755690574646, 0.008674629963934422, 0.008287814445793629, 0.008276429027318954, 0.007816692814230919, 0.09531080722808838, 0.007542651612311602, 0.1514420360326767, 0.007205955684185028, 0.10117889940738678, 0.007175265345722437, 0.10878810286521912, 0.09668127447366714, 0.10829797387123108, 0.00721915066242218, 0.0887625515460968, 0.007184451445937157, 0.007192016579210758, 0.4514167010784149, 0.007823566906154156, 0.008106861263513565, 0.12049387395381927, 0.008695586584508419, 0.11322516202926636, 0.009314493276178837, 0.009442200884222984, 0.010130445472896099, 0.00996338203549385, 0.00983077846467495, 0.1432010531425476, 0.009700852446258068, 0.00968118105083704, 0.09877364337444305, 0.009590727277100086, 0.00942289549857378, 0.10180041193962097, 0.009249330498278141, 0.00906164851039648, 0.008972883224487305, 0.008788189850747585, 0.09850119054317474, 0.008499347604811192, 0.008411170914769173, 0.1208677887916565, 0.007986620999872684, 0.007832488976418972, 0.11508315801620483, 0.12308867275714874, 0.09630532562732697, 0.0076839071698486805, 0.10837029665708542, 0.007630215026438236, 0.13020044565200806, 0.08992145955562592, 0.007718553300946951, 0.007847225293517113, 0.007915277034044266, 0.00786158163100481, 0.1330546885728836, 0.007785205729305744, 0.007864875718951225, 0.39934042096138, 0.11699903011322021, 0.3250579237937927, 0.009336818940937519, 0.3877141773700714, 0.11457864195108414, 0.11870778352022171, 0.014075091108679771, 0.015201088972389698, 0.016150174662470818, 0.09157826006412506, 0.018120791763067245, 0.018152032047510147, 0.10915287584066391, 0.018840162083506584, 0.10047435015439987, 0.01906503178179264, 0.019075654447078705, 0.018853558227419853, 0.01834731549024582, 0.10476531833410263, 0.11330123990774155, 0.1101192906498909, 0.016717929393053055, 0.016278356313705444, 0.015919582918286324, 0.015160332433879375, 0.12212539464235306, 0.01412016712129116, 0.013630623929202557, 0.09641491621732712, 0.012545065954327583, 0.10865950584411621, 0.09724515676498413, 0.011552070267498493, 0.2775111198425293, 0.011235719546675682, 0.011412057094275951, 0.011590812355279922, 0.011279255151748657, 0.3282342255115509, 0.12092466652393341, 0.10056664794683456, 0.10836509615182877, 0.09676084667444229, 0.11354567855596542, 0.013651303946971893, 0.1165061965584755, 0.014461291022598743, 0.3228313624858856, 0.25244033336639404, 0.1080729067325592, 0.2975790202617645, 0.01928751915693283, 0.021033240482211113, 0.0994681641459465, 0.02349887788295746, 0.10697978734970093, 0.11292731761932373, 0.025589974597096443, 0.025889085605740547, 0.02609006129205227, 0.11217936873435974, 0.025285011157393456, 0.024658098816871643, 0.11573757231235504, 0.023418406024575233, 0.02275833487510681, 0.021888792514801025, 0.02090304158627987, 0.01961781643331051, 0.018471993505954742, 0.01770651340484619, 0.11624545603990555, 0.015645114704966545, 0.014759359881281853, 0.013712430372834206, 0.012885810807347298, 0.012225999496877193, 0.2966265380382538, 0.011108013801276684, 0.2786921560764313, 0.011180128902196884, 0.01144080888479948, 0.01145746186375618, 0.01153072901070118, 0.011469000950455666, 0.10836318880319595, 0.011276057921350002, 0.12188474833965302, 0.08066331595182419, 0.010983127169311047, 0.09339743107557297, 0.12271074950695038, 0.2833903431892395, 0.09671827405691147, 0.12004208564758301, 0.012517920695245266, 0.012988981790840626, 0.07027958333492279, 0.11473332345485687, 0.014010562561452389, 0.01401244942098856, 0.10714511573314667, 0.08439961075782776, 0.01419038139283657, 0.08401910960674286, 0.014262387529015541, 0.014310920611023903, 0.013950767926871777, 0.3181386888027191, 0.01450743991881609, 0.014136837795376778, 0.07778763025999069, 0.01455710083246231, 0.2553756833076477, 0.015304556116461754, 0.01567976176738739, 0.10879254341125488, 0.07902152836322784, 0.01639382913708687, 0.01592029444873333, 0.13942016661167145, 0.07881966233253479, 0.6199899911880493, 0.0175347737967968, 0.018141869455575943, 0.019338155165314674, 0.020048491656780243, 0.0203391145914793, 0.020512893795967102, 0.20844559371471405, 0.08127471804618835, 0.021717138588428497, 0.022373024374246597, 0.022005297243595123, 0.11741292476654053, 0.02175978012382984, 0.10302373766899109, 0.021017612889409065, 0.020839806646108627, 0.0920201763510704, 0.019906364381313324, 0.019230244681239128, 0.08711416274309158, 0.14535264670848846, 0.21260793507099152, 0.01734410598874092, 0.01727411150932312, 0.01667032018303871, 0.016663096845149994, 0.015894349664449692, 0.01603713072836399, 0.12224423885345459, 0.014882371760904789, 0.014227583073079586, 0.013424919918179512, 0.24189665913581848, 0.013026376254856586, 0.07452341914176941, 0.08111723512411118, 0.07554078102111816, 0.13873036205768585, 0.013727721758186817, 0.013078234158456326, 0.013029539957642555, 0.012864629738032818, 0.013324040919542313, 0.22972773015499115, 0.09679781645536423, 0.13984821736812592, 0.01321597769856453, 0.013680278323590755, 0.013272449374198914, 0.12541958689689636, 0.013214864768087864, 0.08608496189117432, 0.013065232895314693, 0.01421030517667532, 0.013396814465522766, 0.012556028552353382, 0.1048397496342659, 0.011806345544755459, 0.011922906152904034, 0.011182207614183426, 0.07883140444755554, 0.011493139900267124, 0.2902074158191681, 0.01076681911945343, 0.011046567000448704, 0.14535623788833618, 0.06607387214899063, 0.12627997994422913, 0.416424036026001, 0.012174934148788452, 0.011902744881808758, 0.13599330186843872, 0.013164513744413853, 0.304000586271286, 0.5348008871078491, 0.016155170276761055, 0.01787361316382885, 0.08732089400291443, 0.02115558460354805, 0.2619752585887909, 0.023990774527192116, 0.14619331061840057, 0.029553262516856194, 0.10677549988031387, 0.028829509392380714, 0.24947047233581543, 0.032319653779268265, 0.10648395121097565, 0.2499750256538391, 0.03371662646532059, 0.03334175422787666, 0.03392737731337547, 0.032796334475278854, 0.11697684228420258, 0.2258622944355011, 0.03240257501602173, 0.03229514881968498, 0.03233511000871658, 0.030749516561627388, 0.030524222180247307, 0.11519820988178253, 0.02773876301944256, 0.02604188211262226, 0.12228326499462128, 0.02354738861322403, 0.023178856819868088, 0.11803217977285385, 0.020149828866124153, 0.07178696244955063, 0.017880257219076157, 0.017107980325818062, 0.10324478149414062, 0.015229216776788235, 0.01458645984530449, 0.013837364502251148, 0.013731374405324459, 0.12992635369300842, 0.01158627588301897, 0.012004232034087181, 0.010666433721780777, 0.1074686348438263, 0.13388031721115112, 0.00950290635228157, 0.30603349208831787, 0.09153448045253754, 0.10326208919286728, 0.12471413612365723, 0.09464684873819351, 0.09436214715242386, 0.11992785334587097, 0.3416486084461212, 0.01167559064924717, 0.1166284903883934, 0.011938955634832382, 0.3289347290992737, 0.33318421244621277, 0.014660726301372051, 0.01586340367794037, 0.158066064119339, 0.12570585310459137, 0.01891906186938286, 0.020196350291371346, 0.10701187700033188, 0.021155647933483124, 0.021197086200118065, 0.11000838875770569, 0.021593771874904633, 0.10073615610599518, 0.10108506679534912, 0.020605016499757767, 0.020097188651561737, 0.019663559272885323, 0.09139077365398407, 0.09211438149213791, 0.2397082895040512, 0.018573762848973274, 0.26034966111183167, 0.01934262178838253, 0.019517360255122185, 0.0752280205488205, 0.2564048171043396, 0.1025576964020729, 0.021900376304984093, 0.021420881152153015, 0.02167053334414959, 0.09345122426748276, 0.021329762414097786, 0.021214794367551804, 0.021005069836974144, 0.12623009085655212, 0.11894658207893372, 0.019640866667032242, 0.23340009152889252, 0.01894008368253708, 0.01923414133489132, 0.2485559731721878, 0.019336549565196037, 0.2500416040420532, 0.021539395675063133, 0.5699254870414734, 0.022124985232949257, 0.127660870552063, 0.15436212718486786, 0.026812003925442696, 0.02729746326804161, 0.029085656628012657, 0.02908460609614849, 0.02870124764740467, 0.02978997305035591, 0.027631493285298347, 0.02696618065237999, 0.027462435886263847, 0.026268472895026207, 0.024275222793221474, 0.024568529799580574, 0.13145604729652405, 0.021759117022156715, 0.24920490384101868, 0.21739333868026733, 0.019858261570334435, 0.020510952919721603, 0.019340282306075096, 0.019680887460708618, 0.01911485753953457, 0.018199048936367035, 0.017544033005833626, 0.017262818291783333, 0.11603137105703354, 0.11857776343822479, 0.015752071514725685, 0.10027524828910828, 0.31644001603126526, 0.12520727515220642, 0.014953462406992912, 0.014950219541788101, 0.014488673768937588, 0.2740888297557831, 0.0932479053735733, 0.08430556952953339, 0.13245806097984314, 0.015874242410063744, 0.10143560916185379, 0.016314348205924034, 0.15524503588676453, 0.11197848618030548, 0.1144048422574997, 0.016248278319835663, 0.016017772257328033, 0.09146824479103088, 0.11411530524492264, 0.09296164661645889, 0.3204819858074188, 0.11723234504461288, 0.016808519139885902, 0.017291052266955376, 0.09419648349285126, 0.016868164762854576, 0.017056139186024666, 0.016755539923906326, 0.25295576453208923, 0.016960451379418373, 0.016951803117990494, 0.017111701890826225, 0.017797185108065605, 0.01705276034772396, 0.12712714076042175, 0.11326979845762253, 0.1110440120100975, 0.09772977232933044, 0.0161266066133976, 0.01584799773991108, 0.09215129166841507, 0.09125246107578278, 0.2797175347805023, 0.28109174966812134, 0.016181474551558495, 0.016884753480553627, 0.3416536748409271, 0.01804460771381855, 0.018293531611561775, 0.10095135122537613, 0.10214487463235855, 0.01988392323255539, 0.09795006364583969, 0.020091887563467026, 0.0919467881321907, 0.09072618931531906, 0.11741507053375244, 0.020560694858431816, 0.08729120343923569, 0.02001640573143959, 0.019774029031395912, 0.10037155449390411, 0.019379323348402977, 0.018951164558529854, 0.10910730808973312, 0.10774751752614975, 0.09051690995693207, 0.11615800857543945, 0.10909553617238998, 0.10822898149490356, 0.016352888196706772, 0.016066838055849075, 0.12128829956054688, 0.08431088179349899, 0.11371277272701263, 0.11839160323143005, 0.08277319371700287, 0.1220492422580719, 0.2909613847732544, 0.2703782320022583, 0.015542913228273392, 0.016490092501044273, 0.016510671004652977, 0.01761913299560547, 0.01697804406285286, 0.1382579654455185, 0.017456425353884697, 0.0996459349989891, 0.017156099900603294, 0.09110768139362335, 0.0167510025203228, 0.3187568783760071, 0.10108892619609833, 0.01718326471745968, 0.017158564180135727, 0.10109157115221024, 0.10072024166584015, 0.36445093154907227, 0.018533291295170784, 0.01819547265768051, 0.018290122970938683, 0.0950995609164238, 0.10361144691705704, 0.01864832080900669, 0.24405984580516815, 0.29499757289886475, 0.12953662872314453, 0.020614754408597946, 0.021622024476528168, 0.02162199281156063, 0.021931076422333717, 0.09540095925331116, 0.07222378253936768, 0.12617449462413788, 0.09670215845108032, 0.09853468835353851, 0.021886087954044342, 0.022036977112293243, 0.10518888384103775, 0.02120307832956314, 0.021365104243159294, 0.01990102231502533, 0.019569573923945427, 0.303484708070755, 0.26596546173095703, 0.01902608759701252, 0.01953841745853424, 0.019480857998132706, 0.019279852509498596, 0.11513447761535645, 0.018905887380242348, 0.08056653290987015, 0.10655082017183304, 0.08266819268465042, 0.09399807453155518, 0.2515212893486023, 0.09221206605434418, 0.08809395879507065, 0.23963961005210876, 0.019699545577168465, 0.1057518720626831, 0.0215139277279377, 0.02149593085050583, 0.021203886717557907, 0.021969962865114212, 0.022524220868945122, 0.11976362019777298, 0.020798349753022194, 0.11626113206148148, 0.10976589471101761, 0.1181827038526535, 0.019607096910476685, 0.018451761454343796, 0.01954231970012188, 0.10638013482093811, 0.13371595740318298, 0.10083957016468048, 0.23306426405906677, 0.3147394061088562, 0.01755169965326786, 0.017118941992521286, 0.017548436298966408, 0.01764288730919361, 0.12584780156612396, 0.01781480759382248, 0.2997484803199768, 0.01868269592523575, 0.01871209777891636, 0.018899982795119286, 0.018447471782565117, 0.10536139458417892, 0.49181613326072693, 0.10769785940647125, 0.019709978252649307, 0.021175796166062355, 0.24509789049625397, 0.11315899342298508, 0.024327732622623444, 0.023662103340029716, 0.10391855239868164, 0.02429427206516266, 0.35126757621765137, 0.025333207100629807, 0.2868637442588806, 0.026715578511357307, 0.09476537257432938, 0.027997637167572975, 0.028314340859651566, 0.0284770205616951, 0.028185861185193062, 0.0786314532160759, 0.02697967365384102, 0.10439203679561615, 0.09991838037967682, 0.025363311171531677, 0.09453611075878143, 0.023792240768671036, 0.10713944584131241, 0.022814888507127762, 0.021763892844319344, 0.02086613141000271, 0.020103370770812035, 0.019567960873246193, 0.1266373097896576, 0.017657093703746796, 0.07293404638767242, 0.12278279662132263, 0.015982283279299736, 0.015085806138813496, 0.09437105804681778, 0.11188332736492157, 0.013646995648741722, 0.01312697771936655, 0.09978921711444855, 0.012537984177470207, 0.09396078437566757, 0.08428563922643661, 0.3189673125743866, 0.01166050136089325, 0.01149863563477993, 0.3444366753101349, 0.011973528191447258, 0.10192438960075378, 0.012713474221527576, 0.012971142306923866, 0.013431926257908344, 0.013636654242873192, 0.013228406198322773, 0.08355068415403366, 0.013101315125823021, 0.2754769027233124, 0.33807146549224854, 0.33102288842201233, 0.015534617938101292, 0.10945000499486923, 0.11114823818206787, 0.01840796321630478, 0.09975108504295349, 0.019579028710722923, 0.12153655290603638, 0.020638171583414078, 0.10574007034301758, 0.02090970240533352, 0.02094762958586216, 0.021129829809069633, 0.09917907416820526, 0.29293009638786316, 0.13927805423736572, 0.1315198838710785, 0.021255509927868843, 0.021522624418139458, 0.021426411345601082, 0.09889908134937286, 0.11860132217407227, 0.020728351548314095, 0.02042214758694172, 0.019955966621637344, 0.019566653296351433, 0.018980886787176132, 0.018484795466065407, 0.09878590703010559, 0.10156407207250595, 0.11409567296504974, 0.016076473519206047, 0.015800414606928825, 0.015323071740567684, 0.014813607558608055, 0.01418902538716793, 0.29241955280303955, 0.12445670366287231, 0.013635360635817051, 0.5384034514427185, 0.014464760199189186, 0.08761630952358246, 0.10231237858533859, 0.2555708885192871, 0.01733226329088211, 0.10650282353162766, 0.019039735198020935, 0.09268773347139359, 0.02024724893271923, 0.020871547982096672, 0.1310107707977295, 0.02126152627170086, 0.021347064524888992, 0.021107325330376625, 0.020940106362104416, 0.27861863374710083, 0.11011873930692673, 0.25758668780326843, 0.09502226859331131, 0.02195240743458271, 0.022305510938167572, 0.02240910939872265, 0.10474842041730881, 0.11821325868368149, 0.08724088966846466, 0.022081634029746056, 0.09962569922208786, 0.2641185224056244, 0.11620727926492691, 0.022113831713795662, 0.022382140159606934, 0.11652626842260361, 0.1422450840473175, 0.022168204188346863, 0.021524718031287193, 0.021176127716898918, 0.020680177956819534, 0.10456600040197372, 0.120574951171875, 0.291248083114624, 0.019361373037099838, 0.019160501658916473, 0.01897522062063217, 0.018906209617853165, 0.018305664882063866, 0.10676532238721848, 0.08640658855438232, 0.01728138141334057, 0.017003832384943962, 0.09476162493228912, 0.09902295470237732, 0.09907649457454681, 0.08456791937351227, 0.015249036252498627, 0.10356049984693527, 0.014963662251830101, 0.014628873206675053, 0.12790657579898834, 0.08415072411298752, 0.01352990698069334, 0.10207857191562653, 0.01314238365739584, 0.012920401059091091, 0.1320502907037735, 0.12070225924253464, 0.10911844670772552, 0.31833699345588684, 0.012627070769667625, 0.3126968741416931, 0.013133046217262745, 0.11951666325330734, 0.01409345492720604, 0.014414487406611443, 0.11263184249401093, 0.014884292148053646, 0.014997350051999092, 0.09683896601200104, 0.015320244245231152, 0.015198320150375366, 0.014994432218372822, 0.10635856539011002, 0.014715966768562794, 0.2637515664100647, 0.014825229533016682, 0.0982389897108078, 0.015319274738430977, 0.01519747730344534, 0.12132978439331055, 0.01504193153232336, 0.12157319486141205, 0.10150275379419327, 0.014819139614701271, 0.014655033126473427, 0.014667097479104996, 0.014211111702024937, 0.01382646057754755, 0.01351244281977415, 0.013185188174247742, 0.012873021885752678, 0.11472244560718536, 0.10766363888978958, 0.3062404990196228, 0.011988749727606773, 0.012042702175676823, 0.0121580446138978, 0.09739016741514206, 0.30074387788772583, 0.012453271076083183, 0.012774713337421417, 0.09636517614126205, 0.10177014023065567, 0.013387264683842659, 0.013749949634075165, 0.10515038669109344, 0.09340106695890427, 0.2567542791366577, 0.014275213703513145, 0.014695602469146252, 0.10387204587459564, 0.08966614305973053, 0.12797106802463531, 0.11093990504741669, 0.0157980527728796, 0.01611620932817459, 0.13423015177249908, 0.015942830592393875, 0.016049956902861595, 0.11936779320240021, 0.11822327226400375, 0.015860391780734062, 0.08272486180067062, 0.015322391875088215, 0.1002248004078865, 0.2940090000629425, 0.10975096374750137, 0.11110919713973999, 0.26474642753601074, 0.01633298583328724, 0.09071936458349228, 0.017518041655421257, 0.10434141755104065, 0.017996041104197502, 0.1000913605093956, 0.018319152295589447, 0.1214662715792656, 0.09339787065982819, 0.10739514976739883, 0.01836072839796543, 0.0943160206079483, 0.27092039585113525, 0.0185552891343832, 0.018809672445058823, 0.01902345009148121, 0.018886832520365715, 0.09036590903997421, 0.09338919073343277, 0.018705610185861588, 0.01835639774799347, 0.018009040504693985, 0.01767144724726677, 0.09333503246307373, 0.016865963116288185, 0.01653897948563099, 0.10569067299365997, 0.12464043498039246, 0.015368284657597542, 0.014866228215396404, 0.01445876806974411, 0.12489360570907593, 0.013911334797739983, 0.013315118849277496, 0.012816008180379868, 0.31278014183044434, 0.012451335787773132, 0.09592378884553909, 0.12896737456321716, 0.12392863631248474, 0.09775349497795105, 0.012550756335258484, 0.012536035850644112, 0.10110564529895782, 0.1428045630455017, 0.2829451262950897, 0.012870926409959793, 0.013392734341323376, 0.14172674715518951, 0.013767851516604424, 0.11286766827106476, 0.12922360002994537, 0.11795054376125336, 0.1049327626824379, 0.12619613111019135, 0.014490717090666294, 0.014639300294220448, 0.10704391449689865, 0.09974142163991928, 0.11662212014198303, 0.014697057195007801, 0.09514579176902771, 0.10274124890565872, 0.0890708938241005, 0.014760971069335938, 0.10445038974285126, 0.28836768865585327, 0.09469945728778839, 0.0957595705986023, 0.10744720697402954, 0.2861245274543762, 0.01676858216524124, 0.01737286150455475, 0.26941046118736267, 0.10442183166742325, 0.11184094101190567, 0.02003849484026432, 0.2647104859352112, 0.02163843624293804, 0.02228000946342945, 0.022745264694094658, 0.023086752742528915, 0.11271022260189056, 0.11755818128585815, 0.10074307024478912, 0.023655427619814873, 0.023451317101716995, 0.023059029132127762, 0.02270553819835186, 0.2818191945552826, 0.022314341738820076, 0.022204382345080376, 0.021849295124411583, 0.2643203139305115, 0.09803370386362076, 0.11126499623060226, 0.24751967191696167, 0.022559894248843193, 0.0989641398191452, 0.08970453590154648, 0.023248491808772087, 0.10394750535488129, 0.09333138912916183, 0.02341267839074135, 0.023238755762577057, 0.24056237936019897, 0.1236000657081604, 0.10550622642040253, 0.023533793166279793, 0.023403532803058624, 0.09604021906852722, 0.09094496816396713, 0.022714385762810707, 0.022260691970586777, 0.02188469097018242, 0.02142277918756008, 0.09446786344051361, 0.10480121523141861, 0.019886339083313942, 0.019408132880926132, 0.1182563453912735, 0.2682614028453827, 0.09106318652629852, 0.1121823638677597, 0.017921647056937218, 0.1247260570526123, 0.017689639702439308, 0.10219312459230423, 0.09453628212213516, 0.017300736159086227, 0.016917983070015907, 0.10725525766611099, 0.01627909392118454, 0.015955325216054916, 0.01571033149957657, 0.015233508311212063, 0.01486959494650364, 0.11519820988178253, 0.014005666598677635, 0.09996246546506882, 0.013312573544681072, 0.013063603080809116, 0.01250176876783371, 0.11132486164569855, 0.0958864614367485, 0.011655173264443874, 0.011580424383282661, 0.10998667776584625, 0.010863912291824818, 0.12004482001066208, 0.10254447907209396, 0.32743486762046814, 0.3024333119392395, 0.011036193929612637, 0.09086094051599503, 0.012102405540645123, 0.012388566508889198, 0.012793145142495632, 0.012991376221179962, 0.013114742003381252, 0.10479899495840073, 0.11268633604049683, 0.013402792625129223, 0.09471998363733292, 0.09469635039567947, 0.013432587496936321, 0.278502881526947, 0.11539125442504883, 0.10650953650474548, 0.014613249339163303, 0.014861728064715862, 0.015059572644531727, 0.01507094781845808, 0.015021373517811298, 0.10206510126590729, 0.09219910204410553, 0.014844393357634544, 0.10216803103685379, 0.10604019463062286, 0.5381653308868408, 0.09500356018543243, 0.10592490434646606, 0.01715964265167713, 0.01782200299203396, 0.10814888775348663, 0.10900383442640305, 0.01941230148077011, 0.019603611901402473, 0.10426460206508636, 0.01990717276930809, 0.12133380025625229, 0.019556520506739616, 0.019656913354992867, 0.01932622864842415, 0.018887756392359734, 0.018492072820663452, 0.2924371659755707, 0.24312059581279755, 0.10366940498352051, 0.01891900599002838, 0.2835804522037506, 0.019997941330075264, 0.020416120067238808, 0.02078348770737648, 0.021223824471235275, 0.09265679866075516, 0.08331231027841568, 0.020975619554519653, 0.09385304898023605, 0.4633103609085083, 0.02174624800682068, 0.10568515211343765, 0.023627502843737602, 0.023738915100693703, 0.02402842417359352, 0.02435099333524704, 0.024195050820708275, 0.21614891290664673, 0.024190513417124748, 0.024192266166210175, 0.09155264496803284, 0.11112413555383682, 0.02370866946876049, 0.023599613457918167, 0.023097140714526176, 0.022696396335959435, 0.10793486982584, 0.08778073638677597, 0.02097291685640812, 0.11865591257810593, 0.28378164768218994, 0.02003352716565132, 0.25930675864219666, 0.09059320390224457, 0.02043013460934162, 0.020495934411883354, 0.13023409247398376, 0.4356532096862793, 0.021780487149953842, 0.022488463670015335, 0.02285502664744854, 0.023414023220539093, 0.02396083064377308, 0.023542582988739014, 0.1290995180606842, 0.1169658824801445, 0.08866532146930695, 0.02327020652592182, 0.022966714575886726, 0.022592715919017792, 0.09889081120491028, 0.02198098972439766, 0.12768040597438812, 0.020556658506393433, 0.020178940147161484, 0.10316021740436554, 0.0192441213876009, 0.09971654415130615, 0.10900833457708359, 0.10788650065660477, 0.12122924625873566, 0.01707947999238968, 0.09615655243396759, 0.0829060822725296, 0.09615351259708405, 0.263807475566864, 0.015881380066275597, 0.016144264489412308, 0.015962369740009308, 0.12998320162296295, 0.016037167981266975, 0.015779338777065277, 0.11822819709777832, 0.09025740623474121, 0.015214847400784492, 0.01490039937198162, 0.014618190936744213, 0.08535957336425781, 0.12539823353290558, 0.09981220215559006, 0.01400864589959383, 0.013774634338915348, 0.013417770154774189, 0.013232909142971039, 0.09299611300230026, 0.11055898666381836, 0.012545032426714897, 0.012552240863442421, 0.3095278739929199, 0.012338784523308277, 0.012329732067883015, 0.012212426401674747, 0.012351053766906261, 0.01226227730512619, 0.012106193229556084, 0.011866394430398941, 0.08452791720628738, 0.011828763410449028, 0.11650093644857407, 0.011354074813425541, 0.011036423966288567, 0.010959824547171593, 0.010655765421688557, 0.010477598756551743, 0.010213708505034447, 0.3061947524547577, 0.01014556922018528, 0.01018290314823389, 0.12265396118164062, 0.010402967222034931, 0.010117072612047195, 0.28490036725997925, 0.010330182500183582, 0.010663279332220554, 0.010710719972848892, 0.1393723040819168, 0.01104752253741026, 0.011192269623279572, 0.011137613095343113, 0.14015360176563263, 0.011173276230692863, 0.011420628055930138, 0.10765884816646576, 0.010912892408668995, 0.010948790237307549, 0.01076178252696991, 0.3427084982395172, 0.3290712833404541, 0.011558500118553638, 0.011920955032110214, 0.012266472913324833, 0.25919657945632935, 0.013008076697587967, 0.10069255530834198, 0.013988625258207321, 0.2897990643978119, 0.08999339491128922, 0.015874864533543587, 0.01647311821579933, 0.10940060764551163, 0.11186414211988449, 0.09460505843162537, 0.018062029033899307, 0.018256664276123047, 0.11506066471338272, 0.11450149863958359, 0.12915661931037903, 0.11294053494930267, 0.018551817163825035, 0.018460595980286598, 0.10977473855018616, 0.018495498225092888, 0.017962366342544556, 0.017871465533971786, 0.017388228327035904, 0.10168380290269852, 0.016726281493902206, 0.016350429505109787, 0.016364794224500656, 0.271976500749588, 0.311287522315979, 0.015987809747457504, 0.10834269225597382, 0.09034866094589233, 0.01661328598856926, 0.09181243926286697, 0.017091967165470123, 0.01686391793191433, 0.01690061390399933, 0.016748247668147087, 0.08592020720243454, 0.01645267754793167, 0.11771642416715622, 0.11425462365150452, 0.09300138801336288, 0.10097195208072662, 0.11248046904802322, 0.08108211308717728, 0.1065722107887268, 0.015255996957421303, 0.015320511534810066, 0.5174600481987, 0.015748700127005577, 0.09205125272274017, 0.10061302036046982, 0.12570680677890778, 0.09966893494129181, 0.018201716244220734]\n",
            "Val loss 0.07270377443392327\n",
            "Val auc roc 0.5016880486158002\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10c63761fea74ef1b6a8ebfdc7053a87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1717.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0787\n",
            "Train Losses : [0.2507454752922058, 0.019121713936328888, 0.09061744064092636, 0.01990695297718048, 0.02049572765827179, 0.020773379132151604, 0.020410554483532906, 0.02050016261637211, 0.11129073798656464, 0.02003270760178566, 0.10943304002285004, 0.01957905851304531, 0.019667768850922585, 0.01931808516383171, 0.018422968685626984, 0.0866709053516388, 0.017654916271567345, 0.01726691424846649, 0.22633156180381775, 0.11311403661966324, 0.29753822088241577, 0.10128670930862427, 0.017412928864359856, 0.017520686611533165, 0.01786508783698082, 0.01750767230987549, 0.07524310052394867, 0.01792796701192856, 0.017504112794995308, 0.09598109871149063, 0.11234475672245026, 0.01710324175655842, 0.09322730451822281, 0.0976618081331253, 0.015896150842308998, 0.28785020112991333, 0.31675583124160767, 0.01691434532403946, 0.01674792729318142, 0.09983924776315689, 0.2956460416316986, 0.09082471579313278, 0.12527768313884735, 0.0938064306974411, 0.09866367280483246, 0.020099429413676262, 0.092311792075634, 0.020752884447574615, 0.1281120777130127, 0.020424338057637215, 0.021023117005825043, 0.021390652284026146, 0.10622097551822662, 0.12177441269159317, 0.02063165232539177, 0.11442640423774719, 0.019519956782460213, 0.020698534324765205, 0.018492817878723145, 0.018501169979572296, 0.018188195303082466, 0.11509237438440323, 0.11078128218650818, 0.01663099229335785, 0.016374986618757248, 0.016350654885172844, 0.015429669991135597, 0.1014317199587822, 0.014430434443056583, 0.014133088290691376, 0.08113061636686325, 0.013120438903570175, 0.07253848016262054, 0.08139817416667938, 0.13526657223701477, 0.012197275646030903, 0.011991683393716812, 0.011886846274137497, 0.12970924377441406, 0.011432364583015442, 0.13665039837360382, 0.010842536576092243, 0.01050234492868185, 0.010420805774629116, 0.010239474475383759, 0.10684016346931458, 0.0098460977897048, 0.009719526395201683, 0.009298478253185749, 0.11284047365188599, 0.31368952989578247, 0.11259861290454865, 0.009595499373972416, 0.00954399537295103, 0.009775791317224503, 0.009785255417227745, 0.009691978804767132, 0.009653028100728989, 0.009571990929543972, 0.3721233308315277, 0.09893873333930969, 0.01010946836322546, 0.1039055585861206, 0.010467367246747017, 0.10183697938919067, 0.01060583908110857, 0.010777813382446766, 0.010678275488317013, 0.08827853947877884, 0.010742847807705402, 0.09562475979328156, 0.3410782814025879, 0.011036328971385956, 0.011482762172818184, 0.09371317923069, 0.11544745415449142, 0.011938834562897682, 0.012141872197389603, 0.10823522508144379, 0.10023809224367142, 0.11068333685398102, 0.09964248538017273, 0.12731420993804932, 0.012966630049049854, 0.2658842206001282, 0.30310380458831787, 0.1080375611782074, 0.014539750292897224, 0.015052877366542816, 0.015529311262071133, 0.015927106142044067, 0.016468418762087822, 0.3104080855846405, 0.016908658668398857, 0.017434798181056976, 0.017403826117515564, 0.5346462726593018, 0.23962433636188507, 0.02029193378984928, 0.02114136517047882, 0.022072164341807365, 0.09390939027070999, 0.023899931460618973, 0.1092856228351593, 0.024432510137557983, 0.08853693306446075, 0.12867684662342072, 0.02521846443414688, 0.025203172117471695, 0.1051536351442337, 0.08789782971143723, 0.024705009534955025, 0.1289805918931961, 0.09986989945173264, 0.10397960245609283, 0.07881174236536026, 0.4961729347705841, 0.02399601973593235, 0.09479545801877975, 0.02496953494846821, 0.114410400390625, 0.02561180666089058, 0.11080664396286011, 0.02611675299704075, 0.02547278068959713, 0.10826719552278519, 0.02484200894832611, 0.024556277319788933, 0.02388691157102585, 0.023437289521098137, 0.02279503270983696, 0.2569321095943451, 0.02234010025858879, 0.021359827369451523, 0.02136874943971634, 0.10147235542535782, 0.02032340317964554, 0.019701672717928886, 0.01962558552622795, 0.7698547840118408, 0.02007618546485901, 0.02047964744269848, 0.02124783582985401, 0.1264272779226303, 0.021797992289066315, 0.021644407883286476, 0.02153017185628414, 0.022281194105744362, 0.02133481204509735, 0.49687573313713074, 0.289223313331604, 0.022898292168974876, 0.1435116082429886, 0.02452414110302925, 0.08496782928705215, 0.11178827285766602, 0.20423799753189087, 0.026594338938593864, 0.23932914435863495, 0.02755078300833702, 0.09347105771303177, 0.028985003009438515, 0.02908508852124214, 0.0295341107994318, 0.029271908104419708, 0.028835715726017952, 0.10095862299203873, 0.028072532266378403, 0.10158649832010269, 0.02707815170288086, 0.026577169075608253, 0.02579343318939209, 0.10861216485500336, 0.024669788777828217, 0.023743167519569397, 0.1044464260339737, 0.12149744480848312, 0.02178732492029667, 0.021131817251443863, 0.13147473335266113, 0.11199456453323364, 0.09070117771625519, 0.09787041693925858, 0.01871730573475361, 0.26443925499916077, 0.09367994964122772, 0.017850250005722046, 0.018003955483436584, 0.1377570480108261, 0.12014967948198318, 0.0996486097574234, 0.017630666494369507, 0.01708752103149891, 0.2883067727088928, 0.09924741834402084, 0.01703278161585331, 0.1139458566904068, 0.017138883471488953, 0.10614288598299026, 0.09268143028020859, 0.2605536878108978, 0.09954875707626343, 0.10836540162563324, 0.2690213918685913, 0.11924088001251221, 0.48094597458839417, 0.020319566130638123, 0.021414954215288162, 0.022130832076072693, 0.09829410165548325, 0.12077011168003082, 0.0241400059312582, 0.09819769114255905, 0.09884754568338394, 0.1019398644566536, 0.025285247713327408, 0.23188018798828125, 0.025925882160663605, 0.02602735161781311, 0.2431754171848297, 0.02665424533188343, 0.02683861181139946, 0.026814308017492294, 0.43042275309562683, 0.12685376405715942, 0.10105785727500916, 0.09324123710393906, 0.029786020517349243, 0.029913457110524178, 0.03039584867656231, 0.030246296897530556, 0.029845859855413437, 0.10974126309156418, 0.029305651783943176, 0.08671708405017853, 0.028124401345849037, 0.02753870189189911, 0.11887934058904648, 0.0263743307441473, 0.3879639506340027, 0.02606465294957161, 0.02621319703757763, 0.026244815438985825, 0.025850022211670876, 0.025796562433242798, 0.10014288872480392, 0.10974743962287903, 0.024364545941352844, 0.02405596897006035, 0.11026714742183685, 0.023013535887002945, 0.0997408926486969, 0.11393935233354568, 0.021554473787546158, 0.021079741418361664, 0.020626291632652283, 0.020077796652913094, 0.09430105984210968, 0.01891333982348442, 0.01836509257555008, 0.01779579184949398, 0.10635645687580109, 0.01692941226065159, 0.10561827570199966, 0.015955576673150063, 0.01563803292810917, 0.015197709202766418, 0.1247326210141182, 0.10275426506996155, 0.014011030085384846, 0.014053311198949814, 0.013334552757441998, 0.01323046162724495, 0.11445760726928711, 0.01240974385291338, 0.10804272443056107, 0.012054975144565105, 0.011613700538873672, 0.011367562226951122, 0.011066780425608158, 0.01092255488038063, 0.010772853158414364, 0.010327373631298542, 0.10735739767551422, 0.009825336746871471, 0.009614113718271255, 0.009476397186517715, 0.11553481221199036, 0.009294928051531315, 0.00898407306522131, 0.008768360130488873, 0.11280316859483719, 0.33135920763015747, 0.008583571761846542, 0.00863844808191061, 0.09952083230018616, 0.11354177445173264, 0.008930463343858719, 0.1227131113409996, 0.009019157849252224, 0.009113051928579807, 0.11595941334962845, 0.009174574166536331, 0.009296686388552189, 0.09902361035346985, 0.009164392948150635, 0.00920078530907631, 0.6724177598953247, 0.009678373113274574, 0.010042629204690456, 0.3343215882778168, 0.011083888821303844, 0.01173824816942215, 0.10824686288833618, 0.012641883455216885, 0.09463005512952805, 0.11570996791124344, 0.10052517801523209, 0.2894592583179474, 0.25928279757499695, 0.0896991714835167, 0.016445079818367958, 0.017161590978503227, 0.01795915700495243, 0.018431004136800766, 0.018682479858398438, 0.09598459303379059, 0.09833649545907974, 0.01914879120886326, 0.01944183185696602, 0.01930493675172329, 0.08454570174217224, 0.019186057150363922, 0.2594310939311981, 0.019296113401651382, 0.10393935441970825, 0.08633237332105637, 0.14576400816440582, 0.25678375363349915, 0.020068883895874023, 0.02033761888742447, 0.4080638587474823, 0.09065261483192444, 0.022456876933574677, 0.022913474589586258, 0.023058319464325905, 0.15265335142612457, 0.023874863982200623, 0.08539005368947983, 0.11208092421293259, 0.02464667521417141, 0.02390834502875805, 0.02417714148759842, 0.023822054266929626, 0.02316349372267723, 0.022765379399061203, 0.02247839979827404, 0.022315017879009247, 0.021583184599876404, 0.020755261182785034, 0.02040470577776432, 0.13701355457305908, 0.2231856882572174, 0.32074323296546936, 0.01920771226286888, 0.019109545275568962, 0.09540894627571106, 0.01937863789498806, 0.019118692725896835, 0.10057031363248825, 0.018733298406004906, 0.09291186928749084, 0.01809648610651493, 0.018377427011728287, 0.10555241256952286, 0.01745060831308365, 0.11831408739089966, 0.11104121804237366, 0.11272624135017395, 0.016477875411510468, 0.016091246157884598, 0.09798681735992432, 0.01574532315135002, 0.12783488631248474, 0.01526185404509306, 0.08736705780029297, 0.014798544347286224, 0.08106954395771027, 0.014252726919949055, 0.01404416561126709, 0.013784755021333694, 0.013456759043037891, 0.013656415976583958, 0.012931662611663342, 0.11042772978544235, 0.08912421017885208, 0.01236087828874588, 0.09388966858386993, 0.11643167585134506, 0.011796152219176292, 0.08276821672916412, 0.011490794830024242, 0.011258830316364765, 0.11544902622699738, 0.12413264065980911, 0.08083339035511017, 0.09236811846494675, 0.12686339020729065, 0.11479070037603378, 0.09566441178321838, 0.01119956560432911, 0.1424468457698822, 0.10116351395845413, 0.10309842228889465, 0.010937703773379326, 0.011102059856057167, 0.01099021453410387, 0.09080871939659119, 0.010832228697836399, 0.1133820116519928, 0.01081051304936409, 0.010719511657953262, 0.010636743158102036, 0.09265053272247314, 0.010433325543999672, 0.010485837236046791, 0.010289636440575123, 0.11258602142333984, 0.010214785113930702, 0.08423841744661331, 0.11335652321577072, 0.009859596379101276, 0.08322494477033615, 0.00971471518278122, 0.00992585439234972, 0.10741452127695084, 0.3734939992427826, 0.009831087663769722, 0.10807821899652481, 0.010123386979103088, 0.10560765117406845, 0.3031897246837616, 0.14229942858219147, 0.30865707993507385, 0.011736537329852581, 0.11447463184595108, 0.012589664198458195, 0.013095229864120483, 0.0134835010394454, 0.013658304698765278, 0.09714953601360321, 0.014076697640120983, 0.014476608484983444, 0.014372710138559341, 0.32025808095932007, 0.08344896137714386, 0.014953311532735825, 0.015115968883037567, 0.09279801696538925, 0.08849991112947464, 0.015733972191810608, 0.5373632311820984, 0.25660303235054016, 0.017169242724776268, 0.018140964210033417, 0.10737086087465286, 0.01966968923807144, 0.01990392804145813, 0.020588770508766174, 0.020878979936242104, 0.02071150206029415, 0.10997388511896133, 0.021045558154582977, 0.021219031885266304, 0.021129827946424484, 0.020567642524838448, 0.1176745593547821, 0.020078763365745544, 0.0999014601111412, 0.019457241520285606, 0.093675896525383, 0.01931517943739891, 0.1086549460887909, 0.3015236258506775, 0.018252091482281685, 0.018218612298369408, 0.10910164564847946, 0.2717605531215668, 0.2890576124191284, 0.11782825738191605, 0.01931316964328289, 0.02003156766295433, 0.020008385181427002, 0.2568266987800598, 0.1043032705783844, 0.020859336480498314, 0.5262947678565979, 0.022228263318538666, 0.022937500849366188, 0.023655390366911888, 0.2827289402484894, 0.025013789534568787, 0.12192106246948242, 0.11977893114089966, 0.026449138298630714, 0.02680572122335434, 0.11297394335269928, 0.10580621659755707, 0.11100762337446213, 0.09218047559261322, 0.2280605286359787, 0.027743997052311897, 0.13370488584041595, 0.02745242975652218, 0.027299121022224426, 0.22184617817401886, 0.2581844627857208, 0.1146356463432312, 0.028232118114829063, 0.028940904885530472, 0.02843719720840454, 0.09579553455114365, 0.028030838817358017, 0.027938226237893105, 0.10457552224397659, 0.02703918144106865, 0.027102692052721977, 0.02612922526896, 0.10969703644514084, 0.24664978682994843, 0.10227339714765549, 0.10651738941669464, 0.25553637742996216, 0.02490970864892006, 0.09634179621934891, 0.02466835267841816, 0.02446400560438633, 0.024403436109423637, 0.10882050544023514, 0.2584400177001953, 0.10094442963600159, 0.023883333429694176, 0.023814890533685684, 0.02350969798862934, 0.023440605029463768, 0.023292677477002144, 0.10358408838510513, 0.02217608131468296, 0.021899813786149025, 0.10036134719848633, 0.11623944342136383, 0.10053762048482895, 0.02029135823249817, 0.01986279897391796, 0.0195633452385664, 0.019112849608063698, 0.018858348950743675, 0.018284160643815994, 0.01782155968248844, 0.017429644241929054, 0.12073950469493866, 0.016369927674531937, 0.015883898362517357, 0.015535752288997173, 0.015248679555952549, 0.014578431844711304, 0.014259453862905502, 0.013762114569544792, 0.11690730601549149, 0.012995755299925804, 0.012667964212596416, 0.01247814018279314, 0.011984181590378284, 0.1158505231142044, 0.3072870075702667, 0.12396249175071716, 0.3060111105442047, 0.0118877487257123, 0.11029355227947235, 0.012246748432517052, 0.10929792374372482, 0.09663718193769455, 0.012647869996726513, 0.10333504527807236, 0.01281269732862711, 0.012959590181708336, 0.01293752808123827, 0.012906843796372414, 0.1211731806397438, 0.012778133153915405, 0.01285065058618784, 0.012664426118135452, 0.012664028443396091, 0.01240041758865118, 0.1188443973660469, 0.012171206995844841, 0.01198545377701521, 0.30712875723838806, 0.011829289607703686, 0.011890928260982037, 0.28862351179122925, 0.012145482003688812, 0.09130201488733292, 0.2998941242694855, 0.10005597025156021, 0.013387889601290226, 0.10042569786310196, 0.014017830602824688, 0.01415754109621048, 0.10519300401210785, 0.014591814018785954, 0.014819059520959854, 0.11694305390119553, 0.014939566142857075, 0.09790787845849991, 0.01495632529258728, 0.014744044281542301, 0.09664716571569443, 0.014767353422939777, 0.09946597367525101, 0.014483248814940453, 0.014338858425617218, 0.014283437281847, 0.09628979861736298, 0.09470417350530624, 0.01384709868580103, 0.013681236654520035, 0.0996592715382576, 0.013220666907727718, 0.013135982677340508, 0.013023270294070244, 0.11836238950490952, 0.012600192800164223, 0.012427551671862602, 0.012206204235553741, 0.01208450086414814, 0.11273539811372757, 0.011656251735985279, 0.011416529305279255, 0.10934587568044662, 0.1230606734752655, 0.10351455211639404, 0.01089128665626049, 0.3353399634361267, 0.10059197247028351, 0.011060621589422226, 0.09709086269140244, 0.10678350180387497, 0.011414655484259129, 0.09224902838468552, 0.011500388383865356, 0.10458177328109741, 0.3124445378780365, 0.011983560398221016, 0.012116460129618645, 0.012334544211626053, 0.012512655928730965, 0.012568016536533833, 0.012585130520164967, 0.10434053838253021, 0.09079593420028687, 0.10924901068210602, 0.012774022296071053, 0.1055394858121872, 0.2994539737701416, 0.012906776741147041, 0.09156084060668945, 0.11698340624570847, 0.013506026938557625, 0.013663999736309052, 0.013727843761444092, 0.013823745772242546, 0.10111488401889801, 0.013678056187927723, 0.013579937629401684, 0.013698644004762173, 0.013667470775544643, 0.10272134095430374, 0.013278226368129253, 0.01304477546364069, 0.013060817494988441, 0.27670133113861084, 0.11934176832437515, 0.01313022430986166, 0.012933414429426193, 0.013012873940169811, 0.10530639439821243, 0.09567584842443466, 0.013052909635007381, 0.012745923362672329, 0.012740448117256165, 0.6010846495628357, 0.01306841615587473, 0.013570735231041908, 0.013932449743151665, 0.33014872670173645, 0.541080117225647, 0.015669194981455803, 0.01654663495719433, 0.11027657240629196, 0.0990523025393486, 0.09857526421546936, 0.0999678447842598, 0.09471823275089264, 0.021016811951994896, 0.021295910701155663, 0.02160157635807991, 0.021819431334733963, 0.27349853515625, 0.02236803062260151, 0.12459764629602432, 0.2683907747268677, 0.023462004959583282, 0.12899504601955414, 0.28541743755340576, 0.024563902989029884, 0.02489957958459854, 0.025186903774738312, 0.10364143550395966, 0.11731371283531189, 0.025543130934238434, 0.10731729865074158, 0.02547411434352398, 0.24327336251735687, 0.10861005634069443, 0.10255621373653412, 0.025752881541848183, 0.025658434256911278, 0.025544622913002968, 0.11274655908346176, 0.025070615112781525, 0.02497807890176773, 0.09881564229726791, 0.11875413358211517, 0.0956597551703453, 0.023464342579245567, 0.023173237219452858, 0.11731355637311935, 0.2521078884601593, 0.022226233035326004, 0.2620682120323181, 0.022342955693602562, 0.24481859803199768, 0.09063770622015, 0.02284112386405468, 0.10291314125061035, 0.12060575187206268, 0.023253705352544785, 0.12288226932287216, 0.023171214386820793, 0.09160134196281433, 0.022929444909095764, 0.02268865704536438, 0.022514211013913155, 0.022221112623810768, 0.09841537475585938, 0.09523896872997284, 0.021081482991576195, 0.020718446001410484, 0.02037503756582737, 0.020015226677060127, 0.01961953565478325, 0.019100043922662735, 0.11363676190376282, 0.11418566852807999, 0.01796112209558487, 0.12529537081718445, 0.017131442204117775, 0.016853073611855507, 0.10659759491682053, 0.11698595434427261, 0.10764708369970322, 0.015537424944341183, 0.0971921980381012, 0.09143973886966705, 0.30812662839889526, 0.0149513129144907, 0.015086228027939796, 0.015031687915325165, 0.014973105862736702, 0.26716509461402893, 0.0944826751947403, 0.015231568366289139, 0.09146688133478165, 0.015371439047157764, 0.015442882664501667, 0.11001497507095337, 0.11273244768381119, 0.015349811874330044, 0.015243925154209137, 0.08872446417808533, 0.015168797224760056, 0.12129739671945572, 0.014973370358347893, 0.3005223274230957, 0.014867875725030899, 0.0995432436466217, 0.014990030787885189, 0.1025724709033966, 0.015143750235438347, 0.015087328851222992, 0.12278679758310318, 0.01498640701174736, 0.014910043217241764, 0.09715311974287033, 0.09597553312778473, 0.014571667648851871, 0.5662490725517273, 0.11252438277006149, 0.015357495285570621, 0.015746358782052994, 0.015999503433704376, 0.016215750947594643, 0.09404712915420532, 0.1062692329287529, 0.016581619158387184, 0.016712164506316185, 0.08962802588939667, 0.11314655095338821, 0.01699463278055191, 0.10319694876670837, 0.01667485572397709, 0.01656237058341503, 0.016420157626271248, 0.016162432730197906, 0.015987077727913857, 0.015836389735341072, 0.015513683669269085, 0.015368601307272911, 0.01506949681788683, 0.5488349795341492, 0.015044093132019043, 0.015216042287647724, 0.09613929688930511, 0.015617530792951584, 0.10854924470186234, 0.015763113275170326, 0.09727203845977783, 0.015875596553087234, 0.015880214050412178, 0.015871549025177956, 0.10442175716161728, 0.015626447275280952, 0.2720714807510376, 0.26714426279067993, 0.016026023775339127, 0.2627561688423157, 0.01682666875422001, 0.017146814614534378, 0.11390174925327301, 0.01779428869485855, 0.01795411854982376, 0.018124718219041824, 0.09677595645189285, 0.27293992042541504, 0.24371425807476044, 0.10044190287590027, 0.019383808597922325, 0.24039508402347565, 0.020388027653098106, 0.02090046927332878, 0.1089954525232315, 0.10957954078912735, 0.11719629168510437, 0.2532328963279724, 0.11064526438713074, 0.11301928013563156, 0.11334528028964996, 0.10729633271694183, 0.02381232939660549, 0.09277249127626419, 0.023927396163344383, 0.09755058586597443, 0.024254456162452698, 0.023937398567795753, 0.02382638305425644, 0.10022024065256119, 0.12141899019479752, 0.023051219061017036, 0.022727293893694878, 0.022386929020285606, 0.10214691609144211, 0.02186579816043377, 0.021334294229745865, 0.10724402219057083, 0.09144169092178345, 0.2573181390762329, 0.2605455815792084, 0.02030019462108612, 0.10828125476837158, 0.020602555945515633, 0.020536916330456734, 0.1084388941526413, 0.1019652932882309, 0.09819749742746353, 0.25962507724761963, 0.2722006142139435, 0.020901767536997795, 0.09748944640159607, 0.08879125863313675, 0.02193506807088852, 0.11066698282957077, 0.10226554423570633, 0.02231828309595585, 0.022451255470514297, 0.10349314659833908, 0.02233090251684189, 0.022048423066735268, 0.10143342614173889, 0.09374374896287918, 0.22210638225078583, 0.02159569039940834, 0.2372068613767624, 0.10785683989524841, 0.02243446372449398, 0.25695186853408813, 0.10344372689723969, 0.02274371311068535, 0.022861843928694725, 0.23602119088172913, 0.02374296635389328, 0.023505179211497307, 0.0925082117319107, 0.22260819375514984, 0.02411307767033577, 0.02446461096405983, 0.02435486391186714, 0.2448434680700302, 0.11109951883554459, 0.024815289303660393, 0.024847691878676414, 0.09852936863899231, 0.025206200778484344, 0.25270581245422363, 0.02517913281917572, 0.02531682327389717, 0.27936023473739624, 0.02546370029449463, 0.10088396817445755, 0.025533044710755348, 0.025427792221307755, 0.025262506678700447, 0.02530958317220211, 0.024599367752671242, 0.02436610870063305, 0.2730928659439087, 0.2726975381374359, 0.12793360650539398, 0.1062590628862381, 0.0951000526547432, 0.11501654237508774, 0.10303515195846558, 0.024369504302740097, 0.024343019351363182, 0.02441876381635666, 0.024086900055408478, 0.13156811892986298, 0.10404229164123535, 0.09182862937450409, 0.022965827956795692, 0.11305128037929535, 0.10883432626724243, 0.02224801294505596, 0.02202754281461239, 0.09252744168043137, 0.09337035566568375, 0.02092249132692814, 0.02053612284362316, 0.020142067223787308, 0.10018379241228104, 0.09960296750068665, 0.01915333792567253, 0.018878350034356117, 0.0184327345341444, 0.018148085102438927, 0.2680450975894928, 0.10298316925764084, 0.09002465009689331, 0.017364973202347755, 0.017312072217464447, 0.01706874556839466, 0.016866017132997513, 0.01666022092103958, 0.016471372917294502, 0.016158364713191986, 0.016038889065384865, 0.09971187263727188, 0.0152814332395792, 0.015015442855656147, 0.014718293212354183, 0.09576993435621262, 0.014209462329745293, 0.014015793800354004, 0.11024093627929688, 0.01361862849444151, 0.09289927035570145, 0.13130387663841248, 0.012946377508342266, 0.012698742561042309, 0.11117371171712875, 0.012420970015227795, 0.012201042845845222, 0.3137912154197693, 0.012107987888157368, 0.012093503959476948, 0.11001262068748474, 0.012094834819436073, 0.012035076506435871, 0.012050670571625233, 0.011899224482476711, 0.28776776790618896, 0.30226972699165344, 0.012223799712955952, 0.012457523494958878, 0.012671563774347305, 0.10289455205202103, 0.013052769005298615, 0.10948976129293442, 0.013273917138576508, 0.013312269002199173, 0.11274675279855728, 0.2846422791481018, 0.10810568183660507, 0.10723844915628433, 0.014031980186700821, 0.014183854684233665, 0.10385886579751968, 0.09748844057321548, 0.014538406394422054, 0.11743080615997314, 0.11789806932210922, 0.014753018505871296, 0.014851685613393784, 0.014734196476638317, 0.014722378924489021, 0.014650823548436165, 0.014471655711531639, 0.014541436918079853, 0.014155847951769829, 0.11694909632205963, 0.013997577130794525, 0.013626308180391788, 0.09832236915826797, 0.11818709969520569, 0.2746613621711731, 0.013260774314403534, 0.013290895149111748, 0.013365549966692924, 0.01341401506215334, 0.10049846023321152, 0.10421158373355865, 0.013179011642932892, 0.10715053230524063, 0.09873732179403305, 0.10700168460607529, 0.3302472233772278, 0.013356813229620457, 0.2807929515838623, 0.10804634541273117, 0.2721706032752991, 0.10002220422029495, 0.26231488585472107, 0.09523747861385345, 0.016352783888578415, 0.2686806321144104, 0.12075060606002808, 0.01829124428331852, 0.11703035980463028, 0.10088025033473969, 0.019793475046753883, 0.02025141380727291, 0.02048471011221409, 0.020677411928772926, 0.020777685567736626, 0.12024331837892532, 0.1008840873837471, 0.020727787166833878, 0.10467486828565598, 0.02071717008948326, 0.27395114302635193, 0.1081232875585556, 0.09449219703674316, 0.02095820941030979, 0.09142466634511948, 0.10414775460958481, 0.021006429567933083, 0.02083246223628521, 0.09068126231431961, 0.020560452714562416, 0.1010056734085083, 0.110023632645607, 0.49830517172813416, 0.09758242219686508, 0.020943881943821907, 0.10462477058172226, 0.021557077765464783, 0.021775322034955025, 0.09882798045873642, 0.243793785572052, 0.23758627474308014, 0.10651601105928421, 0.11931534111499786, 0.023737037554383278, 0.10013788938522339, 0.10312655568122864, 0.02420598827302456, 0.024249065667390823, 0.024328822270035744, 0.024219965562224388, 0.024135276675224304, 0.023860808461904526, 0.02355760708451271, 0.023380717262625694, 0.11056358367204666, 0.022572804242372513, 0.23919358849525452, 0.09691660851240158, 0.10667041689157486, 0.021916229277849197, 0.021673792973160744, 0.02157791703939438, 0.23321759700775146, 0.11303601413965225, 0.021131116896867752, 0.02101174369454384, 0.020949939265847206, 0.1079486757516861, 0.02062830701470375, 0.020472252741456032, 0.020014330744743347, 0.019943203777074814, 0.2814677059650421, 0.0869651660323143, 0.019512714818120003, 0.019200222566723824, 0.24850478768348694, 0.09482067823410034, 0.2573229968547821, 0.019653063267469406, 0.019948188215494156, 0.11103039979934692, 0.11280665546655655, 0.019946834072470665, 0.02010388672351837, 0.2646469175815582, 0.020265433937311172, 0.02029973454773426, 0.020256318151950836, 0.020259084179997444, 0.020385174080729485, 0.02008850872516632, 0.019821370020508766, 0.019796336069703102, 0.26189902424812317, 0.019458815455436707, 0.019764814525842667, 0.3047972619533539, 0.019427714869379997, 0.10214748978614807, 0.019741181284189224, 0.019505072385072708, 0.11119741946458817, 0.019473755732178688, 0.10087618231773376, 0.506951093673706, 0.019532129168510437, 0.019894102588295937, 0.020717371255159378, 0.24837210774421692, 0.021000295877456665, 0.0210732314735651, 0.11783836781978607, 0.021414339542388916, 0.27929702401161194, 0.261157363653183, 0.022235311567783356, 0.02290329895913601, 0.2770097255706787, 0.023539014160633087, 0.023859715089201927, 0.02431171014904976, 0.10236447304487228, 0.024395272135734558, 0.024433625862002373, 0.09735485911369324, 0.4442782998085022, 0.09540785104036331, 0.2700273096561432, 0.09176349639892578, 0.02681935764849186, 0.02733241207897663, 0.09603410214185715, 0.11483585834503174, 0.09401710331439972, 0.10189778357744217, 0.02843228541314602, 0.11098809540271759, 0.10391685366630554, 0.02833564579486847, 0.11870116740465164, 0.2536402642726898, 0.1019415631890297, 0.0978190079331398, 0.028528062626719475, 0.09352773427963257, 0.028225712478160858, 0.10266883671283722, 0.11049078404903412, 0.12433170527219772, 0.21828728914260864, 0.027452033013105392, 0.11988706141710281, 0.26749497652053833, 0.09545990079641342, 0.0924619734287262, 0.09849794209003448, 0.027896922081708908, 0.0977056473493576, 0.027550728991627693, 0.027469094842672348, 0.11275126039981842, 0.0270273108035326, 0.026723293587565422, 0.10800787806510925, 0.09342795610427856, 0.10522458702325821, 0.09953093528747559, 0.025085004046559334, 0.02475568652153015, 0.024395452812314034, 0.02427397482097149, 0.10835301876068115, 0.02307467721402645, 0.2456628680229187, 0.022566985338926315, 0.022387098520994186, 0.26254189014434814, 0.022015348076820374, 0.02204705774784088, 0.0922842025756836, 0.02162708342075348, 0.25448358058929443, 0.02174149453639984, 0.2578697204589844, 0.26858824491500854, 0.24277974665164948, 0.0994281992316246, 0.023121874779462814, 0.23335902392864227, 0.09713561087846756, 0.4665549099445343, 0.02557612769305706, 0.02667052671313286, 0.027192946523427963, 0.02770937606692314, 0.028196271508932114, 0.028628498315811157, 0.11131254583597183, 0.028804779052734375, 0.028702011331915855, 0.11443369090557098, 0.09322948008775711, 0.22460982203483582, 0.12198717147111893, 0.028649961575865746, 0.028631938621401787, 0.09092077612876892, 0.0284439530223608, 0.02810887061059475, 0.02771967276930809, 0.027414854615926743, 0.02707217074930668, 0.1030171811580658, 0.2432311773300171, 0.02597651071846485, 0.025678370147943497, 0.02549034170806408, 0.025158146396279335, 0.024782422930002213, 0.25141721963882446, 0.024271434172987938, 0.023951275274157524, 0.08271549642086029, 0.10735443234443665, 0.02320050820708275, 0.23507831990718842, 0.023030752316117287, 0.09573409706354141, 0.022644616663455963, 0.09624137729406357, 0.022542884573340416, 0.022146690636873245, 0.022240612655878067, 0.23426133394241333, 0.021477265283465385, 0.02170957252383232, 0.12134154140949249, 0.10568905621767044, 0.08773195743560791, 0.11215652525424957, 0.26465070247650146, 0.02111600711941719, 0.02095634676516056, 0.020883094519376755, 0.02068585902452469, 0.02075332961976528, 0.02046716772019863, 0.24604833126068115, 0.02020733430981636, 0.10241342335939407, 0.020097076892852783, 0.02015380933880806, 0.14340956509113312, 0.13023053109645844, 0.019525879994034767, 0.019355421885848045, 0.09887737035751343, 0.2716172933578491, 0.13473650813102722, 0.01912686973810196, 0.01927078515291214, 0.019383549690246582, 0.1276366412639618, 0.1014629453420639, 0.01884620077908039, 0.018829450011253357, 0.018570443615317345, 0.018249165266752243, 0.018110720440745354, 0.017994096502661705, 0.017496300861239433, 0.09124386310577393, 0.01717223785817623, 0.016903895884752274, 0.10539093613624573, 0.09087416529655457, 0.10048169642686844, 0.10911761224269867, 0.11090096086263657, 0.10699618607759476, 0.015585663728415966, 0.10832053422927856, 0.015382611192762852, 0.01529708318412304, 0.014874691143631935, 0.13388638198375702, 0.10371202230453491, 0.014463898725807667, 0.014361590147018433, 0.11519409716129303, 0.12003092467784882, 0.013928567059338093, 0.103518545627594, 0.10778571665287018, 0.013653291389346123, 0.10453122854232788, 0.289257287979126, 0.013492596335709095, 0.3078131079673767, 0.01396891474723816, 0.10013657808303833, 0.014327200129628181, 0.10619764775037766, 0.014513787813484669, 0.014515848830342293, 0.097271628677845, 0.014641187153756618, 0.1124543696641922, 0.01467165257781744, 0.01461066398769617, 0.014565017074346542, 0.014703840017318726, 0.014607365243136883, 0.31028375029563904, 0.10980171710252762, 0.014440510421991348, 0.10856182128190994, 0.014537063427269459, 0.09211979806423187, 0.014508419670164585, 0.3119635581970215, 0.014709687791764736, 0.014762021601200104, 0.014914849773049355, 0.015058736316859722, 0.1178472489118576, 0.12389244884252548, 0.014955086633563042, 0.12370353192090988, 0.300260454416275, 0.10353279858827591, 0.01521674171090126, 0.015400019474327564, 0.10400316119194031, 0.015477517619729042, 0.015529436059296131, 0.3101395070552826, 0.11521798372268677, 0.015867792069911957, 0.10639830678701401, 0.0161223653703928, 0.0161651112139225, 0.01613137312233448, 0.01608629710972309, 0.016137022525072098, 0.016068115830421448, 0.01596599444746971, 0.1051480695605278, 0.11378645151853561, 0.015534100122749805, 0.11551713943481445, 0.015366941690444946, 0.2760049104690552, 0.015191728249192238, 0.01522514782845974, 0.01519039086997509, 0.2781780958175659, 0.015451585873961449, 0.015375832095742226, 0.015426362864673138, 0.0941222608089447, 0.015520896762609482, 0.10779808461666107, 0.0955367237329483, 0.01540802139788866, 0.10201618075370789, 0.11454015225172043, 0.09383954852819443, 0.09720288217067719, 0.12028496712446213, 0.015244383364915848, 0.015255770646035671, 0.11052168160676956, 0.27496856451034546, 0.2868082821369171, 0.015532330609858036, 0.11142133176326752, 0.3012893497943878, 0.26078301668167114, 0.1098155677318573, 0.01745239645242691, 0.10774727165699005, 0.10434252768754959, 0.018598131835460663, 0.018992748111486435, 0.01914774440228939, 0.11260508745908737, 0.019401544705033302, 0.019455228000879288, 0.019428696483373642, 0.019524576142430305, 0.0193171426653862, 0.019240090623497963, 0.01905309222638607, 0.27638304233551025, 0.27969011664390564, 0.09815556555986404, 0.09869910776615143, 0.26220130920410156, 0.01979660801589489, 0.020021911710500717, 0.020234618335962296, 0.020354896783828735, 0.020397096872329712, 0.10704293102025986, 0.02043200097978115, 0.020327046513557434, 0.020226536318659782, 0.020099928602576256, 0.019932134076952934, 0.01975017786026001, 0.01950632967054844, 0.01920163258910179, 0.01892978698015213, 0.018707294017076492, 0.018324965611100197, 0.018025537952780724, 0.1097772940993309, 0.25811824202537537, 0.10474754124879837, 0.017361458390951157, 0.11169595271348953, 0.017136266455054283, 0.1180289164185524, 0.017035266384482384, 0.11455249041318893, 0.10902788490056992, 0.01652299426496029, 0.11120952665805817, 0.8146376609802246, 0.016804808750748634, 0.0995597168803215, 0.09865658730268478, 0.017993628978729248, 0.018278541043400764, 0.2705000340938568, 0.018948480486869812, 0.10345987230539322, 0.01949647255241871, 0.11449109762907028, 0.019903019070625305, 0.019998153671622276, 0.020052891224622726, 0.10316190123558044, 0.020054664462804794, 0.020002756267786026, 0.019869375973939896, 0.019814560189843178, 0.019713152199983597, 0.019409002736210823, 0.10659720003604889, 0.09717059135437012, 0.10508664697408676, 0.018619969487190247, 0.0947868749499321, 0.01841072551906109, 0.018070954829454422, 0.017926927655935287, 0.2627471387386322, 0.10535331070423126, 0.09743916243314743, 0.01767125353217125, 0.26630932092666626, 0.017630022019147873, 0.09258956462144852, 0.017748676240444183, 0.017813928425312042, 0.01778256706893444, 0.10568618029356003, 0.017635071650147438, 0.017576660960912704, 0.01751289702951908, 0.01731361262500286, 0.2611023187637329, 0.01720493845641613, 0.10230675339698792, 0.017140425741672516, 0.10859081894159317, 0.017115550115704536, 0.10212952643632889, 0.016940360888838768, 0.016768211498856544, 0.2770752012729645, 0.2543950080871582, 0.09634488821029663, 0.01729765348136425, 0.017317580059170723, 0.017401715740561485, 0.017444511875510216, 0.10070934146642685, 0.01746772974729538, 0.017405755817890167, 0.09825130552053452, 0.09717439115047455, 0.10866975784301758, 0.09841501712799072, 0.017143480479717255, 0.10855723917484283, 0.30304649472236633, 0.01714751124382019, 0.24927769601345062, 0.09464940428733826, 0.2823617458343506, 0.018145952373743057, 0.11064624041318893, 0.018527105450630188, 0.25856223702430725, 0.019187036901712418, 0.12044603377580643, 0.01962132938206196, 0.01991213671863079, 0.019919730722904205, 0.02001495659351349, 0.10682463645935059, 0.020150594413280487, 0.019989049062132835, 0.019815025851130486, 0.2412116378545761, 0.019976036623120308, 0.019887499511241913, 0.019737817347049713, 0.019744830206036568, 0.01947406865656376, 0.019468707963824272, 0.01933322660624981, 0.018993733450770378, 0.018876517191529274, 0.09928961843252182, 0.018344419077038765, 0.01809322088956833, 0.017767736688256264, 0.017495758831501007, 0.017279036343097687, 0.10262725502252579, 0.016737530007958412, 0.01648683100938797, 0.016276273876428604, 0.312247097492218, 0.30202236771583557, 0.016036342829465866, 0.016132060438394547, 0.11246754229068756, 0.10792170464992523, 0.10082503408193588, 0.016350414603948593, 0.016310639679431915, 0.11040692031383514, 0.01612340845167637, 0.016026949509978294, 0.015969187021255493, 0.09855322539806366, 0.015800658613443375, 0.015679599717259407, 0.10098414868116379, 0.10869834572076797, 0.015300331637263298, 0.015228387899696827, 0.08654662221670151, 0.2958749532699585, 0.2887106239795685, 0.24901261925697327, 0.01555953174829483, 0.015910323709249496, 0.016145944595336914, 0.016325704753398895, 0.01638183370232582, 0.1148214340209961, 0.016466660425066948, 0.09634546935558319, 0.016677966341376305, 0.26606953144073486, 0.09946629405021667, 0.10984503477811813, 0.1150444820523262, 0.017116844654083252, 0.10653004050254822, 0.017202487215399742, 0.11226630955934525, 0.017373165115714073, 0.01740855909883976, 0.017239278182387352, 0.2800023853778839, 0.2522509694099426, 0.11752863973379135, 0.017672942951321602, 0.08994311839342117, 0.018008984625339508, 0.0950566902756691, 0.018244827166199684, 0.08845878392457962, 0.1003650426864624, 0.01833922043442726, 0.018392475321888924, 0.01827900856733322, 0.09474586695432663, 0.11354295164346695, 0.0180185716599226, 0.017902469262480736, 0.10545054823160172, 0.1222246065735817, 0.09157410264015198, 0.09667767584323883, 0.01734902709722519, 0.01728738658130169, 0.10529009997844696, 0.017055001109838486, 0.016968145966529846, 0.016818564385175705, 0.09654886275529861, 0.016413945704698563, 0.016185300424695015, 0.11969151347875595, 0.015899566933512688, 0.2678541839122772, 0.015705453231930733, 0.10267219692468643, 0.01564784161746502]\n",
            "Val loss 0.07369164826754106\n",
            "Val auc roc 0.4996147463252726\n",
            "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     2: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "224c194f55f44836b6e002dac5a28f94",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1717.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0760\n",
            "Train Losses : [0.2602565586566925, 0.10647918283939362, 0.01568153128027916, 0.11488202214241028, 0.1065339595079422, 0.01565990224480629, 0.10385145992040634, 0.015743862837553024, 0.0858793780207634, 0.01570482924580574, 0.09057165682315826, 0.015669619664549828, 0.11507054418325424, 0.015711411833763123, 0.0156778022646904, 0.10920888185501099, 0.1103157326579094, 0.09938283264636993, 0.01567263901233673, 0.015629956498742104, 0.015602700412273407, 0.09504681825637817, 0.10012470930814743, 0.015590635128319263, 0.09496685862541199, 0.015498937107622623, 0.27633094787597656, 0.11093797534704208, 0.27808111906051636, 0.015615073963999748, 0.2567373812198639, 0.01560491044074297, 0.015674103051424026, 0.015733659267425537, 0.015717292204499245, 0.3051690459251404, 0.10722573101520538, 0.1233469620347023, 0.11057856678962708, 0.09904404729604721, 0.015869108960032463, 0.015737738460302353, 0.01577952690422535, 0.1113889217376709, 0.10587465763092041, 0.015818409621715546, 0.015775954350829124, 0.01593722775578499, 0.09432072937488556, 0.0955631285905838, 0.015758413821458817, 0.015736062079668045, 0.5418273210525513, 0.11105488985776901, 0.1104944571852684, 0.015833796933293343, 0.27764230966567993, 0.09723483771085739, 0.015961138531565666, 0.10023100674152374, 0.01616186648607254, 0.01598653569817543, 0.016017161309719086, 0.11384457349777222, 0.016048617660999298, 0.1062547042965889, 0.09662236273288727, 0.01617877371609211, 0.015982158482074738, 0.09035156667232513, 0.10908135771751404, 0.10775286704301834, 0.016031786799430847, 0.10477874428033829, 0.2709757685661316, 0.10398490726947784, 0.016050802543759346, 0.09578882902860641, 0.016045168042182922, 0.30720633268356323, 0.10995212197303772, 0.09879646450281143, 0.1080225482583046, 0.11351794749498367, 0.1035289466381073, 0.0991181805729866, 0.09646071493625641, 0.09233422577381134, 0.0985579639673233, 0.09406109899282455, 0.10926910489797592, 0.2917996942996979, 0.016264740377664566, 0.01636451482772827, 0.27177661657333374, 0.09140156954526901, 0.016365494579076767, 0.09659381955862045, 0.01628130115568638, 0.11370642483234406, 0.016334449872374535, 0.10983182489871979, 0.2680472433567047, 0.28823593258857727, 0.01644633337855339, 0.01643315516412258, 0.11180853843688965, 0.016479037702083588, 0.3046477138996124, 0.016543183475732803, 0.01661437563598156, 0.11368794739246368, 0.016557414084672928, 0.01661134511232376, 0.016547374427318573, 0.1153821349143982, 0.016563227400183678, 0.12232136726379395, 0.2636233866214752, 0.0987529456615448, 0.10619577020406723, 0.09775199741125107, 0.016673145815730095, 0.01667187735438347, 0.10965874046087265, 0.11265568435192108, 0.27233919501304626, 0.09398958832025528, 0.10836881399154663, 0.016720090061426163, 0.10648351162672043, 0.01679932326078415, 0.01680784299969673, 0.016854487359523773, 0.016778191551566124, 0.016776343807578087, 0.09220178425312042, 0.016741197556257248, 0.1031893640756607, 0.016725944355130196, 0.01676686480641365, 0.10423951596021652, 0.016646120697259903, 0.016699258238077164, 0.12299680709838867, 0.10859764367341995, 0.2628212571144104, 0.0166309904307127, 0.27134308218955994, 0.09439820051193237, 0.10556478798389435, 0.283251017332077, 0.016664711758494377, 0.016706855967640877, 0.01673598401248455, 0.23684003949165344, 0.016731444746255875, 0.016898570582270622, 0.016919679939746857, 0.01678769662976265, 0.10365819931030273, 0.016830522567033768, 0.11778852343559265, 0.016902973875403404, 0.01683182455599308, 0.10499854385852814, 0.01690743677318096, 0.016811564564704895, 0.10474555194377899, 0.01684727892279625, 0.11434292048215866, 0.08689720183610916, 0.01689220406115055, 0.10230736434459686, 0.01689879223704338, 0.09121542423963547, 0.09817792475223541, 0.016673700883984566, 0.01682176999747753, 0.106756791472435, 0.09824605286121368, 0.016618676483631134, 0.01665598526597023, 0.09265600889921188, 0.016767874360084534, 0.01657859981060028, 0.016607262194156647, 0.016678282991051674, 0.016532113775610924, 0.016627095639705658, 0.016562944278120995, 0.09898275136947632, 0.01661618985235691, 0.01645655557513237, 0.01642671413719654, 0.10270477831363678, 0.01639089733362198, 0.0957011952996254, 0.016379250213503838, 0.105605848133564, 0.016412686556577682, 0.11196921765804291, 0.01626935787498951, 0.01631462387740612, 0.016218332573771477, 0.10998503118753433, 0.016229331493377686, 0.0932847186923027, 0.01617748849093914, 0.11791132390499115, 0.10130120813846588, 0.0988457053899765, 0.016101257875561714, 0.01607212983071804, 0.016050264239311218, 0.01604223996400833, 0.3104398250579834, 0.016099190339446068, 0.27671822905540466, 0.11420567333698273, 0.10172700881958008, 0.01618967577815056, 0.016077661886811256, 0.10236071050167084, 0.016183311119675636, 0.0161091648042202, 0.01617911271750927, 0.10489368438720703, 0.09936157613992691, 0.01606089621782303, 0.01602271758019924, 0.016286326572299004, 0.10336777567863464, 0.28794771432876587, 0.01602603867650032, 0.01607002690434456, 0.26244819164276123, 0.016107821837067604, 0.0160675011575222, 0.11270677298307419, 0.27435216307640076, 0.016088906675577164, 0.01615544967353344, 0.10508309304714203, 0.016085440292954445, 0.10209707170724869, 0.1036783829331398, 0.10531101375818253, 0.016105178743600845, 0.10867723077535629, 0.016208499670028687, 0.016196027398109436, 0.08912526816129684, 0.016115717589855194, 0.016118226572871208, 0.01614064909517765, 0.5087670087814331, 0.11643945425748825, 0.01621789112687111, 0.01620764099061489, 0.11362922191619873, 0.016382304951548576, 0.10121641308069229, 0.08570346236228943, 0.11061833798885345, 0.016275113448500633, 0.09495566040277481, 0.10993988811969757, 0.10854929685592651, 0.016210956498980522, 0.10103947669267654, 0.2986055910587311, 0.016292491927742958, 0.016295360401272774, 0.11302539706230164, 0.016275959089398384, 0.016322899609804153, 0.12283660471439362, 0.016244390979409218, 0.11784862726926804, 0.09481285512447357, 0.016386985778808594, 0.11762724071741104, 0.1218128651380539, 0.10660083591938019, 0.12510833144187927, 0.016255199909210205, 0.1125217080116272, 0.10018867254257202, 0.26822882890701294, 0.10270373523235321, 0.10174331068992615, 0.30178794264793396, 0.016328983008861542, 0.10822982341051102, 0.01636902615427971, 0.25053584575653076, 0.10232049971818924, 0.01640360988676548, 0.0986967459321022, 0.016410009935498238, 0.10882813483476639, 0.016416918486356735, 0.016417549923062325, 0.537039577960968, 0.016473308205604553, 0.016466151922941208, 0.01655261404812336, 0.016522927209734917, 0.01656421273946762, 0.016653062775731087, 0.13018935918807983, 0.016569416970014572, 0.01659179851412773, 0.0165729820728302, 0.11134468764066696, 0.28701072931289673, 0.016576284542679787, 0.016564330086112022, 0.10385195165872574, 0.016636915504932404, 0.016613466665148735, 0.016591990366578102, 0.11955827474594116, 0.11505863070487976, 0.016519594937562943, 0.016558563336730003, 0.09696625173091888, 0.01660672388970852, 0.016587374731898308, 0.3051782250404358, 0.016529690474271774, 0.5200119614601135, 0.016632387414574623, 0.016746455803513527, 0.5070021152496338, 0.28223225474357605, 0.016711048781871796, 0.01678062230348587, 0.2880781888961792, 0.10829157382249832, 0.016905948519706726, 0.016994306817650795, 0.01702163927257061, 0.017015043646097183, 0.10856981575489044, 0.017120128497481346, 0.10142325609922409, 0.09583839029073715, 0.01708288863301277, 0.017100172117352486, 0.01707851141691208, 0.27182862162590027, 0.017193036153912544, 0.10327115654945374, 0.10468841344118118, 0.01716623269021511, 0.017243726179003716, 0.09387766569852829, 0.11149340122938156, 0.017229750752449036, 0.017131604254245758, 0.01712067797780037, 0.01710032857954502, 0.017139237374067307, 0.017300434410572052, 0.017089733853936195, 0.08494704216718674, 0.1066388264298439, 0.01719353348016739, 0.017131080850958824, 0.017201801761984825, 0.09670038521289825, 0.01701994240283966, 0.01703864336013794, 0.11008158326148987, 0.09483974426984787, 0.11145756393671036, 0.01693899556994438, 0.10356593132019043, 0.016964484006166458, 0.016945049166679382, 0.01687994971871376, 0.10452479869127274, 0.01687919721007347, 0.01693868078291416, 0.10438724607229233, 0.016784537583589554, 0.10495522618293762, 0.28778669238090515, 0.10035543888807297, 0.016753744333982468, 0.1113923192024231, 0.11879494041204453, 0.09616917371749878, 0.01684625633060932, 0.01686433143913746, 0.09890390932559967, 0.01674722507596016, 0.11511513590812683, 0.01687104068696499, 0.016817482188344002, 0.016746195033192635, 0.1056298241019249, 0.016686338931322098, 0.01675320230424404, 0.10841722786426544, 0.11122174561023712, 0.11581981927156448, 0.016708189621567726, 0.016708627343177795, 0.10464829951524734, 0.26215311884880066, 0.11046527326107025, 0.0937432199716568, 0.10295487195253372, 0.10538679361343384, 0.01665612868964672, 0.09043125063180923, 0.10183371603488922, 0.016614003106951714, 0.11798369884490967, 0.25091904401779175, 0.01677992008626461, 0.12025599926710129, 0.01667754352092743, 0.11331099271774292, 0.016653845086693764, 0.01663510501384735, 0.09550431370735168, 0.09731137007474899, 0.01667986437678337, 0.01665947586297989, 0.016670027747750282, 0.08552365005016327, 0.01661040261387825, 0.016639219596982002, 0.11393946409225464, 0.016656305640935898, 0.01656271517276764, 0.016565851867198944, 0.016518807038664818, 0.01658214069902897, 0.016477180644869804, 0.016490129753947258, 0.25834888219833374, 0.016537882387638092, 0.0983065813779831, 0.016462218016386032, 0.016432644799351692, 0.11899308115243912, 0.10911799967288971, 0.11247795820236206, 0.106984943151474, 0.01652919128537178, 0.016498683020472527, 0.01652020961046219, 0.0164254829287529, 0.01636398211121559, 0.01644490286707878, 0.09677708148956299, 0.10769806802272797, 0.01639917865395546, 0.016343992203474045, 0.016299817711114883, 0.01628958433866501, 0.01629815623164177, 0.25647714734077454, 0.016273772343993187, 0.10271190106868744, 0.016228841617703438, 0.016264839097857475, 0.09641473740339279, 0.01631283015012741, 0.016255967319011688, 0.11385688185691833, 0.016240321099758148, 0.016177363693714142, 0.01625743694603443, 0.016132492572069168, 0.01617537997663021, 0.016174588352441788, 0.11556108295917511, 0.09262988716363907, 0.016095584258437157, 0.10619944334030151, 0.01621769182384014, 0.016108926385641098, 0.01613420806825161, 0.01599115878343582, 0.29786184430122375, 0.11382006853818893, 0.1061789020895958, 0.10958892852067947, 0.1237725019454956, 0.09861594438552856, 0.11716442555189133, 0.0981069877743721, 0.01610906608402729, 0.016036005690693855, 0.016004478558897972, 0.016029486432671547, 0.01603885553777218, 0.3011120855808258, 0.09921357035636902, 0.015991970896720886, 0.10192203521728516, 0.015951713547110558, 0.2620924711227417, 0.2793159484863281, 0.016024276614189148, 0.016048092395067215, 0.016176274046301842, 0.10684291273355484, 0.25540217757225037, 0.016052519902586937, 0.01619667001068592, 0.016126930713653564, 0.0943836122751236, 0.016136620193719864, 0.09703529626131058, 0.11625642329454422, 0.1121620163321495, 0.10584083199501038, 0.016139868646860123, 0.016213737428188324, 0.016121942549943924, 0.29751214385032654, 0.11280575394630432, 0.1128549724817276, 0.2511340081691742, 0.2656838297843933, 0.2602812945842743, 0.10008884221315384, 0.11329676955938339, 0.10331447422504425, 0.01629810221493244, 0.016355976462364197, 0.016448387876152992, 0.10272124409675598, 0.01649589277803898, 0.10862885415554047, 0.5205251574516296, 0.016538431867957115, 0.27260786294937134, 0.016486985608935356, 0.2856599986553192, 0.016667643561959267, 0.01665615290403366, 0.10853435844182968, 0.016866464167833328, 0.016658231616020203, 0.016798293218016624, 0.016719592735171318, 0.016677582636475563, 0.28745031356811523, 0.09663531184196472, 0.09906274825334549, 0.01683984138071537, 0.016740892082452774, 0.01689380221068859, 0.2605031728744507, 0.09057868272066116, 0.1108417734503746, 0.2762124836444855, 0.01695532165467739, 0.016984807327389717, 0.01690644957125187, 0.11626825481653214, 0.016878511756658554, 0.11420603841543198, 0.016886863857507706, 0.016899891197681427, 0.11508278548717499, 0.016891470178961754, 0.11040081083774567, 0.2760380208492279, 0.017098957672715187, 0.016962364315986633, 0.09099801629781723, 0.016965806484222412, 0.10550510883331299, 0.01687713712453842, 0.11274471879005432, 0.1096026599407196, 0.10902298986911774, 0.016906050965189934, 0.016906285658478737, 0.016878405585885048, 0.11869794130325317, 0.016888057813048363, 0.29061466455459595, 0.016906721517443657, 0.1014104038476944, 0.10130418092012405, 0.10069378465414047, 0.016831789165735245, 0.1195150837302208, 0.10788358002901077, 0.09907428920269012, 0.016860784962773323, 0.01683942787349224, 0.10840614140033722, 0.11191803961992264, 0.016930660232901573, 0.016899991780519485, 0.10229123383760452, 0.01693013310432434, 0.016894694417715073, 0.11075764894485474, 0.016861315816640854, 0.016807381063699722, 0.29098522663116455, 0.016801418736577034, 0.11092811822891235, 0.01678212359547615, 0.016916165128350258, 0.0167824849486351, 0.0880180224776268, 0.09074211865663528, 0.10860013216733932, 0.01674298755824566, 0.01683022454380989, 0.10860844701528549, 0.08967338502407074, 0.1071048229932785, 0.016858674585819244, 0.016701724380254745, 0.10059637576341629, 0.016707804054021835, 0.09988037496805191, 0.08727984130382538, 0.12180789560079575, 0.10935617983341217, 0.09091584384441376, 0.016658013686537743, 0.01672419346868992, 0.016664445400238037, 0.10442067682743073, 0.09875257313251495, 0.016590969637036324, 0.01658821851015091, 0.0945417508482933, 0.016612157225608826, 0.1060771569609642, 0.2634223997592926, 0.016641516238451004, 0.28100094199180603, 0.10710951685905457, 0.016603920608758926, 0.10751041769981384, 0.25214144587516785, 0.09060262888669968, 0.016609733924269676, 0.01674228347837925, 0.11115466803312302, 0.016648737713694572, 0.016659514978528023, 0.016634991392493248, 0.01681842841207981, 0.016820531338453293, 0.10053145885467529, 0.016687987372279167, 0.11760979890823364, 0.016645891591906548, 0.016670992597937584, 0.11564315110445023, 0.016626738011837006, 0.016608377918601036, 0.016647635027766228, 0.11016660183668137, 0.09922384470701218, 0.01653205044567585, 0.10590218007564545, 0.016569124534726143, 0.2727107107639313, 0.26905325055122375, 0.2770453691482544, 0.11159972846508026, 0.10594512522220612, 0.11478384584188461, 0.10046859830617905, 0.09779184311628342, 0.0166450347751379, 0.01668027974665165, 0.016635466367006302, 0.09244334697723389, 0.016795145347714424, 0.01663784869015217, 0.09842925518751144, 0.016636529937386513, 0.016650279983878136, 0.016662366688251495, 0.28614750504493713, 0.016654163599014282, 0.016688473522663116, 0.10817895829677582, 0.016821540892124176, 0.11592426896095276, 0.01664295606315136, 0.10942759364843369, 0.016652163118124008, 0.01662086881697178, 0.09059662371873856, 0.016669029369950294, 0.11860601603984833, 0.016652347519993782, 0.016680972650647163, 0.10063614696264267, 0.016559138894081116, 0.016604522243142128, 0.016549963504076004, 0.016560224816203117, 0.01651107333600521, 0.01650116965174675, 0.11020436882972717, 0.01650681532919407, 0.09993133693933487, 0.10048734396696091, 0.016480984166264534, 0.016463516280055046, 0.016546504572033882, 0.016429457813501358, 0.016408951953053474, 0.016385717317461967, 0.016358166933059692, 0.01643536612391472, 0.016473306342959404, 0.10961232334375381, 0.016354363411664963, 0.016282184049487114, 0.0162617489695549, 0.31713664531707764, 0.01631150022149086, 0.10329098999500275, 0.01623653434216976, 0.09652041643857956, 0.01626076176762581, 0.01620969921350479, 0.1028510257601738, 0.11522385478019714, 0.016238782554864883, 0.1135152205824852, 0.016171107068657875, 0.016268033534288406, 0.0163065604865551, 0.01619667001068592, 0.016231046989560127, 0.01615520939230919, 0.016123052686452866, 0.016092948615550995, 0.09370214492082596, 0.10144592076539993, 0.016166241839528084, 0.09540136158466339, 0.016131160780787468, 0.016062982380390167, 0.27691105008125305, 0.2603951692581177, 0.11082802712917328, 0.016042763367295265, 0.11825871467590332, 0.016141686588525772, 0.01605953462421894, 0.016132954508066177, 0.01604296639561653, 0.0973832830786705, 0.01611516997218132, 0.016098713502287865, 0.10247909277677536, 0.09620939195156097, 0.016043750569224358, 0.01605898328125477, 0.08765619248151779, 0.01605946011841297, 0.0160647202283144, 0.016072798520326614, 0.01596715673804283, 0.016030186787247658, 0.015995796769857407, 0.01594608649611473, 0.01606985181570053, 0.09617076069116592, 0.09325306117534637, 0.11441240459680557, 0.11343863606452942, 0.11281973123550415, 0.015912162140011787, 0.016048738732933998, 0.1154942587018013, 0.09718632698059082, 0.0159626305103302, 0.015896525233983994, 0.5085129141807556, 0.015845121815800667, 0.015913020819425583, 0.01593160815536976, 0.10525238513946533, 0.015871722251176834, 0.01587981916964054, 0.11024641245603561, 0.015867214649915695, 0.015979215502738953, 0.09824544936418533, 0.015981685370206833, 0.01586824283003807, 0.015888158231973648, 0.10214771330356598, 0.10854993015527725, 0.01597677357494831, 0.015830915421247482, 0.016010120511054993, 0.28052136301994324, 0.11607614904642105, 0.015821287408471107, 0.01583716832101345, 0.09771548211574554, 0.01588950864970684, 0.09941272437572479, 0.015870731323957443, 0.01585308648645878, 0.01587723195552826, 0.2536362111568451, 0.015875667333602905, 0.0158404391258955, 0.015856947749853134, 0.015852421522140503, 0.10397155582904816, 0.27955588698387146, 0.10835693031549454, 0.016006164252758026, 0.10500247031450272, 0.015871837735176086, 0.015833603218197823, 0.11098146438598633, 0.10318737477064133, 0.015906034037470818, 0.015874290838837624, 0.015934068709611893, 0.09610478579998016, 0.015832923352718353, 0.015849744901061058, 0.11648956686258316, 0.2897440195083618, 0.10569461435079575, 0.015786781907081604, 0.01582183875143528, 0.10827893018722534, 0.2747730016708374, 0.015803592279553413, 0.10463877767324448, 0.09294995665550232, 0.015843944624066353, 0.01579432003200054, 0.01586209051311016, 0.2761257588863373, 0.01594272442162037, 0.10496240109205246, 0.015911541879177094, 0.015937751159071922, 0.01595574989914894, 0.10554158687591553, 0.01589413732290268, 0.01585293933749199, 0.08950524032115936, 0.015865113586187363, 0.01584220863878727, 0.015812350437045097, 0.09507983177900314, 0.01591283641755581, 0.11223606765270233, 0.015828199684619904, 0.0157871525734663, 0.10599251836538315, 0.01581265963613987, 0.015807747840881348, 0.015774289146065712, 0.015801142901182175, 0.2601631283760071, 0.015767741948366165, 0.01570858061313629, 0.015715328976511955, 0.10076206177473068, 0.015718039125204086, 0.2790308892726898, 0.01572110876441002, 0.09775571525096893, 0.015770141035318375, 0.015771139413118362, 0.2713414132595062, 0.015716109424829483, 0.015835149213671684, 0.01582108438014984, 0.015795111656188965, 0.10022877156734467, 0.015791045501828194, 0.09014327824115753, 0.015809962525963783, 0.08698365837335587, 0.015736185014247894, 0.015773119404911995, 0.10378621518611908, 0.11296335607767105, 0.01570521667599678, 0.01572033017873764, 0.2714788317680359, 0.10548485815525055, 0.015759261325001717, 0.015944965183734894, 0.25888073444366455, 0.015749884769320488, 0.26578208804130554, 0.12044248729944229, 0.10374372452497482, 0.11222504824399948, 0.015853101387619972, 0.015804752707481384, 0.09958302229642868, 0.015789596363902092, 0.01582186482846737, 0.015873966738581657, 0.09441083669662476, 0.015837565064430237, 0.015891406685113907, 0.01581898145377636, 0.10823314636945724, 0.12362101674079895, 0.10490388423204422, 0.01576092652976513, 0.015822138637304306, 0.10382499545812607, 0.09982441365718842, 0.015802083536982536, 0.09646978229284286, 0.015747787430882454, 0.01575213111937046, 0.01571882888674736, 0.12125552445650101, 0.0157721396535635, 0.10137665271759033, 0.015722861513495445, 0.10437586158514023, 0.09156989306211472, 0.015717079862952232, 0.015680264681577682, 0.1097225695848465, 0.015607868321239948, 0.015637453645467758, 0.10276582092046738, 0.015606135129928589, 0.015712780877947807, 0.01572750136256218, 0.015564854256808758, 0.10755832493305206, 0.1074855774641037, 0.015540222637355328, 0.01554231345653534, 0.015535103157162666, 0.30183473229408264, 0.10798344761133194, 0.015527027659118176, 0.015589766204357147, 0.11101836711168289, 0.1092425212264061, 0.090436652302742, 0.015633344650268555, 0.015547254122793674, 0.08984353393316269, 0.09618321061134338, 0.3003842234611511, 0.015682710334658623, 0.01555244904011488, 0.015597019344568253, 0.01552525907754898, 0.015629582107067108, 0.015580338425934315, 0.015588258393108845, 0.015621528960764408, 0.01554716844111681, 0.11689374595880508, 0.12084271758794785, 0.09998543560504913, 0.015511923469603062, 0.015476442873477936, 0.01550192479044199, 0.015466840006411076, 0.015493390150368214, 0.01553165540099144, 0.015426194295287132, 0.015496084466576576, 0.015523018315434456, 0.01553405448794365, 0.10428772866725922, 0.10002268105745316, 0.01541763637214899, 0.12559650838375092, 0.2999984323978424, 0.10734954476356506, 0.11289601773023605, 0.29156675934791565, 0.09630609303712845, 0.10735876858234406, 0.10599371045827866, 0.015377707779407501, 0.015419675968587399, 0.11217150092124939, 0.2966799736022949, 0.015493826009333134, 0.10609838366508484, 0.015517939813435078, 0.1065097376704216, 0.015451368875801563, 0.09913691878318787, 0.015522523783147335, 0.015484003350138664, 0.26801449060440063, 0.10997407138347626, 0.015484672971069813, 0.27305546402931213, 0.015532135032117367, 0.10282208025455475, 0.01563519611954689, 0.10974489152431488, 0.10067968815565109, 0.015568866394460201, 0.015629282221198082, 0.015538441017270088, 0.09944310784339905, 0.11256833374500275, 0.10402081161737442, 0.1104363352060318, 0.10370269417762756, 0.2714707553386688, 0.015536336228251457, 0.10200762748718262, 0.01550754252821207, 0.10285896062850952, 0.015529751777648926, 0.09782053530216217, 0.015612231567502022, 0.11588038504123688, 0.2653336226940155, 0.11228067427873611, 0.10274524986743927, 0.015538827516138554, 0.11238663643598557, 0.11771616339683533, 0.2757575809955597, 0.015608132816851139, 0.09542710334062576, 0.015616212971508503, 0.10091150552034378, 0.015625255182385445, 0.11205939948558807, 0.01569521240890026, 0.11015675216913223, 0.015620406717061996, 0.015626264736056328, 0.015650788322091103, 0.015667375177145004, 0.2836293578147888, 0.01557939313352108, 0.01563289761543274, 0.01573430933058262, 0.015589555725455284, 0.1171206682920456, 0.015588232316076756, 0.015629608184099197, 0.015632163733243942, 0.015603195875883102, 0.11567733436822891, 0.0157174002379179, 0.102684885263443, 0.01565549336373806, 0.09486932307481766, 0.0999867394566536, 0.2901289165019989, 0.01562710665166378, 0.015645496547222137, 0.015603412874042988, 0.015553731471300125, 0.10385169088840485, 0.015582001768052578, 0.015579541213810444, 0.015559274703264236, 0.015520813874900341, 0.015556508675217628, 0.10530517995357513, 0.2834171652793884, 0.10311789065599442, 0.015556707046926022, 0.015550102107226849, 0.015521676279604435, 0.11439564824104309, 0.12136323004961014, 0.015521189197897911, 0.015534881502389908, 0.015494131483137608, 0.11803309619426727, 0.09834218770265579, 0.015515085309743881, 0.1263832002878189, 0.30370277166366577, 0.01550636813044548, 0.01557849906384945, 0.1020551323890686, 0.015581990592181683, 0.01558081153780222, 0.015482443384826183, 0.25761136412620544, 0.01555128674954176, 0.015474129468202591, 0.015481269918382168, 0.09490364044904709, 0.10745466500520706, 0.10454364120960236, 0.10283458977937698, 0.01547645777463913, 0.0901176929473877, 0.015491778030991554, 0.10758880525827408, 0.015547728165984154, 0.015539221465587616, 0.01557628158479929, 0.015465112403035164, 0.10034342855215073, 0.1240934282541275, 0.298926442861557, 0.30281177163124084, 0.10153979808092117, 0.015463555231690407, 0.10808366537094116, 0.09404034167528152, 0.015497719869017601, 0.015602385625243187, 0.09491229057312012, 0.01557476818561554, 0.015517421066761017, 0.08907055854797363, 0.2958829700946808, 0.015575671568512917, 0.11412672698497772, 0.30001285672187805, 0.1084437295794487, 0.10958642512559891, 0.10601265728473663, 0.015571901574730873, 0.27650389075279236, 0.015618016012012959, 0.2640657424926758, 0.27502989768981934, 0.10950132459402084, 0.11063133925199509, 0.01562902331352234, 0.11648855358362198, 0.0885470062494278, 0.26435768604278564, 0.10931877791881561, 0.015741251409053802, 0.11692000180482864, 0.015751278027892113, 0.015857627615332603, 0.11025740951299667, 0.10147802531719208, 0.5092978477478027, 0.01583794690668583, 0.01579943671822548, 0.015813415870070457, 0.01588146761059761, 0.01587703637778759, 0.09787943959236145, 0.10869880020618439, 0.015849221497774124, 0.015920912846922874, 0.01592930592596531, 0.01585014909505844, 0.2740061581134796, 0.0159282386302948, 0.015919769182801247, 0.2728867530822754, 0.015931814908981323, 0.0158806461840868, 0.08896545320749283, 0.015905367210507393, 0.016005873680114746, 0.015912586823105812, 0.27728912234306335, 0.015903515741229057, 0.10169948637485504, 0.015915270894765854, 0.015932898968458176, 0.10860337316989899, 0.015915874391794205, 0.10928245633840561, 0.015943001955747604, 0.09419885277748108, 0.015882521867752075, 0.015901874750852585, 0.09991468489170074, 0.015909070149064064, 0.11235523223876953, 0.015962881967425346, 0.10272262245416641, 0.015934765338897705, 0.01592143438756466, 0.015856165438890457, 0.015910668298602104, 0.10021110624074936, 0.0158650204539299, 0.01583065837621689, 0.015854662284255028, 0.015871329233050346, 0.5259379148483276, 0.09787700325250626, 0.015833305194973946, 0.08977567404508591, 0.1049107015132904, 0.2570769190788269, 0.10570543259382248, 0.015838509425520897, 0.29568609595298767, 0.10126372426748276, 0.01589631661772728, 0.015972336754202843, 0.01594155840575695, 0.11033093184232712, 0.0974891185760498, 0.015940798446536064, 0.016032667830586433, 0.01592235267162323, 0.10598956793546677, 0.015911854803562164, 0.015885312110185623, 0.015928780660033226, 0.11839734762907028, 0.015917470678687096, 0.0160248763859272, 0.09226169437170029, 0.01589340716600418, 0.11076164990663528, 0.0159502811729908, 0.09747672826051712, 0.09232619404792786, 0.2596827447414398, 0.1057526022195816, 0.2818061113357544, 0.01587139070034027, 0.11921128630638123, 0.10714930295944214, 0.01592918299138546, 0.01592899113893509, 0.015950443223118782, 0.01588764600455761, 0.016004854813218117, 0.09555915743112564, 0.10077208280563354, 0.015904199331998825, 0.10600491613149643, 0.09455840289592743, 0.30053436756134033, 0.1067434623837471, 0.01594085991382599, 0.01588543690741062, 0.01589827612042427, 0.015999600291252136, 0.015919484198093414, 0.015895258635282516, 0.015873240306973457, 0.01599048636853695, 0.015916870906949043, 0.015962224453687668, 0.015913868322968483, 0.10560199618339539, 0.01587860845029354, 0.09556782990694046, 0.10969214141368866, 0.01587843708693981, 0.01590082049369812, 0.10212115943431854, 0.01590421050786972, 0.015858566388487816, 0.10490376502275467, 0.1011587530374527, 0.11123170703649521, 0.01586131937801838, 0.0158021692186594, 0.015801317989826202, 0.01588963344693184, 0.015854911878705025, 0.09634242951869965, 0.01581992395222187, 0.015806403011083603, 0.08790479600429535, 0.10780195891857147, 0.3075316250324249, 0.015823859721422195, 0.015846384689211845, 0.09635897725820541, 0.015927687287330627, 0.10064272582530975, 0.01575075276196003, 0.01588655263185501, 0.015781380236148834, 0.11752110719680786, 0.015805447474122047, 0.015887586399912834, 0.01576143503189087, 0.015829812735319138, 0.015750285238027573, 0.10466509312391281, 0.25665226578712463, 0.10404074937105179, 0.11726103723049164, 0.0938149094581604, 0.015760548412799835, 0.01576630026102066, 0.0968567281961441, 0.015809688717126846, 0.27849605679512024, 0.015742408111691475, 0.015843898057937622, 0.015741705894470215, 0.1051018014550209, 0.015808936208486557, 0.015751341357827187, 0.015801774337887764, 0.10623575747013092, 0.27123725414276123, 0.26627254486083984, 0.2561744451522827, 0.0158451609313488, 0.10372509807348251, 0.015735531225800514, 0.09642011672258377, 0.10765796154737473, 0.10842198878526688, 0.015833834186196327, 0.29322561621665955, 0.015842720866203308, 0.27366143465042114, 0.015799028798937798, 0.015877818688750267, 0.01579168438911438, 0.54359370470047, 0.015931110829114914, 0.015929492190480232, 0.11028195172548294, 0.10842782258987427, 0.015889741480350494, 0.10010574012994766, 0.09911241382360458, 0.28757229447364807, 0.1152065321803093, 0.11574184149503708, 0.01591138355433941, 0.11149856448173523, 0.01590622216463089, 0.016010308638215065, 0.015945130959153175, 0.015899166464805603, 0.09853939712047577, 0.015906700864434242, 0.10164624452590942, 0.10937894135713577, 0.10150986164808273, 0.01594131998717785, 0.30384162068367004, 0.09213228523731232, 0.09890960901975632, 0.10723134875297546, 0.1281631737947464, 0.016038626432418823, 0.01593984104692936, 0.01602088287472725, 0.016130421310663223, 0.5277186036109924, 0.01604750193655491, 0.016046304255723953, 0.1097944974899292, 0.01606866531074047, 0.015968872234225273, 0.015961436554789543, 0.015972789376974106, 0.2695727050304413, 0.12294001877307892, 0.10586372017860413, 0.016097573563456535, 0.015987154096364975, 0.015992047265172005, 0.01601804420351982, 0.016031472012400627, 0.016038279980421066, 0.11622948199510574, 0.016084544360637665, 0.015994638204574585, 0.26392829418182373, 0.015996498987078667, 0.10946312546730042, 0.09282451868057251, 0.016029860824346542, 0.01600339077413082, 0.11131539195775986, 0.2659423053264618, 0.09554532170295715, 0.10268496721982956, 0.01600167155265808, 0.01601557433605194, 0.01597907394170761, 0.016051428392529488, 0.016097715124487877, 0.016026124358177185, 0.28976500034332275, 0.015977000817656517, 0.09066491574048996, 0.01605866849422455, 0.016023704782128334, 0.016086004674434662, 0.11780862510204315, 0.016086824238300323, 0.016066573560237885, 0.09097453951835632, 0.016000790521502495, 0.10148502886295319, 0.01602023094892502, 0.11181540787220001, 0.01600215584039688, 0.25820454955101013, 0.10965641587972641, 0.3055858016014099, 0.27837952971458435, 0.10094338655471802, 0.01597186177968979, 0.01602252759039402, 0.016015812754631042, 0.30491068959236145, 0.016076235100626945, 0.27461984753608704, 0.016043880954384804, 0.01602162979543209, 0.2850184440612793, 0.01613340526819229, 0.2658100128173828, 0.016073796898126602, 0.2775987982749939, 0.10351734608411789, 0.10177677124738693, 0.016188114881515503, 0.10811163485050201, 0.01607048325240612, 0.08753108978271484, 0.108045794069767, 0.01630997285246849, 0.10361102968454361, 0.01610332541167736, 0.016106421127915382, 0.08999088406562805, 0.2779715955257416, 0.10432876646518707, 0.10688098520040512, 0.10611514747142792, 0.01608998142182827, 0.11300359666347504, 0.016146522015333176, 0.016210565343499184, 0.5323832631111145, 0.2620222270488739, 0.016152184456586838, 0.01616061106324196, 0.24520976841449738, 0.016170397400856018, 0.10254872590303421, 0.01628958433866501, 0.0995837077498436, 0.016250228509306908, 0.016244860365986824, 0.01626514084637165, 0.09352701902389526, 0.11289896070957184, 0.10339868068695068, 0.01621534861624241, 0.10593897104263306, 0.09288278967142105, 0.10599646717309952, 0.01621653325855732, 0.10085956752300262, 0.29138001799583435, 0.01622668281197548, 0.016207106411457062, 0.10328596085309982, 0.09665706753730774, 0.01625002734363079, 0.016208194196224213, 0.016282614320516586, 0.01616775244474411, 0.016220219433307648, 0.09619762748479843, 0.01625029370188713, 0.10531948506832123, 0.016225196421146393, 0.25254392623901367, 0.11891338229179382, 0.016241831704974174, 0.016249068081378937, 0.016341323032975197, 0.016220146790146828, 0.01627466082572937, 0.28702422976493835, 0.016192970797419548, 0.016174687072634697, 0.09674514085054398, 0.01628871262073517, 0.11075052618980408, 0.016246801242232323, 0.016242360696196556, 0.25731396675109863, 0.016209682449698448, 0.09312481433153152, 0.016211485490202904, 0.12271847575902939, 0.11273367702960968, 0.01619124971330166, 0.10245872288942337, 0.5281010866165161, 0.016261471435427666, 0.01624339260160923, 0.016280338168144226, 0.016231143847107887, 0.016254441812634468, 0.09525413811206818, 0.11168580502271652, 0.10139523446559906, 0.01621486060321331, 0.1085996925830841, 0.01619807817041874, 0.265798956155777, 0.016229921951889992, 0.09135214239358902, 0.10240988433361053, 0.01626572385430336, 0.01628832332789898, 0.016240384429693222, 0.016189686954021454, 0.09873012453317642, 0.09016146510839462, 0.016240650787949562, 0.10422879457473755, 0.0163359846919775, 0.10473901778459549, 0.30152541399002075, 0.0996176078915596, 0.016203831881284714, 0.016268901526927948, 0.016324037685990334, 0.01621892675757408, 0.0162370428442955, 0.1050228625535965, 0.279850572347641, 0.2915849983692169, 0.016217298805713654, 0.016329199075698853, 0.016338376328349113, 0.09994581341743469, 0.01623004674911499, 0.016263695433735847, 0.01623399369418621, 0.016326259821653366, 0.1189977303147316, 0.016192428767681122, 0.11024752259254456, 0.11068763583898544, 0.016225753352046013, 0.0999007597565651, 0.016316361725330353, 0.10616515576839447, 0.016299402341246605, 0.10983423888683319, 0.016241582110524178, 0.01621653325855732, 0.10506395250558853, 0.016278928145766258, 0.016194920986890793, 0.016338182613253593, 0.01628296822309494, 0.10148131847381592, 0.10725881159305573, 0.016236012801527977, 0.016277629882097244, 0.11001384258270264, 0.09759430587291718, 0.10654950886964798, 0.016305118799209595, 0.10617443174123764, 0.016205959022045135, 0.016216756775975227, 0.1161012127995491, 0.01620868593454361, 0.016177037730813026, 0.2801736295223236, 0.01619808003306389, 0.11976323276758194, 0.016279052942991257, 0.01617455668747425, 0.11139749735593796, 0.09915513545274734, 0.016255704686045647, 0.2579610347747803, 0.016199277713894844, 0.09389940649271011, 0.10486305505037308, 0.0162348635494709, 0.016261069104075432, 0.016158681362867355, 0.01621110364794731, 0.016168493777513504, 0.01619729772210121, 0.11199451982975006, 0.10659704357385635, 0.01619274541735649, 0.016164053231477737, 0.10352031141519547, 0.01623968966305256, 0.016167106106877327, 0.10587943345308304, 0.0162627175450325, 0.10386598110198975, 0.016242213547229767, 0.10462002456188202, 0.016276758164167404, 0.08710188418626785, 0.28328633308410645, 0.2861924171447754, 0.016233526170253754, 0.10126853734254837, 0.016185523942112923, 0.01616961881518364, 0.016172222793102264, 0.10157014429569244, 0.09725626558065414, 0.01617511361837387, 0.016167547553777695, 0.01615019142627716, 0.01620093546807766, 0.01616276241838932, 0.10269719362258911, 0.1107560396194458, 0.09273569285869598, 0.0969490110874176, 0.2754891812801361, 0.10852565616369247, 0.016225701197981834, 0.10514640063047409, 0.01625143736600876, 0.016223344951868057, 0.016223130747675896, 0.10095282644033432, 0.016163870692253113, 0.10016126930713654, 0.09619076550006866, 0.1087675541639328, 0.11605563014745712, 0.2625964879989624, 0.09888164699077606, 0.0161916371434927, 0.10030891746282578, 0.09751257300376892, 0.10991346091032028, 0.10332933813333511, 0.016202902421355247, 0.09880576282739639, 0.016191963106393814, 0.016283724457025528, 0.10523021221160889, 0.016232585534453392, 0.11360972374677658, 0.10234235227108002, 0.2668208181858063, 0.016188757494091988, 0.016184257343411446, 0.11443518102169037, 0.016301250085234642, 0.016250787302851677, 0.10812464356422424, 0.016200771555304527, 0.016166528686881065, 0.11149277538061142, 0.01617276296019554, 0.016198495402932167, 0.10866494476795197, 0.106434665620327, 0.01616806350648403, 0.3003637194633484, 0.01623724400997162, 0.309318482875824, 0.016202092170715332, 0.26689398288726807, 0.016183240339159966, 0.01618470624089241, 0.10387158393859863, 0.2772315442562103, 0.016214504837989807, 0.28551965951919556, 0.08779208362102509, 0.10247477889060974, 0.016161717474460602, 0.09163640439510345, 0.29464486241340637, 0.2731124758720398, 0.016241405159235, 0.01626293547451496, 0.016201715916395187, 0.016227491199970245, 0.10919224470853806, 0.01616007089614868, 0.016227982938289642, 0.10731655359268188, 0.016156131401658058, 0.10427986085414886]\n",
            "Val loss 0.07335323496640984\n",
            "Val auc roc 0.4490220483641536\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-05.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5063e93c-0a39-45f5-9b1a-be7a3fe8501b"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}