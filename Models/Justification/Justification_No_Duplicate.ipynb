{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Justification_No_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40d1007a15954a1392cb0dc12fbfea23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2c69091e80b48a0aa5744b4e1c817c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_037b5b06650c4d43af66e0bb2274a618",
              "IPY_MODEL_a8ca860c65ac4c7dba847724b6fe47d1"
            ]
          }
        },
        "f2c69091e80b48a0aa5744b4e1c817c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "037b5b06650c4d43af66e0bb2274a618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_449888b2a74c4f23b4c1a6a9da8365b4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32d1af4b0c5a4fa9b8d9254904ba2745"
          }
        },
        "a8ca860c65ac4c7dba847724b6fe47d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22a114f84df24af2944c749717141ee9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:12&lt;00:00, 19.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8962af376de04efc97424e3623d47b8b"
          }
        },
        "449888b2a74c4f23b4c1a6a9da8365b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32d1af4b0c5a4fa9b8d9254904ba2745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22a114f84df24af2944c749717141ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8962af376de04efc97424e3623d47b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "011500f39aa54656aed777d262920b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_542c8687aa1041c383f2b6335abc0fee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce624c27ed1846f287e6d05e29e72431",
              "IPY_MODEL_f52fc72662f549daa5bde7094f70d402"
            ]
          }
        },
        "542c8687aa1041c383f2b6335abc0fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce624c27ed1846f287e6d05e29e72431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4d773aeba9414d26b1fa2474c4192def",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c201b416e53440dafe17a30da196947"
          }
        },
        "f52fc72662f549daa5bde7094f70d402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8f88b21a440460688c505d7ac91bf9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [1:25:30&lt;00:00,  3.22s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a7bda2991964d8b989cad083cff9092"
          }
        },
        "4d773aeba9414d26b1fa2474c4192def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c201b416e53440dafe17a30da196947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8f88b21a440460688c505d7ac91bf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a7bda2991964d8b989cad083cff9092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "400a701433044609a3dd1279690dad06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_947bd50bbcad4ed6845d4fc341a678ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4010ded44711424ba79fc1ff730ad370",
              "IPY_MODEL_fa962df80b3340f3831ffa35552fa16e"
            ]
          }
        },
        "947bd50bbcad4ed6845d4fc341a678ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4010ded44711424ba79fc1ff730ad370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_74629dd188ab4734bc08b9a1ac221dd2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4267e04eb2194af78c691d045193671c"
          }
        },
        "fa962df80b3340f3831ffa35552fa16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bce6619c2894e21a5b995e88804ad1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [27:54&lt;00:00,  1.05s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc8d99b5d8d24ba490c30b14d5785d30"
          }
        },
        "74629dd188ab4734bc08b9a1ac221dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4267e04eb2194af78c691d045193671c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bce6619c2894e21a5b995e88804ad1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc8d99b5d8d24ba490c30b14d5785d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03f3d544c3b6455d979ed4ae1280b33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f268ac10bc94ac092381d9da2348e04",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_38d7ea95f24345b3a3e3029972ab9fd1",
              "IPY_MODEL_8f89254faf35402f9f087dff0dad8f5a"
            ]
          }
        },
        "9f268ac10bc94ac092381d9da2348e04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38d7ea95f24345b3a3e3029972ab9fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fa0d214eabf8452e84ba1adbb734f083",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79368b838610453db5a6e79882c87dcc"
          }
        },
        "8f89254faf35402f9f087dff0dad8f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ebe7a1e94f38483dae9bde83d834e15e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [28:06&lt;00:00,  1.06s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58fb4f43bb8b45a09e7eb609245ed2aa"
          }
        },
        "fa0d214eabf8452e84ba1adbb734f083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79368b838610453db5a6e79882c87dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebe7a1e94f38483dae9bde83d834e15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58fb4f43bb8b45a09e7eb609245ed2aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0957969e-a183-48b0-8453-051071b0b4e8"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 15.43 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b7a601a-4216-4d9a-bb54-c869976c93c2"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa2b75ea-afc3-43fc-ebd2-37f48ad898ca"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "906af561-169f-454d-dc3a-d68bb8908cc1"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "563de782-7801-4ab0-c77e-d0253974fb6e"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "16a1d884-590b-4ecf-a3d8-50a5e33a8628"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 603kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "71e80804-72bd-4b72-cbca-7eecb343ba3c"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a5c86b39-7e31-476c-830b-05ad274d9840"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "5d81f6a4-110b-46f0-fdd1-7dd7829ad3d9"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "35b2a457-8848-407b-85bc-ffea9183ab4e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    #MeeTooIndia #Mee Too #MeeToo india #MeToo #Me...\n",
              "1    #MeToo | 17 women journalists come out in supp...\n",
              "2    As #MeToo is hitting a chord in #China, dozens...\n",
              "3    Rajnath Singh Takes MeToo Potshots at Cong And...\n",
              "4    Hypocracy of @TOIIndiaNews  Stand on what you ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faf3b011-58b3-4cfe-ea1e-ee2748e349dc"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:15<00:00, 25785298.06B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcc8e63e-8ca8-4cdf-db62-fff4d56046bd"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 687878.11B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "b8863825-391f-4309-a8f4-edd78d7ab31d"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf2d5bde-94ce-447a-8063-643a192b6b08"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        df4 = df2.copy().reset_index(drop=True)\n",
        "        df5 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            random.shuffle(text)\n",
        "            text3 = ' '.join(text)\n",
        "            df3['text'][i]=text3\n",
        "            random.shuffle(text)\n",
        "            text4 = ' '.join(text)\n",
        "            df4['text'][i]=text4\n",
        "            random.shuffle(text)\n",
        "            text5 = ' '.join(text)\n",
        "            df5['text'][i]=text5\n",
        "        #self.data = self.data.append(df2, ignore_index=True)\n",
        "        #self.data = self.data.append(df3, ignore_index=True)\n",
        "        #self.data = self.data.append(df4, ignore_index=True)\n",
        "        #self.data = self.data.append(df5, ignore_index=True)\n",
        "        #self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a7eeb5f-85ec-4d65-f14a-5680a3fc6b8e"
      },
      "source": [
        "col_name = \"Justification\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "40d1007a15954a1392cb0dc12fbfea23",
            "f2c69091e80b48a0aa5744b4e1c817c3",
            "037b5b06650c4d43af66e0bb2274a618",
            "a8ca860c65ac4c7dba847724b6fe47d1",
            "449888b2a74c4f23b4c1a6a9da8365b4",
            "32d1af4b0c5a4fa9b8d9254904ba2745",
            "22a114f84df24af2944c749717141ee9",
            "8962af376de04efc97424e3623d47b8b",
            "011500f39aa54656aed777d262920b89",
            "542c8687aa1041c383f2b6335abc0fee",
            "ce624c27ed1846f287e6d05e29e72431",
            "f52fc72662f549daa5bde7094f70d402",
            "4d773aeba9414d26b1fa2474c4192def",
            "5c201b416e53440dafe17a30da196947",
            "c8f88b21a440460688c505d7ac91bf9e",
            "9a7bda2991964d8b989cad083cff9092",
            "400a701433044609a3dd1279690dad06",
            "947bd50bbcad4ed6845d4fc341a678ad",
            "4010ded44711424ba79fc1ff730ad370",
            "fa962df80b3340f3831ffa35552fa16e",
            "74629dd188ab4734bc08b9a1ac221dd2",
            "4267e04eb2194af78c691d045193671c",
            "0bce6619c2894e21a5b995e88804ad1f",
            "cc8d99b5d8d24ba490c30b14d5785d30",
            "03f3d544c3b6455d979ed4ae1280b33f",
            "9f268ac10bc94ac092381d9da2348e04",
            "38d7ea95f24345b3a3e3029972ab9fd1",
            "8f89254faf35402f9f087dff0dad8f5a",
            "fa0d214eabf8452e84ba1adbb734f083",
            "79368b838610453db5a6e79882c87dcc",
            "ebe7a1e94f38483dae9bde83d834e15e",
            "58fb4f43bb8b45a09e7eb609245ed2aa"
          ]
        },
        "outputId": "653ba200-a964-43bd-8ed4-b3e386bdd3ca"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6382\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40d1007a15954a1392cb0dc12fbfea23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "011500f39aa54656aed777d262920b89",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0335\n",
            "Train Losses : [0.1856558918952942, 0.21627923846244812, 1.083045482635498, 0.7138148546218872, 1.2559887170791626, 2.0012786388397217, 1.3720089197158813, 0.5005372166633606, 0.8212484121322632, 0.7512298226356506, 0.5040058493614197, 0.20341674983501434, 0.33329638838768005, 0.6151336431503296, 0.39006859064102173, 2.757991313934326, 0.7310373187065125, 0.6689885258674622, 0.15293702483177185, 0.8664973378181458, 0.10733002424240112, 0.5034112930297852, 0.0012145960936322808, 0.14341233670711517, 0.036051951348781586, 0.17613357305526733, 0.17814499139785767, 0.04917493835091591, 0.0462653674185276, 0.11103150993585587, 0.03591533377766609, 0.040682412683963776, 0.01379292644560337, 0.00906793400645256, 0.008317261002957821, 0.009917723946273327, 0.0056574237532913685, 0.003522970248013735, 0.004338646773248911, 0.0040439157746732235, 0.101547472178936, 0.002053373958915472, 0.006290464196354151, 0.004700106102973223, 0.33284297585487366, 0.002104878891259432, 0.0008967443136498332, 0.0026120892725884914, 0.0008512729546055198, 0.0043482291512191296, 0.3973312973976135, 0.0021672106813639402, 0.0008376257610507309, 0.0011563269654288888, 0.0009844684973359108, 0.0008274693391285837, 0.0015293629840016365, 0.003786106826737523, 0.001429514610208571, 0.0008891249890439212, 0.08810863643884659, 0.0007502977969124913, 0.0007800518069416285, 0.26614418625831604, 0.00127472507301718, 0.002571223536506295, 0.001935715088620782, 0.023811984807252884, 0.0010748247150331736, 0.0027085724286735058, 0.0011975769884884357, 0.000818488304503262, 0.001324112294241786, 0.001254281378351152, 0.0021624502260237932, 0.00185528548900038, 0.0010482396464794874, 0.0014263528864830732, 0.008047543466091156, 0.002192450687289238, 0.22992128133773804, 0.0012994669377803802, 0.007062565069645643, 0.001710747485049069, 0.0011366340331733227, 0.0019991216249763966, 0.0027984227053821087, 0.0012695379555225372, 0.001153809716925025, 0.0012622253270819783, 0.007615529466420412, 0.001267004874534905, 0.0009374312357977033, 0.003512944793328643, 0.001187596470117569, 0.0031518798787146807, 0.2874503433704376, 0.09012016654014587, 0.001453559729270637, 0.0014327912358567119, 0.00407266803085804, 0.0029333559796214104, 0.001162331085652113, 0.002264391863718629, 0.0012222069781273603, 0.002684571547433734, 0.0032579482067376375, 0.00602409103885293, 0.001517880242317915, 0.003209940390661359, 0.0036002371925860643, 0.12614542245864868, 0.005973167717456818, 0.1932353675365448, 0.002501830691471696, 0.0024600063916295767, 0.003641177201643586, 0.0035416744649410248, 0.002495306311175227, 0.0019115741597488523, 0.0019543643575161695, 0.0019521022913977504, 0.002591009484604001, 0.004251635167747736, 0.007591031026095152, 0.0025677441153675318, 0.0037005844060331583, 0.0018260349752381444, 0.0020561078563332558, 0.001480432110838592, 0.001346728065982461, 0.005136429797858, 0.0024280077777802944, 0.0011739934561774135, 0.0023490753956139088, 0.0009962716139853, 0.0008303530048578978, 0.0008763300138525665, 0.0017129785846918821, 0.0011017750948667526, 0.17754095792770386, 0.2699078917503357, 0.0016520054778084159, 0.0013720999704673886, 0.0013398436130955815, 0.0019484710646793246, 0.301278293132782, 0.0009094204870052636, 0.0009569248068146408, 0.0012855727691203356, 0.001179694663733244, 0.0016698527615517378, 0.0011260255705565214, 0.29138240218162537, 0.001244713319465518, 0.0019978531636297703, 0.0020821276120841503, 0.001629044534638524, 0.0013591654133051634, 0.001419608830474317, 0.0015760118840262294, 0.0015074069378897548, 0.05217612162232399, 0.0015873549273237586, 0.0016604538541287184, 0.0016274157678708434, 0.0019494070438668132, 0.0017085365252569318, 0.0016242495039477944, 0.0019554109312593937, 0.0017417107010260224, 0.001904775621369481, 0.0025843793991953135, 0.0018229424022138119, 0.0015382551355287433, 0.24450412392616272, 0.0016703249420970678, 0.001760956714861095, 0.002506897784769535, 0.0025061483029276133, 0.002262090565636754, 0.0023671675007790327, 0.00201212614774704, 0.002008993411436677, 0.003130455268546939, 0.001833794522099197, 0.0027150206733494997, 0.001729481155052781, 0.002439634408801794, 0.002229860285297036, 0.0018971742829307914, 0.001738357008434832, 0.002225996693596244, 0.0016338905552402139, 0.001426234608516097, 0.1970037817955017, 0.0015609341207891703, 0.23793978989124298, 0.0017043112311512232, 0.002050039591267705, 0.001780940918251872, 0.27444538474082947, 0.0024685512762516737, 0.002086214255541563, 0.0020885299891233444, 0.0023851958103477955, 0.0024039822164922953, 0.20949560403823853, 0.002435814356431365, 0.11572153121232986, 0.0030267531983554363, 0.0027912931982427835, 0.0026224968023598194, 0.002827133284881711, 0.002861741464585066, 0.12748101353645325, 0.09355691075325012, 0.003712143050506711, 0.0042614745907485485, 0.0038728658109903336, 0.004188563209027052, 0.004155420698225498, 0.07485518604516983, 0.004208477213978767, 0.004988319706171751, 0.10221724212169647, 0.11585471779108047, 0.004910225979983807, 0.005038250237703323, 0.006611567921936512, 0.005327210761606693, 0.005594550631940365, 0.006231488194316626, 0.005212531890720129, 0.0052463519386947155, 0.007916484959423542, 0.005495456047356129, 0.0062703960575163364, 0.005019377451390028, 0.0060200137086212635, 0.004531024489551783, 0.0041395253501832485, 0.22514037787914276, 0.0763479620218277, 0.004350225906819105, 0.00499346386641264, 0.005610230378806591, 0.004379372578114271, 0.0037680526729673147, 0.004002001136541367, 0.003714826423674822, 0.0033950405195355415, 0.004616746678948402, 0.003395262872800231, 0.004531299229711294, 0.003015761263668537, 0.002880294341593981, 0.0027450094930827618, 0.002547499490901828, 0.1432574838399887, 0.0031498768366873264, 0.0025974600575864315, 0.23135435581207275, 0.002494039246812463, 0.0028531320858746767, 0.003993981052190065, 0.002749295439571142, 0.0029230648651719093, 0.1929827183485031, 0.003190507646650076, 0.0029875391628593206, 0.0028148998972028494, 0.003621234791353345, 0.0029891878366470337, 0.12182710319757462, 0.1910240799188614, 0.004226860590279102, 0.004052737727761269, 0.003528645960614085, 0.0036454310175031424, 0.0036742626689374447, 0.0038261134177446365, 0.004030529409646988, 0.00411434518173337, 0.003814099822193384, 0.0037562802899628878, 0.0036239558830857277, 0.1833193004131317, 0.20936164259910583, 0.10550698637962341, 0.003888040082529187, 0.14403018355369568, 0.00439863046631217, 0.08697501569986343, 0.004787563346326351, 0.005294585134834051, 0.16389645636081696, 0.08435703068971634, 0.006093102972954512, 0.006475212052464485, 0.00675892923027277, 0.007331961765885353, 0.007415984757244587, 0.0072268838994205, 0.007322000805288553, 0.008071395568549633, 0.007073082961142063, 0.007235326804220676, 0.0065808673389256, 0.006584280636161566, 0.005912731401622295, 0.14775453507900238, 0.005403924733400345, 0.005249744281172752, 0.005547415465116501, 0.004770171362906694, 0.004506211262196302, 0.00474566500633955, 0.005003007128834724, 0.003924683667719364, 0.003717400599271059, 0.004025585018098354, 0.0034991521388292313, 0.0034217662177979946, 0.0034422464668750763, 0.0028737077955156565, 0.002807138254866004, 0.0027092776726931334, 0.00245215417817235, 0.0023908750154078007, 0.0023362061474472284, 0.0022002514451742172, 0.002083867322653532, 0.0019291015341877937, 0.0018458854174241424, 0.0017731080297380686, 0.0017253189580515027, 0.0016361840534955263, 0.08818306773900986, 0.0016430154209956527, 0.0015706801787018776, 0.0016654408536851406, 0.0016477246535941958, 0.0016671284101903439, 0.0017102359561249614, 0.001501276041381061, 0.0014687489019706845, 0.0017072958871722221, 0.0015950481174513698, 0.1316772997379303, 0.0016696632374078035, 0.0015264435205608606, 0.001701705507002771, 0.12380804121494293, 0.0017493880586698651, 0.0016907688695937395, 0.07524757832288742, 0.002201711991801858, 0.0020974609069526196, 0.0021253509912639856, 0.002435234608128667, 0.1315828412771225, 0.002602273365482688, 0.10300574451684952, 0.16525870561599731, 0.0036302481312304735, 0.0036071797367185354, 0.003452907083556056, 0.005269051995128393, 0.06866096705198288, 0.004077915567904711, 0.11186163872480392, 0.005297355819493532, 0.004441318567842245, 0.00517618702724576, 0.0061943791806697845, 0.11645839363336563, 0.0054524908773601055, 0.007527351379394531, 0.005505234003067017, 0.005377885419875383, 0.006749263498932123, 0.005565144121646881, 0.0064966329373419285, 0.005792560521513224, 0.005306695122271776, 0.00485210632905364, 0.005761285778135061, 0.004702320322394371, 0.005170394200831652, 0.0044018179178237915, 0.0041383481584489346, 0.004216204397380352, 0.004995795898139477, 0.0037457612343132496, 0.003893128130584955, 0.0037550705019384623, 0.0035281467717140913, 0.003236121963709593, 0.10567058622837067, 0.158133402466774, 0.0029813924338668585, 0.003477209247648716, 0.0032960029784590006, 0.11697909235954285, 0.003590900683775544, 0.0031144488602876663, 0.0038687121123075485, 0.003032888285815716, 0.00313665927387774, 0.003795489203184843, 0.004002290777862072, 0.0029002358205616474, 0.00390703696757555, 0.11674956977367401, 0.2188209444284439, 0.0038923213724046946, 0.0037555082235485315, 0.005089137703180313, 0.005153588019311428, 0.003718552179634571, 0.005169956013560295, 0.003697276348248124, 0.003649142337962985, 0.00408749608322978, 0.003767651040107012, 0.003540895413607359, 0.0034905895590782166, 0.08288879692554474, 0.004446523729711771, 0.0033997849095612764, 0.003075710730627179, 0.0029242713935673237, 0.003366559511050582, 0.0028535742312669754, 0.0035948504228144884, 0.003405490191653371, 0.0033254260197281837, 0.002794718835502863, 0.0029836460016667843, 0.0027210451662540436, 0.0027361188549548388, 0.002492380328476429, 0.0025028004311025143, 0.0027734057512134314, 0.0024498896673321724, 0.0021125508937984705, 0.002095784991979599, 0.0021310076117515564, 0.1508096158504486, 0.5671694278717041, 0.0023914286866784096, 0.002295098965987563, 0.002742350334301591, 0.0033639755565673113, 0.003563889069482684, 0.003279149765148759, 0.20888745784759521, 0.005985238589346409, 0.19056667387485504, 0.004132763482630253, 0.004703081212937832, 0.004838776774704456, 0.005167685449123383, 0.005085206124931574, 0.005173108074814081, 0.0063202702440321445, 0.006460806354880333, 0.16964863240718842, 0.0059679653495550156, 0.005392940249294043, 0.1571769416332245, 0.006150891073048115, 0.006483659613877535, 0.0057065547443926334, 0.006088847294449806, 0.006129717919975519, 0.005061118397861719, 0.005178905092179775, 0.004835391882807016, 0.0047332909889519215, 0.005668547470122576, 0.004307990428060293, 0.004235728178173304, 0.00442330539226532, 0.0037325958255678415, 0.003872891189530492, 0.004005145281553268, 0.1303597241640091, 0.0034856924321502447, 0.0033714461605995893, 0.0032309454400092363, 0.0032008427660912275, 0.0029295184649527073, 0.00301573658362031, 0.0028307910542935133, 0.002798394300043583, 0.0026616365648806095, 0.002696457551792264, 0.0025453430134803057, 0.002521209418773651, 0.0024616189766675234, 0.002254560124129057, 0.002350604860112071, 0.0022380498703569174, 0.0023204220924526453, 0.0020016832277178764, 0.0019760257564485073, 0.0019334435928612947, 0.0019721121061593294, 0.001973607111722231, 0.0018777494551613927, 0.6090691089630127, 0.1410786658525467, 0.0021927710622549057, 0.002424937440082431, 0.12962490320205688, 0.002797446446493268, 0.003061187919229269, 0.003385002724826336, 0.0034625972621142864, 0.0036583321634680033, 0.004150204360485077, 0.003916833084076643, 0.0041955518536269665, 0.003989076241850853, 0.08229183405637741, 0.00417281361296773, 0.004257048945873976, 0.13159994781017303, 0.004569781944155693, 0.00448606489226222, 0.005226841662079096, 0.004565367475152016, 0.004705619532614946, 0.005043366923928261, 0.00454110698774457, 0.005108952987939119, 0.004490896128118038, 0.004305030684918165, 0.00428376067429781, 0.0924462303519249, 0.0040365103632211685, 0.10704031586647034, 0.004216422326862812, 0.004531039856374264, 0.004633296746760607, 0.004639985039830208, 0.004269633442163467, 0.004248412325978279, 0.11838129907846451, 0.004435423761606216, 0.004164841026067734, 0.004643529653549194, 0.004101101774722338, 0.004186250269412994, 0.0045843119733035564, 0.004356133285909891, 0.004514631815254688, 0.003761384403333068, 0.0036946202162653208, 0.0038276377599686384, 0.0032425960525870323, 0.0032845500390976667, 0.0032428402919322252, 0.003090562066063285, 0.17643773555755615, 0.0029361755587160587, 0.003097648499533534, 0.0028338031843304634, 0.0031619269866496325, 0.0027209711261093616, 0.0027019933331757784, 0.002710387809202075, 0.0028605745173990726, 0.0029042880050837994, 0.002472176682204008, 0.0024582501500844955, 0.0026250160299241543, 0.002523258328437805, 0.0024213276337832212, 0.002371374983340502, 0.0020578212570399046, 0.0021622180938720703, 0.0021850294433534145, 0.002043538261204958, 0.0020667104981839657, 0.0019099831115454435, 0.0018041396979242563, 0.0017491881735622883, 0.0017424272373318672, 0.0016233301721513271, 0.0017852013697847724, 0.0015242625959217548, 0.0016896836459636688, 0.001638462650589645, 0.0014417545171454549, 0.0013835487188771367, 0.0015864865854382515, 0.0013900044141337276, 0.0015043255407363176, 0.0012915292754769325, 0.001342765404842794, 0.18479682505130768, 0.001251164940185845, 0.5034359097480774, 0.0015341084217652678, 0.0016813988331705332, 0.0019493605941534042, 0.002187921665608883, 0.0021925584878772497, 0.002411303576081991, 0.0025503316428512335, 0.002858320949599147, 0.0027685558889061213, 0.0029977289959788322, 0.002897990634664893, 0.00340032740496099, 0.0029923277907073498, 0.0032550618052482605, 0.002947470871731639, 0.002965636318549514, 0.0031894673593342304, 0.16365846991539001, 0.003424984635785222, 0.16409561038017273, 0.15265217423439026, 0.0035462568048387766, 0.003943557385355234, 0.003999820910394192, 0.003910838160663843, 0.003982264548540115, 0.00424577109515667, 0.004786937031894922, 0.00495547242462635, 0.004101799335330725, 0.004080728627741337, 0.004133644048124552, 0.004154882859438658, 0.004265342839062214, 0.003937897738069296, 0.003944117575883865, 0.15496361255645752, 0.004029920790344477, 0.004030725918710232, 0.0036585701163858175, 0.003693296341225505, 0.0038652364164590836, 0.00391105841845274, 0.003643896197900176, 0.003465344663709402, 0.1279739886522293, 0.003495369339361787, 0.0037710259202867746, 0.00347328488714993, 0.0034409097861498594, 0.00352184334769845, 0.003393817925825715, 0.0033356209751218557, 0.0031366832554340363, 0.0031294161453843117, 0.1539539098739624, 0.0032228142954409122, 0.1370316594839096, 0.003266136161983013, 0.003324523800984025, 0.0033728668931871653, 0.0034612449817359447, 0.0034337122924625874, 0.0035454975441098213, 0.003370968159288168, 0.00340671231970191, 0.003281369572505355, 0.0032963957637548447, 0.003224416635930538, 0.0031521879136562347, 0.0031160004436969757, 0.0030798192601650953, 0.0031243893317878246, 0.0030850283801555634, 0.002932971343398094, 0.002729252213612199, 0.11802110821008682, 0.0030003287829458714, 0.0026976042427122593, 0.002695459872484207, 0.0027794649358838797, 0.002818470820784569, 0.0026960463728755713, 0.002720154356211424, 0.002541644498705864, 0.0025591813027858734, 0.0024213080760091543, 0.13041435182094574, 0.002432913752272725, 0.1318056881427765, 0.0027238642796874046, 0.002603936241939664, 0.0027081931475549936, 0.0027528235223144293, 0.0027355714701116085, 0.002731453161686659, 0.0026851422153413296, 0.0026725870557129383, 0.0027057959232479334, 0.11206093430519104, 0.0027743554674088955, 0.002821464091539383, 0.002776198787614703, 0.13631057739257812, 0.003064562566578388, 0.0030691777355968952, 0.003061926458030939, 0.00293603353202343, 0.0029563289135694504, 0.002960457932204008, 0.0029877854976803064, 0.11666472256183624, 0.0030768669676035643, 0.0031757138203829527, 0.003293912159278989, 0.38761162757873535, 0.0036697592586278915, 0.0046119107864797115, 0.004158440511673689, 0.004323686473071575, 0.0043533844873309135, 0.13290750980377197, 0.00468839518725872, 0.005043931305408478, 0.005101106595247984, 0.005540526006370783, 0.005579871591180563, 0.1471172720193863, 0.0058814166113734245, 0.005466673523187637, 0.006723262369632721, 0.005664232186973095, 0.005679204128682613, 0.1213158443570137, 0.1161409467458725, 0.005443306639790535, 0.005670827813446522, 0.005574062932282686, 0.005639736074954271, 0.005669772624969482, 0.005422976333647966, 0.16510014235973358, 0.0056744045577943325, 0.16897565126419067, 0.005644075106829405, 0.0053758081048727036, 0.0062848241068422794, 0.005656437948346138, 0.005537854973226786, 0.005392266903072596, 0.13372208178043365, 0.005051331594586372, 0.004988376051187515, 0.005560452584177256, 0.4522131383419037, 0.0052995020523667336, 0.006128048058599234, 0.005669945385307074, 0.006171347573399544, 0.006121755577623844, 0.006138168275356293, 0.006623048335313797, 0.0061700306832790375, 0.006206531077623367, 0.006161742843687534, 0.006219123024493456, 0.005899388343095779, 0.005725707858800888, 0.006030163262039423, 0.005473962984979153, 0.005168191157281399, 0.005123547278344631, 0.004888530820608139, 0.0046753655187785625, 0.004588186740875244, 0.004680687561631203, 0.004137929528951645, 0.003940119408071041, 0.0037314232904464006, 0.0039479369297623634, 0.003742586588487029, 0.0033431951887905598, 0.0032191192731261253, 0.00301685300655663, 0.0030179391615092754, 0.0028301377315074205, 0.0027095871046185493, 0.0025893484707921743, 0.08903487771749496, 0.0027111298404634, 0.0025671992916613817, 0.002505712443962693, 0.0024626250378787518, 0.0023668985813856125, 0.18601980805397034, 0.0023799778427928686, 0.12379083782434464, 0.0024139105807989836, 0.002478986280038953, 0.0024931468069553375, 0.0025727003812789917, 0.0027192530687898397, 0.0026233866810798645, 0.002641845727339387, 0.12642841041088104, 0.002786764409393072, 0.0027749149594455957, 0.002814935054630041, 0.002880634507164359, 0.002965376479551196, 0.0028875134885311127, 0.002868635579943657, 0.002851199358701706, 0.0028363631572574377, 0.00282372091896832, 0.002826242707669735, 0.0027160278987139463, 0.002781664254143834, 0.0026396450120955706, 0.0026405612006783485, 0.002713090507313609, 0.0025021759793162346, 0.0024732653982937336, 0.0024661701172590256, 0.0025292683858424425, 0.002368065994232893, 0.14179357886314392, 0.0024034969974309206, 0.002314968267455697, 0.002297048456966877, 0.0022850804962217808, 0.11045503616333008, 0.0022454815916717052, 0.0024021354038268328, 0.0024360644165426493, 0.0024251972790807486, 0.002468237653374672, 0.002410940593108535, 0.002472101943567395, 0.002476147376000881, 0.0025204753037542105, 0.0023682427126914263, 0.002350098453462124, 0.0022998217027634382, 0.0022870388347655535, 0.002373662544414401, 0.0022390300873667, 0.0021638022735714912, 0.0022467216476798058, 0.0021169830579310656, 0.0020782898645848036, 0.0021288571879267693, 0.14092949032783508, 0.0019829764496535063, 0.002029657829552889, 0.002013184130191803, 0.0020377314649522305, 0.0019657027442008257, 0.002054239623248577, 0.002073773415759206, 0.002187131904065609, 0.0019077560864388943, 0.0019713970832526684, 0.002026611240580678, 0.0021034437231719494, 0.001929383841343224, 0.0018782182596623898, 0.001788218622095883, 0.0019529219716787338, 0.0018305301200598478, 0.0017937078373506665, 0.0017295057186856866, 0.001676754909567535, 0.0016473907744511962, 0.0016837380826473236, 0.0954049825668335, 0.001552284462377429, 0.12912946939468384, 0.001623347750864923, 0.0017808802658692002, 0.002260732464492321, 0.14613553881645203, 0.0020098150707781315, 0.0020494426134973764, 0.0023306983057409525, 0.0022948516998440027, 0.0022587294224649668, 0.0022456359583884478, 0.0023422257509082556, 0.002462463453412056, 0.0024943745229393244, 0.002613763092085719, 0.002354904543608427, 0.0026985243894159794, 0.002492442261427641, 0.0022845349740236998, 0.002530320780351758, 0.0024000713601708412, 0.002406122861430049, 0.07302632182836533, 0.0022533806040883064, 0.10465946793556213, 0.0025502031203359365, 0.0024115736596286297, 0.07975573092699051, 0.002690202323719859, 0.0029092428740113974, 0.002784758573397994, 0.0033463924191892147, 0.0029956542421132326, 0.11709534376859665, 0.003961716312915087, 0.0033939226996153593, 0.002985358703881502, 0.0031918762251734734, 0.003989615477621555, 0.0029636125545948744, 0.003358465852215886, 0.003376071574166417, 0.0035609910264611244, 0.05351933836936951, 0.0035765692591667175, 0.002957895863801241, 0.0032656299881637096, 0.002984823891893029, 0.003270573914051056, 0.003196494420990348, 0.10377535223960876, 0.08918936550617218, 0.0034637374337762594, 0.13770592212677002, 0.0032587270252406597, 0.003622002201154828, 0.1456047147512436, 0.003567454405128956, 0.0037420615553855896, 0.33121258020401, 0.004269360098987818, 0.00433068023994565, 0.004717595875263214, 0.004919645842164755, 0.004201205912977457, 0.004946034401655197, 0.21649599075317383, 0.004466658923774958, 0.005441803950816393, 0.005440122913569212, 0.004532172344624996, 0.1202823668718338, 0.1713256686925888, 0.004678945057094097, 0.005205695051699877, 0.12405817210674286, 0.00486893393099308, 0.004985705949366093, 0.005418920889496803, 0.005101325921714306, 0.00507283303886652, 0.005047954153269529, 0.0049727498553693295, 0.12811274826526642, 0.11185503005981445, 0.0055214655585587025, 0.005019415635615587, 0.005221026949584484, 0.08722994476556778, 0.005411271471530199, 0.005435622297227383, 0.07721878588199615, 0.0054771630093455315, 0.11103212088346481, 0.0056079900823533535, 0.11389508843421936, 0.005690873134881258, 0.07499004900455475, 0.0057734339497983456, 0.17835396528244019, 0.006433455739170313, 0.006710456218570471, 0.006858705077320337, 0.00633631506934762, 0.006372537929564714, 0.0068506584502756596, 0.006430154200643301, 0.00649303151294589, 0.005897392984479666, 0.006005844101309776, 0.005472713150084019, 0.0054136100225150585, 0.005530484486371279, 0.005187425296753645, 0.005054134409874678, 0.15985386073589325, 0.004666888155043125, 0.004491833969950676, 0.004409103654325008, 0.004663902334868908, 0.004100481513887644, 0.08457501977682114, 0.003960621543228626, 0.15610195696353912, 0.00446893647313118, 0.004118168260902166, 0.0038672853261232376, 0.16224487125873566, 0.004066350869834423, 0.004431646782904863, 0.1258256733417511, 0.00433244276791811, 0.0042314184829592705, 0.11109300702810287, 0.004851981066167355, 0.08526333421468735, 0.004936329089105129, 0.0048388149589300156, 0.004863181617110968, 0.0050666313618421555, 0.004909144714474678, 0.00546049140393734, 0.0050883106887340546, 0.004782178904861212, 0.005138003267347813, 0.004971682094037533, 0.00484140170738101, 0.11692505329847336, 0.0044907936826348305, 0.0043678912334144115, 0.004452442284673452, 0.004239826463162899, 0.0044876569882035255, 0.0041192201897501945, 0.004046472255140543, 0.004065532702952623, 0.004157980438321829, 0.08395695686340332, 0.0035758500453084707, 0.003489635419100523, 0.13324536383152008, 0.003700335044413805, 0.003553690854460001, 0.0037568379193544388, 0.17606794834136963, 0.003586728125810623, 0.00427551195025444, 0.003747454844415188, 0.0038869427517056465, 0.003878121729940176, 0.003608080092817545, 0.003499936545267701, 0.11385944485664368, 0.0035448595881462097, 0.003675278276205063, 0.0037599995266646147, 0.0038228111807256937, 0.003479813691228628, 0.0034514053259044886, 0.003478565253317356, 0.003718152642250061, 0.0037134652957320213, 0.003559422679245472, 0.0032866932451725006, 0.003307721810415387, 0.003120334818959236, 0.0030934398528188467, 0.1126340851187706, 0.0031498726457357407, 0.1403614729642868, 0.003133700927719474, 0.0029859428759664297, 0.0028767536859959364, 0.003094171406701207, 0.0029544455464929342, 0.003038709983229637, 0.0030140515882521868, 0.0030939914286136627, 0.0031238177325576544, 0.003276530187577009, 0.0030020540580153465, 0.0027117072604596615, 0.0029896842315793037, 0.0027701633516699076, 0.47808507084846497, 0.002806337783113122, 0.003105649957433343, 0.0032966374419629574, 0.003288817824795842, 0.0036320469807833433, 0.0033667890820652246, 0.0035884298849850893, 0.0036695722956210375, 0.0035617349203675985, 0.0038549299351871014, 0.11151191592216492, 0.003692042548209429, 0.003698482410982251, 0.003691233927384019, 0.003825119463726878, 0.003918017726391554, 0.004185434430837631, 0.0040337578393518925, 0.003638036549091339, 0.00381294172257185, 0.003887489438056946, 0.003409703029319644, 0.0033935965038836002, 0.0032584231812506914, 0.003216442186385393, 0.0032963906414806843, 0.0032009005080908537, 0.0032054211478680372, 0.003433333244174719, 0.0030802336987107992, 0.0026900835800915956, 0.002714249538257718, 0.0025763879530131817, 0.002731994027271867, 0.002475131070241332, 0.0023189347703009844, 0.002285464433953166, 0.17106157541275024, 0.002460668794810772, 0.0024527099449187517, 0.0023844228126108646, 0.002292518736794591, 0.002183995908126235, 0.5736352205276489, 0.002568709198385477, 0.0026243727188557386, 0.002956666285172105, 0.0033415392972528934, 0.003230790141969919, 0.003210719209164381, 0.003200025297701359, 0.12717856466770172, 0.003863137448206544, 0.00391274644061923, 0.003783133579418063, 0.003959883004426956, 0.0038931970484554768, 0.003963884431868792, 0.003929318860173225, 0.09884323179721832, 0.004189385566860437, 0.003989976365119219, 0.004271992482244968, 0.0040492406114935875, 0.004851834382861853, 0.00425785081461072, 0.004280409775674343, 0.0038529573939740658, 0.11307422071695328, 0.003798755817115307, 0.003849032334983349, 0.003806554712355137, 0.003967976663261652, 0.003951969090849161, 0.003912557382136583, 0.004326993133872747, 0.1413700133562088, 0.003720262087881565, 0.0036036085803061724, 0.003455567639321089, 0.003658400382846594, 0.0035768654197454453, 0.003560246666893363, 0.003432235447689891, 0.12276948988437653, 0.0032999892719089985, 0.0035950089804828167, 0.07685501873493195, 0.0036663184873759747, 0.003455338068306446, 0.0035259523428976536, 0.003571917302906513, 0.0038159782998263836, 0.0033896227832883596, 0.003563724225386977, 0.0035689882934093475, 0.003359950613230467, 0.003471540752798319, 0.003555646864697337, 0.0031564661767333746, 0.0032384307123720646, 0.003011550987139344, 0.10591533035039902, 0.0029275892302393913, 0.0028963815420866013, 0.0030562011525034904, 0.00292013818398118, 0.0029266802594065666, 0.002870578318834305, 0.0029728682711720467, 0.002802946837618947, 0.09215208142995834, 0.0027433629147708416, 0.002754665445536375, 0.0026226004119962454, 0.0026375981979072094, 0.0027467594482004642, 0.00261271302588284, 0.002751579275354743, 0.0026345495134592056, 0.0025145222898572683, 0.002532379701733589, 0.0024851488415151834, 0.002442606259137392, 0.002306275302544236, 0.002509868238121271, 0.0022147574927657843, 0.002217911183834076, 0.0022022405173629522, 0.00215929071418941, 0.002323367167264223, 0.00205743545666337, 0.001994329271838069, 0.0019666480366140604, 0.0019482991192489862, 0.10369265824556351, 0.002001214539632201, 0.0020350192207843065, 0.001912259147502482, 0.0020023961551487446, 0.002056797966361046, 0.0019366326741874218, 0.0019356441916897893, 0.00215463200584054, 0.0020774316508322954, 0.0018713191384449601, 0.0018588202074170113, 0.0017815303290262818, 0.001708379597403109, 0.0017879408551380038, 0.0017756372690200806, 0.001597983529791236, 0.0017120876582339406, 0.0015765941934660077, 0.001653033890761435, 0.0018210535636171699, 0.0014573425287380815, 0.0014233848778530955, 0.0015304087428376079, 0.001524031045846641, 0.0014386462280526757, 0.0013442315394058824, 0.00135128665715456, 0.0014870158629491925, 0.0014447274152189493, 0.001295887166634202, 0.16077375411987305, 0.0012541016330942512, 0.0014231544919312, 0.0013564594555646181, 0.0013354194816201925, 0.001494326163083315, 0.001504562678746879, 0.0014191506197676063, 0.001389988698065281, 0.001370901707559824, 0.0013477734755724669, 0.0015282384119927883, 0.0014744645450264215, 0.0014304786454886198, 0.0013028254033997655, 0.0013246717862784863, 0.001440605497919023, 0.0012990625109523535, 0.0013003547210246325, 0.001270463690161705, 0.0012479393044486642, 0.0013674726942554116, 0.0012752009788528085, 0.0012129286769777536, 0.0011760129127651453, 0.14425452053546906, 0.001379589200951159, 0.001341725466772914, 0.0013078118208795786, 0.0014529800973832607, 0.001318125519901514, 0.0012805245351046324, 0.0012888081837445498, 0.20981070399284363, 0.0013774175895377994, 0.0014918902888894081, 0.0016598993679508567, 0.0014726760564371943, 0.0014954040525481105, 0.0018588399980217218, 0.001772487536072731, 0.10886167734861374, 0.0017045327695086598, 0.0016346322372555733, 0.0017167723271995783, 0.0017520387191325426, 0.0018851038767024875, 0.001865781145170331, 0.001983596244826913, 0.001986571354791522, 0.001980193192139268, 0.0020127419847995043, 0.0018403121503069997, 0.0018518792930990458, 0.0019975032191723585, 0.0021896502003073692, 0.002171281259506941, 0.0020556116942316294, 0.0018562976038083434, 0.0018122228793799877, 0.0018219330813735723, 0.0017142496071755886, 0.0017921807011589408, 0.0017767134122550488, 0.0016148739960044622, 0.0017109536565840244, 0.0016006202204152942, 0.001714031328447163, 0.0015363501152023673, 0.001663932460360229, 0.0014989175833761692, 0.0016670734621584415, 0.0016984117683023214, 0.0015058796852827072, 0.00145392504055053, 0.0013410275569185615, 0.1381218433380127, 0.0014570384519174695, 0.0014158901758491993, 0.0014033663319423795, 0.15874813497066498, 0.0016168701695278287, 0.001611648011021316, 0.0015577368903905153, 0.001750833005644381, 0.15388822555541992, 0.0018236048053950071, 0.0019846109207719564, 0.13621006906032562, 0.002180511364713311, 0.002140540163964033, 0.0021848841570317745, 0.0024648138787597418, 0.0023404653184115887, 0.002550724893808365, 0.0025222417898476124, 0.0026104820426553488, 0.002571685705333948, 0.12635289132595062, 0.002809603465721011, 0.15326616168022156, 0.15233463048934937, 0.003450741758570075, 0.17067067325115204, 0.0036354137118905783, 0.003582610981538892, 0.00412376131862402, 0.004354551434516907, 0.004309636075049639, 0.004175916779786348, 0.10893263667821884, 0.004576578736305237, 0.005041684024035931, 0.004660776816308498, 0.00486220046877861, 0.00482914550229907, 0.00496671674773097, 0.0047189355827867985, 0.13315661251544952, 0.004819198977202177, 0.004937355872243643, 0.004788183607161045, 0.0049044182524085045, 0.0050955903716385365, 0.004935304634273052, 0.00450283195823431, 0.004547598771750927, 0.004599994048476219, 0.004258619621396065, 0.00438070110976696, 0.004019222687929869, 0.1342511922121048, 0.004178280010819435, 0.0038202963769435883, 0.004107655957341194, 0.0038959258235991, 0.14662356674671173, 0.004065252840518951, 0.003930137492716312, 0.003908590879291296, 0.0038167540915310383, 0.003661827649921179, 0.003746360307559371, 0.19738872349262238, 0.0036310108844190836, 0.12181965261697769, 0.003976809326559305, 0.003775401273742318, 0.003856030758470297, 0.003993615508079529, 0.0038722509052604437, 0.003949070814996958, 0.003808430163189769, 0.0037813931703567505, 0.1413145810365677, 0.003818671917542815, 0.13685967028141022, 0.003914008382707834, 0.003913463093340397, 0.004197114612907171, 0.004144747741520405, 0.004021547269076109, 0.10634857416152954, 0.00412743492051959, 0.004224003758281469, 0.004252261016517878, 0.004168190527707338, 0.004174964502453804, 0.0042212060652673244, 0.004098220728337765, 0.004002606030553579, 0.003938926383852959, 0.0039051324129104614, 0.0038911618757992983, 0.003779683029279113, 0.003656086977571249, 0.16382861137390137, 0.11512014269828796, 0.0035671975929290056, 0.0036152885295450687, 0.0037765500601381063, 0.003715370548889041, 0.11878789216279984, 0.0037704112473875284, 0.003992157988250256, 0.00403971690684557, 0.004051256459206343, 0.004048144444823265, 0.0039344835095107555, 0.0040024337358772755, 0.003893244545906782, 0.003780017141252756, 0.10592499375343323, 0.003749560797587037, 0.15254078805446625, 0.00387153890915215, 0.07877957820892334, 0.0040527149103581905, 0.14793924987316132, 0.004338439553976059, 0.004318417515605688, 0.004453815054148436, 0.004698183853179216, 0.004673736169934273, 0.1037970781326294, 0.004723773337900639, 0.004938452038913965, 0.0048719532787799835, 0.00486143771559, 0.12098370492458344, 0.004915020894259214, 0.005170740187168121, 0.0052716354839503765, 0.12227199971675873, 0.4568261206150055, 0.005584249272942543, 0.005975600332021713, 0.08127246797084808, 0.006389674264937639, 0.006912734359502792, 0.007010853383690119, 0.00728185148909688, 0.007599215488880873, 0.007348314393311739, 0.007698526605963707, 0.007712858263403177, 0.007617041934281588, 0.007125981617718935, 0.007372076157480478, 0.007022335194051266, 0.006805118639022112, 0.006426134146749973, 0.006223300471901894, 0.006314173806458712, 0.005904849153012037, 0.13298240303993225, 0.005638013128191233, 0.10807027667760849, 0.0053448243997991085, 0.005272707436233759, 0.005227054003626108, 0.005133155267685652, 0.005044721998274326, 0.004907773341983557, 0.0047903102822601795, 0.004651888273656368, 0.004776122514158487, 0.004491714760661125, 0.004250491037964821, 0.004175759851932526, 0.420464426279068, 0.004217556677758694, 0.0044080703519284725, 0.004627934191375971, 0.004724437370896339, 0.004830454476177692, 0.005076862405985594, 0.004972596652805805, 0.00502580963075161, 0.0049055395647883415, 0.10209593176841736, 0.004975602496415377, 0.00509135564789176, 0.005021659657359123, 0.0049608610570430756, 0.004770929459482431, 0.004737494979053736, 0.004672566894441843, 0.0047380635514855385, 0.00449763098731637, 0.004480492789298296, 0.09387289732694626, 0.004296720493584871, 0.0042250510305166245, 0.004313708748668432, 0.004081318620592356, 0.004131676163524389, 0.00399889936670661, 0.003838411532342434, 0.003923737443983555, 0.003664433490484953, 0.003818623721599579, 0.003782141488045454, 0.003453915473073721, 0.10450892895460129, 0.003390707541257143, 0.0032671529334038496, 0.0032472028397023678, 0.003350748447701335, 0.0032370593398809433, 0.0031932571437209845, 0.0030756965279579163, 0.0029454634059220552, 0.0029375916346907616, 0.0029005154501646757, 0.002779788337647915, 0.0027301430236548185, 0.0028406225610524416, 0.10322382301092148, 0.002663444261997938, 0.0025896255392581224, 0.002760710660368204, 0.0025678505189716816, 0.002612943761050701, 0.0024754744954407215, 0.002610489958897233, 0.002458724891766906, 0.0024895770475268364, 0.0025483996141701937, 0.0023888282012194395, 0.0024813630152493715, 0.0022075313609093428, 0.0022759553976356983, 0.0022590255830436945, 0.0022120890207588673, 0.00206609140150249, 0.08491087704896927, 0.0021405427251011133, 0.0020355151500552893, 0.0020505141001194715, 0.0020799932535737753, 0.18003354966640472, 0.0020307230297476053, 0.10745017975568771, 0.0021772400941699743, 0.0022902132477611303, 0.002245259238407016, 0.002533625578507781, 0.0023721952456980944, 0.0024694206658750772, 0.11493659019470215, 0.0025827211793512106, 0.0026826998218894005, 0.0028519697953015566, 0.0026267983485013247, 0.002666443819180131, 0.09737342596054077, 0.002730605425313115, 0.0027924892492592335, 0.0030315949115902185, 0.0028442339971661568]\n",
            "Val loss 0.019813028440803737\n",
            "Val auc roc 0.4838643383818254\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "400a701433044609a3dd1279690dad06",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0214\n",
            "Train Losses : [0.0028714979998767376, 0.13859519362449646, 0.002911817980930209, 0.00318247452378273, 0.12088409811258316, 0.00339151406660676, 0.003492687363177538, 0.003214541357010603, 0.003388592042028904, 0.0034096734598279, 0.0033404354471713305, 0.003359975991770625, 0.0033902274444699287, 0.0034202574752271175, 0.0033311014994978905, 0.0034218935761600733, 0.003488765098154545, 0.003544487524777651, 0.003238493809476495, 0.0031732050701975822, 0.003282847348600626, 0.002984406193718314, 0.0032202776055783033, 0.00286685093306005, 0.0027753727044910192, 0.10933627188205719, 0.002903967397287488, 0.0028624669648706913, 0.0028884783387184143, 0.0027747186832129955, 0.0026236623525619507, 0.0027081428561359644, 0.002554583828896284, 0.002542527625337243, 0.0967579260468483, 0.0026349432300776243, 0.0026713514234870672, 0.002664837520569563, 0.002546165604144335, 0.0025251605547964573, 0.14054249227046967, 0.0025465080980211496, 0.0026816849131137133, 0.0027355742640793324, 0.002593747805804014, 0.002572671975940466, 0.002655919874086976, 0.0025451872497797012, 0.002566675655543804, 0.002507667988538742, 0.002601673360913992, 0.0027031449135392904, 0.0027457275427877903, 0.002607255009934306, 0.07899405807256699, 0.002471490763127804, 0.0023468032013624907, 0.0025104156229645014, 0.09656986594200134, 0.002503512194380164, 0.002633729251101613, 0.10240450501441956, 0.19344978034496307, 0.0026472292374819517, 0.002712597604840994, 0.0029827088583260775, 0.0030549801886081696, 0.0031711074989289045, 0.003297305665910244, 0.0032558785751461983, 0.0034029600210487843, 0.003454160178080201, 0.003404363989830017, 0.003105481853708625, 0.003419718937948346, 0.0032651827204972506, 0.003350398503243923, 0.0030347087886184454, 0.003099513705819845, 0.0029944146517664194, 0.003096899949014187, 0.0030825110152363777, 0.06933623552322388, 0.0029205121099948883, 0.003109073732048273, 0.002685471437871456, 0.0027949605137109756, 0.0029746529180556536, 0.002759875962510705, 0.0027755287010222673, 0.12927396595478058, 0.002677844138815999, 0.0027608037926256657, 0.002542539732530713, 0.002750117564573884, 0.473337858915329, 0.003143565496429801, 0.0030952468514442444, 0.08691868931055069, 0.0033581287134438753, 0.004039972089231014, 0.003757408121600747, 0.004041816107928753, 0.004117423202842474, 0.004333983175456524, 0.0042155226692557335, 0.004560173023492098, 0.004747574217617512, 0.0044141970574855804, 0.004252173937857151, 0.004252864979207516, 0.004792972467839718, 0.004240496549755335, 0.004377387464046478, 0.004302648361772299, 0.004144128877669573, 0.37442538142204285, 0.004271800629794598, 0.00442641694098711, 0.004751694388687611, 0.004612189717590809, 0.005295563023537397, 0.0052849226631224155, 0.005775311030447483, 0.0051561761647462845, 0.1301848590373993, 0.005069264210760593, 0.005649060942232609, 0.005542575381696224, 0.005056924652308226, 0.005084012169390917, 0.004997268319129944, 0.005097285844385624, 0.005117981228977442, 0.005173482000827789, 0.0045730192214250565, 0.0045595248229801655, 0.005263255909085274, 0.004373183473944664, 0.004944787826389074, 0.004202598240226507, 0.004484078846871853, 0.004060336388647556, 0.13679775595664978, 0.003884823527187109, 0.003874989226460457, 0.0036595668643712997, 0.0035875209141522646, 0.0034336126409471035, 0.003707056399434805, 0.0033890746999531984, 0.0038385181687772274, 0.1583007127046585, 0.003143966430798173, 0.003331630490720272, 0.003599837888032198, 0.0032849141862243414, 0.003273922950029373, 0.003330671926960349, 0.0031059500761330128, 0.003468034090474248, 0.0029387581162154675, 0.18218941986560822, 0.0029442261438816786, 0.0031947772949934006, 0.49111929535865784, 0.0032679419964551926, 0.0035725743509829044, 0.003550073131918907, 0.0038621174171566963, 0.10478493571281433, 0.004321413114666939, 0.004569828510284424, 0.004238747525960207, 0.004697422031313181, 0.00435966020449996, 0.004728788509964943, 0.15718083083629608, 0.40602055191993713, 0.139273539185524, 0.005619395058602095, 0.006030186545103788, 0.006069157738238573, 0.10458674281835556, 0.007215453311800957, 0.0072638969868421555, 0.11245394498109818, 0.008046875707805157, 0.007954704575240612, 0.008567830547690392, 0.008561261929571629, 0.008479448966681957, 0.008486036211252213, 0.00830418523401022, 0.009031841531395912, 0.008260523900389671, 0.008344864472746849, 0.0075500160455703735, 0.007890653796494007, 0.007723167538642883, 0.007298436015844345, 0.007313553709536791, 0.45965176820755005, 0.007334152702242136, 0.006766409147530794, 0.007329776883125305, 0.39476487040519714, 0.007291601505130529, 0.00754129234701395, 0.007799210026860237, 0.008172387257218361, 0.00819961167871952, 0.08600717782974243, 0.008653011173009872, 0.009101334027945995, 0.11599061638116837, 0.13028651475906372, 0.008872454054653645, 0.009386944584548473, 0.008807468228042126, 0.008855520747601986, 0.009078007191419601, 0.11839050054550171, 0.008661900646984577, 0.008548447862267494, 0.008211435750126839, 0.008627482689917088, 0.008285940624773502, 0.007895182818174362, 0.007591551635414362, 0.007561212405562401, 0.007047372404485941, 0.07257925719022751, 0.006738028023391962, 0.006560312118381262, 0.00641236687079072, 0.006130077410489321, 0.00616098428145051, 0.005823335610330105, 0.0059877424500882626, 0.005565731320530176, 0.005613469984382391, 0.005129409953951836, 0.004905308596789837, 0.004775357432663441, 0.004771340172737837, 0.004454426001757383, 0.004161719232797623, 0.004167117644101381, 0.004136533476412296, 0.0038225052412599325, 0.0038016189355403185, 0.00377042219042778, 0.0035606955643743277, 0.0033678305335342884, 0.003189561190083623, 0.003156527876853943, 0.00309548806399107, 0.0029942605178803205, 0.16977542638778687, 0.0029569072648882866, 0.002887844340875745, 0.0027713074814528227, 0.0027536721900105476, 0.00278094713576138, 0.0027120676822960377, 0.15555323660373688, 0.002669059671461582, 0.12301518023014069, 0.11564941704273224, 0.13459421694278717, 0.002912491327151656, 0.0031751191709190607, 0.0032252995297312737, 0.0032917296048253775, 0.0033875086810439825, 0.0034187561832368374, 0.0034872861579060555, 0.0035970790777355433, 0.003557831048965454, 0.0035732323303818703, 0.0035014671739190817, 0.0035448085982352495, 0.003676255699247122, 0.0034819403663277626, 0.0035003051161766052, 0.0035404691006988287, 0.003342112060636282, 0.0032537535298615694, 0.003204614156857133, 0.003160899505019188, 0.0031485361978411674, 0.0031243283301591873, 0.003071269253268838, 0.0029121716506779194, 0.002941560698673129, 0.0029791747219860554, 0.0027995742857456207, 0.0029612730722874403, 0.0026809703558683395, 0.002836397383362055, 0.002617947291582823, 0.15405750274658203, 0.0024978676810860634, 0.0026346095837652683, 0.0025478918105363846, 0.002526130760088563, 0.002545721363276243, 0.0024249334819614887, 0.002512871054932475, 0.0024587654042989016, 0.0023710383102297783, 0.002417248673737049, 0.002375891664996743, 0.0023877560161054134, 0.0024812009651213884, 0.00227790093049407, 0.002215647604316473, 0.1314501166343689, 0.0022667665034532547, 0.002230219077318907, 0.002175725530833006, 0.0022658230736851692, 0.0022298062685877085, 0.0021910432260483503, 0.002191115403547883, 0.0021328325383365154, 0.0023514702916145325, 0.0021627123933285475, 0.00211975141428411, 0.16305458545684814, 0.12540274858474731, 0.0022073499858379364, 0.002248764969408512, 0.002242644317448139, 0.002364818472415209, 0.0023629656061530113, 0.15817397832870483, 0.12474505603313446, 0.002553594531491399, 0.0026913988403975964, 0.0027920641005039215, 0.11143386363983154, 0.003031803062185645, 0.4034620225429535, 0.0033636298030614853, 0.0038188679609447718, 0.0038834416773170233, 0.004116126336157322, 0.004357044119387865, 0.14456187188625336, 0.004899390507489443, 0.0052073304541409016, 0.00541080255061388, 0.0053057558834552765, 0.17429830133914948, 0.005804205313324928, 0.005820568650960922, 0.005850645713508129, 0.005996897350996733, 0.005973081570118666, 0.10461410135030746, 0.006122643128037453, 0.0061754691414535046, 0.006163541227579117, 0.006140756420791149, 0.00607760064303875, 0.005974940024316311, 0.005932297557592392, 0.005748456809669733, 0.0058270907029509544, 0.005679034627974033, 0.00579053582623601, 0.005307292100042105, 0.005242480430752039, 0.11003605276346207, 0.005044625606387854, 0.004999470431357622, 0.004866347182542086, 0.004841793328523636, 0.004918017890304327, 0.004654337652027607, 0.004565290175378323, 0.004393723793327808, 0.004336782265454531, 0.004270986188203096, 0.004062856547534466, 0.003961360082030296, 0.003905905643478036, 0.00384620763361454, 0.1053178682923317, 0.0036135991103947163, 0.0035812710411846638, 0.0035981168039143085, 0.0035208058543503284, 0.0034114480949938297, 0.0034323979634791613, 0.0033588334918022156, 0.0032162813004106283, 0.14027316868305206, 0.003196404315531254, 0.11397518217563629, 0.003328380174934864, 0.08188220858573914, 0.003227264154702425, 0.0033564106561243534, 0.0034179585054516792, 0.0034995446912944317, 0.003566105617210269, 0.003455833997577429, 0.1499224454164505, 0.0034317271783947945, 0.003449824405834079, 0.003476211102679372, 0.0037530569825321436, 0.003524849656969309, 0.0035026867408305407, 0.0035676041152328253, 0.0035481094382703304, 0.0034947649110108614, 0.14918363094329834, 0.0034643805120140314, 0.003504781285300851, 0.0034399337600916624, 0.003484682645648718, 0.13851509988307953, 0.00349636422470212, 0.003485250985249877, 0.10610181838274002, 0.003537491662427783, 0.0036031613126397133, 0.003605905454605818, 0.0036230399273335934, 0.003797926940023899, 0.0037998503539711237, 0.0036403825506567955, 0.0037172329612076283, 0.0036285719834268093, 0.0035467802081257105, 0.003593627130612731, 0.0035628085024654865, 0.0035485532134771347, 0.0035417196340858936, 0.0034309723414480686, 0.0034296459052711725, 0.003206767840310931, 0.003248438239097595, 0.003092397004365921, 0.11002061516046524, 0.0030953707173466682, 0.0031105142552405596, 0.0032299254089593887, 0.0029759767930954695, 0.0029912942554801702, 0.0032219719141721725, 0.15917113423347473, 0.0029162743594497442, 0.002929076785221696, 0.11542114615440369, 0.002990223001688719, 0.0029756887815892696, 0.0030587082728743553, 0.0031082634814083576, 0.0032031890004873276, 0.0030398883391171694, 0.0029697201680392027, 0.0030439309775829315, 0.0030502737499773502, 0.0030493070371448994, 0.002908704336732626, 0.0029601948335766792, 0.0028916029259562492, 0.0031056732404977083, 0.002759176306426525, 0.0027285576798021793, 0.0026897189673036337, 0.002674334915354848, 0.0026517477817833424, 0.002602056600153446, 0.002607767703011632, 0.13794510066509247, 0.0025184412952512503, 0.002473353175446391, 0.0024979824665933847, 0.0025063075590878725, 0.0024915337562561035, 0.1320517361164093, 0.00255785440094769, 0.0024830095935612917, 0.153898686170578, 0.0025888336822390556, 0.002735347021371126, 0.00282449834048748, 0.0028625300619751215, 0.002813158091157675, 0.0028379049617797136, 0.002921361243352294, 0.0027713256422430277, 0.002879016799852252, 0.0028213593177497387, 0.0028639514930546284, 0.002816674066707492, 0.00272944662719965, 0.0028161779046058655, 0.0026829680427908897, 0.002719916170462966, 0.0026779479812830687, 0.0025552082806825638, 0.002636351389810443, 0.0025483500212430954, 0.00252213841304183, 0.002453569322824478, 0.0024938012938946486, 0.0024108923971652985, 0.002374486066401005, 0.08952323347330093, 0.002267449162900448, 0.0022406899370253086, 0.002289747353643179, 0.0023079237435013056, 0.0022302258294075727, 0.0022711032070219517, 0.0023305427748709917, 0.002183126052841544, 0.0021830350160598755, 0.002112935297191143, 0.002079971833154559, 0.0020515304058790207, 0.0020305898506194353, 0.002056946512311697, 0.0019860221073031425, 0.001941370777785778, 0.0019654654897749424, 0.0019452226115390658, 0.0018919430440291762, 0.0018615395529195666, 0.00187824503518641, 0.001794060692191124, 0.001833035727031529, 0.0017366268439218402, 0.0017017589416354895, 0.13840825855731964, 0.0017539100954309106, 0.001827017404139042, 0.001772096729837358, 0.0017683154437690973, 0.0018029318889603019, 0.001768959336914122, 0.0017029629088938236, 0.0017320627812296152, 0.0017438450595363975, 0.00171743577811867, 0.0017441853415220976, 0.0016346961492672563, 0.0016458608442917466, 0.0016343402676284313, 0.0016510030254721642, 0.0016202711267396808, 0.0015964373014867306, 0.0015872926451265812, 0.0015763224801048636, 0.12334631383419037, 0.0016545569524168968, 0.15886421501636505, 0.0016824229387566447, 0.0016660724068060517, 0.13777820765972137, 0.0018670690478757024, 0.0018646970856934786, 0.0020235690753906965, 0.0019838172011077404, 0.00203535589389503, 0.002047924790531397, 0.16794893145561218, 0.002212104620411992, 0.0022608970757573843, 0.002285380382090807, 0.0023597923573106527, 0.002410896122455597, 0.0023541792761534452, 0.0024056341499090195, 0.0023947760928422213, 0.002480832627043128, 0.0025145430117845535, 0.0024420125409960747, 0.002420989330857992, 0.0025194091722369194, 0.002452014246955514, 0.0024675324093550444, 0.002394510665908456, 0.00246915640309453, 0.0024140807799994946, 0.002339038299396634, 0.1308182179927826, 0.002316228346899152, 0.14043933153152466, 0.0023911711759865284, 0.0024333803448826075, 0.0025206778664141893, 0.0025079259648919106, 0.0024959444999694824, 0.0025184580590575933, 0.002567755291238427, 0.0025665732100605965, 0.0025611435994505882, 0.002479787217453122, 0.0024978613946586847, 0.0024623065255582333, 0.1585652232170105, 0.0026587885804474354, 0.00267866556532681, 0.002509800251573324, 0.1520373374223709, 0.14381949603557587, 0.002776504261419177, 0.0027851792983710766, 0.10306993871927261, 0.0029772233683615923, 0.0031211376190185547, 0.0032184647861868143, 0.003264450468122959, 0.003325741970911622, 0.0033215838484466076, 0.0033540520817041397, 0.00350378779694438, 0.0035365072544664145, 0.003403429174795747, 0.0033796082716435194, 0.0033045413438230753, 0.003293415065854788, 0.0033072400838136673, 0.003374840132892132, 0.003197668120265007, 0.0033173917327076197, 0.0031649635639041662, 0.0031018154695630074, 0.0031786111649125814, 0.1339358389377594, 0.1301712542772293, 0.003090339247137308, 0.003090890124440193, 0.0032038262579590082, 0.003188303206115961, 0.0031540445052087307, 0.003170269075781107, 0.0032549998722970486, 0.003319535171613097, 0.003259509801864624, 0.0031779399141669273, 0.003086839569732547, 0.0031395386904478073, 0.0031133980955928564, 0.0029675900004804134, 0.002968959277495742, 0.0029832241125404835, 0.002862014574930072, 0.002830268582329154, 0.002831630175933242, 0.0027472309302538633, 0.12884171307086945, 0.0027287225238978863, 0.002743175718933344, 0.002795121632516384, 0.0027005760930478573, 0.002629878930747509, 0.13257858157157898, 0.002634169301018119, 0.14394161105155945, 0.11874131858348846, 0.002853004029020667, 0.0030449340119957924, 0.002995425136759877, 0.0030775407794862986, 0.0031148153357207775, 0.0032889314461499453, 0.003269361099228263, 0.0031882168259471655, 0.0032167001627385616, 0.0032658474519848824, 0.11572124063968658, 0.003228031098842621, 0.0033574076369404793, 0.003295202273875475, 0.003323015058413148, 0.003485559020191431, 0.0034818367566913366, 0.0034157338086515665, 0.0032715387642383575, 0.0032400859054178, 0.003205342683941126, 0.003291705157607794, 0.0031940252520143986, 0.0031465899664908648, 0.003048865357413888, 0.10532281547784805, 0.002992779016494751, 0.0029833721928298473, 0.003086481709033251, 0.0029531046748161316, 0.0029888523276895285, 0.0028958001639693975, 0.0028979708440601826, 0.0030125051271170378, 0.0027897905092686415, 0.0029875943437218666, 0.0027381302788853645, 0.002717314288020134, 0.0026813307777047157, 0.002570428652688861, 0.002571301069110632, 0.0025705902371555567, 0.0024582974147051573, 0.002430081833153963, 0.002409272128716111, 0.0023362392093986273, 0.14044998586177826, 0.13621793687343597, 0.11135011911392212, 0.0024442465510219336, 0.0025769092608243227, 0.10036060959100723, 0.002677873009815812, 0.0028384437318891287, 0.0029399350751191378, 0.0029330162797123194, 0.003150353441014886, 0.003082837676629424, 0.0031727617606520653, 0.0031680779065936804, 0.003134246217086911, 0.003094895277172327, 0.0031900727190077305, 0.003095359541475773, 0.0031069081742316484, 0.003062926698476076, 0.0030986156780272722, 0.0029953382909297943, 0.002978091361001134, 0.0029654069803655148, 0.10657167434692383, 0.13573575019836426, 0.002985752420499921, 0.0030371539760380983, 0.0030659742187708616, 0.003078198293223977, 0.003077588276937604, 0.0031082050409168005, 0.003129761666059494, 0.0030803459230810404, 0.0031150244176387787, 0.0030900510028004646, 0.003076165681704879, 0.0031302785500884056, 0.002949629444628954, 0.0029751399997621775, 0.0028563826344907284, 0.002974322997033596, 0.002817336702719331, 0.002841457026079297, 0.0026966803707182407, 0.0027085510082542896, 0.1580563336610794, 0.002639398444443941, 0.0026357269380241632, 0.0027307120617479086, 0.0026227326598018408, 0.0026984454598277807, 0.00260535697452724, 0.11788255721330643, 0.0026125581935048103, 0.0026091067120432854, 0.002666599815711379, 0.0026938635855913162, 0.11097903549671173, 0.002754857297986746, 0.002760233823210001, 0.0027809611055999994, 0.002784647746011615, 0.002853767015039921, 0.0028607824351638556, 0.12807950377464294, 0.4665423035621643, 0.13188549876213074, 0.003420712426304817, 0.0036030367482453585, 0.003932131454348564, 0.004020974040031433, 0.004207735415548086, 0.004507386591285467, 0.004509188234806061, 0.004591567907482386, 0.004839184693992138, 0.004707442596554756, 0.004885035566985607, 0.004858449567109346, 0.1065378412604332, 0.005038565024733543, 0.005102499853819609, 0.12349104881286621, 0.004975166171789169, 0.362215518951416, 0.005396229214966297, 0.005699255503714085, 0.005934412125498056, 0.006182000506669283, 0.006288588512688875, 0.006283900700509548, 0.006408599205315113, 0.006521829403936863, 0.0064195008017122746, 0.006539967842400074, 0.0965779647231102, 0.006528861820697784, 0.158062145113945, 0.00663773063570261, 0.0065359012223780155, 0.006440894212573767, 0.11255837231874466, 0.006546017713844776, 0.11857399344444275, 0.007152366917580366, 0.006624103523790836, 0.006818993482738733, 0.006495452951639891, 0.006496604066342115, 0.006429292261600494, 0.006359913386404514, 0.006185803562402725, 0.006227853242307901, 0.005958396941423416, 0.005833456292748451, 0.005808813497424126, 0.005707285366952419, 0.11087623983621597, 0.005574997514486313, 0.005334836430847645, 0.005362863186746836, 0.005092070437967777, 0.12355347722768784, 0.004935168195515871, 0.005012819077819586, 0.00499879801645875, 0.004855462349951267, 0.09449703991413116, 0.004757263697683811, 0.004694515373557806, 0.004625694360584021, 0.004617151338607073, 0.004546415992081165, 0.004662043415009975, 0.0044843475334346294, 0.004367663990706205, 0.004214777145534754, 0.004194479435682297, 0.004071471281349659, 0.003951192367821932, 0.003951779566705227, 0.003869371023029089, 0.0037401681765913963, 0.0036471174098551273, 0.0037398263812065125, 0.0034879788290709257, 0.0034566225949674845, 0.0033504189923405647, 0.0032387380488216877, 0.0032329608220607042, 0.0031506249215453863, 0.13665921986103058, 0.00302385026589036, 0.003250213572755456, 0.002959273988381028, 0.002956806216388941, 0.0029050090815871954, 0.16641643643379211, 0.09571265429258347, 0.0029971462208777666, 0.12851522862911224, 0.0030519443098455667, 0.0030718380585312843, 0.1395600587129593, 0.003407815471291542, 0.0035426365211606026, 0.0033941445872187614, 0.0034581797663122416, 0.003622873453423381, 0.003634860971942544, 0.003570915199816227, 0.003601088421419263, 0.0035674353130161762, 0.0036978586576879025, 0.0036217598244547844, 0.003662482835352421, 0.0034556996542960405, 0.0034534879960119724, 0.13169601559638977, 0.0034350946079939604, 0.0034444332122802734, 0.4406984746456146, 0.003620954928919673, 0.004022323526442051, 0.0040606348775327206, 0.004264487884938717, 0.004208160098642111, 0.0043265800923109055, 0.0043258750811219215, 0.004438094794750214, 0.004419056698679924, 0.004441984463483095, 0.09048487991094589, 0.004610387608408928, 0.004508577287197113, 0.004668813664466143, 0.004604059271514416, 0.13547755777835846, 0.09894025325775146, 0.004880466498434544, 0.004773315507918596, 0.00473268236964941, 0.004822352435439825, 0.004798527341336012, 0.0047985040582716465, 0.14418970048427582, 0.004786258097738028, 0.1359933763742447, 0.005051339045166969, 0.004832706414163113, 0.005107259843498468, 0.005010085180401802, 0.004838408902287483, 0.004879166837781668, 0.004871309269219637, 0.005006100982427597, 0.004795977380126715, 0.004615893121808767, 0.004729737993329763, 0.004505247808992863, 0.004482216667383909, 0.004615486599504948, 0.004220997914671898, 0.004307540133595467, 0.004263577051460743, 0.0039865318685770035, 0.09557954221963882, 0.003958812449127436, 0.003845623694360256, 0.15280723571777344, 0.0037799538113176823, 0.003807052271440625, 0.003782927058637142, 0.003725845366716385, 0.0037156054750084877, 0.0036797348875552416, 0.0037473225966095924, 0.0036376737989485264, 0.0036042092833667994, 0.003695546416565776, 0.11859116703271866, 0.11106835305690765, 0.0035676565021276474, 0.0036967326886951923, 0.0035160372499376535, 0.003647656412795186, 0.0035091459285467863, 0.003497086698189378, 0.00357691734097898, 0.0035264799371361732, 0.0034588538110256195, 0.0033959192223846912, 0.10509798675775528, 0.12030243873596191, 0.003420124528929591, 0.10849866271018982, 0.0035118365194648504, 0.0036252103745937347, 0.09237257391214371, 0.00369483744725585, 0.003875488881021738, 0.0038625739980489016, 0.004002634901553392, 0.003950948361307383, 0.003924881108105183, 0.003970613703131676, 0.003947331104427576, 0.003877304494380951, 0.003855813294649124, 0.0039054465014487505, 0.003796845441684127, 0.0038925502449274063, 0.0037426080089062452, 0.0036978963762521744, 0.003611734602600336, 0.0035970525350421667, 0.0035374301951378584, 0.0035558242816478014, 0.0034095931332558393, 0.003355070948600769, 0.003439683699980378, 0.16363099217414856, 0.4607144296169281, 0.0035167133901268244, 0.0036026949528604746, 0.10802824050188065, 0.004125728737562895, 0.003959389869123697, 0.004275776445865631, 0.08983217924833298, 0.004478625021874905, 0.00448812497779727, 0.0046143317595124245, 0.004828571807593107, 0.0046651652082800865, 0.004723645281046629, 0.004782567266374826, 0.126221165060997, 0.004816363099962473, 0.005038132891058922, 0.004921751096844673, 0.004933275748044252, 0.005090076941996813, 0.004821762442588806, 0.004734862130135298, 0.004751605447381735, 0.00461153220385313, 0.004572708625346422, 0.0047302888706326485, 0.004607583861798048, 0.0044980901293456554, 0.004377077333629131, 0.004252173006534576, 0.004119317512959242, 0.11758120357990265, 0.11611216515302658, 0.004063545726239681, 0.004094085190445185, 0.00415418017655611, 0.004065711982548237, 0.004039989784359932, 0.004098192322999239, 0.003952117171138525, 0.0038942277897149324, 0.003949388395994902, 0.003886227263137698, 0.0038577369414269924, 0.0038117871154099703, 0.0036171437241137028, 0.0036624439526349306, 0.00356379640288651, 0.003484039567410946, 0.0035090199671685696, 0.003371057566255331, 0.003269589738920331, 0.003215398406609893, 0.0032814983278512955, 0.12226656079292297, 0.0030786790885031223, 0.0030773566104471684, 0.003061500610783696, 0.003027523634955287, 0.0030622510239481926, 0.002960912184789777, 0.0029503637924790382, 0.002991015324369073, 0.002864440670236945, 0.002967400476336479, 0.002775497967377305, 0.0027837143279612064, 0.0028772777877748013, 0.13359872996807098, 0.15905871987342834, 0.17818279564380646, 0.1256086677312851, 0.002933414652943611, 0.13342154026031494, 0.0031639470253139734, 0.0033011583145707846, 0.12213931977748871, 0.0035689701326191425, 0.003686241339892149, 0.003834894858300686, 0.003915474284440279, 0.004232141654938459, 0.004005115944892168, 0.0040340060368180275, 0.004090299364179373, 0.004093102645128965, 0.004070820286870003, 0.004058370366692543, 0.004146512597799301, 0.004114998504519463, 0.003996712621301413, 0.00400484399870038, 0.003963317256420851, 0.003947274759411812, 0.11085465550422668, 0.00385968666523695, 0.003897154238075018, 0.003917510621249676, 0.003797932295128703, 0.10742875188589096, 0.0038028808776289225, 0.0037683374248445034, 0.0037954612635076046, 0.14506065845489502, 0.0037484983913600445, 0.003797305980697274, 0.0037997455801814795, 0.003859412856400013, 0.0037673753686249256, 0.0038005963433533907, 0.10162743926048279, 0.003911956213414669, 0.003746023867279291, 0.003868731902912259, 0.0037864292971789837, 0.12191276252269745, 0.10748512297868729, 0.003860752796754241, 0.003890697844326496, 0.004047366324812174, 0.003935213200747967, 0.12117544561624527, 0.004135508555918932, 0.004333535209298134, 0.004217516165226698, 0.0041794199496507645, 0.004081680439412594, 0.004086454398930073, 0.004238415509462357, 0.004037599544972181, 0.004118572920560837, 0.004002213478088379, 0.00401344196870923, 0.003924671094864607, 0.1475127637386322, 0.0038515361957252026, 0.00380518427118659, 0.0038335879798978567, 0.1197931244969368, 0.003809599904343486, 0.0038905625697225332, 0.003892753506079316, 0.003944271709769964, 0.12570413947105408, 0.0038412201683968306, 0.003913296852260828, 0.0038169343024492264, 0.003823823295533657, 0.0038708928041160107, 0.003918949980288744, 0.09940844774246216, 0.11677907407283783, 0.003818005323410034, 0.003988951910287142, 0.003948683384805918, 0.004006818402558565, 0.0040374030359089375, 0.0039048169273883104, 0.003882991150021553, 0.0038648268673568964, 0.003906385973095894, 0.0037817617412656546, 0.0037999467458575964, 0.003822093363851309, 0.0036743427626788616, 0.00365022593177855, 0.0036244550719857216, 0.003588503459468484, 0.0034520141780376434, 0.0034697758965194225, 0.0033421884290874004, 0.003404710441827774, 0.003268312430009246, 0.10565673559904099, 0.403363436460495, 0.003639447269961238, 0.003705193055793643, 0.003793930634856224, 0.003792334580793977, 0.003854562761262059, 0.003930896520614624, 0.004068383947014809, 0.004077310673892498, 0.004363703541457653, 0.004096853081136942, 0.004197716247290373, 0.004208155442029238, 0.12735135853290558, 0.004238501191139221, 0.004227305296808481, 0.004266816657036543, 0.004159865900874138, 0.004173751920461655, 0.09524191170930862, 0.0042301383800804615, 0.004271864891052246, 0.004339457955211401, 0.004285675007849932, 0.004165127407759428, 0.004096144810318947, 0.0043979003094136715, 0.004078465513885021, 0.004009436350315809, 0.003884538309648633, 0.0039998251013457775, 0.003864794736728072, 0.0037261920515447855, 0.11149390786886215, 0.003756687743589282, 0.13578858971595764, 0.0037032885011285543, 0.0037653944455087185, 0.003791464725509286, 0.0037641413509845734, 0.0037391120567917824, 0.003676165360957384, 0.003664751071482897, 0.003601257223635912, 0.0036709699779748917, 0.003595420392230153, 0.003477087477222085, 0.0035619980189949274, 0.003459346480667591, 0.003477567108348012, 0.0033359909430146217, 0.003317450638860464, 0.0034226130228489637, 0.0032895635813474655, 0.003318485803902149, 0.003058038651943207, 0.003098543733358383, 0.00299219973385334, 0.0030334845650941133, 0.002935516880825162, 0.002906498732045293, 0.0027859751135110855, 0.002755196299403906, 0.0026883797254413366, 0.002724128309637308, 0.002591619035229087, 0.002587321912869811, 0.0025497721508145332, 0.0025429970119148493, 0.0024817308876663446, 0.1515912562608719, 0.0023849038407206535, 0.002381502650678158, 0.002417911309748888, 0.002416301053017378, 0.002378318225964904, 0.0023414166644215584, 0.0023555755615234375, 0.12212439626455307, 0.002364635467529297, 0.0024697505868971348, 0.002358458237722516, 0.0023749659303575754, 0.0023866447154432535, 0.0023482337128371, 0.002403050195425749, 0.002302017295733094, 0.14246006309986115, 0.0023525841534137726, 0.0023603737354278564, 0.0024363910779356956, 0.0023441340308636427, 0.0024841229896992445, 0.0023506053257733583, 0.0023670613300055265, 0.0023364771623164415, 0.0024148328229784966, 0.00235768873244524, 0.0023309080861508846, 0.0023355656303465366, 0.002279839711263776, 0.0022370624355971813, 0.1435699760913849, 0.14001792669296265, 0.0022974468301981688, 0.00239167339168489, 0.002382993930950761, 0.0024480028077960014, 0.0024528144858777523, 0.0024544084444642067, 0.0025112999137490988, 0.0025121879298239946, 0.0024733261670917273, 0.002690308727324009, 0.0025335578247904778, 0.002448244718834758, 0.002432464389130473, 0.0026593171060085297, 0.0024467685725539923, 0.0024279849603772163, 0.0024703152012079954, 0.0024143047630786896, 0.1178479865193367, 0.14554789662361145, 0.0023758630268275738, 0.00241046492010355, 0.002574359532445669, 0.0024780835956335068, 0.002599117113277316, 0.14376573264598846, 0.0025327783077955246, 0.0026203638408333063, 0.0025935699231922626, 0.13443060219287872, 0.002727900166064501, 0.002770716790109873, 0.0028165606781840324, 0.12026060372591019, 0.09899189323186874, 0.0031337332911789417, 0.11957405507564545, 0.003204990178346634, 0.003325875848531723, 0.003398864297196269, 0.0034125216770917177, 0.003609143663197756, 0.11972387135028839, 0.10977985709905624, 0.0037362994626164436, 0.14086541533470154, 0.003989900462329388, 0.004320880863815546, 0.004202445037662983, 0.004233842715620995, 0.004298902582377195, 0.004369734786450863, 0.00446167029440403, 0.004536301363259554, 0.004417181480675936, 0.004460559226572514, 0.004438409581780434, 0.00434842286631465, 0.00427596690133214, 0.1473216861486435, 0.004357301164418459, 0.0043388125486671925, 0.004224657081067562, 0.00438555097207427, 0.0042445422150194645, 0.004303108900785446, 0.004223709460347891, 0.004160209093242884, 0.0042681316845119, 0.11562870442867279, 0.003945403732359409, 0.004020643420517445, 0.003992291167378426, 0.0038946159183979034, 0.003919705748558044, 0.00390778761357069, 0.0037879867013543844, 0.00382355903275311, 0.11086662858724594, 0.003739712294191122, 0.0038212621584534645, 0.00364117044955492, 0.0036581449676305056, 0.0036177183501422405, 0.12537437677383423, 0.003569398308172822, 0.0035622266586869955, 0.0037537822499871254, 0.003753252560272813, 0.0035355344880372286, 0.0035342848859727383, 0.14686085283756256, 0.0037540756165981293, 0.0036088551860302687, 0.0035000350326299667, 0.0035271584056317806, 0.12000340223312378, 0.0038669889327138662, 0.0036525866016745567, 0.003737581893801689, 0.003632989013567567, 0.0035481969825923443, 0.003507163841277361, 0.0035318981390446424, 0.0035266641061753035, 0.0035150644835084677, 0.003404065268114209, 0.0035474596079438925, 0.10391830652952194, 0.0034150872379541397, 0.15114626288414001, 0.0033972091041505337, 0.003447542432695627, 0.00343323964625597, 0.10998815298080444, 0.003532060422003269, 0.003623083932325244, 0.00356704811565578, 0.003712261328473687, 0.0035754740238189697, 0.0037563107907772064, 0.003641914576292038, 0.0037408277858048677, 0.13645298779010773, 0.0037194874603301287, 0.003619413822889328, 0.003623662982136011, 0.0036838436499238014, 0.003567145438864827, 0.003629695624113083, 0.0035075282212346792, 0.0035537623334676027, 0.0035040194634348154, 0.003563142381608486, 0.0034062224440276623, 0.12923213839530945, 0.10624352842569351, 0.11347417533397675, 0.0035310920793563128, 0.1478099524974823, 0.0036979091819375753, 0.003751943353563547, 0.1009049043059349, 0.003890684340149164, 0.004007092211395502, 0.004038285464048386, 0.004034938290715218, 0.004160772077739239, 0.004203591030091047, 0.004147496074438095, 0.004172689747065306, 0.004181775264441967, 0.004135719034820795, 0.004074783064424992, 0.004071684554219246, 0.004050932824611664, 0.004011084791272879, 0.003918554168194532, 0.09249938279390335, 0.003900496056303382, 0.00387318292632699, 0.0038408811669796705, 0.0038073561154305935, 0.0037564777303487062, 0.12443789094686508, 0.003758067265152931, 0.0037237529177218676, 0.003808580571785569, 0.0036842981353402138, 0.003762143896892667, 0.0037104852963238955, 0.0036829542368650436, 0.003849432338029146, 0.003574569243937731, 0.0035266156774014235, 0.003537470940500498, 0.0035588201135396957, 0.003466266207396984, 0.0033258465118706226, 0.003295137779787183, 0.0032244957983493805, 0.0033421413972973824, 0.003273158334195614, 0.0031295977532863617, 0.0030804176349192858, 0.0030357656069099903, 0.003056886373087764, 0.002893866738304496, 0.002846010960638523, 0.0028767718467861414, 0.0029246227350085974, 0.002878631232306361, 0.002730022184550762, 0.0027498567942529917, 0.0026355634909123182, 0.0025787593331187963, 0.0025393171235919, 0.00265321577899158, 0.0024808503221720457, 0.0023940845858305693, 0.00248211482539773, 0.0023634310346096754, 0.002326240064576268, 0.0022685278672724962, 0.002255141967907548, 0.0022661180701106787, 0.0022104547824710608, 0.0021357142832130194, 0.002151983557268977, 0.0020837783813476562, 0.0021324458066374063, 0.002147954422980547, 0.00198405422270298, 0.002008618088439107, 0.0019405244383960962, 0.0019567315466701984, 0.14085176587104797, 0.13469822704792023, 0.15030819177627563, 0.0020850596483796835, 0.0020887786522507668, 0.0020975556690245867, 0.002169273793697357, 0.0022021045442670584, 0.49059197306632996, 0.002402751473709941, 0.002481024945154786, 0.00259262858889997, 0.002701669465750456, 0.002778327791020274, 0.002913491101935506, 0.003186724614351988, 0.0029891340527683496, 0.0030113314278423786, 0.0031123936641961336, 0.0030959444120526314, 0.003146181581541896, 0.003179125254973769, 0.0032655850518494844, 0.003376539098098874, 0.0032165064476430416, 0.0033171488903462887, 0.003207949222996831, 0.0032682486344128847, 0.0031445277854800224, 0.0031163205858319998, 0.003075185464695096, 0.003211717586964369, 0.0030398371163755655, 0.003061616327613592, 0.0030020778067409992, 0.002984097693115473, 0.002904720837250352, 0.0028780619613826275, 0.0028543502558022738, 0.002893260447308421, 0.0027794602792710066, 0.0027305169496685266, 0.0026734066195786, 0.002687461208552122, 0.002675540279597044, 0.0026989649049937725, 0.002594893565401435, 0.1370365172624588, 0.002537938766181469, 0.1343577355146408, 0.0025683282874524593, 0.002606388181447983, 0.0025428752414882183, 0.0026959157548844814, 0.002690417692065239, 0.0026448091957718134, 0.0025996000040322542, 0.0025498808827251196, 0.0026030363515019417, 0.002570856362581253, 0.0025858604349195957, 0.0024953579995781183, 0.002494208747521043, 0.002522050403058529, 0.0026133100036531687, 0.0024598659947514534, 0.0023978385142982006, 0.002379567129537463, 0.002510405844077468, 0.0023663195315748453, 0.0023187061306089163, 0.13121327757835388, 0.12374547868967056, 0.002377399941906333, 0.002342661377042532, 0.12663212418556213, 0.0024507632479071617, 0.0024476381950080395, 0.0025586378760635853, 0.11254368722438812, 0.002573399106040597, 0.002632042160257697, 0.0026684708427637815, 0.0027068243362009525, 0.0028884285129606724, 0.0027728599961847067, 0.0027740015648305416, 0.002754536457359791, 0.0027529739309102297, 0.002816503867506981, 0.0027489971835166216, 0.0027459831908345222, 0.002747901948168874, 0.002743373392149806, 0.08767478168010712, 0.0027323998510837555, 0.0029017797205597162, 0.0028407855425029993, 0.002774693537503481, 0.0027539748698472977, 0.002770016435533762, 0.0026953411288559437]\n",
            "Val loss 0.019294242589340024\n",
            "Val auc roc 0.5537564766839379\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03f3d544c3b6455d979ed4ae1280b33f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0211\n",
            "Train Losses : [0.0027452779468148947, 0.0026980622205883265, 0.0027857485692948103, 0.1354445517063141, 0.1476992964744568, 0.0026916570495814085, 0.00279012368991971, 0.0027558687143027782, 0.002818822395056486, 0.002783906878903508, 0.0029794201254844666, 0.002912899712100625, 0.0029435299802571535, 0.002843210007995367, 0.002837791107594967, 0.002965741790831089, 0.002856336534023285, 0.0028139667119830847, 0.0028246971778571606, 0.11126252263784409, 0.0027577991131693125, 0.0027831143233925104, 0.0028365403413772583, 0.002842165529727936, 0.0028078900650143623, 0.0027700792998075485, 0.002758706919848919, 0.002797718858346343, 0.5666794180870056, 0.002850886434316635, 0.0029910278972238302, 0.14109155535697937, 0.4488874673843384, 0.003498082049190998, 0.09906652569770813, 0.0037898612208664417, 0.004173413384705782, 0.004425333347171545, 0.004318059887737036, 0.0045655760914087296, 0.004729758482426405, 0.004822525195777416, 0.004830730147659779, 0.0049880873411893845, 0.004940419923514128, 0.005057821981608868, 0.005120206158608198, 0.005043365526944399, 0.005042952485382557, 0.005119019653648138, 0.005204020533710718, 0.005172272678464651, 0.004980094730854034, 0.004918505437672138, 0.005008610896766186, 0.0048246802762150764, 0.0048411632888019085, 0.1129092127084732, 0.004709810484200716, 0.004665409680455923, 0.00467278016731143, 0.004641322884708643, 0.00472860736772418, 0.004543938208371401, 0.004528871737420559, 0.004440488759428263, 0.004351045470684767, 0.00442564208060503, 0.00466228649020195, 0.004299878142774105, 0.004105087369680405, 0.12110913544893265, 0.004019539337605238, 0.004017974250018597, 0.00393331004306674, 0.003923846408724785, 0.0039056004025042057, 0.003840255318209529, 0.00380400987342, 0.0038262242451310158, 0.00389313162304461, 0.003645900171250105, 0.0035965819843113422, 0.0036561323795467615, 0.003597868140786886, 0.0035262000747025013, 0.003505376633256674, 0.13481032848358154, 0.003419066546484828, 0.003571188310161233, 0.003332791617140174, 0.003647981910035014, 0.11100715398788452, 0.0034190770238637924, 0.003307368839159608, 0.1499031037092209, 0.0032921554520726204, 0.003363498020917177, 0.0034605718683451414, 0.1447974294424057, 0.0033831496257334948, 0.0034058070741593838, 0.003476693294942379, 0.0036216320004314184, 0.0035327691584825516, 0.0034651244059205055, 0.1614459604024887, 0.003474797122180462, 0.0035650923382490873, 0.003560449928045273, 0.0034753670915961266, 0.00345210381783545, 0.0035451946314424276, 0.0034987127874046564, 0.0034502597991377115, 0.0034563776571303606, 0.12523172795772552, 0.0033958544954657555, 0.003470485797151923, 0.003430015407502651, 0.0034235354978591204, 0.0033550593070685863, 0.003357840236276388, 0.0033446887973695993, 0.0034553951118141413, 0.003300097305327654, 0.0032893058378249407, 0.14086663722991943, 0.0033024875447154045, 0.003235317999497056, 0.0032386742532253265, 0.0032882431987673044, 0.0032424256205558777, 0.0032856918405741453, 0.106648288667202, 0.0032474580220878124, 0.003195849247276783, 0.003198928665369749, 0.003213436109945178, 0.0032155367080122232, 0.0031878952868282795, 0.14063332974910736, 0.0031925307121127844, 0.0031923577189445496, 0.0032018343918025494, 0.003252943279221654, 0.003316964255645871, 0.003269465873017907, 0.0032226492185145617, 0.0033190271351486444, 0.0031464651692658663, 0.0031294352374970913, 0.0031059314496815205, 0.0031053940765559673, 0.0030579909216612577, 0.10698595643043518, 0.0031195776537060738, 0.12095566838979721, 0.0031202330719679594, 0.1304267942905426, 0.1272887885570526, 0.0031849327497184277, 0.003268411848694086, 0.0032977694645524025, 0.003399115987122059, 0.0034283671993762255, 0.0034429875668138266, 0.003404120448976755, 0.003513350384309888, 0.11421436816453934, 0.0034731777850538492, 0.003504740307107568, 0.0035938434302806854, 0.003519033547490835, 0.003502019913867116, 0.0035428334958851337, 0.0034791408106684685, 0.0035724283661693335, 0.003774030599743128, 0.0035093394108116627, 0.0034128406550735235, 0.0034987868275493383, 0.0033705916721373796, 0.003348891856148839, 0.0033378053922206163, 0.003282204968854785, 0.14495591819286346, 0.003245838452130556, 0.0032639491837471724, 0.003279491327702999, 0.0032000895589590073, 0.003228092333301902, 0.0034209266304969788, 0.003147925715893507, 0.003159300424158573, 0.003176157595589757, 0.12439515441656113, 0.0030995530541986227, 0.0030690538696944714, 0.0030820881947875023, 0.12237940728664398, 0.0031156744807958603, 0.0031109885312616825, 0.003223987063392997, 0.0031011139508336782, 0.003099061083048582, 0.46100249886512756, 0.003307632403448224, 0.0032671664375811815, 0.003339761169627309, 0.003406626172363758, 0.003485599998384714, 0.0035462058149278164, 0.0037618426140397787, 0.1477585732936859, 0.0036286695394665003, 0.0037517515011131763, 0.003874826245009899, 0.0038261483423411846, 0.0037386969197541475, 0.003915832843631506, 0.0037784685846418142, 0.08876460045576096, 0.003847880754619837, 0.003951568156480789, 0.11805836111307144, 0.0038329847157001495, 0.003880840027704835, 0.003933068364858627, 0.003950674552470446, 0.0038796167355030775, 0.003917318768799305, 0.0038696161936968565, 0.00392601964995265, 0.10188278555870056, 0.003866065526381135, 0.13038817048072815, 0.003900138195604086, 0.003950475249439478, 0.10861660540103912, 0.003945281263440847, 0.0039864215068519115, 0.00405709445476532, 0.004002353176474571, 0.0040802303701639175, 0.004114959388971329, 0.0040113478899002075, 0.0039760647341609, 0.0040639895014464855, 0.003951359074562788, 0.004024339374154806, 0.004002285655587912, 0.003979198634624481, 0.003965758718550205, 0.0037930558901280165, 0.10978531092405319, 0.10217016935348511, 0.0038267611525952816, 0.095395527780056, 0.0038159587420523167, 0.003872147761285305, 0.003893852001056075, 0.1461459845304489, 0.003909946419298649, 0.00398093368858099, 0.003945895936340094, 0.0040180315263569355, 0.003984752576798201, 0.12314487248659134, 0.0039789811708033085, 0.004112460184842348, 0.11095263063907623, 0.004194049630314112, 0.004129344131797552, 0.004120105877518654, 0.004103188402950764, 0.0041082194074988365, 0.00410545663908124, 0.004143858328461647, 0.1102856770157814, 0.0041333590634167194, 0.0040793148800730705, 0.004066165070980787, 0.10869123041629791, 0.0042444937862455845, 0.004449236206710339, 0.004114112816751003, 0.004117764066904783, 0.11878658086061478, 0.004136372823268175, 0.004440530203282833, 0.004216453060507774, 0.004227543715387583, 0.004103650338947773, 0.004127190914005041, 0.004127826076000929, 0.004131309222429991, 0.11307185143232346, 0.00419160071760416, 0.004042003303766251, 0.004077508579939604, 0.004050560295581818, 0.004091572016477585, 0.003992157056927681, 0.0040351757779717445, 0.0039137545973062515, 0.004063443746417761, 0.003836654592305422, 0.0037665399722754955, 0.003810777561739087, 0.003735967446118593, 0.003757030703127384, 0.0038238477427512407, 0.0036563645116984844, 0.0035354322753846645, 0.003525085747241974, 0.0035065195988863707, 0.0034496088046580553, 0.09567075222730637, 0.003470083000138402, 0.1230894923210144, 0.0035617488902062178, 0.0033314493484795094, 0.00338058196939528, 0.00346811069175601, 0.003373071551322937, 0.0034613434690982103, 0.1316133439540863, 0.003327716141939163, 0.0033885249868035316, 0.00337023101747036, 0.003489395137876272, 0.0033302840311080217, 0.0034226696006953716, 0.0033120305743068457, 0.0033820399548858404, 0.003430306212976575, 0.0034187212586402893, 0.0033386098220944405, 0.0033808669541031122, 0.0032081834506243467, 0.003288546809926629, 0.10864533483982086, 0.003292175242677331, 0.15609239041805267, 0.0032529712188988924, 0.0031864189077168703, 0.0032415231689810753, 0.003317784983664751, 0.003348971949890256, 0.0033186122309416533, 0.003208255860954523, 0.003268027910962701, 0.003344345837831497, 0.003154915291815996, 0.0031375670805573463, 0.0030915571842342615, 0.0030485407914966345, 0.003100505331531167, 0.0030032298527657986, 0.003173124510794878, 0.003012116067111492, 0.002960869809612632, 0.002943790052086115, 0.0028848364017903805, 0.0028666271828114986, 0.002853104379028082, 0.0028259409591555595, 0.002908210502937436, 0.0027976955752819777, 0.0027966031339019537, 0.002855372615158558, 0.002765526995062828, 0.0027923027519136667, 0.002625754801556468, 0.0026470348238945007, 0.15392270684242249, 0.002587271621450782, 0.0026135703083127737, 0.002612967975437641, 0.161208376288414, 0.002605500863865018, 0.002686150372028351, 0.002654958050698042, 0.1295974850654602, 0.0026863240636885166, 0.11703843623399734, 0.00277156219817698, 0.0027972522657364607, 0.002833511447533965, 0.09894967079162598, 0.09696954488754272, 0.15112335979938507, 0.142009437084198, 0.0031075298320502043, 0.0033127188216894865, 0.0032511225435882807, 0.003378283930942416, 0.12274541705846786, 0.0034504763316363096, 0.003529180772602558, 0.003685163566842675, 0.0038365619257092476, 0.003689119126647711, 0.0036818517837673426, 0.10564030706882477, 0.1128033995628357, 0.004002085886895657, 0.003917742054909468, 0.1277472823858261, 0.004002578090876341, 0.004148731008172035, 0.004212976898998022, 0.0041201552376151085, 0.0041744583286345005, 0.0043070074170827866, 0.004233744461089373, 0.004243683069944382, 0.1363448202610016, 0.0042989240027964115, 0.00438633281737566, 0.0041811116971075535, 0.004348382819443941, 0.004202287178486586, 0.004277314059436321, 0.1255812793970108, 0.004414833150804043, 0.004220111761242151, 0.004500079900026321, 0.00425939355045557, 0.004261981230229139, 0.004137622192502022, 0.004170875996351242, 0.0041337814182043076, 0.0041157277300953865, 0.004022798500955105, 0.004023286048322916, 0.004060456994920969, 0.003965213429182768, 0.004011824261397123, 0.0038752639666199684, 0.0038282026071101427, 0.0038176130037754774, 0.00373203307390213, 0.0037967434618622065, 0.0037309853360056877, 0.0036216985899955034, 0.0036000681575387716, 0.003554178401827812, 0.0037000051233917475, 0.0035598932299762964, 0.003464610781520605, 0.003411353100091219, 0.003438565181568265, 0.0033827617298811674, 0.0033440899569541216, 0.003362265881150961, 0.0032432193402200937, 0.003138843458145857, 0.12869793176651, 0.00310337683185935, 0.0030826993752270937, 0.003080810885876417, 0.0030348976142704487, 0.0030736573971807957, 0.003117126179859042, 0.003078990615904331, 0.0030486660543829203, 0.0029648172203451395, 0.0029776599258184433, 0.002937467535957694, 0.002971210051327944, 0.002906953450292349, 0.0028669184539467096, 0.002857430838048458, 0.0028442225884646177, 0.002825088333338499, 0.0027467715553939342, 0.0027083575259894133, 0.0026737316511571407, 0.002643134444952011, 0.00264529581181705, 0.002601886633783579, 0.127396821975708, 0.0026290693785995245, 0.0025603848043829203, 0.0027060413267463446, 0.0026231782976537943, 0.002617240883409977, 0.002558155683800578, 0.002576684346422553, 0.0025030451361089945, 0.0025647268630564213, 0.0024844331201165915, 0.002454394707456231, 0.002485796809196472, 0.002480148570612073, 0.00245113717392087, 0.002432061592116952, 0.002436735201627016, 0.0023820435162633657, 0.0023982946295291185, 0.0023387412074953318, 0.0023505983408540487, 0.0023172723595052958, 0.0023111775517463684, 0.002267659641802311, 0.0022744094021618366, 0.11704246699810028, 0.0022794995456933975, 0.0022449137177318335, 0.002256926614791155, 0.002242955146357417, 0.002227004151791334, 0.0022612763568758965, 0.0022601024247705936, 0.18901634216308594, 0.002192030195146799, 0.002213589148595929, 0.0022300216369330883, 0.002228171331807971, 0.00233086128719151, 0.0022734992671757936, 0.0022580837830901146, 0.0022225354332476854, 0.12462614476680756, 0.0022461519110947847, 0.0022350300569087267, 0.0022508299443870783, 0.11659163981676102, 0.0022741693537682295, 0.0023255730047822, 0.0024387456942349672, 0.002318507758900523, 0.0024416472297161818, 0.11389593034982681, 0.002381312195211649, 0.0024145012721419334, 0.0023889776784926653, 0.0024048027116805315, 0.0024147105868905783, 0.0025105723179876804, 0.0024388532619923353, 0.002440526382997632, 0.0025033392012119293, 0.002467420184984803, 0.0024147112853825092, 0.0024870876222848892, 0.002387169748544693, 0.0023848863784223795, 0.002384237479418516, 0.002363302046433091, 0.0024018094409257174, 0.0023565245792269707, 0.002331548137590289, 0.0023113805800676346, 0.0024607377126812935, 0.0022780620492994785, 0.0022786373738199472, 0.002331142546609044, 0.0022794927936047316, 0.0022928209509700537, 0.002219255082309246, 0.0022745137102901936, 0.12159254401922226, 0.0022697902750223875, 0.0021927603520452976, 0.002185559133067727, 0.0022108356934040785, 0.0022006065119057894, 0.002252960344776511, 0.12027312815189362, 0.002196589717641473, 0.002299818443134427, 0.0022270656190812588, 0.0022041003685444593, 0.0022274942602962255, 0.002265749964863062, 0.0022533296141773462, 0.002244027331471443, 0.11504501104354858, 0.15160582959651947, 0.002290611155331135, 0.0022701886482536793, 0.0023297651205211878, 0.0024330969899892807, 0.0024470179341733456, 0.002358635887503624, 0.002420996781438589, 0.0023412220180034637, 0.002429015003144741, 0.002525853458791971, 0.002336992183700204, 0.002386382780969143, 0.08908471465110779, 0.002353543182834983, 0.002360729267820716, 0.00236425269395113, 0.0023693463299423456, 0.002401321427896619, 0.0023588379845023155, 0.0024748914875090122, 0.0024308960419148207, 0.0023391663562506437, 0.002334615681320429, 0.0023253359831869602, 0.0023184753954410553, 0.0023244707845151424, 0.002399335615336895, 0.0023202390875667334, 0.002281075343489647, 0.0023758751340210438, 0.0022891785483807325, 0.0022331299260258675, 0.0022147977724671364, 0.0022976789623498917, 0.002187625039368868, 0.0022334137465804815, 0.0021842163987457752, 0.0021991177927702665, 0.0021509591024369, 0.002139110816642642, 0.1585984230041504, 0.0021248995326459408, 0.002227919176220894, 0.0021166789811104536, 0.0020971919875591993, 0.002143454272300005, 0.002119121141731739, 0.0021342800464481115, 0.0021133606787770987, 0.002124063903465867, 0.0020920068491250277, 0.0020733820274472237, 0.002093326533213258, 0.0020958459936082363, 0.002171523170545697, 0.002082786289975047, 0.0020399836357682943, 0.0021017282269895077, 0.0020869469735771418, 0.0020037656649947166, 0.002003768691793084, 0.001996613573282957, 0.001965875970199704, 0.001970966113731265, 0.001976142870262265, 0.002087855478748679, 0.002006145194172859, 0.0018993178382515907, 0.0019098104676231742, 0.0019268011674284935, 0.0018509617075324059, 0.0018495750846341252, 0.0019053432624787092, 0.0018707975978031754, 0.16832184791564941, 0.0019015715224668384, 0.0018408620962873101, 0.18046309053897858, 0.0018628676189109683, 0.0018985418137162924, 0.0957217589020729, 0.0019313199445605278, 0.0019301200518384576, 0.001941704424098134, 0.0019701782148331404, 0.0020816342439502478, 0.12863069772720337, 0.0021334895864129066, 0.12280787527561188, 0.0021603975910693407, 0.002111898036673665, 0.1326635628938675, 0.002201081020757556, 0.0022563019301742315, 0.002282270696014166, 0.0022744513116776943, 0.002310024807229638, 0.00238701980561018, 0.0023999842815101147, 0.0023585068993270397, 0.0023696084972471, 0.002356279641389847, 0.002365135122090578, 0.0024200365878641605, 0.002422686666250229, 0.0023653279058635235, 0.11461301147937775, 0.0024156898725777864, 0.002399281831458211, 0.0024314208421856165, 0.0024002022109925747, 0.002396856900304556, 0.002559026936069131, 0.0024133343249559402, 0.002450081054121256, 0.0025532268919050694, 0.0024754046462476254, 0.17242197692394257, 0.0024870673660188913, 0.0026138878893107176, 0.002515569794923067, 0.0024891209322959185, 0.0024200472980737686, 0.002424524864181876, 0.002459712093695998, 0.1294916272163391, 0.0025004553608596325, 0.14655394852161407, 0.13461002707481384, 0.0026754536665976048, 0.0025819409638643265, 0.002645291620865464, 0.0026287331711500883, 0.002749913139268756, 0.0027209999971091747, 0.0026906898710876703, 0.0027128641959279776, 0.002726972568780184, 0.002767073456197977, 0.002785532968118787, 0.002754843095317483, 0.0027972529642283916, 0.0027599718887358904, 0.002781321993097663, 0.12381882220506668, 0.0027976292185485363, 0.002817535540089011, 0.0958109200000763, 0.0028961675707250834, 0.12545686960220337, 0.0028584697283804417, 0.0028853928670287132, 0.0030050326604396105, 0.0029012032318860292, 0.0029501505196094513, 0.002931880531832576, 0.0029851861763745546, 0.0029305932112038136, 0.00293182535097003, 0.0029430168215185404, 0.12451227009296417, 0.0029457188211381435, 0.12204357981681824, 0.003016451606526971, 0.0030104750767350197, 0.0030651860870420933, 0.00320203835144639, 0.003063748823478818, 0.003028229344636202, 0.0031208358705043793, 0.0031253148335963488, 0.003101182635873556, 0.003020725678652525, 0.0031520382035523653, 0.0030170774552971125, 0.00304117938503623, 0.0030409670434892178, 0.003033821005374193, 0.002936430275440216, 0.16046999394893646, 0.0029428554698824883, 0.0029221640434116125, 0.002981208497658372, 0.002981984056532383, 0.0029809896368533373, 0.0029057904612272978, 0.0029946418944746256, 0.13390445709228516, 0.00294711091555655, 0.002963253064081073, 0.002907574875280261, 0.002987818093970418, 0.0029238376300781965, 0.0029482445679605007, 0.002916227327659726, 0.002896140795201063, 0.0029855493921786547, 0.0028960304334759712, 0.0029079888481646776, 0.0028371508233249187, 0.0028219858650118113, 0.00280837737955153, 0.14154674112796783, 0.0029173106886446476, 0.002857116749510169, 0.0028424819465726614, 0.0028006816282868385, 0.0028508324176073074, 0.0027944915927946568, 0.47424742579460144, 0.0029375285375863314, 0.0029133372008800507, 0.0029421434737741947, 0.003006227780133486, 0.0030417051166296005, 0.003030699910596013, 0.003076369408518076, 0.003110739169642329, 0.0031041344627738, 0.003176494501531124, 0.10722009092569351, 0.00315871206112206, 0.0031487352680414915, 0.0031853001564741135, 0.13792255520820618, 0.003240152494981885, 0.003375052707269788, 0.0032638295087963343, 0.0032541395630687475, 0.003415237180888653, 0.003270849585533142, 0.1257646083831787, 0.0033786832354962826, 0.1306997835636139, 0.003472827607765794, 0.0035450977738946676, 0.12269800156354904, 0.09709049016237259, 0.0034871899988502264, 0.13493801653385162, 0.003651353996247053, 0.0037040801253169775, 0.0036320567596703768, 0.003692573867738247, 0.13063310086727142, 0.0037641646340489388, 0.0037761300336569548, 0.003825722960755229, 0.003993139136582613, 0.004057240206748247, 0.1338357776403427, 0.003956070635467768, 0.0039346287958323956, 0.003988610114902258, 0.003967588301748037, 0.003930905368179083, 0.11158376187086105, 0.0040590506978333, 0.0040274569764733315, 0.003981897607445717, 0.0040132831782102585, 0.004076213575899601, 0.004000326152890921, 0.003982773516327143, 0.003967071417719126, 0.003997440449893475, 0.0039732917211949825, 0.004002509638667107, 0.0038885469548404217, 0.003862614743411541, 0.00391249218955636, 0.003954487387090921, 0.0039027302991598845, 0.003818854922428727, 0.0037939343601465225, 0.1508777141571045, 0.0037151926662772894, 0.0037967218086123466, 0.0037120424676686525, 0.0038030059076845646, 0.003674229606986046, 0.0036818122025579214, 0.003717282321304083, 0.0036165642086416483, 0.003674654057249427, 0.0037175912875682116, 0.0036316984333097935, 0.003567338455468416, 0.1384410560131073, 0.0035040928050875664, 0.003490875940769911, 0.0035255977418273687, 0.0035402984358370304, 0.0035441499203443527, 0.0034782784059643745, 0.11388897150754929, 0.0034829911310225725, 0.0034856623969972134, 0.0034286214504390955, 0.0034625628031790257, 0.0034296810626983643, 0.003420158987864852, 0.003398910863325, 0.003401670604944229, 0.003437100676819682, 0.003352311672642827, 0.0034441747702658176, 0.0033348286524415016, 0.0032843751832842827, 0.003427977440878749, 0.003306289669126272, 0.0032762556802481413, 0.0032138752285391092, 0.1254810094833374, 0.14523197710514069, 0.0032353217247873545, 0.003266629995778203, 0.0032682691235095263, 0.0032476044725626707, 0.0033333515748381615, 0.0032469299621880054, 0.0032667091581970453, 0.1325554996728897, 0.14209556579589844, 0.003329851431772113, 0.003434601007029414, 0.09817041456699371, 0.0033299021888524294, 0.003455955069512129, 0.003450090531259775, 0.10471848398447037, 0.0035023062955588102, 0.003444743575528264, 0.003478815546259284, 0.0034637334756553173, 0.003502307692542672, 0.003501360071823001, 0.003474628087133169, 0.0035047978162765503, 0.0035078267101198435, 0.11861132085323334, 0.003577430499717593, 0.0035201632417738438, 0.0035218598786741495, 0.00361876399256289, 0.0034796397667378187, 0.0035592198837548494, 0.003735420759767294, 0.0035217057447880507, 0.0035501394886523485, 0.0035861798096448183, 0.0034284291323274374, 0.003433007514104247, 0.003556544426828623, 0.003367665223777294, 0.11301019042730331, 0.0034449417144060135, 0.003373249201104045, 0.0033439500257372856, 0.003361113602295518, 0.42467015981674194, 0.0033895131200551987, 0.0034920182079076767, 0.0035875902976840734, 0.0035341186448931694, 0.11845269799232483, 0.0036158228758722544, 0.003667296841740608, 0.10616225749254227, 0.10891427099704742, 0.0037835044786334038, 0.0037997134495526552, 0.0039043340366333723, 0.003943086136132479, 0.003906309604644775, 0.004097626078873873, 0.003956846427172422, 0.09723043441772461, 0.003974956925958395, 0.004043866880238056, 0.0039882049895823, 0.12241461127996445, 0.004222774878144264, 0.004100655671209097, 0.00406531011685729, 0.004179013427346945, 0.004090733826160431, 0.004083590116351843, 0.004059193655848503, 0.16256016492843628, 0.004180418327450752, 0.004110249225050211, 0.004143569618463516, 0.47648659348487854, 0.004363521002233028, 0.00417567603290081, 0.10769021511077881, 0.004365470260381699, 0.004324562381953001, 0.4426099359989166, 0.0044450899586081505, 0.12974824011325836, 0.004637746140360832, 0.35687389969825745, 0.004899435210973024, 0.005019695498049259, 0.005127341952174902, 0.005255651660263538, 0.005272881127893925, 0.005378936883062124, 0.005514516029506922, 0.005633031018078327, 0.13013724982738495, 0.005645771976560354, 0.005762688349932432, 0.15072154998779297, 0.005759801249951124, 0.005778370425105095, 0.0058325352147221565, 0.09247492998838425, 0.005996018182486296, 0.005957683548331261, 0.005812884774059057, 0.0057996707037091255, 0.005793169606477022, 0.005804803222417831, 0.00578346336260438, 0.005818013101816177, 0.15236490964889526, 0.005797669757157564, 0.005732335615903139, 0.005737054627388716, 0.00595393730327487, 0.005777569953352213, 0.005703127011656761, 0.005736053921282291, 0.005630097817629576, 0.005703691393136978, 0.005722855217754841, 0.005551764741539955, 0.0054817963391542435, 0.005516787059605122, 0.005415858700871468, 0.005359030794352293, 0.005352069158107042, 0.005296078510582447, 0.005242911167442799, 0.10688438266515732, 0.13257065415382385, 0.005201444029808044, 0.12024439126253128, 0.005212684627622366, 0.005197450518608093, 0.0052744001150131226, 0.005153830163180828, 0.005121393594890833, 0.005173163954168558, 0.11225057393312454, 0.005113345105201006, 0.11285942792892456, 0.005152303725481033, 0.005111248232424259, 0.005124024115502834, 0.005257710348814726, 0.005088507663458586, 0.005069397855550051, 0.0050901323556900024, 0.005092738661915064, 0.005025016143918037, 0.004966389387845993, 0.004997801501303911, 0.005014418624341488, 0.004947497975081205, 0.004907377064228058, 0.004842283204197884, 0.004859201144427061, 0.004852656275033951, 0.004764715675264597, 0.004751818720251322, 0.004720486234873533, 0.004686135333031416, 0.004663803614675999, 0.004604589659720659, 0.12639960646629333, 0.004680347163230181, 0.0045283022336661816, 0.004530250560492277, 0.004520428832620382, 0.004517357796430588, 0.004461084026843309, 0.004518275614827871, 0.004452941007912159, 0.00441954517737031, 0.1539265215396881, 0.004470538347959518, 0.004343267064541578, 0.11732753366231918, 0.004367035813629627, 0.004328987095504999, 0.004382194019854069, 0.11840478330850601, 0.004450759384781122, 0.004358492325991392, 0.004329571034759283, 0.1172824501991272, 0.0043830471113324165, 0.004368074703961611, 0.004442415200173855, 0.004371423274278641, 0.004337375517934561, 0.0043101985938847065, 0.004304688423871994, 0.004287364427000284, 0.004354788456112146, 0.004278986714780331, 0.00425742706283927, 0.004295769147574902, 0.0043109566904604435, 0.0043039326556026936, 0.004269992932677269, 0.004183018114417791, 0.0041538081131875515, 0.004170508589595556, 0.10625803470611572, 0.10054565966129303, 0.004201216623187065, 0.004179263487458229, 0.13147158920764923, 0.00420494144782424, 0.004133080132305622, 0.12589259445667267, 0.004142465069890022, 0.12852275371551514, 0.004192262887954712, 0.004177455324679613, 0.004243022296577692, 0.004197010770440102, 0.004297120496630669, 0.004301616456359625, 0.004195034503936768, 0.00425712438300252, 0.004233375191688538, 0.0041748411022126675, 0.004161046352237463, 0.004185420926660299, 0.004171897191554308, 0.004147863015532494, 0.004106950480490923, 0.004141142126172781, 0.0040941303595900536, 0.0040991464629769325, 0.004052973818033934, 0.004038487561047077, 0.00408243527635932, 0.004034946206957102, 0.003993777558207512, 0.004036804661154747, 0.003986353985965252, 0.09545642882585526, 0.003914967179298401, 0.003942924086004496, 0.003875726368278265, 0.004053632263094187, 0.0039041799027472734, 0.14061686396598816, 0.0039027074817568064, 0.0038470588624477386, 0.0038636906538158655, 0.0038517876528203487, 0.003937184810638428, 0.003833240130916238, 0.0038293558172881603, 0.003876006230711937, 0.0038175752852112055, 0.0037871499080210924, 0.003794508520513773, 0.11615899950265884, 0.0037577610928565264, 0.003745862515643239, 0.003778852056711912, 0.003765258938074112, 0.0037172280717641115, 0.003838952165096998, 0.003719917731359601, 0.003705147886648774, 0.0038101356476545334, 0.0036886255256831646, 0.003662955015897751, 0.0036364358384162188, 0.0037294854409992695, 0.0036163590848445892, 0.0036948868073523045, 0.0036111432127654552, 0.003604736877605319, 0.0036003480199724436, 0.003614741377532482, 0.0035696488339453936, 0.003498234087601304, 0.003521391423419118, 0.0034983393270522356, 0.0034907073713839054, 0.0034556312020868063, 0.00363189447671175, 0.003469710238277912, 0.00341765396296978, 0.0034015399869531393, 0.0033588760998100042, 0.003370496444404125, 0.003339272690936923, 0.0033520623110234737, 0.003353562904521823, 0.003310304833576083, 0.0033046964090317488, 0.14108940958976746, 0.00328059121966362, 0.0032827933318912983, 0.003285665763542056, 0.0032501905225217342, 0.003281942568719387, 0.10110748559236526, 0.0032583833672106266, 0.11600899696350098, 0.0032852706499397755, 0.003274435643106699, 0.003253992646932602, 0.0033413663040846586, 0.003239706391468644, 0.0032971184700727463, 0.0032384637743234634, 0.1398661732673645, 0.0032771292608231306, 0.0032829632982611656, 0.00325929862447083, 0.003268855856731534, 0.003273553913459182, 0.003257174277678132, 0.1353743076324463, 0.0032556962687522173, 0.13579213619232178, 0.0034030969254672527, 0.0032891188748180866, 0.12909568846225739, 0.003328620223328471, 0.003342078533023596, 0.0033530036453157663, 0.0033394028432667255, 0.0033356996718794107, 0.0033577270805835724, 0.0033500054851174355, 0.003346068551763892, 0.0033413488417863846, 0.0033363953698426485, 0.0033318030182272196, 0.00333600677549839, 0.0033330197911709547, 0.0033158231526613235, 0.1163262128829956, 0.0034836281556636095, 0.003337936010211706, 0.0033301697112619877, 0.0033618593588471413, 0.00331033393740654, 0.003311099950224161, 0.003290903754532337, 0.0032829144038259983, 0.003375439438968897, 0.1617463231086731, 0.0032856708858162165, 0.0032761893235147, 0.0033077807165682316, 0.0032910320442169905, 0.003353583626449108, 0.0032666546758264303, 0.0033005522564053535, 0.003280557692050934, 0.0033314789179712534, 0.0032475455664098263, 0.0032547384034842253, 0.003341942559927702, 0.003214133670553565, 0.0032326874788850546, 0.0032117574010044336, 0.0032323538325726986, 0.10753663629293442, 0.0032046381384134293, 0.003192216157913208, 0.4546515941619873, 0.003304047044366598, 0.0032367692328989506, 0.14079977571964264, 0.0033071013167500496, 0.1282287836074829, 0.0033613694831728935, 0.0033391197212040424, 0.0034026517532765865, 0.0034005099441856146, 0.11907023936510086, 0.1302206963300705, 0.0035276610869914293, 0.003482154104858637, 0.003514773678034544, 0.0036265773233026266, 0.003525102511048317, 0.003511016722768545, 0.0035029221326112747, 0.0036757730413228273, 0.003564394311979413, 0.0035600338596850634, 0.0035274734254926443, 0.003564130747690797, 0.0035222487058490515, 0.0035120639950037003, 0.003581359051167965, 0.00350808328948915, 0.0035192735958844423, 0.1383078694343567, 0.003548289183527231, 0.003517156234011054, 0.003484887070953846, 0.003518805606290698, 0.0034860006999224424, 0.003544575534760952, 0.0034733405336737633, 0.003519719000905752, 0.14038099348545074, 0.0034921453334391117, 0.0035357391461730003, 0.003455311292782426, 0.003459066618233919, 0.003527177032083273, 0.0034779140260070562, 0.0034517666790634394, 0.003498059930279851, 0.0034509310498833656, 0.13335730135440826, 0.003460969077423215, 0.00344281573779881, 0.0034556735772639513, 0.10277347266674042, 0.0034235354978591204, 0.003564442042261362, 0.13617537915706635, 0.0034838460851460695, 0.003535628318786621, 0.12010477483272552, 0.0034726958256214857, 0.003489882219582796, 0.003484204178676009, 0.0035330415703356266, 0.0034873730037361383, 0.003491549054160714, 0.0034805454779416323, 0.0035183040890842676, 0.0035004655364900827, 0.0035027791745960712, 0.003485857043415308, 0.003501889994367957, 0.1216999813914299, 0.0034771529026329517, 0.0035235725808888674, 0.003486177884042263, 0.00347643019631505, 0.0035267071798443794, 0.003500024089589715, 0.0034698236268013716, 0.003574464237317443, 0.003529729787260294, 0.12700320780277252, 0.11642593145370483, 0.0034763170406222343, 0.1142851859331131, 0.0034916982986032963, 0.0034915804862976074, 0.003526414278894663, 0.0035412185825407505, 0.0035193650983273983, 0.0035438218619674444, 0.0035348543897271156, 0.0035271195229142904, 0.0036428000312298536, 0.0035237527918070555, 0.003471835982054472, 0.0034893217962235212, 0.003498530015349388, 0.0035103661939501762, 0.0035482693929225206, 0.0034743729047477245, 0.003504424821585417, 0.0034946040250360966, 0.003463996574282646, 0.003548430511727929, 0.0034370701760053635, 0.0034974338486790657, 0.0035279407165944576, 0.0034347178880125284, 0.12283136695623398, 0.003408374497666955, 0.0033950924407690763, 0.0033891545608639717, 0.0034851504024118185, 0.0034095318987965584, 0.003387155942618847, 0.1260860711336136, 0.0034151815343648195, 0.00342600978910923, 0.003368555335327983, 0.0034091344568878412, 0.003417764790356159, 0.0033836420625448227, 0.003375724423676729, 0.003386985743418336, 0.0034696515649557114, 0.0033718326594680548, 0.0033759018406271935, 0.0033757395576685667, 0.003444163128733635, 0.0033652049023658037, 0.0033370726741850376, 0.0033325606491416693, 0.0034015760757029057, 0.003317019669339061, 0.0033121430315077305, 0.003321017138659954, 0.003284010337665677, 0.003313785418868065, 0.0033050882630050182, 0.12611854076385498, 0.0033660002518445253, 0.003322428558021784, 0.0032657801639288664, 0.0032975857611745596, 0.399028480052948, 0.12783265113830566, 0.0033197628799825907, 0.003426601877436042, 0.0033210075926035643, 0.003361059119924903, 0.003363087773323059, 0.0033685893286019564, 0.003365419339388609, 0.0034287450835108757, 0.0033755884505808353, 0.003350131679326296, 0.0033798764925450087, 0.0033679110929369926, 0.0034210425801575184, 0.003421608591452241, 0.0034527238458395004, 0.003380037611350417, 0.0033861848060041666, 0.0033640218898653984, 0.003398506436496973, 0.0033523242454975843, 0.10966139286756516, 0.0033985315822064877, 0.0033574001863598824, 0.003377256914973259, 0.11664750427007675, 0.0033825968857854605, 0.0034094376023858786, 0.003361183451488614, 0.0033627322409301996, 0.0033749055583029985, 0.003443280002102256, 0.13698001205921173, 0.0033356109634041786, 0.0034078138414770365, 0.003347911639139056, 0.00333977653644979, 0.003418596228584647, 0.0033448059111833572, 0.00343326129950583, 0.003404313465580344, 0.0033383402042090893, 0.003330099629238248, 0.003327824641019106, 0.003352809464558959, 0.0033329196739941835, 0.0033403453417122364, 0.0033418177627027035, 0.003348683938384056, 0.0033615082502365112, 0.00329696387052536, 0.003335497109219432, 0.14517123997211456, 0.003324951510876417, 0.003296350361779332, 0.003325131256133318, 0.0033171698451042175, 0.0033081481233239174, 0.0032824347727000713, 0.12637868523597717, 0.0033401213586330414, 0.00336074223741889, 0.0032827097456902266, 0.003299131989479065, 0.003278388874605298, 0.1380397528409958, 0.003354429267346859, 0.003318381030112505, 0.0032970428001135588, 0.0032882250379770994, 0.0033289529383182526, 0.0033038482069969177, 0.003309055930003524, 0.0033710894640535116, 0.003357797162607312, 0.0032800128683447838, 0.0032940409146249294, 0.003282135585322976, 0.10583075881004333, 0.15214066207408905, 0.0033686491660773754, 0.0033710941206663847, 0.003371871542185545, 0.0033060386776924133, 0.0034015385899692774, 0.0032725976780056953, 0.1189868301153183, 0.0032902411185204983, 0.0032892925664782524, 0.12722621858119965, 0.0034069260582327843, 0.003332690102979541, 0.003305106656625867, 0.003297820221632719, 0.0032993657514452934, 0.0033269168343394995, 0.00329878949560225, 0.0032950968015938997, 0.003389159217476845, 0.0033255605958402157, 0.0032995077781379223, 0.0032965121790766716, 0.0032809616532176733, 0.00328522059135139, 0.003316916525363922, 0.0033341720700263977, 0.003283908125013113, 0.003276313655078411, 0.0032950141467154026, 0.0033479323610663414, 0.0032747765071690083, 0.0033126678317785263, 0.00332021526992321, 0.0032647803891450167, 0.003305415390059352, 0.003359587164595723, 0.0032798945903778076, 0.11486250162124634, 0.003261985955759883, 0.0032450954895466566, 0.0032543165143579245, 0.0032655687537044287, 0.12592220306396484, 0.0032727394718676805, 0.13121919333934784, 0.0033139956649392843, 0.0032829141709953547, 0.0032887973356992006, 0.003311645705252886, 0.003277948359027505, 0.003259361255913973, 0.003247360000386834, 0.0032848408445715904, 0.0032702337484806776, 0.00328850164078176, 0.0033108368515968323, 0.13087953627109528, 0.0032659864518791437, 0.003304086858406663, 0.003354378743097186, 0.003267692867666483, 0.003323608310893178, 0.0032497860956937075, 0.0032559859100729227, 0.11882394552230835, 0.003252028487622738, 0.0032725532073527575, 0.1059558168053627, 0.0033170690294355154, 0.0032553146593272686, 0.003294198540970683, 0.0033605480566620827, 0.003296182258054614, 0.003248487366363406, 0.003307980950921774, 0.0032823928631842136, 0.0033282421063631773, 0.4014228284358978, 0.0032493406906723976, 0.0983673706650734, 0.0032534722704440355, 0.0033659199252724648, 0.003346304642036557, 0.0032735439017415047, 0.10824926942586899, 0.0032611386850476265, 0.003304705722257495, 0.003291749395430088, 0.00329609215259552, 0.0032810198608785868, 0.10846096277236938, 0.0033341804519295692, 0.003269607899710536, 0.0032858781050890684, 0.0033310307189822197, 0.003299018833786249, 0.003315503941848874, 0.0032668423373252153, 0.0033082186710089445, 0.1506953239440918, 0.12367728352546692]\n",
            "Val loss 0.01978448633207265\n",
            "Val auc roc 0.5509416102032683\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50302322-2264-4810-ed6b-246e1f9db2e4"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}