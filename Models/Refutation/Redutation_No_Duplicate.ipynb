{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10(1)_account_tres.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bc989f50f8e416daa3d2cfdf437722e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_76c42a0265f0461b89b56a84b16388da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_387a392677b342ee865411dd06eb6311",
              "IPY_MODEL_100775c0e6f848b8960e8c3d8eb37ca5"
            ]
          }
        },
        "76c42a0265f0461b89b56a84b16388da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "387a392677b342ee865411dd06eb6311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0cd409f2f3554111b111d817ebbfafe8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c5f1a538a3c434484eadac64d76b2fb"
          }
        },
        "100775c0e6f848b8960e8c3d8eb37ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0dfb7433550d4ce2b93b6cf8860c26bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:17&lt;00:00, 13.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce841f8426f8421983fb843a407dfad1"
          }
        },
        "0cd409f2f3554111b111d817ebbfafe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c5f1a538a3c434484eadac64d76b2fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dfb7433550d4ce2b93b6cf8860c26bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce841f8426f8421983fb843a407dfad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34d996169f5b4cdd9b639de17044fdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_118d66604cd941b49f555a97e9c7968b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90bcb17d39c74a2c998afe4b130db3f0",
              "IPY_MODEL_d364c336800d4054ac06ea49927d25aa"
            ]
          }
        },
        "118d66604cd941b49f555a97e9c7968b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90bcb17d39c74a2c998afe4b130db3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f6c6cd11f044452dad58d80f198bda4f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2c7647e0ce14a4bafc4f988e0022889"
          }
        },
        "d364c336800d4054ac06ea49927d25aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_382297cb30ad499aa7e6f90516651d80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [46:03&lt;00:00,  1.73s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f2d5f69e8e745ed86486bc9b97c7614"
          }
        },
        "f6c6cd11f044452dad58d80f198bda4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2c7647e0ce14a4bafc4f988e0022889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "382297cb30ad499aa7e6f90516651d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f2d5f69e8e745ed86486bc9b97c7614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72375b994e21468889d2ec3d1f48a4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b5159a8fa7f48a8bf2af95d4a29dc42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_35ed46e3d2884f0292f55168a3d402cc",
              "IPY_MODEL_833eedfc03534c539974f05881f86245"
            ]
          }
        },
        "2b5159a8fa7f48a8bf2af95d4a29dc42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35ed46e3d2884f0292f55168a3d402cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86b697b01b5a4265bbd2c48765f27fba",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c263218cb1684b93a94afeb908ecf66c"
          }
        },
        "833eedfc03534c539974f05881f86245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_082f13da9ef24aaca0c28ce99fb99b72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [14:54&lt;00:00,  1.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0221e5794694ff9bf1853d8a3487f34"
          }
        },
        "86b697b01b5a4265bbd2c48765f27fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c263218cb1684b93a94afeb908ecf66c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "082f13da9ef24aaca0c28ce99fb99b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0221e5794694ff9bf1853d8a3487f34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "285502e92f074aeea1d71ee2b6cab875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dcb5c7189ec849cc9465131af65fadb8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a05f19440fa448d2b46971e83ccd22e1",
              "IPY_MODEL_38a25147f7de4d8b8774b6f52b5dc406"
            ]
          }
        },
        "dcb5c7189ec849cc9465131af65fadb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a05f19440fa448d2b46971e83ccd22e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ded0cf80df84defa53fddaed5867681",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d2a420dab274e4baa3216ca8100cf6c"
          }
        },
        "38a25147f7de4d8b8774b6f52b5dc406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6ecfc15982c41378d9ec2a4b9d793a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [14:53&lt;00:00,  1.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68e69c63689f4775b982c6e2a47feb8b"
          }
        },
        "0ded0cf80df84defa53fddaed5867681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d2a420dab274e4baa3216ca8100cf6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6ecfc15982c41378d9ec2a4b9d793a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68e69c63689f4775b982c6e2a47feb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "834f02a5-835f-43ec-aec3-0d313db71aba"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 42.36 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10d06a3e-a105-4a1b-e4d3-c434034f4a21"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97206927-8d71-4481-bd76-ee8ba904678b"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3d3f8009-2cf4-433c-d908-a06e8a67c2b0"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f7da51d9-0c61-43ae-a25c-d806ba145ed6"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "36701a87-1fbf-4f65-b07c-db4252e669d4"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 24.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 61.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "115b5916-ba94-4619-dbe5-a0f659dc554c"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "724050ec-fd61-405b-d68b-0f1ff6775c7c"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "2d16f9e2-ff6d-4777-e4a9-43617203d9f6"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4681085c-71e9-4128-abc9-419614c2e5bf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Clean bowled by Congress, Now this is another ...\n",
              "1    @jbowser74 @rgrun1 @Michell39030764 @NelsonFor...\n",
              "2    #MeToo: Raveena Tandon talks about workplace h...\n",
              "3    I am at the @ekpotliretki public hearing in #C...\n",
              "4    If you missed it, check out Cheryl Mcwhorter a...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "542cde47-404d-43a6-8bc0-bb638be1b127"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:13<00:00, 29964157.16B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aa92c39-fa96-4ded-adc1-17dc29a51ad5"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 874856.01B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "68de8006-277b-4bff-b1d5-e9b07238336d"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f3e3ea5-d851-4b3f-e14b-f3af948060e6"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        df4 = df2.copy().reset_index(drop=True)\n",
        "        df5 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            random.shuffle(text)\n",
        "            text3 = ' '.join(text)\n",
        "            df3['text'][i]=text3\n",
        "            random.shuffle(text)\n",
        "            text4 = ' '.join(text)\n",
        "            df4['text'][i]=text4\n",
        "            random.shuffle(text)\n",
        "            text5 = ' '.join(text)\n",
        "            df5['text'][i]=text5\n",
        "        #self.data = self.data.append(df2, ignore_index=True)\n",
        "        #self.data = self.data.append(df3, ignore_index=True)\n",
        "        #self.data = self.data.append(df4, ignore_index=True)\n",
        "        #self.data = self.data.append(df5, ignore_index=True)\n",
        "        #self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "979156d4-3773-446c-b347-69f76fe362f8"
      },
      "source": [
        "col_name = \"Refutation\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4bc989f50f8e416daa3d2cfdf437722e",
            "76c42a0265f0461b89b56a84b16388da",
            "387a392677b342ee865411dd06eb6311",
            "100775c0e6f848b8960e8c3d8eb37ca5",
            "0cd409f2f3554111b111d817ebbfafe8",
            "2c5f1a538a3c434484eadac64d76b2fb",
            "0dfb7433550d4ce2b93b6cf8860c26bd",
            "ce841f8426f8421983fb843a407dfad1",
            "34d996169f5b4cdd9b639de17044fdec",
            "118d66604cd941b49f555a97e9c7968b",
            "90bcb17d39c74a2c998afe4b130db3f0",
            "d364c336800d4054ac06ea49927d25aa",
            "f6c6cd11f044452dad58d80f198bda4f",
            "b2c7647e0ce14a4bafc4f988e0022889",
            "382297cb30ad499aa7e6f90516651d80",
            "2f2d5f69e8e745ed86486bc9b97c7614",
            "72375b994e21468889d2ec3d1f48a4cc",
            "2b5159a8fa7f48a8bf2af95d4a29dc42",
            "35ed46e3d2884f0292f55168a3d402cc",
            "833eedfc03534c539974f05881f86245",
            "86b697b01b5a4265bbd2c48765f27fba",
            "c263218cb1684b93a94afeb908ecf66c",
            "082f13da9ef24aaca0c28ce99fb99b72",
            "c0221e5794694ff9bf1853d8a3487f34",
            "285502e92f074aeea1d71ee2b6cab875",
            "dcb5c7189ec849cc9465131af65fadb8",
            "a05f19440fa448d2b46971e83ccd22e1",
            "38a25147f7de4d8b8774b6f52b5dc406",
            "0ded0cf80df84defa53fddaed5867681",
            "6d2a420dab274e4baa3216ca8100cf6c",
            "e6ecfc15982c41378d9ec2a4b9d793a0",
            "68e69c63689f4775b982c6e2a47feb8b"
          ]
        },
        "outputId": "abbe2e96-bbe2-44be-a10e-822b3e121a89"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6382\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bc989f50f8e416daa3d2cfdf437722e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34d996169f5b4cdd9b639de17044fdec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0288\n",
            "Train Losses : [0.18342357873916626, 0.41181591153144836, 1.6242187023162842, 2.205982208251953, 2.0727367401123047, 2.044450283050537, 1.1804708242416382, 0.3109275996685028, 0.5567217469215393, 0.49198096990585327, 0.16063381731510162, 0.23438642919063568, 0.6792712211608887, 1.5888301134109497, 1.4611544609069824, 1.1048426628112793, 0.778170645236969, 0.8594663739204407, 0.31049177050590515, 0.21369709074497223, 0.18129420280456543, 0.0682048350572586, 0.07820187509059906, 0.0417073518037796, 0.07380183041095734, 0.1575264036655426, 0.04321425035595894, 0.01418489869683981, 0.0385943278670311, 0.021806571632623672, 0.017552899196743965, 0.006769451778382063, 0.022145984694361687, 0.0030613865237683058, 0.002674646209925413, 0.005523490719497204, 0.2659463882446289, 0.005433239042758942, 0.0025521297939121723, 0.002167836530134082, 0.009319360367953777, 0.0034400750882923603, 0.0029899636283516884, 0.001500039012171328, 0.001395170809701085, 0.0009965032804757357, 0.001103291055187583, 0.000786111515481025, 0.009752554818987846, 0.0020484563428908587, 0.0021827444434165955, 0.0026064703706651926, 0.0009151299600489438, 0.000921169645152986, 0.0005231075338087976, 0.0013449836988002062, 0.0003329968312755227, 0.0014794141752645373, 0.0009573196293786168, 0.0012455390533432364, 0.0019762618467211723, 0.0002526254393160343, 0.0002593748504295945, 0.00034929168759845197, 0.0009819871047511697, 0.0004215360095258802, 0.001271457294933498, 0.001005876692943275, 0.0005124147864989936, 0.00022372222156263888, 0.4731821119785309, 0.290785014629364, 0.0006608841940760612, 0.00029461158555932343, 0.0019189683953300118, 0.0004595317877829075, 0.0017980122938752174, 0.4207232892513275, 0.0017395790200680494, 0.0014972230419516563, 0.0011954779038205743, 0.0012271021259948611, 0.001234167953953147, 0.0016492388676851988, 0.0007890700362622738, 0.0005946580786257982, 0.0015073159011080861, 0.29322516918182373, 0.051532723009586334, 0.001715829479508102, 0.10774174332618713, 0.0028206161223351955, 0.0025671564508229494, 0.0017048430163413286, 0.039690498262643814, 0.002159305615350604, 0.006913102697581053, 0.006918584927916527, 0.006287173833698034, 0.0025612253230065107, 0.016262633726000786, 0.002804019721224904, 0.03332836553454399, 0.0015023961896076798, 0.007193253841251135, 0.007595297414809465, 0.002454199828207493, 0.0032513090409338474, 0.0009610311826691031, 0.0049770609475672245, 0.0023348808754235506, 0.0011772230500355363, 0.002517953747883439, 0.0012877524131909013, 0.0007015907904133201, 0.0007296432740986347, 0.261447548866272, 0.0006710868328809738, 0.0007989434525370598, 0.0006803386495448649, 0.1561850905418396, 0.0009519113809801638, 0.001065724645741284, 0.001139686442911625, 0.31466740369796753, 0.0009019906865432858, 0.0012919498840346932, 0.10815846920013428, 0.001549752545543015, 0.0026887471321970224, 0.0010333767859265208, 0.003597469301894307, 0.0017893677577376366, 0.0016244680155068636, 0.0018055833643302321, 0.5268105268478394, 0.0021094605326652527, 0.004795013461261988, 0.002552528865635395, 0.001828990294598043, 0.004669921938329935, 0.004255078267306089, 0.0017957913223654032, 0.0015073431422933936, 0.004776063375174999, 0.0022342808078974485, 0.006070130970329046, 0.0016733977245166898, 0.0031158041674643755, 0.0015448502963408828, 0.0015660537173971534, 0.0013728314079344273, 0.002647354966029525, 0.004675924777984619, 0.002117353258654475, 0.001872896566055715, 0.0015346462605521083, 0.0019449192332103848, 0.0012939717853441834, 0.0016534436726942658, 0.0011231560492888093, 0.19278688728809357, 0.0011397694470360875, 0.0017332513816654682, 0.0010979147627949715, 0.0015311456518247724, 0.0009165693772956729, 0.10983283072710037, 0.001858797506429255, 0.001071201404556632, 0.002174980705603957, 0.001245511113665998, 0.0013456587912514806, 0.001417152932845056, 0.002718555275350809, 0.0016830231761559844, 0.0013135414337739348, 0.0013016692828387022, 0.04787169024348259, 0.0014250369276851416, 0.0017643168102949858, 0.002489585429430008, 0.001800272730179131, 0.0016173585318028927, 0.001583558158017695, 0.0046914382837712765, 0.0029572714120149612, 0.003148504067212343, 0.0018338613444939256, 0.0011287960223853588, 0.002875420730561018, 0.0017517077503725886, 0.48029789328575134, 0.0013488505501300097, 0.003545922227203846, 0.0009465781622566283, 0.0013501469511538744, 0.0015576385194435716, 0.0012457126285880804, 0.00141618843190372, 0.0013614402851089835, 0.002023613080382347, 0.0015417139511555433, 0.14973071217536926, 0.0021032479126006365, 0.0015177964232861996, 0.0015252563171088696, 0.0021020935382694006, 0.0018185364315286279, 0.0013507329858839512, 0.0011423468822613358, 0.0013009500689804554, 0.022324560210108757, 0.0028675261419266462, 0.0011664187768474221, 0.0025166873820126057, 0.25836920738220215, 0.0014511829940602183, 0.004481527488678694, 0.004495356231927872, 0.001158135011792183, 0.06671161949634552, 0.002395188668742776, 0.0026034752372652292, 0.0024654276203364134, 0.003741032676771283, 0.002648730529472232, 0.0024623682256788015, 0.002380581106990576, 0.0033459586557000875, 0.0019503487274050713, 0.004870013799518347, 0.0029919645749032497, 0.0016270079649984837, 0.004218098241835833, 0.0014961493434384465, 0.0016685378504917026, 0.0012483106693252921, 0.0012313674669712782, 0.001358523964881897, 0.0012851622886955738, 0.0012246862752363086, 0.0723680630326271, 0.0012075324775651097, 0.0038933984469622374, 0.9173280000686646, 0.0011320890625938773, 0.0014382358640432358, 0.001948523218743503, 0.00458079157397151, 0.0016930249985307455, 0.0030924836173653603, 0.0022059313487261534, 0.0025479502510279417, 0.0035484565887600183, 0.0019895208533853292, 0.002652463037520647, 0.00321392435580492, 0.002933438401669264, 0.007200730498880148, 0.004950159694999456, 0.0029351997654885054, 0.08527002483606339, 0.003981428686529398, 0.002441403456032276, 0.002591859782114625, 0.002325200941413641, 0.09175705164670944, 0.0031373652163892984, 0.005799320060759783, 0.005689500831067562, 0.0039620669558644295, 0.0031372031662613153, 0.00251769763417542, 0.003735820297151804, 0.007517234887927771, 0.002493067877367139, 0.00468407291918993, 0.0036946104373782873, 0.005348753184080124, 0.0025753588415682316, 0.0020455564372241497, 0.002325300360098481, 0.0030408708844333887, 0.002608733018860221, 0.00648263655602932, 0.0022205926943570375, 0.0013780905865132809, 0.0021775204222649336, 0.0025853661354631186, 0.0029007394332438707, 0.0020682092290371656, 0.0012316766660660505, 0.20573464035987854, 0.0015481121372431517, 0.0012411953648552299, 0.0020253576803952456, 0.001153907272964716, 0.0021642250940203667, 0.16965211927890778, 0.001406300812959671, 0.001717534614726901, 0.0013503174996003509, 0.0011352825677022338, 0.0011647058418020606, 0.0014729994582012296, 0.0031915083527565002, 0.0015339672099798918, 0.0018851067870855331, 0.1839638501405716, 0.0019513312727212906, 0.002170088468119502, 0.0015637247124686837, 0.001595641253516078, 0.0018586274236440659, 0.0014812103472650051, 0.0012277888599783182, 0.0019073480507358909, 0.0014377834741026163, 0.0020541551057249308, 0.0011663713958114386, 0.0016178714577108622, 0.0015790535835549235, 0.0017716221045702696, 0.0017444589175283909, 0.001316178822889924, 0.0013325030449777842, 0.001363541348837316, 0.0017464677803218365, 0.0031342285219579935, 0.0012246753321960568, 0.0018076105043292046, 0.0016121260123327374, 0.0010587358847260475, 0.0015734576154500246, 0.001249009044840932, 0.2995864152908325, 0.0013508936390280724, 0.0013265941524878144, 0.0010235735680907965, 0.0014949934557080269, 0.0009174784063361585, 0.0011585620231926441, 0.00103921873960644, 0.001633104751817882, 0.0009597076568752527, 0.0015436335233971477, 0.0009218286722898483, 0.0011059019016101956, 0.002093279967084527, 0.0011478258529677987, 0.0008142520673573017, 0.002062625950202346, 0.0010237329406663775, 0.0011063184356316924, 0.0012241144431754947, 0.001621472300030291, 0.0010976638877764344, 0.0013121331576257944, 0.0009533401462249458, 0.0006916363490745425, 0.0008109675836749375, 0.0016019250033423305, 0.000663125014398247, 0.0010213424684479833, 0.18956705927848816, 0.19309444725513458, 0.0010534117463976145, 0.0010104298125952482, 0.0008885093848221004, 0.0010044511873275042, 0.0025436412543058395, 0.002684416249394417, 0.0010838451562449336, 0.29395291209220886, 0.0013082425575703382, 0.0025012162514030933, 0.0019645330030471087, 0.001239573466591537, 0.005416119005531073, 0.004102068021893501, 0.001695107202976942, 0.0025210054591298103, 0.16237452626228333, 0.0026463414542376995, 0.003397094551473856, 0.0015457303961738944, 0.002552746795117855, 0.0017333695432171226, 0.002663245890289545, 0.0019600014202296734, 0.0019902328494936228, 0.002663064282387495, 0.003139744745567441, 0.001584399025887251, 0.00283693615347147, 0.003190287621691823, 0.001581590622663498, 0.18214748799800873, 0.001615902641788125, 0.002306971000507474, 0.0018433922668918967, 0.0018331792671233416, 0.002368643879890442, 0.14155064523220062, 0.001498422585427761, 0.0016513230511918664, 0.001655205967836082, 0.00185853720176965, 0.0017263985937461257, 0.33217164874076843, 0.00421296339482069, 0.002508350647985935, 0.001963399350643158, 0.0022291094064712524, 0.0020813802257180214, 0.12785962224006653, 0.0027168455999344587, 0.002511868253350258, 0.002387253800407052, 0.0021917938720434904, 0.0027410846669226885, 0.0020801299251616, 0.0026314554270356894, 0.10985451936721802, 0.0028341375291347504, 0.002429414540529251, 0.0020420837681740522, 0.0027518155984580517, 0.0025651128962635994, 0.0020330375991761684, 0.0031323975417762995, 0.12046055495738983, 0.002874965313822031, 0.0023904431145638227, 0.0028138291090726852, 0.00305715249851346, 0.002867724047973752, 0.0028938481118530035, 0.0036299233324825764, 0.002406505635008216, 0.003433101810514927, 0.002716220449656248, 0.003267693566158414, 0.0029458189383149147, 0.0029599578119814396, 0.0024101133458316326, 0.0023281155154109, 0.0028505034279078245, 0.42923304438591003, 0.0021233786828815937, 0.002279088133946061, 0.002478766953572631, 0.003164529101923108, 0.0019186631543561816, 0.0022101853974163532, 0.0022142704110592604, 0.0019223782001063228, 0.0016258042305707932, 0.0021512843668460846, 0.0015716193011030555, 0.0016980796353891492, 0.10310481488704681, 0.0017620755825191736, 0.0016776500269770622, 0.0016944583039730787, 0.0017669359222054482, 0.0016105049289762974, 0.0021302662789821625, 0.2685536742210388, 0.001950734294950962, 0.0021044875029474497, 0.001572903711348772, 0.1143205538392067, 0.001939318492077291, 0.001807702356018126, 0.10749639570713043, 0.0017703433986753225, 0.0024621332995593548, 0.0020734453573822975, 0.16218237578868866, 0.0021416901145130396, 0.002643904648721218, 0.0036002935376018286, 0.0032107539009302855, 0.0026432594750076532, 0.002492808038368821, 0.0027871739584952593, 0.00304834614507854, 0.0036859754472970963, 0.0027749151922762394, 0.002682196442037821, 0.0028238072991371155, 0.002345344517379999, 0.002904136199504137, 0.002408378291875124, 0.002594942459836602, 0.003874989226460457, 0.0028764628805220127, 0.003342107404023409, 0.002901559928432107, 0.002262949012219906, 0.003231283975765109, 0.002801896771416068, 0.0018851348431780934, 0.0020353489089757204, 0.003004480851814151, 0.0019598386716097593, 0.0017391197616234422, 0.0016429189126938581, 0.0019574041943997145, 0.001602503820322454, 0.13069188594818115, 0.0020131447818130255, 0.0014821700751781464, 0.0015838800463825464, 0.3170759081840515, 0.0019097966141998768, 0.0028169353026896715, 0.0020152349025011063, 0.0018801350379362702, 0.002242092741653323, 0.0019642459228634834, 0.0015628041001036763, 0.0943702906370163, 0.11998879164457321, 0.001959229586645961, 0.0019550288561731577, 0.0017465821001678705, 0.0022576581686735153, 0.3112809360027313, 0.0021719690412282944, 0.002181167481467128, 0.0026779347099363804, 0.0029511151369661093, 0.002565493108704686, 0.0029310400132089853, 0.0030083765741437674, 0.0025467462837696075, 0.0024004410952329636, 0.0024486901238560677, 0.0024887938052415848, 0.0024504594039171934, 0.0022034740541130304, 0.0030640740878880024, 0.0032498857472091913, 0.0025127255357801914, 0.0025321152061223984, 0.002146391896530986, 0.0021120209712535143, 0.0020815355237573385, 0.002023314358666539, 0.0027455182280391455, 0.0028830862138420343, 0.002147938823327422, 0.12495023757219315, 0.0018758031073957682, 0.001872439868748188, 0.0018063061870634556, 0.0019042693311348557, 0.002362640341743827, 0.0017580753192305565, 0.0019147315761074424, 0.0018963004695251584, 0.0021590529941022396, 0.001650164253078401, 0.0018098469590768218, 0.0022591636516153812, 0.0017598638078197837, 0.0019322314765304327, 0.00168644601944834, 0.0016388279618695378, 0.0014458672376349568, 0.0015622825594618917, 0.001602989505045116, 0.0020385824609547853, 0.0015052882954478264, 0.001587342587299645, 0.0016284907469525933, 0.0013364924816414714, 0.0013107041595503688, 0.001414990401826799, 0.0012292710598558187, 0.0012262656819075346, 0.0011503116693347692, 0.0013511049328371882, 0.0012123859487473965, 0.0012209417764097452, 0.0011767990654334426, 0.001064895186573267, 0.001648218953050673, 0.0009946087375283241, 0.0011110386112704873, 0.0011249519884586334, 0.001040329341776669, 0.0010186078725382686, 0.0010489762062206864, 0.0012416422832757235, 0.001298432471230626, 0.0010313594248145819, 0.10378368198871613, 0.0009512274409644306, 0.0009755754726938903, 0.17946022748947144, 0.0012494244147092104, 0.001316922134719789, 0.0011068774620071054, 0.0010588029399514198, 0.0015868559712544084, 0.07135669887065887, 0.12613554298877716, 0.11390026658773422, 0.0016779975267127156, 0.0015138793969526887, 0.003108520992100239, 0.0016475082375109196, 0.0020757848396897316, 0.0019793915562331676, 0.0024080260191112757, 0.002521042712032795, 0.002269456861540675, 0.0019820830784738064, 0.00405163737013936, 0.002699774457141757, 0.0023199892602860928, 0.001965037314221263, 0.002822023816406727, 0.0019455173751339316, 0.002789050340652466, 0.0034400373697280884, 0.0029472345486283302, 0.0020444048568606377, 0.0023756215814501047, 0.0020522037521004677, 0.002196643501520157, 0.002071578288450837, 0.0016870381077751517, 0.21967603266239166, 0.0028654690831899643, 0.0019496515160426497, 0.0018058193381875753, 0.002615362172946334, 0.003313593100756407, 0.0022612768225371838, 0.0023323355708271265, 0.09502942860126495, 0.0019844078924506903, 0.0030895075760781765, 0.0023305597715079784, 0.002342893974855542, 0.0020538142416626215, 0.0019992645829916, 0.0022222960833460093, 0.0018686900148168206, 0.0020923037081956863, 0.12151636183261871, 0.002317244652658701, 0.0023499291855841875, 0.002029803115874529, 0.002181283663958311, 0.002363970037549734, 0.0019970592111349106, 0.11985974758863449, 0.002829257631674409, 0.00415021413937211, 0.0026631259825080633, 0.0022287163883447647, 0.004239081405103207, 0.00247457018122077, 0.002634731587022543, 0.002700657118111849, 0.002542308298870921, 0.0020855946931988, 0.003925134893506765, 0.002232857048511505, 0.0024501103907823563, 0.005000744480639696, 0.0022207272704690695, 0.0017871850868687034, 0.0020064702257514, 0.10785633325576782, 0.0023731719702482224, 0.0026682489551603794, 0.003551909700036049, 0.0023098941892385483, 0.0015740981325507164, 0.0033335480839014053, 0.001993749290704727, 0.0040607457049191, 0.0015799711691215634, 0.002100585959851742, 0.0016260152915492654, 0.0014641095185652375, 0.002707153093069792, 0.002737276954576373, 0.06888736039400101, 0.002157284412533045, 0.10672618448734283, 0.0016424490604549646, 0.004392503760755062, 0.0026619434356689453, 0.001610167557373643, 0.0019685898441821337, 0.6705300807952881, 0.0019267486641183496, 0.0027661072090268135, 0.0028779502026736736, 0.002229269128292799, 0.003380746114999056, 0.11965076625347137, 0.004025542177259922, 0.003217389341443777, 0.008386564441025257, 0.00531836599111557, 0.0035286233760416508, 0.0040065147913992405, 0.15778887271881104, 0.003164283698424697, 0.0046072835102677345, 0.0035033661406487226, 0.004209747537970543, 0.0055845435708761215, 0.005537740886211395, 0.008260412141680717, 0.004903898108750582, 0.004100526683032513, 0.0729840025305748, 0.00446620536968112, 0.17709310352802277, 0.0035776731092482805, 0.004291912540793419, 0.0033244090154767036, 0.0036956642288714647, 0.004211410414427519, 0.0033951883669942617, 0.004357236437499523, 0.003076975466683507, 0.05985128879547119, 0.0038345230277627707, 0.003326728940010071, 0.004040207713842392, 0.003030093852430582, 0.005321473814547062, 0.002799190115183592, 0.003178731305524707, 0.0038226302713155746, 0.004467373713850975, 0.002903546905145049, 0.0034241185057908297, 0.003696769941598177, 0.0038001197390258312, 0.003794945776462555, 0.0024832538329064846, 0.003933757543563843, 0.002038285369053483, 0.001966234063729644, 0.0031151925213634968, 0.002097967080771923, 0.0020836296025663614, 0.0018975057173520327, 0.0025347864720970392, 0.002579642692580819, 0.0017917038640007377, 0.30784136056900024, 0.0015330903697758913, 0.001892948872409761, 0.0015749530866742134, 0.0018291887827217579, 0.0022750801872462034, 0.0018829781329259276, 0.0018484529573470354, 0.0017605116590857506, 0.1980135142803192, 0.0023415160831063986, 0.0020498831290751696, 0.0016529661370441318, 0.001817946438677609, 0.0018332817126065493, 0.0021296003833413124, 0.0024935428518801928, 0.001935480860993266, 0.0024380481336265802, 0.0018243130762130022, 0.001984989270567894, 0.0017405094113200903, 0.0018043394666165113, 0.0016812084941193461, 0.0016335234977304935, 0.001843097503297031, 0.0019362313905730844, 0.0021750975865870714, 0.001659353612922132, 0.0016078581102192402, 0.0013669690815731883, 0.0013863886706531048, 0.0015193361323326826, 0.0016446295194327831, 0.0012880975846201181, 0.0014368235133588314, 0.0016784819308668375, 0.0012542945332825184, 0.00126939220353961, 0.17700165510177612, 0.0015594805590808392, 0.0014711131807416677, 0.001223054830916226, 0.0013366141356527805, 0.001539228716865182, 0.001276307157240808, 0.00131483213044703, 0.0015337120275944471, 0.0015725565608590841, 0.001283851801417768, 0.0016896576853469014, 0.001373860752210021, 0.001280599390156567, 0.0013009544927626848, 0.001283645979128778, 0.0011912337504327297, 0.0011821764055639505, 0.0013778319116681814, 0.20297522842884064, 0.001247465261258185, 0.0013090188149362803, 0.001564151025377214, 0.0015497799031436443, 0.001365402713418007, 0.0016944888047873974, 0.0017310993280261755, 0.0015850960044190288, 0.21234256029129028, 0.0013687487225979567, 0.0016618343070149422, 0.001421890570782125, 0.0019244204740971327, 0.001670319470576942, 0.2210402637720108, 0.0017976571107283235, 0.0016129312571138144, 0.0023644331376999617, 0.001716163009405136, 0.001764453249052167, 0.1313137412071228, 0.0018493379466235638, 0.0021513972897082567, 0.0021321221720427275, 0.002804897725582123, 0.1758083701133728, 0.002282160334289074, 0.002547971671447158, 0.0028627514839172363, 0.003040772397071123, 0.003627082332968712, 0.002689934801310301, 0.0027489380445331335, 0.003121134592220187, 0.0025548648554831743, 0.08019188791513443, 0.08875442296266556, 0.002770007587969303, 0.1675156056880951, 0.0033111555967479944, 0.003427120391279459, 0.0036096456460654736, 0.003468497423455119, 0.0035001880023628473, 0.003766255918890238, 0.004616961814463139, 0.003972145728766918, 0.0036308057606220245, 0.0037936619482934475, 0.0034936177544295788, 0.003370658028870821, 0.0035407464019954205, 0.004522805102169514, 0.0029836848843842745, 0.0029555761720985174, 0.0031283407006412745, 0.0029303226619958878, 0.20920726656913757, 0.002930309157818556, 0.0031929260585457087, 0.0032517598010599613, 0.0028083377983421087, 0.0026574982330203056, 0.0027265259996056557, 0.002810005098581314, 0.0026782348286360502, 0.0024926667101681232, 0.0023622242733836174, 0.002652284223586321, 0.002285948721691966, 0.257514089345932, 0.0022442874033004045, 0.002313527511432767, 0.003556539537385106, 0.2703561782836914, 0.13789904117584229, 0.0025404696352779865, 0.141394704580307, 0.002760786097496748, 0.002735579153522849, 0.002935913158580661, 0.003223591949790716, 0.0030544730834662914, 0.003656641347333789, 0.0030545005574822426, 0.003170964540913701, 0.0032208701595664024, 0.0031080814078450203, 0.0035501783713698387, 0.0030925972387194633, 0.003206616500392556, 0.0031168637797236443, 0.0032028534915298223, 0.003015619469806552, 0.0031854058615863323, 0.0029709574300795794, 0.002959319157525897, 0.0026707653887569904, 0.002844402100890875, 0.0026680149603635073, 0.002920553321018815, 0.0025885789655148983, 0.002395694376900792, 0.002383588580414653, 0.0026760816108435392, 0.0022268807515501976, 0.002353541785851121, 0.0023063072003424168, 0.0019973048474639654, 0.0021155832801014185, 0.0019516260363161564, 0.0018671512370929122, 0.001985969254747033, 0.00197861110791564, 0.001716353464871645, 0.0016950627323240042, 0.0018703974783420563, 0.001643972471356392, 0.0015515234554186463, 0.0015872116200625896, 0.001512635499238968, 0.0016099393833428621, 0.0014666490023955703, 0.0015379198594018817, 0.0013609218876808882, 0.001393548445776105, 0.0013479616027325392, 0.0013185481075197458, 0.0014575544046238065, 0.0012299929512664676, 0.001184303779155016, 0.11091426014900208, 0.0012451158836483955, 0.001308686682023108, 0.0013293192023411393, 0.13005748391151428, 0.001302205491811037, 0.0015734480693936348, 0.001464766450226307, 0.001429111696779728, 0.0014911958714947104, 0.001421660534106195, 0.001438418752513826, 0.0016183671541512012, 0.0015169789548963308, 0.0016189423622563481, 0.0016057412140071392, 0.0015157770831137896, 0.0014854972250759602, 0.0016540877986699343, 0.0015589201357215643, 0.0014924341812729836, 0.0014590024948120117, 0.0016625882126390934, 0.0015992869157344103, 0.0015129264211282134, 0.0015124223427847028, 0.00144226907286793, 0.0015090901870280504, 0.0015284684486687183, 0.0014438304351642728, 0.0014390064170584083, 0.0015902266604825854, 0.0014207882340997458, 0.0011999767739325762, 0.1252903789281845, 0.0013922755606472492, 0.0020833048038184643, 0.00134531210642308, 0.0013446874218061566, 0.0015075559495016932, 0.001331185339950025, 0.0014129328774288297, 0.0014383068773895502, 0.0013728151097893715, 0.0013197766384109855, 0.001388002187013626, 0.0012941132299602032, 0.0013921454083174467, 0.001663485076278448, 0.0014277129666879773, 0.0012670124415308237, 0.0012372488854452968, 0.0013965039979666471, 0.0015103945042937994, 0.001302174641750753, 0.10780037194490433, 0.001220602192915976, 0.0012578010791912675, 0.001371879014186561, 0.001486893161199987, 0.0012409236514940858, 0.0012847051257267594, 0.0013529049465432763, 0.0013554716715589166, 0.0014775037998333573, 0.0011671712854877114, 0.0013935017632320523, 0.0015022085281088948, 0.0014002124080434442, 0.0015404074219986796, 0.0012787888990715146, 0.0013730955542996526, 0.001180722494609654, 0.001615830697119236, 0.17407773435115814, 0.0012892332160845399, 0.0013109671417623758, 0.0013367736246436834, 0.0015894934767857194, 0.0014554752269759774, 0.0014489335007965565, 0.002007598290219903, 0.0012891794322058558, 0.0011826532427221537, 0.0013170626480132341, 0.0013451803242787719, 0.0011846583802253008, 0.0012869331985712051, 0.0013311804505065084, 0.0013275450328364968, 0.0014320777263492346, 0.0011610167566686869, 0.0012325842399150133, 0.0013485598610714078, 0.001133157406002283, 0.001197319128550589, 0.0019119192147627473, 0.0012006500037387013, 0.0014770040288567543, 0.0010213125497102737, 0.12105414271354675, 0.0012699622893705964, 0.001250510336831212, 0.00129132647998631, 0.0011571915820240974, 0.0011223010951653123, 0.0014713638229295611, 0.0011905559804290533, 0.047424472868442535, 0.0013797972351312637, 0.0014062094269320369, 0.001190053764730692, 0.0014260973548516631, 0.0014298319583758712, 0.0013450627448037267, 0.0013422768097370863, 0.0013088074047118425, 0.001844128011725843, 0.0013669409090653062, 0.11944863200187683, 0.0013299506390467286, 0.00130528025329113, 0.0013690914493054152, 0.0013789378572255373, 0.0019728634506464005, 0.001954996259883046, 0.0015063649043440819, 0.053399231284856796, 0.0016285391757264733, 0.0019955530297011137, 0.0016097765183076262, 0.0017282903427258134, 0.002013938268646598, 0.00161162915173918, 0.002064615022391081, 0.2709149420261383, 0.0017573636723682284, 0.002080981619656086, 0.0019727807957679033, 0.0017905088607221842, 0.0017593037337064743, 0.0020944704301655293, 0.0019507692195475101, 0.0023782614152878523, 0.0020085920114070177, 0.002049418166279793, 0.0017445423873141408, 0.001846618833951652, 0.0018197346944361925, 0.0017386641120538116, 0.0016677312087267637, 0.0028238333761692047, 0.001988111063838005, 0.002079838188365102, 0.001621297444216907, 0.0016018253518268466, 0.0017874428303912282, 0.001553767709992826, 0.0018370755715295672, 0.0017437024507671595, 0.0014797350158914924, 0.0013759706635028124, 0.001406090916134417, 0.0014083818532526493, 0.0016455516451969743, 0.0015159613685682416, 0.0014856307534500957, 0.0015469711506739259, 0.2142312377691269, 0.001217507990077138, 0.0013827208895236254, 0.0013777146814391017, 0.001586287864483893, 0.0013229699106886983, 0.0013915105955675244, 0.13063612580299377, 0.0013998100766912103, 0.0015641107456758618, 0.0021228722762316465, 0.0014705258654430509, 0.0017396077746525407, 0.0016013482818379998, 0.13900882005691528, 0.001736510661430657, 0.00198426959104836, 0.0017937144730240107, 0.001687915762886405, 0.002135233720764518, 0.0019913872238248587, 0.002394299255684018, 0.0021844615694135427, 0.0018878555856645107, 0.0025887698866426945, 0.18917790055274963, 0.002148780971765518, 0.002307776128873229, 0.002224394353106618, 0.0018690259894356132, 0.0020500640384852886, 0.0021445052698254585, 0.002471664920449257, 0.0019001782638952136, 0.31001120805740356, 0.003471420845016837, 0.0028159304056316614, 0.14188168942928314, 0.0023071523755788803, 0.002136061666533351, 0.0027260349597781897, 0.0027358983643352985, 0.09988252818584442, 0.13737641274929047, 0.13511882722377777, 0.003439138410612941, 0.003096918808296323, 0.0029839221388101578, 0.0037340358830988407, 0.003459726460278034, 0.0036589978262782097, 0.004308647941797972, 0.003838410833850503, 0.08867064863443375, 0.0034484374336898327, 0.007945123128592968, 0.003509082365781069, 0.0047738635912537575, 0.004136587958782911, 0.004339351784437895, 0.0037648507859557867, 0.0036625657230615616, 0.0034588156268000603, 0.0035085983108729124, 0.0037343890871852636, 0.00442242668941617, 0.003960501402616501, 0.10764935612678528, 0.0030928642954677343, 0.0033726857509464025, 0.1449124813079834, 0.004749620333313942, 0.004718999844044447, 0.004066767171025276, 0.003459501313045621, 0.0036909598857164383, 0.0032380884513258934, 0.0038034007884562016, 0.003555453382432461, 0.13665318489074707, 0.004055615980178118, 0.003452453762292862, 0.003271672409027815, 0.003129363991320133, 0.004161277785897255, 0.0041539231315255165, 0.002901574829593301, 0.00309639610350132, 0.0028448118828237057, 0.0028893162962049246, 0.0037506294902414083, 0.19366978108882904, 0.0028300397098064423, 0.0027449829503893852, 0.0029823421500623226, 0.0030823301058262587, 0.00318725174292922, 0.24240514636039734, 0.00308129470795393, 0.003120703622698784, 0.0043924120254814625, 0.0036163832992315292, 0.0029921329114586115, 0.0031620520167052746, 0.004128886852413416, 0.003208891488611698, 0.002696407027542591, 0.0027706644032150507, 0.002702980535104871, 0.002956697251647711, 0.00297663826495409, 0.002705022692680359, 0.0029892700258642435, 0.002464157762005925, 0.0025055324658751488, 0.0022528180852532387, 0.0021750684827566147, 0.0024029563646763563, 0.002307741204276681, 0.0024544738698750734, 0.0021003037691116333, 0.002219366142526269, 0.0019867585506290197, 0.0018647173419594765, 0.11684021353721619, 0.0021272050216794014, 0.0019209947204217315, 0.002523713279515505, 0.002247374504804611, 0.0022941604256629944, 0.00222949986346066, 0.0017429884755983949, 0.0017601189902052283, 0.0017788961995393038, 0.0017110098851844668, 0.0016582413809373975, 0.0015947328647598624, 0.0017527812160551548, 0.0016840274911373854, 0.001888223341666162, 0.0019598561339080334, 0.0018182694911956787, 0.0014260768657550216, 0.0016547180712223053, 0.001613786444067955, 0.0014723555650562048, 0.0016442063497379422, 0.0017291945405304432, 0.001276136375963688, 0.0013273840304464102, 0.0012984492350369692, 0.0012877300614491105, 0.0012053160462528467, 0.0014609964564442635, 0.0012639511842280626, 0.001370855956338346, 0.0011065161088481545, 0.0011512463679537177, 0.0011339802294969559, 0.0011215488193556666, 0.0011430460726842284, 0.0010931002907454967, 0.001012983382679522, 0.0010375853162258863, 0.0010869945399463177, 0.0010228060418739915, 0.0010082598309963942, 0.0009713696781545877, 0.0009547551744617522, 0.0010186845902353525, 0.000917155877687037, 0.0010902801295742393, 0.0008748397813178599, 0.0009319167584180832, 0.001116617931984365, 0.0009515259298495948, 0.0008282935013994575, 0.0010737540433183312, 0.0008890031604096293, 0.0008068110910244286, 0.0008491549524478614, 0.0008125503663904965, 0.0007890979759395123, 0.0007746262126602232, 0.0009084815392270684, 0.0007941091316752136, 0.1467134803533554, 0.0008786531980149448, 0.0011381494114175439, 0.0008078473620116711, 0.0008993210503831506, 0.0008876046631485224, 0.0008106075110845268, 0.0010084881214424968, 0.00098754046484828, 0.0008695528958924115, 0.0009671099251136184, 0.001325849094428122, 0.0009065215708687901, 0.0009373072534799576, 0.001055367523804307, 0.001111438381485641, 0.0009944220073521137, 0.12255813181400299, 0.001272442750632763, 0.0009584056097082794, 0.0010775340488180518, 0.0009159771725535393, 0.0011939547257497907, 0.0010534619214013219, 0.000957054493483156, 0.0012030410580337048, 0.001080985413864255, 0.0010800332529470325, 0.0010302565060555935, 0.001043586409650743, 0.0010558980284258723, 0.001074982457794249, 0.2612888216972351, 0.0010749027132987976, 0.19770774245262146, 0.0012447290355339646, 0.001289609121158719, 0.001228140201419592, 0.0014713499695062637, 0.0018566136714071035, 0.001570330117829144, 0.0014341489877551794, 0.0016269454499706626, 0.0017049984307959676, 0.0016488686669617891, 0.0015122819459065795, 0.0015221883077174425, 0.001555088092572987, 0.10669513046741486, 0.001773195224814117, 0.0016292664222419262, 0.0015908863861113787, 0.001628598547540605, 0.0016567029524594545, 0.0016864382196217775, 0.0019733496010303497, 0.001667525852099061, 0.0019181182142347097, 0.0018262790981680155, 0.0017143386648967862, 0.0017592443618923426, 0.001597112393938005, 0.0015918054850772023, 0.0019729819614440203, 0.0017406041733920574, 0.0016683907015249133, 0.0018316131317988038, 0.0015664417296648026, 0.0016595422057434916, 0.0017368573462590575, 0.0014888378791511059, 0.285563200712204, 0.001732582226395607, 0.0017048753798007965, 0.0018735856283456087, 0.0016052330611273646, 0.0019718443509191275, 0.0016057665925472975, 0.001820370089262724, 0.00166082545183599, 0.0016083224909380078, 0.0014972162898629904, 0.0015059196157380939, 0.001936170388944447, 0.0018267111154273152, 0.001486165914684534, 0.0014313283609226346, 0.0014887438155710697, 0.001762549625709653, 0.0014930285979062319, 0.0013784609036520123, 0.0014978396939113736, 0.0013617436634376645, 0.0013486832613125443, 0.0014138725819066167, 0.0012414836091920733, 0.0013315575197339058, 0.001430509495548904, 0.0011972779175266623, 0.0011818066705018282, 0.0011575702810660005, 0.0011578749399632215, 0.001114940969273448, 0.0013015336589887738, 0.001318112714216113, 0.0010651216143742204, 0.001109464792534709, 0.001096063177101314, 0.0010428071254864335, 0.0011455542407929897, 0.001089767785742879, 0.0010911819990724325, 0.0009646131657063961, 0.0010257757967337966, 0.0009515774436295033, 0.001062535447999835, 0.0010409372625872493, 0.0009172149584628642, 0.0009160640183836222, 0.0008857477223500609, 0.10883525013923645, 0.0009481939487159252, 0.000893393880687654, 0.0009000147692859173, 0.0010594753548502922, 0.0010717965196818113, 0.0009248452843166888, 0.0009341620025224984, 0.0012412520591169596, 0.0009281305829063058, 0.001025443896651268, 0.0009804897708818316, 0.0010993732139468193, 0.10969187319278717, 0.15718518197536469, 0.0009982732590287924, 0.0011998048285022378, 0.0012934112455695868, 0.0011480740504339337, 0.0013273594668135047, 0.0013820009771734476, 0.001230478985235095, 0.0013983349781483412, 0.0013724209275096655, 0.0013258745893836021, 0.0013954263413324952, 0.0017780984053388238, 0.0014943097485229373, 0.0017381069483235478, 0.0014481906546279788, 0.001408661832101643, 0.0014198743738234043, 0.0014568665064871311, 0.0014546294696629047, 0.0014866669662296772, 0.0015608081594109535, 0.0013371328823268414, 0.0013487943215295672, 0.0013855422148481011, 0.0012744436971843243, 0.0014110354240983725, 0.001577623886987567, 0.001232396112754941, 0.0012707210844382644, 0.0013530729338526726, 0.0011973215732723475, 0.0011771735735237598, 0.001470843912102282, 0.0012434549862518907, 0.09839079529047012, 0.0011378577910363674, 0.0011662106262519956, 0.0011413681786507368, 0.0012546178186312318, 0.001263193553313613, 0.001168462447822094, 0.0013402975164353848, 0.0012508182553574443, 0.0019054095027968287, 0.0012245781254023314, 0.11614770442247391, 0.0015715619083493948, 0.0012529944069683552, 0.0012795912334695458, 0.0014029485173523426, 0.0017227367497980595, 0.0015123975463211536, 0.09395220130681992, 0.0016338687855750322, 0.001342675881460309, 0.0017116520320996642, 0.11974673718214035, 0.0015104702906683087, 0.001610483042895794, 0.0017670417437329888, 0.0016678173560649157, 0.0019512057770043612, 0.0017779837362468243, 0.0019923930522054434, 0.0018246223917230964, 0.0019797661807388067, 0.003167602699249983, 0.0028466309886425734, 0.002422691322863102, 0.1590130627155304, 0.00209224596619606, 0.0022292921785265207, 0.0023297651205211878, 0.0028468454256653786, 0.0021324786357581615, 0.002515778411179781, 0.002457929542288184, 0.0026471526362001896, 0.002632239367812872, 0.0021968840155750513, 0.00253885961137712, 0.002335940022021532, 0.002078382298350334, 0.002575752791017294, 0.0022364663891494274, 0.0024245278909802437, 0.002096291398629546, 0.0019114967435598373, 0.0020894648041576147, 0.0027913900557905436, 0.0018924238393083215, 0.0018593448912724853, 0.002074895426630974, 0.001710292068310082, 0.0015690450090914965, 0.0022372487001121044, 0.0016357807908207178, 0.001574534340761602, 0.0016599309165030718, 0.13888753950595856, 0.13109862804412842, 0.001591312699019909, 0.0020476512145251036, 0.0018033067462965846, 0.0015943548642098904, 0.0018793579656630754, 0.08534909784793854, 0.0019729668274521828, 0.0019526764517650008, 0.09348119795322418, 0.0022283021826297045, 0.002106875879690051, 0.002490825718268752, 0.0022055767476558685, 0.002420935546979308, 0.002972618443891406, 0.00235773716121912, 0.002908991649746895, 0.09654881805181503, 0.0025145141407847404, 0.0027274431195110083, 0.002372425515204668, 0.002363430568948388, 0.0023624892346560955, 0.2290358543395996, 0.0028927018865942955, 0.0031289567705243826, 0.0031962734647095203, 0.056601736694574356, 0.14743244647979736, 0.16643880307674408, 0.0032361100893467665, 0.0032858543563634157, 0.004088076297193766, 0.004451328422874212, 0.00407104566693306, 0.003738260129466653, 0.00477748503908515, 0.006299007683992386, 0.004121299367398024, 0.005312501918524504, 0.003630989696830511, 0.006426707841455936, 0.004208837635815144, 0.003784717759117484, 0.0038624994922429323, 0.00323540554381907, 0.0036647371016442776, 0.0039434959180653095, 0.06855378299951553, 0.0039029240142554045, 0.0038601155392825603, 0.0030363688711076975]\n",
            "Val loss 0.015243765239820893\n",
            "Val auc roc 0.5392188165176671\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72375b994e21468889d2ec3d1f48a4cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0152\n",
            "Train Losses : [0.0031022033654153347, 0.0030834118369966745, 0.0029113891068845987, 0.0026726392097771168, 0.004957797937095165, 0.0037795696407556534, 0.003001550678163767, 0.003889505285769701, 0.0024313009344041348, 0.0028023819904774427, 0.002309320727363229, 0.003715147264301777, 0.003911200445145369, 0.0026777430903166533, 0.0035885248798877, 0.0019947357941418886, 0.0031712527852505445, 0.0027645931113511324, 0.002354108728468418, 0.00206456589512527, 0.0018275639740750194, 0.07603718340396881, 0.002884741872549057, 0.0019496340537443757, 0.0024893644731491804, 0.0021196005400270224, 0.0017420081421732903, 0.0017799633787944913, 0.0018825622973963618, 0.002088759560137987, 0.002141344826668501, 0.0029749602545052767, 0.0016350819496437907, 0.003542947815731168, 0.0017201144946739078, 0.002900021616369486, 0.001519100391305983, 0.001477035111747682, 0.001285939710214734, 0.0018918064888566732, 0.002102762693539262, 0.0015326767461374402, 0.0018290551379323006, 0.0012449956266209483, 0.0016304954187944531, 0.0013744630850851536, 0.0011028768494725227, 0.0012919363798573613, 0.002542902948334813, 0.19257619976997375, 0.0010799352312460542, 0.0014275949215516448, 0.001146004069596529, 0.0010790093801915646, 0.0016869029495865107, 0.0012537826551124454, 0.0017490581376478076, 0.0010647253366187215, 0.060000501573085785, 0.0012551967520266771, 0.002573055913671851, 0.0013914299197494984, 0.0016297796973958611, 0.0013305620523169637, 0.0013650971231982112, 0.14923998713493347, 0.0012707319110631943, 0.0018452350050210953, 0.0017856571357697248, 0.06166311725974083, 0.0014002355746924877, 0.0015740052331238985, 0.0014065781142562628, 0.0014617710839956999, 0.0030510067008435726, 0.002838899614289403, 0.20332011580467224, 0.0016715183155611157, 0.0026258518919348717, 0.0023678604047745466, 0.002745208563283086, 0.0018420771230012178, 0.0019998466596007347, 0.0028566347900778055, 0.0017945464933291078, 0.0019149314612150192, 0.0020045191049575806, 0.0027392806950956583, 0.002053967909887433, 0.002505370182916522, 0.002614809898659587, 0.002046372275799513, 0.0016883728094398975, 0.002191216452047229, 0.002168223261833191, 0.0034148378763347864, 0.22924326360225677, 0.0020841597579419613, 0.001685286988504231, 0.001990189542993903, 0.0019018057500943542, 0.002163530560210347, 0.0017243565525859594, 0.21364416182041168, 0.001835695467889309, 0.0025291182100772858, 0.0026799265760928392, 0.0022081336937844753, 0.0018461106810718775, 0.002424768405035138, 0.00208299420773983, 0.002181415446102619, 0.0036717248149216175, 0.002110617933794856, 0.00276955240406096, 0.0028060644399374723, 0.0022086231037974358, 0.0020718316081911325, 0.001946148695424199, 0.0023946885485202074, 0.0019632636103779078, 0.0017894249176606536, 0.002199839800596237, 0.002189691411331296, 0.0017930055037140846, 0.002048108959570527, 0.001904507982544601, 0.001597717753611505, 0.0014932423364371061, 0.0017431937158107758, 0.0015775988576933742, 0.0015113753033801913, 0.0015859614359214902, 0.00165078928694129, 0.0017732646083459258, 0.001475426135584712, 0.0014307079836726189, 0.0013887019595131278, 0.001295891939662397, 0.0012284851400181651, 0.0014417393831536174, 0.0011948313331231475, 0.0015298174694180489, 0.0012286334531381726, 0.0014250134117901325, 0.0011531489435583353, 0.0011471847537904978, 0.0012716340133920312, 0.0011940437834709883, 0.00128333386965096, 0.24586154520511627, 0.0015785816358402371, 0.0014005107805132866, 0.001520283636637032, 0.0013918838230893016, 0.0015060189180076122, 0.21757827699184418, 0.001130527351051569, 0.0013048808323219419, 0.0014333972940221429, 0.0014909894671291113, 0.07622172683477402, 0.0013555617770180106, 0.0016580316005274653, 0.0014667295617982745, 0.0016087302938103676, 0.002491376828402281, 0.0022463644854724407, 0.002252773614600301, 0.00200680922716856, 0.001703696558251977, 0.001572251203469932, 0.0017459936207160354, 0.001680976478382945, 0.0017667921492829919, 0.00193113018758595, 0.1784861832857132, 0.002176677342504263, 0.001678349799476564, 0.00197851681150496, 0.00226807314902544, 0.1866014450788498, 0.001811542664654553, 0.002013756660744548, 0.002469003200531006, 0.0022263762075453997, 0.001905420096591115, 0.0019402664620429277, 0.002370451344177127, 0.0025366228073835373, 0.002225344767794013, 0.002531170379370451, 0.0975833311676979, 0.0025325852911919355, 0.0024132973048835993, 0.0021178661845624447, 0.002862307708710432, 0.0020580387208610773, 0.002488872269168496, 0.00247819721698761, 0.0021633110009133816, 0.0028901072219014168, 0.0021479397546499968, 0.002406506333500147, 0.0025103960651904345, 0.002152369124814868, 0.0020990276243537664, 0.00253500253893435, 0.0030776008497923613, 0.0023827524855732918, 0.00184158596675843, 0.0018662628717720509, 0.0019060784252360463, 0.17208319902420044, 0.0018162125488743186, 0.0020000652875751257, 0.0018467658665031195, 0.0021968672517687082, 0.0018897783011198044, 0.18184632062911987, 0.002212889725342393, 0.0019457261078059673, 0.002205094089731574, 0.002281046938151121, 0.002587420865893364, 0.002279855776578188, 0.15839825570583344, 0.10084996372461319, 0.00262559880502522, 0.0021352823823690414, 0.10950417071580887, 0.00251719425432384, 0.00258005503565073, 0.07493685930967331, 0.0037297448143363, 0.003434802871197462, 0.0034693272318691015, 0.002993915695697069, 0.003741444321349263, 0.0029961129184812307, 0.004179809708148241, 0.003940974827855825, 0.0030682357028126717, 0.0031522889621555805, 0.0037263422273099422, 0.0033566714264452457, 0.0035140174441039562, 0.003370781894773245, 0.004314477555453777, 0.0030803217086941004, 0.0035108807496726513, 0.0028082523494958878, 0.003339243121445179, 0.003639433765783906, 0.003464450128376484, 0.0027124120388180017, 0.0024830542970448732, 0.0025873358827084303, 0.00258801132440567, 0.002744471188634634, 0.0024866261519491673, 0.0031127475667744875, 0.002826948883011937, 0.002151567954570055, 0.0022786366753280163, 0.1333523541688919, 0.0019614254124462605, 0.0022137106861919165, 0.0023336606100201607, 0.001933722640387714, 0.003024311503395438, 0.002128101419657469, 0.0021039966959506273, 0.0020720523316413164, 0.0031949293334037066, 0.0018063598545268178, 0.0019872039556503296, 0.0019160794327035546, 0.00201117480173707, 0.0023171864449977875, 0.001808889559470117, 0.0018378407694399357, 0.0022524737287312746, 0.002272032666951418, 0.001549341483041644, 0.0016961729852482677, 0.0018953655380755663, 0.0016033054562285542, 0.0014703839551657438, 0.0015994444256648421, 0.0018430587369948626, 0.0014350336277857423, 0.0018614542204886675, 0.001703668269328773, 0.0013615292264148593, 0.0016209677560254931, 0.0012841214193031192, 0.0012617616448551416, 0.0014916528016328812, 0.0011961731361225247, 0.001969203818589449, 0.6803045868873596, 0.0020045298151671886, 0.0016965633258223534, 0.0020373412407934666, 0.001907693105749786, 0.0019296444952487946, 0.002347217872738838, 0.00199379725381732, 0.001867140643298626, 0.0019624209962785244, 0.0023839229252189398, 0.002140260301530361, 0.002259170636534691, 0.0023792400024831295, 0.00219230935908854, 0.002267558593302965, 0.002301255939528346, 0.002260643756017089, 0.0030573485419154167, 0.002370415721088648, 0.002695078495889902, 0.0023318068124353886, 0.002390386536717415, 0.0021208017133176327, 0.17487706243991852, 0.14912277460098267, 0.0020837332122027874, 0.002217900473624468, 0.0024106488563120365, 0.1439010053873062, 0.003220195882022381, 0.1779540479183197, 0.00338374893181026, 0.0035167946480214596, 0.1535608023405075, 0.003574630944058299, 0.08208376169204712, 0.09579411149024963, 0.003507506800815463, 0.00434936722740531, 0.004154656082391739, 0.005591266788542271, 0.005704320501536131, 0.005404143128544092, 0.00448245694860816, 0.004774920176714659, 0.004416104406118393, 0.1508006751537323, 0.005023912061005831, 0.004876718390733004, 0.005774556193500757, 0.0047561428509652615, 0.004649390932172537, 0.16324427723884583, 0.004704516381025314, 0.004747285507619381, 0.004700097255408764, 0.10951217263936996, 0.19768385589122772, 0.0045652007684111595, 0.004969719797372818, 0.004659218713641167, 0.00514190224930644, 0.004741284530609846, 0.00480643892660737, 0.005085424520075321, 0.005531127564609051, 0.004509525373578072, 0.004802461247891188, 0.004824533127248287, 0.00494141923263669, 0.00440829386934638, 0.004406571853905916, 0.005131704267114401, 0.004414098337292671, 0.003924961667507887, 0.004017520230263472, 0.0038081358652561903, 0.0040006437338888645, 0.003636574139818549, 0.0034623544197529554, 0.0034485668875277042, 0.0035179408732801676, 0.003137033898383379, 0.23441660404205322, 0.0030229100957512856, 0.0034430702216923237, 0.1300957202911377, 0.003126922296360135, 0.0030226183589547873, 0.0030108962673693895, 0.003233963157981634, 0.18519166111946106, 0.0033693991135805845, 0.0033340072259306908, 0.0033748249989002943, 0.003067142330110073, 0.003445517970249057, 0.003420754801481962, 0.0031463238410651684, 0.0030498886480927467, 0.003000119235366583, 0.0032391734421253204, 0.0028959985356777906, 0.0030494825914502144, 0.0030360333621501923, 0.003013722598552704, 0.002863621339201927, 0.0027386993169784546, 0.0026826022658497095, 0.0026073558256030083, 0.0026108676102012396, 0.0025457963347434998, 0.0024711827281862497, 0.0024618750903755426, 0.002785101532936096, 0.00237049488350749, 0.0022305159363895655, 0.0024913433007895947, 0.002161117037758231, 0.0022078698966652155, 0.0021805651485919952, 0.0022069946862757206, 0.16830739378929138, 0.002171664033085108, 0.002186044119298458, 0.0020907928701490164, 0.0019846265204250813, 0.002067441353574395, 0.0020337013993412256, 0.002069980837404728, 0.0020160400308668613, 0.0020155790261924267, 0.17042820155620575, 0.0019996233750134706, 0.001982938265427947, 0.002148742787539959, 0.0021242129150778055, 0.0020716965664178133, 0.0020828049164265394, 0.0019712215289473534, 0.0020464323461055756, 0.001962267793715, 0.0019768206402659416, 0.002013013930991292, 0.0019921809434890747, 0.0021134621929377317, 0.0020428297575563192, 0.0018681648653000593, 0.0019028267124667764, 0.001893052482046187, 0.0018891905201599002, 0.0019915986340492964, 0.0019551708828657866, 0.001738189603202045, 0.0018494684481993318, 0.0017044558189809322, 0.0016418349696323276, 0.001674096449278295, 0.0016700263367965817, 0.00177815614733845, 0.0016296333633363247, 0.0015832505887374282, 0.0016778368735685945, 0.0015090712113305926, 0.001507184118963778, 0.0015524353366345167, 0.0015038142446428537, 0.0014405902475118637, 0.0013938387855887413, 0.0014170629438012838, 0.0013511802535504103, 0.0013546018162742257, 0.12106234580278397, 0.596340537071228, 0.18390139937400818, 0.0017407742561772466, 0.0018986649811267853, 0.0022864986676722765, 0.0022346810437738895, 0.0023717412259429693, 0.16921785473823547, 0.0027312913443893194, 0.002992785070091486, 0.0032668118365108967, 0.0032133623026311398, 0.0035186749882996082, 0.0037097155582159758, 0.003709882963448763, 0.0036698863841593266, 0.0038327944930642843, 0.0038942426908761263, 0.003831008914858103, 0.003963993862271309, 0.003988266922533512, 0.0038871290162205696, 0.0037339194677770138, 0.13981615006923676, 0.003802686696872115, 0.003771056653931737, 0.0039391061291098595, 0.003872091881930828, 0.003841939615085721, 0.13591670989990234, 0.0038657584227621555, 0.0038349998649209738, 0.003950073383748531, 0.003785080276429653, 0.09869438409805298, 0.0039419326931238174, 0.003811090486124158, 0.00400410033762455, 0.003923103213310242, 0.003783018561080098, 0.0038573977071791887, 0.003812050446867943, 0.0038224831223487854, 0.003853055415675044, 0.0035690092481672764, 0.0035787427332252264, 0.1116860955953598, 0.0036234098952263594, 0.003517103847116232, 0.003467497183009982, 0.0034459861926734447, 0.13504160940647125, 0.0035013763699680567, 0.0035117098595947027, 0.13819195330142975, 0.0034773985389620066, 0.003547538537532091, 0.0035550629254430532, 0.0036069441121071577, 0.003561430610716343, 0.003567251143977046, 0.0037106808740645647, 0.0035590094048529863, 0.13131213188171387, 0.0035757524892687798, 0.003507547779008746, 0.0036697520408779383, 0.0035469159483909607, 0.003618489019572735, 0.11292748153209686, 0.1111537516117096, 0.0036902728024870157, 0.0037504557985812426, 0.0036655550356954336, 0.0037933317944407463, 0.0037843298632651567, 0.15484297275543213, 0.0040511745028197765, 0.1482207179069519, 0.004014813806861639, 0.0041987719014286995, 0.004111765418201685, 0.004238385707139969, 0.004176084417849779, 0.004274709150195122, 0.004499207716435194, 0.004180339630693197, 0.004321328364312649, 0.004136698320508003, 0.0041967956349253654, 0.0040579563938081264, 0.0040794722735881805, 0.003909374121576548, 0.0038611481431871653, 0.003784698434174061, 0.0038863380905240774, 0.003680269466713071, 0.003683734918013215, 0.0035341959446668625, 0.0033634332939982414, 0.003318371716886759, 0.0032663147430866957, 0.0032097897492349148, 0.003095002844929695, 0.003006831742823124, 0.002977070864289999, 0.002874596044421196, 0.002869520802050829, 0.0029038896318525076, 0.0027864407747983932, 0.0026696340646594763, 0.14345015585422516, 0.0026372799184173346, 0.002525265095755458, 0.0025542848743498325, 0.0025258739478886127, 0.0025072188582271338, 0.0024471785873174667, 0.002435013884678483, 0.14629268646240234, 0.002459390554577112, 0.002443907782435417, 0.002502326387912035, 0.002483290620148182, 0.002499390859156847, 0.0024859062395989895, 0.002489657374098897, 0.002471251878887415, 0.002534979023039341, 0.002499345922842622, 0.0024103401228785515, 0.002337259240448475, 0.0023460593074560165, 0.11217496544122696, 0.0023052613250911236, 0.0022921671625226736, 0.0023009483702480793, 0.002329239621758461, 0.0023058168590068817, 0.00229745008982718, 0.00228923955000937, 0.002267354866489768, 0.1341777741909027, 0.002299880376085639, 0.002363707171753049, 0.002350001595914364, 0.0023086771834641695, 0.0023451789747923613, 0.002304826630279422, 0.12993428111076355, 0.002373815281316638, 0.0024126458447426558, 0.0024712856393307447, 0.002568413270637393, 0.0025283147115260363, 0.0025498727336525917, 0.002511796075850725, 0.00246058264747262, 0.0025909135583788157, 0.002456091810017824, 0.002523413160815835, 0.0023991544730961323, 0.12414303421974182, 0.0025039513129740953, 0.0025316053070127964, 0.0024570473469793797, 0.0024595954455435276, 0.0024746982380747795, 0.0024950436782091856, 0.002570493146777153, 0.002502288669347763, 0.002430807566270232, 0.14671453833580017, 0.0024399079848080873, 0.002480994677171111, 0.0024530133232474327, 0.5299089550971985, 0.002695464063435793, 0.0028646495193243027, 0.0030310789588838816, 0.00316808233037591, 0.0032891985028982162, 0.0034145743120461702, 0.0035705899354070425, 0.003616773523390293, 0.00369005324319005, 0.0037081080954521894, 0.0038601707201451063, 0.003801316022872925, 0.003802361898124218, 0.0037937918677926064, 0.0037920442409813404, 0.0037852816749364138, 0.0037232355680316687, 0.0037098005414009094, 0.0036975352559238672, 0.00368375307880342, 0.1078173965215683, 0.003592472756281495, 0.0036705697420984507, 0.003736403537914157, 0.0036735462490469217, 0.0034912191331386566, 0.003505551256239414, 0.0034691584296524525, 0.003443696303293109, 0.003373185871168971, 0.0033495365642011166, 0.003301525255665183, 0.003245165105909109, 0.0031908757518976927, 0.003110403660684824, 0.13796204328536987, 0.003067996818572283, 0.0030629937537014484, 0.10780022293329239, 0.0030215601436793804, 0.003067468060180545, 0.003063720650970936, 0.0032975529320538044, 0.0031132062431424856, 0.003058751579374075, 0.003079357324168086, 0.0030330780427902937, 0.003092055208981037, 0.003075958928093314, 0.0029997138772159815, 0.002897685393691063, 0.002865526592358947, 0.002851910889148712, 0.002872772980481386, 0.0028180761728435755, 0.0028887710068374872, 0.0026777703315019608, 0.0026035422924906015, 0.0026235468685626984, 0.002555843908339739, 0.002537498017773032, 0.0024816575460135937, 0.002393702045083046, 0.0023345998488366604, 0.002294887788593769, 0.002347170142456889, 0.002273434540256858, 0.0021950521040707827, 0.002125845057889819, 0.0021077997516840696, 0.002170443767681718, 0.0020284922793507576, 0.0020152777433395386, 0.0019527531694620848, 0.0019229294266551733, 0.0019973404705524445, 0.0019585099071264267, 0.001837297691963613, 0.0018794576171785593, 0.0017947410233318806, 0.0018127275398001075, 0.1447817087173462, 0.0017609141068533063, 0.0017196194967254996, 0.001745607820339501, 0.001754221273586154, 0.001867247512564063, 0.0017579799750819802, 0.0017466787248849869, 0.0017234527040272951, 0.0017710148822516203, 0.12071918696165085, 0.001908681239001453, 0.0017764564836397767, 0.001847386360168457, 0.0018157209269702435, 0.10827991366386414, 0.0018414452206343412, 0.001953576225787401, 0.0019236085936427116, 0.0019152614986523986, 0.0020531893242150545, 0.002080115955322981, 0.0019767230842262506, 0.0020276301074773073, 0.13022753596305847, 0.0020413894671946764, 0.0020485036075115204, 0.0020823159720748663, 0.0021328022703528404, 0.0021519081201404333, 0.0021487718913704157, 0.0021432298235595226, 0.0021488897036761045, 0.14477595686912537, 0.0022803298197686672, 0.002232747618108988, 0.002275842009112239, 0.0023025162518024445, 0.0022835959680378437, 0.13817241787910461, 0.002337895566597581, 0.0024676898028701544, 0.002422443125396967, 0.0024569486267864704, 0.002539739478379488, 0.002496055793017149, 0.0025450563989579678, 0.002543060341849923, 0.002492621075361967, 0.0026424871757626534, 0.002459258073940873, 0.002480685245245695, 0.0024569316301494837, 0.0024544731713831425, 0.0024150784593075514, 0.002404287690296769, 0.0023276619613170624, 0.0024851493071764708, 0.002255065133795142, 0.0022451693657785654, 0.002324486616998911, 0.002332789823412895, 0.002253069309517741, 0.0021706579718738794, 0.0021580110769718885, 0.002113149268552661, 0.0020964655559509993, 0.0019838265143334866, 0.002018001163378358, 0.15389011800289154, 0.0019700145348906517, 0.0019305592868477106, 0.0020055691711604595, 0.001956190913915634, 0.180740624666214, 0.0019846910145133734, 0.002021992579102516, 0.002057224279269576, 0.002090357942506671, 0.0023348741233348846, 0.002109047956764698, 0.00209286087192595, 0.00211620912887156, 0.0021242592483758926, 0.0021738812793046236, 0.0021585652139037848, 0.0021222317591309547, 0.0020638417918235064, 0.0020841418299824, 0.002080301521345973, 0.002049478702247143, 0.18450896441936493, 0.0021050323266535997, 0.0021845826413482428, 0.00205107475630939, 0.0020396290346980095, 0.002124636899679899, 0.0021528785582631826, 0.0021146186627447605, 0.0020995924714952707, 0.002067520748823881, 0.0020891688764095306, 0.002034340752288699, 0.002030770294368267, 0.002087273867800832, 0.0019871986005455256, 0.001949747558683157, 0.001960276858881116, 0.0019341461593285203, 0.001915930537506938, 0.0018753429176285863, 0.0018565829377621412, 0.0019544092938303947, 0.0018791970796883106, 0.0018723004031926394, 0.0017759475158527493, 0.0017535837832838297, 0.001703051500953734, 0.0016931776190176606, 0.0017110520275309682, 0.0016606362769380212, 0.0016411516116932034, 0.0016198701923713088, 0.00159916200209409, 0.0015636876923963428, 0.15746498107910156, 0.0015446876641362906, 0.0015937081770971417, 0.0015746494755148888, 0.001603337936103344, 0.0016034378204494715, 0.0016115537146106362, 0.0016235329676419497, 0.00157710921484977, 0.001575323287397623, 0.0016370532102882862, 0.0015699206851422787, 0.0015838750405237079, 0.0015450784703716636, 0.00153720926027745, 0.0015400254633277655, 0.0015276857884600759, 0.15176695585250854, 0.0015730925370007753, 0.001600563176907599, 0.0015577239682897925, 0.0016015121946111321, 0.0015842189313843846, 0.0016114715253934264, 0.0016192843904718757, 0.0015889268834143877, 0.001632997882552445, 0.0015923547325655818, 0.0016825688071548939, 0.001587489154189825, 0.0015606689266860485, 0.0015673987800255418, 0.15264315903186798, 0.0015689149731770158, 0.0017288604285567999, 0.001653736107982695, 0.0016519789351150393, 0.001661065616644919, 0.0016860654577612877, 0.001677101943641901, 0.0016809923108667135, 0.0016601147362962365, 0.001680718152783811, 0.0016639874083921313, 0.0016800356097519398, 0.001634029671549797, 0.0016475083539262414, 0.0016655977815389633, 0.001641800394281745, 0.001601075753569603, 0.0015886313049122691, 0.0015622859355062246, 0.001535879448056221, 0.0015193490544334054, 0.0015255754115059972, 0.001574091613292694, 0.0014962427085265517, 0.0015429602935910225, 0.0014613153180107474, 0.0014460724778473377, 0.001445308211259544, 0.001428186777047813, 0.0013874999713152647, 0.0013634024653583765, 0.0014305256772786379, 0.001348826102912426, 0.0013893964933231473, 0.0013030768604949117, 0.001294414629228413, 0.0012688067508861423, 0.0012754281051456928, 0.0012706969864666462, 0.001285697566345334, 0.5644133687019348, 0.0013394751586019993, 0.0014046089490875602, 0.0014765887754037976, 0.0015659789787605405, 0.001638412824831903, 0.0017456209752708673, 0.0018116880673915148, 0.0018682582303881645, 0.0018484639003872871, 0.0019036015728488564, 0.0019066791282966733, 0.001933582709170878, 0.12652277946472168, 0.0020721342880278826, 0.002151748863980174, 0.0020961863920092583, 0.0021783323027193546, 0.002251436933875084, 0.0021938313730061054, 0.0022189163137227297, 0.0022000770550221205, 0.0023489512968808413, 0.0022290560882538557, 0.0022287743631750345, 0.0022354479879140854, 0.0022281932178884745, 0.0022779423743486404, 0.002321036532521248, 0.002143469173461199, 0.0022424422204494476, 0.002164005534723401, 0.0021083408500999212, 0.0021140293683856726, 0.0021217153407633305, 0.0022707637399435043, 0.002050060546025634, 0.0019954529125243425, 0.0019627397414296865, 0.0019817559514194727, 0.001958823064342141, 0.001968719530850649, 0.0018670575227588415, 0.001875643851235509, 0.11145147681236267, 0.0018621108029037714, 0.001835147850215435, 0.16182401776313782, 0.001860175863839686, 0.002124445978552103, 0.0020665558986365795, 0.0019447447266429663, 0.0019773447420448065, 0.002008468611165881, 0.0020510966423898935, 0.0020244386978447437, 0.001987358322367072, 0.001980620203539729, 0.0020511557813733816, 0.0019624093547463417, 0.0020903765689581633, 0.001942268805578351, 0.0020189769566059113, 0.00203216215595603, 0.001994143007323146, 0.001955203013494611, 0.001929002464748919, 0.0018901495495811105, 0.0018744398839771748, 0.0018768570153042674, 0.0019561294466257095, 0.0017692953115329146, 0.0017753150314092636, 0.001794996322132647, 0.10496347397565842, 0.001788547495380044, 0.001975460210815072, 0.0017770279664546251, 0.0017439239891245961, 0.0017462675459682941, 0.13369448482990265, 0.001775285811163485, 0.0018113577971234918, 0.0018891823710873723, 0.001865455531515181, 0.001848817802965641, 0.001974751939997077, 0.001877209055237472, 0.0018977428553625941, 0.1615237295627594, 0.0019519793568179011, 0.0020168335177004337, 0.0019244778668507934, 0.001970415934920311, 0.001975523540750146, 0.001971297897398472, 0.0020144744776189327, 0.0019954608287662268, 0.002027310198172927, 0.0019940717611461878, 0.001962982816621661, 0.00200430559925735, 0.001921835937537253, 0.001912452164106071, 0.0019273220095783472, 0.001922424416989088, 0.0019419373711571097, 0.0018813360948115587, 0.0019179540686309338, 0.001821895712055266, 0.0018081149319186807, 0.0018560497555881739, 0.0017885781126096845, 0.001838241470977664, 0.0017578249098733068, 0.001741696847602725, 0.001755999866873026, 0.0016950438730418682, 0.0016642491100355983, 0.0016770277870818973, 0.0016099243657663465, 0.0015874082455411553, 0.0015881741419434547, 0.0015538482693955302, 0.001571249682456255, 0.0015228457050397992, 0.0014802577206864953, 0.001482462976127863, 0.0014622000744566321, 0.0015168554382398725, 0.0014207593630999327, 0.0015605632215738297, 0.0013958344934508204, 0.0014188201166689396, 0.001514546456746757, 0.001388446893543005, 0.001389610581099987, 0.001341465744189918, 0.17747542262077332, 0.0012990108225494623, 0.0013176815118640661, 0.00138091912958771, 0.0013621821999549866, 0.001350334961898625, 0.0013573482865467668, 0.0014128063339740038, 0.0013772184029221535, 0.0013647305313497782, 0.0013854106655344367, 0.001356526161544025, 0.0014221019810065627, 0.0013598765945062041, 0.11309391260147095, 0.001385500654578209, 0.0014827335253357887, 0.0014506011502817273, 0.13902822136878967, 0.0014976186212152243, 0.001487108995206654, 0.0015412741340696812, 0.0016617582878097892, 0.0015710663283243775, 0.0016130906296893954, 0.001647105673328042, 0.0017196886474266648, 0.0016409510280936956, 0.15545794367790222, 0.0017114203656092286, 0.001699015381745994, 0.0018595962319523096, 0.0017601159634068608, 0.0018118094885721803, 0.0019141881493851542, 0.001829766551963985, 0.001841419842094183, 0.0018605339573696256, 0.0018750906456261873, 0.0019021618645638227, 0.001826058141887188, 0.0019219164969399571, 0.0017954199574887753, 0.0018347596051171422, 0.0017976561794057488, 0.12071792781352997, 0.0018312354804947972, 0.15549013018608093, 0.0020732232369482517, 0.14704126119613647, 0.0020748779643326998, 0.0020399978384375572, 0.002109714550897479, 0.0021948744542896748, 0.0022596155758947134, 0.0022481598425656557, 0.002291630022227764, 0.0023883318062871695, 0.0023566533345729113, 0.0023649875074625015, 0.002480784896761179, 0.00238048960454762, 0.002434029709547758, 0.002367181470617652, 0.0023957015946507454, 0.002361847786232829, 0.002350238151848316, 0.002303754212334752, 0.002304475987330079, 0.002262858208268881, 0.002230176469311118, 0.1275768280029297, 0.002228778088465333, 0.0022467211820185184, 0.0025658055674284697, 0.002383054466918111, 0.0022603904362767935, 0.0023211746010929346, 0.14177583158016205, 0.0022817968856543303, 0.0023342997301369905, 0.0024241048377007246, 0.002323501743376255, 0.5104502439498901, 0.002529003657400608, 0.0026938929222524166, 0.0029401974752545357, 0.002932731993496418, 0.003012231085449457, 0.003163424087688327, 0.0032117704395204782, 0.09901933372020721, 0.12377673387527466, 0.0035133163910359144, 0.003537495620548725, 0.0037409921642392874, 0.003734046360477805, 0.00377946300432086, 0.00406023021787405, 0.003986821044236422, 0.003970898687839508, 0.004009982105344534, 0.003989686258137226, 0.003918798174709082, 0.003934293519705534, 0.003998933359980583, 0.003922814968973398, 0.0038019735366106033, 0.0037678848020732403, 0.003840793389827013, 0.003823504550382495, 0.003689745906740427, 0.003608908038586378, 0.16177964210510254, 0.12689125537872314, 0.09757900983095169, 0.0036295161116868258, 0.0036648784298449755, 0.003914583008736372, 0.0037572572473436594, 0.003894022200256586, 0.0038168092723935843, 0.10999734699726105, 0.003824374405667186, 0.003896348876878619, 0.003941404167562723, 0.003944677300751209, 0.13784699141979218, 0.00396457314491272, 0.004142207559198141, 0.004001236986368895, 0.0040084682404994965, 0.004120946861803532, 0.004106223117560148, 0.09852053225040436, 0.004201753530651331, 0.004115799907594919, 0.004000325687229633, 0.003964762669056654, 0.004076716955751181, 0.11050983518362045, 0.003919536247849464, 0.003911533858627081, 0.0038849827833473682, 0.003946094773709774, 0.003925074823200703, 0.00389013160020113, 0.003951490856707096, 0.0038806654047220945, 0.0037444960325956345, 0.0038126143626868725, 0.0036678584292531013, 0.0037173088639974594, 0.003602823708206415, 0.003537194337695837, 0.0035105105489492416, 0.003421769943088293, 0.0033186052460223436, 0.003391226753592491, 0.003495351877063513, 0.0031549392733722925, 0.003083947114646435, 0.0969887375831604, 0.003202411811798811, 0.003206466091796756, 0.00301468838006258, 0.0029818438924849033, 0.14481358230113983, 0.0029432368464767933, 0.0030549801886081696, 0.0029926758725196123, 0.0029669690411537886, 0.0029446312692016363, 0.002909141592681408, 0.0028752340003848076, 0.002856313018128276, 0.11109522730112076, 0.0029633454978466034, 0.0029431015718728304, 0.0029163979925215244, 0.0028526848182082176, 0.13133969902992249, 0.0029012493323534727, 0.0029273086693137884, 0.002972186077386141, 0.0030938948038965464, 0.003173654433339834, 0.0029351350385695696, 0.0029315492138266563, 0.0029599203262478113, 0.003174402052536607, 0.002891342854127288, 0.002880284795537591, 0.0028789215721189976, 0.0029217111878097057, 0.0028316532261669636, 0.002898674923926592, 0.0028243029955774546, 0.002939825411885977, 0.0027200111653655767, 0.002649985020980239, 0.0026640112046152353, 0.002595806960016489, 0.002513175830245018, 0.002522405469790101, 0.0025309508200734854, 0.002430129796266556, 0.0023629185743629932, 0.0024427054449915886, 0.002295138081535697, 0.0023764718789607286, 0.0024394963402301073, 0.0022324309684336185, 0.002158908639103174, 0.002243787283077836, 0.002117334632202983, 0.0020811366848647594, 0.002050766721367836, 0.002065417356789112, 0.0019750483334064484, 0.0019403942860662937, 0.0019979923963546753, 0.002013971097767353, 0.0018734496552497149, 0.09865880757570267, 0.0018983990885317326, 0.0018395116785541177, 0.0019014073768630624, 0.0019068075343966484, 0.0018726520938798785, 0.0018866657046601176, 0.0020120334811508656, 0.0018152231350541115, 0.0019233054481446743, 0.09909550100564957, 0.00181439274456352, 0.0019086810061708093, 0.14663538336753845, 0.001989721553400159, 0.0020532412454485893, 0.1511683464050293, 0.002177039161324501, 0.0021681352518498898, 0.0020935239735990763, 0.0022690552286803722, 0.0022216257639229298, 0.002171303378418088, 0.002220573602244258, 0.0022117767948657274, 0.002226108917966485, 0.0023362592328339815, 0.0024124400224536657, 0.1453903466463089, 0.002303516259416938, 0.00231041107326746, 0.0023534689098596573, 0.00238866382278502, 0.0024829513859003782, 0.0023965341970324516, 0.0025157195050269365, 0.0024224836379289627, 0.002489443402737379, 0.0024701585061848164, 0.002375951036810875, 0.0023463834077119827, 0.0023527024313807487, 0.0023926054127514362, 0.002317422768101096, 0.0023544079158455133, 0.0022892439737915993, 0.0022970286663621664, 0.0022016919683665037, 0.002178293652832508, 0.0022024440113455057, 0.002158908173441887, 0.0021283430978655815, 0.0021451860666275024, 0.11755458265542984, 0.0022016160655766726, 0.002139844000339508, 0.002077176235616207, 0.002197504509240389, 0.0021729073487222195, 0.002251475350931287, 0.002097328659147024, 0.002090343739837408, 0.002068622037768364, 0.002105721039697528, 0.00219129235483706, 0.0020737098529934883, 0.0021801197435706854, 0.002006127731874585, 0.0019326315959915519, 0.001984798116609454, 0.0019623178523033857, 0.0019146024715155363, 0.0019229470053687692, 0.001844145474024117, 0.0019235135987401009, 0.0018374179489910603, 0.0018104194896295667, 0.0018644323572516441, 0.0018606266239657998, 0.0017269047675654292, 0.001778092817403376, 0.0016943129012361169, 0.0018261297373101115, 0.0017053969204425812, 0.0016618025256320834, 0.0016383742913603783, 0.10242179781198502, 0.1449684351682663, 0.0016699552070349455, 0.0018231122521683574, 0.0016962551744654775, 0.0018058165442198515, 0.0017761822091415524, 0.0017373261507600546, 0.17439527809619904, 0.0018207872053608298, 0.0018748831935226917, 0.002125483937561512, 0.0019713942892849445, 0.0019201490795239806, 0.002006384078413248, 0.0019623301923274994, 0.002053941134363413, 0.0019770206417888403, 0.16390572488307953, 0.002156368689611554, 0.0021031207870692015, 0.0021863719448447227, 0.002085325540974736, 0.0021596907172352076, 0.0021298767533153296, 0.002116903429850936, 0.0021875551901757717, 0.0020945933647453785, 0.16011811792850494, 0.0022954847663640976, 0.0022670223843306303, 0.002165330806747079, 0.0022104810923337936, 0.0022847470827400684, 0.002351188799366355, 0.0022346621844917536, 0.002247456694021821, 0.0021835302468389273, 0.0023152874782681465, 0.002240482484921813, 0.0022970319259911776, 0.0024190223775804043, 0.0021341852843761444, 0.0022610377054661512, 0.0021979438606649637, 0.0020883134566247463, 0.002050166018307209, 0.0021425357554107904, 0.0020701466128230095, 0.13826610147953033, 0.002017216756939888, 0.002160135190933943, 0.002111307345330715, 0.0020610264036804438, 0.002061625709757209, 0.11794891208410263, 0.002104185288771987, 0.0021580876782536507, 0.00224235188215971, 0.0021391045302152634, 0.002424047328531742, 0.002351731527596712, 0.0022632009349763393, 0.0022166315466165543, 0.0021920972503721714, 0.002184502314776182, 0.0021901139989495277, 0.002174713183194399, 0.0021448947954922915, 0.0020632862579077482, 0.002071094699203968, 0.002087414264678955, 0.002037322847172618, 0.00204912549816072, 0.0019921634811908007, 0.002132943831384182, 0.001932703424245119, 0.0020891877356916666, 0.001910028513520956, 0.001918196096085012, 0.0019282420398667455, 0.0018462175503373146, 0.0018582468619570136, 0.0018957663560286164, 0.0019035524455830455, 0.20139092206954956, 0.0018693710444495082, 0.0018090509111061692, 0.001827126368880272, 0.001805644715204835, 0.0017921541584655643, 0.0018253771122545004, 0.0018516796408221126, 0.00179586885496974, 0.0018053192179650068, 0.0017651425441727042, 0.0018380590481683612, 0.0017932647606357932, 0.0017400213982909918, 0.0017532265046611428, 0.0018293544417247176, 0.001756032812409103, 0.0017150584608316422, 0.0018159099854528904, 0.0016689631156623363, 0.0017437287606298923, 0.0016760287107899785, 0.0016160771483555436, 0.0016165801789611578, 0.0016022754134610295, 0.12315960228443146, 0.0015934931579977274, 0.0016147616552188993, 0.14976856112480164, 0.14854983985424042, 0.001706954324617982, 0.0017620454309508204, 0.001827034866437316, 0.0018443097360432148, 0.0019736529793590307, 0.12849250435829163, 0.0019676981028169394, 0.0020428814459592104, 0.002039301209151745, 0.002161505864933133, 0.0021104570478200912, 0.0022031846456229687, 0.0022232448682188988, 0.00219106231816113, 0.0022479528561234474, 0.0022827587090432644, 0.0024061899166554213, 0.002222859300673008, 0.0021764368284493685, 0.0022099020425230265, 0.002281615976244211, 0.002165005309507251, 0.15415816009044647, 0.00234922394156456, 0.10888417810201645, 0.002237847540527582, 0.0022838525474071503, 0.0024145888164639473, 0.002508787903934717, 0.0023926985450088978, 0.002356928773224354, 0.0023739724420011044, 0.002385950880125165, 0.00237060128711164, 0.0023940270766615868, 0.0023875480983406305, 0.0023905972484499216, 0.002427206840366125, 0.0025418750010430813, 0.00243170908652246, 0.0024871393106877804, 0.0022857277654111385, 0.0023524146527051926, 0.002237927634268999, 0.0022220537066459656, 0.0022233063355088234, 0.002261989051476121, 0.0021729138679802418, 0.0024348830338567495, 0.0021267030388116837, 0.0020993591751903296, 0.00208519515581429, 0.0021174901630729437, 0.002008541487157345, 0.0020002785604447126, 0.116519995033741, 0.0020718059968203306, 0.002060162601992488, 0.002000671112909913, 0.14060942828655243, 0.0020592729561030865, 0.0020351510029286146, 0.0020738013554364443, 0.002064148196950555, 0.0022692696657031775, 0.0021130468230694532, 0.0020995894446969032, 0.0020893120672553778, 0.002188232261687517, 0.0021037638653069735, 0.10762493312358856, 0.0022898365277796984, 0.0021585782524198294, 0.002109410474076867, 0.0022543598897755146, 0.0021889875642955303, 0.002279055304825306, 0.002156920963898301, 0.1137603223323822, 0.10719867795705795, 0.0021681017242372036, 0.0022877701558172703, 0.002314965473487973, 0.002596027683466673, 0.00231513031758368, 0.0023773435968905687, 0.0025132689625024796, 0.002441307995468378, 0.0024923300370573997, 0.002514761406928301, 0.0024119485169649124, 0.002634829143062234, 0.002452992368489504, 0.002317656297236681, 0.0023295842111110687, 0.1313302218914032, 0.1299135386943817, 0.0026148147881031036, 0.0025174019392579794, 0.0026033816393464804, 0.002523869276046753]\n",
            "Val loss 0.012673119966519581\n",
            "Val auc roc 0.47955512984248616\n",
            "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     2: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "285502e92f074aeea1d71ee2b6cab875",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0146\n",
            "Train Losses : [0.0027520337607711554, 0.20143026113510132, 0.0026441027875989676, 0.0025773330125957727, 0.0025896287988871336, 0.0025569340214133263, 0.0025615841150283813, 0.1460648626089096, 0.0026604279410094023, 0.0027848437894135714, 0.0026818697806447744, 0.0026947397273033857, 0.0026821817737072706, 0.0026091800536960363, 0.0025211439933627844, 0.0027783263940364122, 0.12347409874200821, 0.0026125155854970217, 0.0025794128887355328, 0.002594463061541319, 0.0025270753540098667, 0.0025222913827747107, 0.0027195161674171686, 0.002514549298211932, 0.002604852896183729, 0.002549818018451333, 0.002608052222058177, 0.0026041141245514154, 0.0026373579166829586, 0.002543346956372261, 0.0025393208488821983, 0.002510974882170558, 0.0025926134549081326, 0.0026019755750894547, 0.00277169537730515, 0.0026275671552866697, 0.002541003981605172, 0.0025906278751790524, 0.002508762525394559, 0.0025049420073628426, 0.0026961606927216053, 0.002560435328632593, 0.00255822972394526, 0.0024872159119695425, 0.14039936661720276, 0.0026813612785190344, 0.0026305788196623325, 0.0024982159957289696, 0.002504664473235607, 0.0026532956399023533, 0.002625915687531233, 0.002470629522576928, 0.002536653308197856, 0.0026853298768401146, 0.0025454137939959764, 0.002474756445735693, 0.0025467260275036097, 0.002515365369617939, 0.002670558402314782, 0.0026977870147675276, 0.0025919023901224136, 0.0024733259342610836, 0.002512275008484721, 0.002491014776751399, 0.0024217262398451567, 0.13519451022148132, 0.0025491623673588037, 0.0024850701447576284, 0.0024476409889757633, 0.002458341186866164, 0.002804460469633341, 0.002537319203838706, 0.002741702366620302, 0.0024825725704431534, 0.0024925009347498417, 0.0024398392997682095, 0.0024108083453029394, 0.0025643266271799803, 0.002597400452941656, 0.002541088033467531, 0.0025590439327061176, 0.0025629287119954824, 0.002477523172274232, 0.0024726397823542356, 0.002492370083928108, 0.0027191510889679193, 0.0024282478261739016, 0.11897089332342148, 0.0025616504717618227, 0.0024289770517498255, 0.0023806411772966385, 0.00264483829960227, 0.0024983203038573265, 0.002403974998742342, 0.002518218709155917, 0.002439098432660103, 0.0024456416722387075, 0.00262710964307189, 0.0024224307853728533, 0.002430341439321637, 0.0027037905529141426, 0.002523699775338173, 0.002636405173689127, 0.0023949705064296722, 0.0025582080706954002, 0.0025647368747740984, 0.0025742333382368088, 0.0025426927022635937, 0.0023796954192221165, 0.002359026810154319, 0.0024851977359503508, 0.0026119002141058445, 0.0024162118788808584, 0.0023410392459481955, 0.13839171826839447, 0.002426894148811698, 0.0025817244313657284, 0.0024644178338348866, 0.002358081052079797, 0.0023716322612017393, 0.0025084412191063166, 0.002373301424086094, 0.45924320816993713, 0.002354711527004838, 0.0023657376877963543, 0.0024320147931575775, 0.0026447612326592207, 0.0024756116326898336, 0.002485968405380845, 0.002530122408643365, 0.002565855858847499, 0.0024671040009707212, 0.002702619880437851, 0.0024645263329148293, 0.0024232256691902876, 0.002403625287115574, 0.1557939052581787, 0.0025724885053932667, 0.0025321212597191334, 0.002618182683363557, 0.0024619519244879484, 0.002525939140468836, 0.0024179357569664717, 0.0024352031759917736, 0.002582615939900279, 0.0024331784807145596, 0.0025895307771861553, 0.0025677024386823177, 0.0025191104505211115, 0.11425097286701202, 0.002463117241859436, 0.002544801915064454, 0.0024515874683856964, 0.0025557803455740213, 0.002632361138239503, 0.002405021572485566, 0.002428221981972456, 0.1131143793463707, 0.0027764744590967894, 0.0024924639146775007, 0.0026789894327521324, 0.0025563142262399197, 0.0025964381638914347, 0.0024782000109553337, 0.002824486931785941, 0.0026013015303760767, 0.0024241325445473194, 0.002412717090919614, 0.0024290618021041155, 0.0999523252248764, 0.002488375874236226, 0.002395289484411478, 0.0025488538667559624, 0.002586787100881338, 0.002420192351564765, 0.0023897765204310417, 0.1036958396434784, 0.002579359570518136, 0.002462269039824605, 0.0024172698613256216, 0.0024979712907224894, 0.002418082905933261, 0.0026064743287861347, 0.0025091473944485188, 0.002420353703200817, 0.11429931968450546, 0.002425698097795248, 0.0027110381051898003, 0.002421114593744278, 0.002751963445916772, 0.0025306344032287598, 0.0024502298329025507, 0.002449453342705965, 0.0024565448984503746, 0.14667446911334991, 0.0026018687058240175, 0.002511716680601239, 0.002460511401295662, 0.002538996282964945, 0.0024585097562521696, 0.0024729440920054913, 0.0025302162393927574, 0.0025100556667894125, 0.15337520837783813, 0.0025080081541091204, 0.12081047147512436, 0.16306151449680328, 0.0025296651292592287, 0.002452269895002246, 0.0026093334890902042, 0.0024467248003929853, 0.002749738981947303, 0.002562740119174123, 0.0026439956855028868, 0.0024360893294215202, 0.0026304752100259066, 0.0024687154218554497, 0.0025656053330749273, 0.1503814309835434, 0.002578416373580694, 0.002625697758048773, 0.002477316651493311, 0.0026515289209783077, 0.002634287578985095, 0.0025048137176781893, 0.0026898703072220087, 0.0024548929650336504, 0.002626940840855241, 0.0025326311588287354, 0.0025610500015318394, 0.0024906385224312544, 0.002537151798605919, 0.0024441860150545835, 0.0025967576075345278, 0.0024970693048089743, 0.0025063559878617525, 0.0026765805669128895, 0.0024330653250217438, 0.002480966504663229, 0.002493764040991664, 0.0027035395614802837, 0.0025096298195421696, 0.13889342546463013, 0.002463826211169362, 0.0025984509848058224, 0.0025034905411303043, 0.0024865474551916122, 0.002446034224703908, 0.002493756590411067, 0.0025223218835890293, 0.002508921781554818, 0.0026215589605271816, 0.0025046293158084154, 0.002498914021998644, 0.002428716514259577, 0.002544234972447157, 0.002471148269250989, 0.002688840264454484, 0.16162952780723572, 0.002474379725754261, 0.0024906229227781296, 0.002485245931893587, 0.002405462320894003, 0.0025702263228595257, 0.002502067480236292, 0.0025148019194602966, 0.0024139643646776676, 0.002403541933745146, 0.0024565488565713167, 0.00246751238591969, 0.002404886996373534, 0.12603658437728882, 0.0026539829559624195, 0.0024079782888293266, 0.002548819174990058, 0.00239810929633677, 0.002402905374765396, 0.002404490252956748, 0.0026141477283090353, 0.002627895912155509, 0.0024529960937798023, 0.0026490974705666304, 0.002491064602509141, 0.0024637982714921236, 0.002411387860774994, 0.0024355154018849134, 0.002481523435562849, 0.0024136074353009462, 0.0024409606121480465, 0.0023878426291048527, 0.0024189988616853952, 0.0024818596430122852, 0.0026506721042096615, 0.002402585931122303, 0.002432492794468999, 0.002423353958874941, 0.0025133308954536915, 0.0023723605554550886, 0.0024872564245015383, 0.002342166379094124, 0.14901256561279297, 0.002467941027134657, 0.12070440500974655, 0.0023730320390313864, 0.002379397163167596, 0.002372538670897484, 0.002357520628720522, 0.12366640567779541, 0.0024470379576087, 0.002413723152130842, 0.0025049452669918537, 0.002421730197966099, 0.0027735838666558266, 0.10186386108398438, 0.11536421626806259, 0.0026072384789586067, 0.002473716391250491, 0.0024541246239095926, 0.0025229372549802065, 0.0026247468777000904, 0.0024075680412352085, 0.0027890773490071297, 0.0025188748259097338, 0.0024669684935361147, 0.0027571148239076138, 0.002672225935384631, 0.002615908393636346, 0.00238950178027153, 0.0024166915100067854, 0.0025552965234965086, 0.002432428300380707, 0.1338634490966797, 0.002427036641165614, 0.002501165261492133, 0.14885243773460388, 0.0024944543838500977, 0.0024175492580980062, 0.002474280772730708, 0.002447109669446945, 0.0025346477050334215, 0.0024921882431954145, 0.0025021599140018225, 0.002484781900420785, 0.0024338525254279375, 0.002422646852210164, 0.002526300959289074, 0.0024929435458034277, 0.0024509024806320667, 0.0025317014660686255, 0.00244536274112761, 0.002503363648429513, 0.11331331729888916, 0.002663380466401577, 0.0024977466091513634, 0.002605997258797288, 0.0024493031669408083, 0.0025193749461323023, 0.002496355911716819, 0.0024342259857803583, 0.0024162197951227427, 0.002488010562956333, 0.0023998424876481295, 0.002501091221347451, 0.002573164878413081, 0.0024623859208077192, 0.002733040601015091, 0.0023910892195999622, 0.0023706951178610325, 0.0026939697563648224, 0.0024984616320580244, 0.1326005905866623, 0.002436187583953142, 0.002438392024487257, 0.0024880305863916874, 0.0024182498455047607, 0.002475738525390625, 0.0024936289992183447, 0.002407108899205923, 0.0025098577607423067, 0.0024268776178359985, 0.12998348474502563, 0.002518465742468834, 0.0025610600132495165, 0.002442572731524706, 0.002405190607532859, 0.0023906980641186237, 0.002391340909525752, 0.002419563475996256, 0.002390597714111209, 0.0024489525239914656, 0.0025908052921295166, 0.0027425303123891354, 0.0027101251762360334, 0.0024537297431379557, 0.002367684617638588, 0.0025854401756078005, 0.002404981292784214, 0.10392216593027115, 0.0024850910995155573, 0.002461496274918318, 0.002490560756996274, 0.0023666208144277334, 0.002503457013517618, 0.002383217914029956, 0.002345664892345667, 0.12457109242677689, 0.002390556503087282, 0.0024079580325633287, 0.1759074330329895, 0.002440723357722163, 0.0024504107423126698, 0.002519266912713647, 0.002517360495403409, 0.0024413997307419777, 0.00263541960157454, 0.002467947546392679, 0.0025007184594869614, 0.13592562079429626, 0.0023997926618903875, 0.002650125417858362, 0.002460644580423832, 0.0025591568555682898, 0.0025179744698107243, 0.0024379538372159004, 0.0024163336493074894, 0.0024668409023433924, 0.0024183474015444517, 0.0026200171560049057, 0.002404291881248355, 0.002505336422473192, 0.0025840364396572113, 0.0025478063616901636, 0.002614268334582448, 0.10086890310049057, 0.0025829020887613297, 0.0023930412717163563, 0.0024668206460773945, 0.0025130168069154024, 0.0026477682404220104, 0.0025597047060728073, 0.00241737044416368, 0.002400138881057501, 0.002469721483066678, 0.00240671937353909, 0.0024975542910397053, 0.002462102100253105, 0.0024906841572374105, 0.11876979470252991, 0.0023925318382680416, 0.0024258748162537813, 0.0024843611754477024, 0.002450237749144435, 0.002536135958507657, 0.0026732790283858776, 0.0024749452713876963, 0.002431251807138324, 0.0023755733855068684, 0.0025020220782607794, 0.0023372063878923655, 0.002353386487811804, 0.0024195932783186436, 0.0024120179004967213, 0.002388181397691369, 0.002398482523858547, 0.002340859267860651, 0.0024170982651412487, 0.002437826944515109, 0.002427242463454604, 0.0024000005796551704, 0.00245996518060565, 0.0024011984933167696, 0.0025870888493955135, 0.002377689816057682, 0.002690614201128483, 0.002460784511640668, 0.0025146601255983114, 0.002336198929697275, 0.002400518860667944, 0.002415470313280821, 0.0026278886944055557, 0.0025062663480639458, 0.002472654217854142, 0.0023077731020748615, 0.0023230346851050854, 0.0023319495376199484, 0.002487676218152046, 0.14839236438274384, 0.0024071054067462683, 0.002429149579256773, 0.0023502660915255547, 0.0024839621037244797, 0.0025435532443225384, 0.0024132688995450735, 0.002375247422605753, 0.0024630059488117695, 0.002353591611608863, 0.0023608976043760777, 0.0024226533714681864, 0.0023050284944474697, 0.0024270638823509216, 0.0023052049800753593, 0.002294750651344657, 0.0024484749883413315, 0.0025307252071797848, 0.0023170814383774996, 0.002500945935025811, 0.0024166821967810392, 0.0022806799970567226, 0.002254665130749345, 0.002290988340973854, 0.0023384836968034506, 0.0023472814355045557, 0.0025600309018045664, 0.002442855853587389, 0.00232921214774251, 0.002379361307248473, 0.002389822155237198, 0.002376104239374399, 0.002274078782647848, 0.0023116725496947765, 0.0022856532596051693, 0.0023197135888040066, 0.002445571357384324, 0.002327253110706806, 0.0023235862608999014, 0.0022399332374334335, 0.002414488233625889, 0.0022608733270317316, 0.002373425057157874, 0.002321020234376192, 0.0022411493118852377, 0.0023395600728690624, 0.002220312599092722, 0.002367880893871188, 0.002288367599248886, 0.00241622026078403, 0.002213665284216404, 0.002457388211041689, 0.002367990091443062, 0.12868396937847137, 0.002270605182275176, 0.002273558871820569, 0.0024296240881085396, 0.0024760637897998095, 0.0022595792543143034, 0.0023091183975338936, 0.0022194297052919865, 0.0022482224740087986, 0.00264441198669374, 0.10609714686870575, 0.0022257885430008173, 0.002279500011354685, 0.15486998856067657, 0.002307697432115674, 0.002447378821671009, 0.002194644184783101, 0.0022131542209535837, 0.11795870959758759, 0.17418131232261658, 0.0022969970013946295, 0.0022253068163990974, 0.0026032649911940098, 0.002443121513351798, 0.002380690537393093, 0.14758644998073578, 0.002225561998784542, 0.0025840147864073515, 0.002341575687751174, 0.002240042435005307, 0.0024832296185195446, 0.0023229436483234167, 0.0023316398728638887, 0.0023035744670778513, 0.0022734575904905796, 0.002333782147616148, 0.0024343892000615597, 0.002308270428329706, 0.15093523263931274, 0.002336879726499319, 0.0024054620880633593, 0.0022751553915441036, 0.002448509680107236, 0.002392387017607689, 0.00240403157658875, 0.0022937962785363197, 0.0024097845889627934, 0.0023613672237843275, 0.11598952114582062, 0.0022716776002198458, 0.002430562162771821, 0.002325519220903516, 0.0025520059280097485, 0.0023041602689772844, 0.0023701947648078203, 0.002258274471387267, 0.12465547025203705, 0.002321493113413453, 0.002327411435544491, 0.002345923101529479, 0.002370214555412531, 0.0022477044258266687, 0.0022721239365637302, 0.0023094164207577705, 0.002328190952539444, 0.0022647795267403126, 0.0025049501564353704, 0.002269933233037591, 0.002285461174324155, 0.002352394862100482, 0.0023773927241563797, 0.0023809068370610476, 0.0023162669967859983, 0.0025158608332276344, 0.0024165944196283817, 0.0023825750686228275, 0.0023378075566142797, 0.002370681380853057, 0.0022856099531054497, 0.0023033430334180593, 0.0022307976614683867, 0.0023871860466897488, 0.002297930419445038, 0.0022498497273772955, 0.0022804830223321915, 0.0022827000357210636, 0.11479485034942627, 0.002399141201749444, 0.0025560958310961723, 0.0022382130846381187, 0.0022265957668423653, 0.0023318107705563307, 0.0024320038501173258, 0.0022636742796748877, 0.002361101098358631, 0.0024561055470257998, 0.0023169463966041803, 0.0022861992474645376, 0.0023400618229061365, 0.0022216641809791327, 0.002433208515867591, 0.002234632382169366, 0.002284339629113674, 0.0022162965033203363, 0.0022485952358692884, 0.002198275411501527, 0.002533575752750039, 0.0022745030000805855, 0.0023582670837640762, 0.002198031870648265, 0.0022450995165854692, 0.0023246221244335175, 0.0022796806879341602, 0.0021954483818262815, 0.0022790124639868736, 0.002276010112836957, 0.002303431276232004, 0.0022534579038619995, 0.002297883853316307, 0.002180909039452672, 0.0023157361429184675, 0.002226644428446889, 0.002466385718435049, 0.0022868718951940536, 0.002171657280996442, 0.002319605555385351, 0.002288338728249073, 0.002288772026076913, 0.002157253911718726, 0.0022526634857058525, 0.0023552561178803444, 0.0021978418808430433, 0.0024508857168257236, 0.0021693145390599966, 0.002245367271825671, 0.002260286593809724, 0.0022853745613247156, 0.0022141465451568365, 0.0022486650850623846, 0.0023030322045087814, 0.0022405076306313276, 0.0021954562980681658, 0.1493479460477829, 0.00219225836917758, 0.002240646630525589, 0.0023330403491854668, 0.0021461322903633118, 0.0022611895110458136, 0.002174503169953823, 0.0023254151456058025, 0.0021555782295763493, 0.0021637764293700457, 0.002179889939725399, 0.00217266334220767, 0.0021652490831911564, 0.0022607804276049137, 0.0022517498582601547, 0.0022452054545283318, 0.0022816115524619818, 0.0023143223952502012, 0.14907939732074738, 0.0021336942445486784, 0.0023104867432266474, 0.0022051066625863314, 0.002146111335605383, 0.00215600966475904, 0.002180128125473857, 0.0021398041862994432, 0.0021414426155388355, 0.0022973790764808655, 0.1296619027853012, 0.002152326749637723, 0.002149918582290411, 0.002160706790164113, 0.0021256795153021812, 0.0022123614326119423, 0.002230196027085185, 0.002190710511058569, 0.002227452350780368, 0.002220558002591133, 0.0021872054785490036, 0.0021209707483649254, 0.00219704769551754, 0.002155990106984973, 0.002298451727256179, 0.002144196769222617, 0.002114596776664257, 0.002290382282808423, 0.0022538122721016407, 0.0024810603354126215, 0.0021084973122924566, 0.0022128899581730366, 0.0021338998340070248, 0.0021168445236980915, 0.0022121232468634844, 0.0022187386639416218, 0.0022755274549126625, 0.0021705320104956627, 0.0021356206852942705, 0.002109888941049576, 0.002118224510923028, 0.0022411691024899483, 0.002096011769026518, 0.002161135198548436, 0.0021323927212506533, 0.0021148778032511473, 0.002211477607488632, 0.002158999675884843, 0.0021754633635282516, 0.00210154359228909, 0.1483171284198761, 0.002575936960056424, 0.0021345082204788923, 0.0022430229000747204, 0.0024046311154961586, 0.0022565240506082773, 0.002080520847812295, 0.0021947671193629503, 0.002226274460554123, 0.0022669092286378145, 0.1844477355480194, 0.10749524086713791, 0.0021768943406641483, 0.0022020135074853897, 0.0023277339059859514, 0.0022065143566578627, 0.0023446239065378904, 0.0022120734211057425, 0.0022541892249137163, 0.002095481613650918, 0.0022177069913595915, 0.0022195475175976753, 0.002180461771786213, 0.0023612859658896923, 0.0021137043368071318, 0.0021259014029055834, 0.0022754857782274485, 0.0021646064706146717, 0.0021074051037430763, 0.0021961720194667578, 0.0021363531704992056, 0.0022345460020005703, 0.0022068354301154613, 0.0021245782263576984, 0.0021504543256014585, 0.002212133491411805, 0.0021289431024342775, 0.002077453536912799, 0.0021101278252899647, 0.0021692453883588314, 0.002247350988909602, 0.0022017755545675755, 0.002112501999363303, 0.0021057603880763054, 0.0021013931836932898, 0.002103231381624937, 0.002223153132945299, 0.002086580963805318, 0.002085707150399685, 0.002227209275588393, 0.0021858736872673035, 0.15860967338085175, 0.0020878177601844072, 0.002128761261701584, 0.0842786356806755, 0.00210416573099792, 0.0021480105351656675, 0.002065075095742941, 0.0021457222755998373, 0.0021265752147883177, 0.00208866479806602, 0.0021045589819550514, 0.0021830846089869738, 0.002255139872431755, 0.0022374731488525867, 0.0020663009490817785, 0.0021013813093304634, 0.0022568441927433014, 0.0020903092809021473, 0.002106517320498824, 0.002189469523727894, 0.002543728332966566, 0.002274020342156291, 0.0021148889791220427, 0.0020854538306593895, 0.002056746045127511, 0.0020600883290171623, 0.002151919761672616, 0.1158781349658966, 0.0021170945838093758, 0.0022202266845852137, 0.002106175757944584, 0.002110361587256193, 0.002188728889450431, 0.00219802837818861, 0.0021564525086432695, 0.0021481020376086235, 0.0022870677057653666, 0.5480733513832092, 0.09547294676303864, 0.002072323579341173, 0.002355740172788501, 0.0021077156998217106, 0.0021295666228979826, 0.0022392780520021915, 0.0021160247270017862, 0.0021543197799474, 0.002152715576812625, 0.0021424521692097187, 0.0022325078025460243, 0.0021533584222197533, 0.0021400675177574158, 0.002274321625009179, 0.0021079317666590214, 0.0021982251200824976, 0.0021963361650705338, 0.002287672832608223, 0.0021469241473823786, 0.002178889000788331, 0.002115207491442561, 0.0021403252612799406, 0.0021148989908397198, 0.002131713554263115, 0.0021873190999031067, 0.12306265532970428, 0.002215724205598235, 0.1891845166683197, 0.00250709755346179, 0.002239453373476863, 0.002285629976540804, 0.0022467919625341892, 0.002193812746554613, 0.0021070486400276423, 0.0022600244265049696, 0.002199338749051094, 0.002315192949026823, 0.13832814991474152, 0.0022089823614805937, 0.002099640667438507, 0.002221089554950595, 0.0021248096600174904, 0.002402539597824216, 0.002181645715609193, 0.002356929238885641, 0.002246101386845112, 0.0021515926346182823, 0.0022511989809572697, 0.0021334215998649597, 0.0021778789814561605, 0.0021551097743213177, 0.0021743529941886663, 0.0021811597980558872, 0.002115407958626747, 0.0021776515059173107, 0.0021412463393062353, 0.0021095837000757456, 0.0023235934786498547, 0.0023312014527618885, 0.0021490268409252167, 0.13555005192756653, 0.0022960249334573746, 0.0022985658142715693, 0.0023062583059072495, 0.0022539799101650715, 0.0021238764747977257, 0.0023818069603294134, 0.12381759285926819, 0.0021228620316833258, 0.0023960217367857695, 0.0021399182733148336, 0.0022009985987097025, 0.0021360397804528475, 0.0023798446636646986, 0.0021745008416473866, 0.002369949361309409, 0.002292211866006255, 0.002311320975422859, 0.0022175884805619717, 0.00216157385148108, 0.0022943723015487194, 0.0022394333500415087, 0.0021416961681097746, 0.0021835919469594955, 0.0021924388129264116, 0.002118069911375642, 0.0021257936023175716, 0.0022217566147446632, 0.002216948661953211, 0.0022016000002622604, 0.0022271815687417984, 0.002153480425477028, 0.00213416269980371, 0.002194954315200448, 0.08766602724790573, 0.0021928625646978617, 0.002144020516425371, 0.0022325615864247084, 0.10162026435136795, 0.0021115378476679325, 0.002152535133063793, 0.0022141586523503065, 0.002156743546947837, 0.002100608078762889, 0.09338600188493729, 0.002171953208744526, 0.002185931196436286, 0.0020882452372461557, 0.1323358416557312, 0.0021484976168721914, 0.0021781153045594692, 0.46496060490608215, 0.002144113415852189, 0.0022208825685083866, 0.00224023568443954, 0.0022150275763124228, 0.0021204124204814434, 0.0021648576948791742, 0.00217546452768147, 0.002203524811193347, 0.002156588016077876, 0.0022207775618880987, 0.002207990735769272, 0.002218157984316349, 0.09252163767814636, 0.0022691881749778986, 0.00223755557090044, 0.002216108376160264, 0.002161407843232155, 0.0021664462983608246, 0.002208997495472431, 0.0024221569765359163, 0.12465254217386246, 0.002174719702452421, 0.002142106182873249, 0.0024226538371294737, 0.002258071443066001, 0.0021400838159024715, 0.11805709451436996, 0.12668190896511078, 0.14346250891685486, 0.0021959312725812197, 0.0022510476410388947, 0.0022190166637301445, 0.0024561798200011253, 0.0021805381402373314, 0.002192842774093151, 0.002359094563871622, 0.002288336167111993, 0.002349134534597397, 0.0023154469672590494, 0.0022037934977561235, 0.14927367866039276, 0.0022178601939231157, 0.002233541337773204, 0.0022464545909315348, 0.0023968061432242393, 0.002415240975096822, 0.0022095791064202785, 0.002194988774135709, 0.002263022353872657, 0.0022349590435624123, 0.002274441998451948, 0.0023968026507645845, 0.0022509812843054533, 0.002266398398205638, 0.0022274754010140896, 0.0022125497926026583, 0.00216847681440413, 0.002202126197516918, 0.0022995707113295794, 0.002257739892229438, 0.0022754755336791277, 0.002354324096813798, 0.002208387479186058, 0.0023261806927621365, 0.002316891448572278, 0.18675267696380615, 0.11688027530908585, 0.0022134624887257814, 0.15120525658130646, 0.0021756945643574, 0.002166358521208167, 0.002208333695307374, 0.1001497358083725, 0.0022424496710300446, 0.0023576202802360058, 0.002186911879107356, 0.0021903032902628183, 0.0022615441121160984, 0.0022306861355900764, 0.0024366702418774366, 0.002394853625446558, 0.0023231334052979946, 0.0022313438821583986, 0.0022257347591221333, 0.0022000130265951157, 0.002210102742537856, 0.0022405877243727446, 0.002321230247616768, 0.0023061574902385473, 0.00218858290463686, 0.0024064083117991686, 0.002514768159016967, 0.0022682417184114456, 0.002355567878112197, 0.0022125302348285913, 0.0022608996368944645, 0.002368217334151268, 0.002195165492594242, 0.0022264495491981506, 0.0022925653029233217, 0.0021884983871132135, 0.0024161548353731632, 0.0022238583769649267, 0.0021768382284790277, 0.002302743960171938, 0.002181734424084425, 0.002233305014669895, 0.002290313132107258, 0.002251315163448453, 0.002183443633839488, 0.0022165197879076004, 0.0021820140536874533, 0.0022800243459641933, 0.121364526450634, 0.0021877700928598642, 0.002278500236570835, 0.0022937620524317026, 0.0023013364989310503, 0.0021860443521291018, 0.002281096065416932, 0.0022044568322598934, 0.0023756008595228195, 0.0021945524495095015, 0.002202354371547699, 0.0023504921700805426, 0.0022027320228517056, 0.002323513850569725, 0.0022377478890120983, 0.0021857230458408594, 0.0021582457702606916, 0.002257385291159153, 0.002368189627304673, 0.002208317629992962, 0.10533036291599274, 0.0022235303185880184, 0.002179594011977315, 0.0022001091856509447, 0.0022228595335036516, 0.002155116992071271, 0.0021942434832453728, 0.0021958425641059875, 0.0022815056145191193, 0.0022496595047414303, 0.06871835887432098, 0.002155453898012638, 0.0022098866757005453, 0.0022181272506713867, 0.0021663326770067215, 0.002221657196059823, 0.002228784142062068, 0.002269292715936899, 0.0021497057750821114, 0.002228704746812582, 0.14290112257003784, 0.002248064847663045, 0.002191704697906971, 0.00228580622933805, 0.0021775392815470695, 0.002155412919819355, 0.0022893997374922037, 0.0022726745810359716, 0.00220649060793221, 0.002260063774883747, 0.0021564862690865993, 0.09053204953670502, 0.00222631823271513, 0.0023519936949014664, 0.0021756994538009167, 0.0022157812491059303, 0.002182949800044298, 0.002260841429233551, 0.1364610344171524, 0.002195819979533553, 0.0021766771096736193, 0.002325312467291951, 0.002311802702024579, 0.00227303896099329, 0.0023651074152439833, 0.002164672128856182, 0.002287935232743621, 0.002220770576968789, 0.002231247490271926, 0.0023562684655189514, 0.0022003198973834515, 0.08661697804927826, 0.0022353329695761204, 0.0021746596321463585, 0.0022800015285611153, 0.002226465381681919, 0.17061986029148102, 0.1188090518116951, 0.002244268311187625, 0.002230631187558174, 0.0021797791123390198, 0.002173199551180005, 0.0022429104428738356, 0.002306945389136672, 0.002214296255260706, 0.0021775017958134413, 0.002217524917796254, 0.002427040133625269, 0.0024409638717770576, 0.002247196389362216, 0.00217633880674839, 0.0021806983277201653, 0.0023967656306922436, 0.002254859311506152, 0.13581760227680206, 0.00228315033018589, 0.002186198253184557, 0.09568807482719421, 0.002281439956277609, 0.0023194507230073214, 0.0022335066460072994, 0.0022508176043629646, 0.002543392591178417, 0.0021843041758984327, 0.0022952326107770205, 0.0023227583151310682, 0.002343033440411091, 0.002218396868556738, 0.16241657733917236, 0.0023523052223026752, 0.002377680502831936, 0.002231328282505274, 0.0022193859331309795, 0.0022963748779147863, 0.13862736523151398, 0.0024325225967913866, 0.0022295729722827673, 0.002406570827588439, 0.0021792855113744736, 0.00222130143083632, 0.0021779448725283146, 0.0021937342826277018, 0.002221390139311552, 0.00243587139993906, 0.0023068871814757586, 0.002268434502184391, 0.0021734926849603653, 0.002447133883833885, 0.0024024881422519684, 0.0021832988131791353, 0.0022084484808146954, 0.0022307627368718386, 0.00239666854031384, 0.002230292884632945, 0.0022843661718070507, 0.002328695962205529, 0.0021854802034795284, 0.0023704851046204567, 0.002275229897350073, 0.0021791437175124884, 0.002248160308226943, 0.002318075392395258, 0.002232828177511692, 0.002200492424890399, 0.002254163147881627, 0.002235858468338847, 0.0023467636201530695, 0.002183548640459776, 0.0023555683437734842, 0.002285370836034417, 0.0022978410124778748, 0.0022440338507294655, 0.002186964266002178, 0.0021683790255337954, 0.002163276309147477, 0.002278357744216919, 0.0022525868844240904, 0.002359478734433651, 0.18630412220954895, 0.002257842803373933, 0.0023374014999717474, 0.18863244354724884, 0.0021626402158290148, 0.0021726314444094896, 0.17296350002288818, 0.0022957546170800924, 0.0021646004170179367, 0.002164350124076009, 0.0022222825791686773, 0.0021770114544779062, 0.15039537847042084, 0.0022685895673930645, 0.002200840041041374, 0.0024029125925153494, 0.0022321438882499933, 0.4454846680164337, 0.002261086832731962, 0.002215166576206684, 0.0022685702424496412, 0.002425840822979808, 0.17178405821323395, 0.0021888918709009886, 0.0022880949545651674, 0.002405287930741906, 0.002357573015615344, 0.0023781112395226955, 0.0022659464739263058, 0.0021886404138058424, 0.0022058458998799324, 0.0022729558404535055, 0.0023590014316141605, 0.13079088926315308, 0.0023372420109808445, 0.002496608067303896, 0.0022970642894506454, 0.002240773756057024, 0.0022196562495082617, 0.0022753681987524033, 0.002262486843392253, 0.0022716661915183067, 0.0024946616031229496, 0.0022753034718334675, 0.0024794370401650667, 0.0023685835767537355, 0.00224774656817317, 0.002260818611830473, 0.0024097594432532787, 0.002203236101195216, 0.002386169508099556, 0.0023378951009362936, 0.0022876099683344364, 0.0022105856332927942, 0.0022453882265836, 0.002220462542027235, 0.002375564305111766, 0.002247630152851343, 0.002332734176889062, 0.0022647278383374214, 0.002254041377454996, 0.0022828164510428905, 0.002329933224245906, 0.00253335596062243, 0.00225771963596344, 0.0022724366281181574, 0.0022824357729405165, 0.002195284003391862, 0.16823634505271912, 0.002231935504823923, 0.0021902681328356266, 0.002225341275334358, 0.0023351716808974743, 0.17326019704341888, 0.002261681016534567, 0.00223611481487751, 0.0022170250304043293, 0.0025146605912595987, 0.002317097969353199, 0.002246252493932843, 0.0022311080247163773, 0.002370058558881283, 0.002214568667113781, 0.0022575068287551403, 0.0022208732552826405, 0.0022561869118362665, 0.0023977968376129866, 0.0022745998576283455, 0.00226337811909616, 0.00228464906103909, 0.0022832711692899466, 0.0023282873444259167, 0.0022313541267067194, 0.0022593217436224222, 0.002337721176445484, 0.0022814436815679073, 0.0022311771754175425, 0.0023456779308617115, 0.0022942021023482084, 0.002356400713324547, 0.0022907410748302937, 0.0023308685049414635, 0.0022604085970669985, 0.002297681290656328, 0.002276405692100525, 0.002254711464047432, 0.0022122799418866634, 0.15884587168693542, 0.0021782913245260715, 0.002372455783188343, 0.0022152552846819162, 0.0021799018140882254, 0.002285309135913849, 0.0022932509891688824, 0.0024177164305001497, 0.0023618319537490606, 0.0022118925116956234, 0.0023048038128763437, 0.0023632110096514225, 0.0022710287012159824, 0.0022553582675755024, 0.002208512043580413, 0.0022379469592124224, 0.0022136811167001724, 0.2048434615135193, 0.00219670869410038, 0.0022933059372007847, 0.0023744995705783367, 0.002210243372246623, 0.0022293999791145325, 0.002344339620321989, 0.0021834694780409336, 0.0023158739786595106, 0.002270155819132924, 0.10600832849740982, 0.0024934501852840185, 0.0022326514590531588, 0.002327876165509224, 0.002250302117317915, 0.4731403589248657, 0.0022469006944447756, 0.0022030959371477365, 0.002206038450822234, 0.0022022558841854334, 0.002182838972657919, 0.0022958198096603155, 0.0021819889079779387, 0.002196683781221509, 0.16371819376945496, 0.0022035434376448393, 0.0024024387821555138, 0.002228503581136465, 0.0022711229976266623, 0.002546191681176424, 0.0024353316985070705, 0.0022067094687372446, 0.0994829311966896, 0.002212061081081629, 0.0022344153840094805, 0.0021940027363598347, 0.13886584341526031, 0.002234232844784856, 0.002197155263274908, 0.0022053064312785864, 0.002201311755925417, 0.09817314147949219, 0.002202654955908656, 0.002370961243286729, 0.0022414023987948895, 0.002237883396446705, 0.002390363020822406, 0.0022746168542653322, 0.0022847983054816723, 0.0024539888836443424, 0.0023655900731682777, 0.13136067986488342, 0.0022951343562453985, 0.002232808619737625, 0.002213843399658799, 0.002570128533989191, 0.0022724210284650326, 0.0022844604682177305, 0.002315978752449155, 0.0022185661364346743, 0.002393219154328108, 0.0022857373114675283, 0.0024614217691123486, 0.002339437371119857, 0.002245810115709901, 0.0023755815345793962, 0.1531282514333725, 0.0022811018861830235, 0.002234089421108365, 0.0023092650808393955, 0.0023542745038866997, 0.00222198897972703, 0.002294036326929927, 0.0022229019086807966, 0.0023304354399442673, 0.0022700002882629633, 0.002192655811086297, 0.0022273531649261713, 0.002377843949943781, 0.002227621152997017, 0.002260373905301094, 0.002248607110232115, 0.002219892106950283, 0.0024702372029423714, 0.0021846790332347155, 0.002206092933192849, 0.4897935390472412, 0.0022283371072262526, 0.0023007793352007866, 0.002336860168725252, 0.13395579159259796, 0.08193784952163696, 0.002455668058246374, 0.09993220865726471, 0.002449767431244254, 0.002327261259779334, 0.0022172420285642147, 0.002197427209466696, 0.0022870153188705444, 0.002219806658104062, 0.0023245925549417734, 0.0023705277126282454, 0.15125250816345215, 0.0022882604971528053, 0.0022826320491731167, 0.11641496419906616, 0.0022647189907729626, 0.002234011422842741, 0.002238790038973093, 0.0022660973481833935, 0.0022763144224882126, 0.0025054148864001036, 0.0022878374438732862, 0.00260632811114192, 0.0023052184842526913, 0.0022279084660112858, 0.0022063308861106634, 0.002299061045050621, 0.0022907082457095385, 0.0022805447224527597, 0.002258364111185074, 0.002288182731717825, 0.12426601350307465, 0.002218458103016019, 0.002284096321091056, 0.0022594004403799772, 0.002278100699186325, 0.16366197168827057, 0.002260238630697131, 0.0022684570867568254, 0.0022775204852223396, 0.002473860513418913, 0.0022716771345585585, 0.0022896332666277885, 0.12831535935401917, 0.002275242703035474, 0.0023374445736408234, 0.0022255023941397667, 0.002215692540630698, 0.10282532870769501, 0.002430084627121687, 0.0022293375805020332, 0.00226837070658803, 0.0023022161331027746, 0.002324902219697833, 0.0022592120803892612, 0.00222920929081738, 0.002286449773237109, 0.0022610798478126526, 0.002385083818808198, 0.0022523344960063696, 0.0022446794901043177, 0.002418657299131155, 0.0022084072697907686, 0.002306461101397872, 0.0022315301466733217, 0.002264576032757759, 0.0024666155222803354, 0.0022542979568243027, 0.1455237865447998, 0.16084161400794983, 0.00226787943392992, 0.0023413219023495913, 0.0022215337958186865, 0.0022949138656258583, 0.002313323086127639, 0.0023529755417257547, 0.002270039636641741, 0.002526757540181279, 0.0022533778101205826, 0.002318761544302106, 0.0023765922524034977, 0.0022202609106898308, 0.002329453593119979, 0.002331316703930497, 0.002264808863401413, 0.0022779712453484535, 0.002245812676846981, 0.0022148999851197004, 0.00246774242259562, 0.0022367837373167276, 0.0023060981184244156, 0.0024099492002278566, 0.0022276188246905804, 0.0022529438138008118, 0.0022495652083307505, 0.0023920924868434668, 0.0022264099679887295, 0.0023955274373292923, 0.002372251357883215, 0.0022675353102385998, 0.002534898230805993, 0.0022248316090554, 0.002461685100570321, 0.0023026010021567345, 0.002275099977850914, 0.002240010304376483, 0.0024580175522714853, 0.0023045786656439304, 0.0022280074190348387, 0.0023661262821406126, 0.14534713327884674, 0.0023041132371872663, 0.0023919076193124056, 0.0023693221155554056, 0.0023109742905944586, 0.002310106996446848, 0.002567997667938471, 0.0022315254900604486, 0.002443443750962615, 0.002260402077808976, 0.1599075049161911, 0.10822858661413193, 0.002232229569926858, 0.15861032903194427, 0.002324997913092375, 0.002281640423461795, 0.0024121468886733055, 0.002281953115016222, 0.002311734715476632, 0.002291314536705613, 0.0027454697992652655, 0.002343932166695595, 0.1354798972606659, 0.0022817999124526978, 0.002306820824742317, 0.0022736573591828346, 0.0022770229261368513, 0.002289852360263467, 0.0022213293705135584, 0.002264630049467087, 0.0022334232926368713, 0.16631320118904114, 0.0022645280696451664, 0.0022265769075602293, 0.0022422869224101305, 0.0022823382169008255, 0.002378258155658841, 0.00227735610678792, 0.0022145630791783333, 0.0022154126781970263, 0.16767866909503937, 0.0023265795316547155, 0.0022328635677695274, 0.002309791510924697, 0.15208126604557037, 0.0022110696882009506, 0.0022239061072468758, 0.002304741181433201, 0.0022719225380569696]\n",
            "Val loss 0.01220886058111052\n",
            "Val auc roc 0.5034695615155385\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-05.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69a2c465-3933-42b0-e742-9cf8a388cd13"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}