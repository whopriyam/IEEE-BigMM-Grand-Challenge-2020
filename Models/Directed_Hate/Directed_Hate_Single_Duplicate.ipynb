{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Directed_Hate_Single_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff7532594fa24dc4ae64e1d854583a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4af4e6e0edd944d5adaae9ae5c4b29f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe3588494cea4ae68abdc9203a5d38ae",
              "IPY_MODEL_7544dfc85aa649ef9f7fd6b780f0c051"
            ]
          }
        },
        "4af4e6e0edd944d5adaae9ae5c4b29f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe3588494cea4ae68abdc9203a5d38ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b07229a6efa47aca254859e2c5b4815",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1e92bb5cee343d7924ab14374077d8a"
          }
        },
        "7544dfc85aa649ef9f7fd6b780f0c051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b3d31e83e364c1c972de618c45b81fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:07&lt;00:00, 32.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d27c54359da42e6a454beacdc5e28e2"
          }
        },
        "9b07229a6efa47aca254859e2c5b4815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1e92bb5cee343d7924ab14374077d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b3d31e83e364c1c972de618c45b81fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d27c54359da42e6a454beacdc5e28e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e119be514d7482880b59c1bd9699944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d64049c56a68444ab79417e8b2101bd3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6627e82e1e04e41a615593f04b5b3e4",
              "IPY_MODEL_b01b343e554f412f86e1c9377ef9a512"
            ]
          }
        },
        "d64049c56a68444ab79417e8b2101bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6627e82e1e04e41a615593f04b5b3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd6ae326bdb74cc0976e1ef53d0cce65",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1658,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1658,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1778ce3d925247c3991f85cf7b1afbaa"
          }
        },
        "b01b343e554f412f86e1c9377ef9a512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e44d657e1bb44fdb90d889814b15cb59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1658/1658 [28:06&lt;00:00,  1.02s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdf4da4e467d43fb9348ae24956bc311"
          }
        },
        "bd6ae326bdb74cc0976e1ef53d0cce65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1778ce3d925247c3991f85cf7b1afbaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e44d657e1bb44fdb90d889814b15cb59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdf4da4e467d43fb9348ae24956bc311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a051a712d3984b488001bde81288a0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f0ca723014894548af5f99aa3b548f38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7c13e8a76d734661ab66b29277d4e45a",
              "IPY_MODEL_deb8f625a12c4f689c03fe08ecd940be"
            ]
          }
        },
        "f0ca723014894548af5f99aa3b548f38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c13e8a76d734661ab66b29277d4e45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_153981b25b55497e8794c6f49150640f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1658,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1658,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24a3fa40f497496b8a3a07a283597b31"
          }
        },
        "deb8f625a12c4f689c03fe08ecd940be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e97bdea77314b53866abad7bbb53077",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1658/1658 [28:36&lt;00:00,  1.04s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d34b6971cf1649c2a4ad1113c43269a1"
          }
        },
        "153981b25b55497e8794c6f49150640f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24a3fa40f497496b8a3a07a283597b31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e97bdea77314b53866abad7bbb53077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d34b6971cf1649c2a4ad1113c43269a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4e8a7e45e314b00a9c360318dea89c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08bbc27ddbb24f9b9617722a9e86c674",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a4b61a79f1fd409d9d0b67cac7dde29d",
              "IPY_MODEL_5c81bd157f444c1abed36bcf2d76c913"
            ]
          }
        },
        "08bbc27ddbb24f9b9617722a9e86c674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4b61a79f1fd409d9d0b67cac7dde29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84c78ef186e84140821b457e31a58197",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1658,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1658,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_579d9e4406b34dfe84b02b24eb9ba4f0"
          }
        },
        "5c81bd157f444c1abed36bcf2d76c913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d49a60573a504b169d384c6b4e78cc44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1658/1658 [28:47&lt;00:00,  1.04s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad642e96739e4bcca34ab281c56f5f76"
          }
        },
        "84c78ef186e84140821b457e31a58197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "579d9e4406b34dfe84b02b24eb9ba4f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d49a60573a504b169d384c6b4e78cc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad642e96739e4bcca34ab281c56f5f76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "14e3f3ba-9f5f-4858-bd68-2923de45b864"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 35.14 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29fd0f36-84b9-4255-f55a-a672f0ec1c3b"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08b1adb7-7734-4255-abdd-2b87abac11bc"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "94418427-0fef-4ba5-f29f-bbf04877d571"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "86374a4a-8f30-4a4d-f3ab-503a3ddf11ef"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "44e27c61-4c8b-40e2-c079-8fd1b8252e8d"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "720d91b2-4c19-4bac-ed1a-a4a87e24db9d"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c6fc8820-e68b-4bf4-9465-e6220deeff70"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "68b4331d-682e-4f32-a8f9-f522c1762cb7"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "68e1ce32-019b-4ea4-ac3d-31aa55bb59b2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Times are tough for many in my close sphere. #...\n",
              "1    I am in real confusion,,, should I wait furthe...\n",
              "2    @LoriKMorrison My #life in in general why ask ...\n",
              "3    Trump Tells Supporters At Rally That #MeToo Ke...\n",
              "4    Midterms, #MeToo and badass women: Inside Vari...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "794eb006-d364-4c9c-8591-4ec25480e16b"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:07<00:00, 51897709.88B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc220ec7-841c-402c-e779-b3151b1effef"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 4408214.00B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "767621ad-2131-4290-cf0d-15773d8cb05c"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa74cda2-a9b2-4992-ce13-8b10ff169cc9"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        df4 = df2.copy().reset_index(drop=True)\n",
        "        df5 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            # random.shuffle(text)\n",
        "            # text3 = ' '.join(text)\n",
        "            # df3['text'][i]=text3\n",
        "            # random.shuffle(text)\n",
        "            # text4 = ' '.join(text)\n",
        "            # df4['text'][i]=text4\n",
        "            # random.shuffle(text)\n",
        "            # text5 = ' '.join(text)\n",
        "            # df5['text'][i]=text5\n",
        "        self.data = self.data.append(df2, ignore_index=True)\n",
        "        # self.data = self.data.append(df3, ignore_index=True)\n",
        "        # self.data = self.data.append(df4, ignore_index=True)\n",
        "        # self.data = self.data.append(df5, ignore_index=True)\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1c9f48c-7f2a-4ec4-9cbc-95e741dc4ef9"
      },
      "source": [
        "col_name = \"Directed_Hate\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828,
          "referenced_widgets": [
            "ff7532594fa24dc4ae64e1d854583a78",
            "4af4e6e0edd944d5adaae9ae5c4b29f2",
            "fe3588494cea4ae68abdc9203a5d38ae",
            "7544dfc85aa649ef9f7fd6b780f0c051",
            "9b07229a6efa47aca254859e2c5b4815",
            "a1e92bb5cee343d7924ab14374077d8a",
            "9b3d31e83e364c1c972de618c45b81fa",
            "8d27c54359da42e6a454beacdc5e28e2",
            "1e119be514d7482880b59c1bd9699944",
            "d64049c56a68444ab79417e8b2101bd3",
            "c6627e82e1e04e41a615593f04b5b3e4",
            "b01b343e554f412f86e1c9377ef9a512",
            "bd6ae326bdb74cc0976e1ef53d0cce65",
            "1778ce3d925247c3991f85cf7b1afbaa",
            "e44d657e1bb44fdb90d889814b15cb59",
            "cdf4da4e467d43fb9348ae24956bc311",
            "a051a712d3984b488001bde81288a0e2",
            "f0ca723014894548af5f99aa3b548f38",
            "7c13e8a76d734661ab66b29277d4e45a",
            "deb8f625a12c4f689c03fe08ecd940be",
            "153981b25b55497e8794c6f49150640f",
            "24a3fa40f497496b8a3a07a283597b31",
            "1e97bdea77314b53866abad7bbb53077",
            "d34b6971cf1649c2a4ad1113c43269a1",
            "d4e8a7e45e314b00a9c360318dea89c7",
            "08bbc27ddbb24f9b9617722a9e86c674",
            "a4b61a79f1fd409d9d0b67cac7dde29d",
            "5c81bd157f444c1abed36bcf2d76c913",
            "84c78ef186e84140821b457e31a58197",
            "579d9e4406b34dfe84b02b24eb9ba4f0",
            "d49a60573a504b169d384c6b4e78cc44",
            "ad642e96739e4bcca34ab281c56f5f76"
          ]
        },
        "outputId": "904b8b3a-b3d4-4249-be89-5f89d3340d90"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6634\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff7532594fa24dc4ae64e1d854583a78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e119be514d7482880b59c1bd9699944",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1658.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0524\n",
            "Train Losses : [0.19119693338871002, 0.34673863649368286, 1.928858995437622, 0.7104588747024536, 0.541025698184967, 0.8776286840438843, 0.7717795968055725, 1.2175867557525635, 0.21965444087982178, 0.22884130477905273, 0.11964750289916992, 0.33133673667907715, 0.19653800129890442, 0.2059609740972519, 1.3742570877075195, 1.2907180786132812, 0.17084820568561554, 0.11435537040233612, 0.0771617665886879, 0.0903925821185112, 0.061428602784872055, 0.059569403529167175, 0.07372206449508667, 0.025592787191271782, 0.04208771511912346, 0.020900271832942963, 0.02081393077969551, 0.04662889614701271, 0.07399225234985352, 0.006644310895353556, 0.03925598785281181, 0.011888865381479263, 0.007630959618836641, 0.0031904317438602448, 0.005816575139760971, 0.004301831126213074, 0.007940634153783321, 0.17701171338558197, 0.0010001055197790265, 0.0009317725780420005, 0.0009499088046140969, 0.3147946894168854, 0.0015604955842718482, 0.0006662103696726263, 0.0029366498347371817, 0.0006756546790711582, 0.0011050573084503412, 0.000510475249029696, 0.00238171243108809, 0.33392685651779175, 0.0008047993178479373, 0.00315264449454844, 0.002367363777011633, 0.0013254036894068122, 0.002037112833932042, 0.0012803253484889865, 0.0017266054637730122, 0.0007892120047472417, 0.0018840919947251678, 0.1574474722146988, 0.0015262158121913671, 0.0006130363908596337, 0.0005253547569736838, 0.16327783465385437, 0.2778691053390503, 0.15988455712795258, 0.0009013452799990773, 0.11550427228212357, 0.001152616343460977, 0.0015416720416396856, 0.0014757298631593585, 0.004157579503953457, 0.006328159477561712, 0.005464823916554451, 0.13069824874401093, 0.00373946619220078, 0.0024849672336131334, 0.005581770557910204, 0.21488331258296967, 0.013027036562561989, 0.005408349446952343, 0.6099818348884583, 0.011719739064574242, 0.0032182654831558466, 0.003022847231477499, 0.002321824664250016, 0.002153961220756173, 0.0036168002989143133, 0.002113984664902091, 0.0020120220724493265, 0.0021964022889733315, 0.003641961608082056, 0.002407762920483947, 0.001943289302289486, 0.11904539167881012, 0.07632648944854736, 0.003328202525153756, 0.0023733582347631454, 0.00648155715316534, 0.004185420926660299, 0.003894963301718235, 0.002536509884521365, 0.06404319405555725, 0.4912738800048828, 0.005262062419205904, 0.00437225541099906, 0.008034922182559967, 0.007142903283238411, 0.016865067183971405, 0.00954784732311964, 0.2929208278656006, 0.007347626145929098, 0.23766553401947021, 0.010176952928304672, 0.006396479904651642, 0.47041651606559753, 0.0064248270355165005, 0.005230087786912918, 0.02495468594133854, 0.005085795186460018, 0.004202178213745356, 0.07356205582618713, 0.01936197280883789, 0.08295125514268875, 0.05567820742726326, 0.008142919279634953, 0.0056077572517097, 0.5719431638717651, 0.01059471070766449, 0.006474494002759457, 0.4319479167461395, 0.008640233427286148, 0.00658446317538619, 0.00901284534484148, 0.007617933209985495, 0.006920284125953913, 0.00916990265250206, 0.007653430569916964, 0.00728827528655529, 0.010301529429852962, 0.008110207505524158, 0.006838175468146801, 0.005943126045167446, 0.010786643251776695, 0.00833097193390131, 0.0049695163033902645, 0.00898150634020567, 0.12912605702877045, 0.003977607004344463, 0.004441810771822929, 0.003939935006201267, 0.003660069778561592, 0.00363034731708467, 0.0037172057200223207, 0.38543790578842163, 0.14730694890022278, 0.0058236741460859776, 0.004873866215348244, 0.005284800194203854, 0.005216421093791723, 0.21470730006694794, 0.17276902496814728, 0.004767905920743942, 0.15198072791099548, 0.005247225984930992, 0.005771177355200052, 0.008421753533184528, 0.006128157023340464, 0.15892386436462402, 0.08158538490533829, 0.00611318601295352, 0.11194761842489243, 0.008205508813261986, 0.006270329933613539, 0.007678309455513954, 0.009734425693750381, 0.006512592080980539, 0.14519616961479187, 0.007025051396340132, 0.0071001676842570305, 0.12429159134626389, 0.007188665214926004, 0.251539409160614, 0.006918355822563171, 0.07449950277805328, 0.006905151065438986, 0.0065494198352098465, 0.005990212317556143, 0.006544667296111584, 0.005848391447216272, 0.007822281681001186, 0.006430312525480986, 0.006433705799281597, 0.0057475147768855095, 0.0051520951092243195, 0.14085160195827484, 0.18234378099441528, 0.07105206698179245, 0.0046929409727454185, 0.0053756264969706535, 0.00678999675437808, 0.004822276998311281, 0.0044662924483418465, 0.004812906961888075, 0.08112890273332596, 0.15383601188659668, 0.09976571053266525, 0.004646425601094961, 0.0063598486594855785, 0.006574398372322321, 0.004734644666314125, 0.04168194159865379, 0.009363762103021145, 0.008952803909778595, 0.4475914537906647, 0.051928095519542694, 0.037769634276628494, 0.008517828769981861, 0.011399522423744202, 0.07756897807121277, 0.008787278085947037, 0.012332559563219547, 0.23823624849319458, 0.010928137227892876, 0.009180719032883644, 0.012035360559821129, 0.008432673290371895, 0.011490507051348686, 0.008823622018098831, 0.15070420503616333, 0.10015644133090973, 0.18701307475566864, 0.008587636053562164, 0.012605691328644753, 0.007972334511578083, 0.20488324761390686, 0.007671150844544172, 0.24636310338974, 0.12765321135520935, 0.00783600565046072, 0.011874228715896606, 0.06890665739774704, 0.03470384702086449, 0.011149265803396702, 0.00867608841508627, 0.01272644568234682, 0.20977240800857544, 0.01272644568234682, 0.00991816446185112, 0.02017703279852867, 0.15209494531154633, 0.014549528248608112, 0.01144692488014698, 0.013368313200771809, 0.06767231971025467, 0.022435491904616356, 0.018521767109632492, 0.03988984599709511, 0.04773106426000595, 0.8071980476379395, 0.010227058082818985, 0.07775701582431793, 0.011767854914069176, 0.15466710925102234, 0.011319187469780445, 0.07642939686775208, 0.012065477669239044, 0.013700621202588081, 0.055707551538944244, 0.00945450458675623, 0.016176989302039146, 0.011683761142194271, 0.008970484137535095, 0.010946444235742092, 0.008355779573321342, 0.08176935464143753, 0.007944729179143906, 0.058681171387434006, 0.008709623478353024, 0.011495642364025116, 0.08748399466276169, 0.00822131335735321, 0.07203446328639984, 0.1144956573843956, 0.009231314063072205, 0.012594422325491905, 0.011636286973953247, 0.008643252775073051, 0.010591688565909863, 0.006033583544194698, 0.005534709431231022, 0.004569997079670429, 0.005561833269894123, 0.006898803170770407, 0.00458260765299201, 0.004669689107686281, 0.0057556102983653545, 0.12709379196166992, 0.07042066752910614, 0.0035779746249318123, 0.0041761817410588264, 0.003043686505407095, 0.007797010242938995, 0.0043710446916520596, 0.004155420232564211, 0.07553043961524963, 0.0027893632650375366, 0.06133993715047836, 0.003708121133968234, 0.005749872419983149, 0.09842593222856522, 0.004740339703857899, 0.005171091761440039, 0.004314804449677467, 0.059971604496240616, 0.00414573447778821, 0.0033261659555137157, 0.003807392669841647, 0.6273282170295715, 0.010215065442025661, 0.005202416330575943, 0.005504859145730734, 0.014696506783366203, 0.012201090343296528, 0.007513848599046469, 0.007968176156282425, 0.014681926928460598, 0.12126308679580688, 0.0062448629178106785, 0.013626397587358952, 0.009332896210253239, 0.015479513444006443, 0.012406066060066223, 0.05021986737847328, 0.01409943774342537, 0.009884444065392017, 0.01358637772500515, 0.006601919420063496, 0.08241917937994003, 0.007758698426187038, 0.010954156517982483, 0.14712175726890564, 0.007421920541673899, 0.008816746063530445, 0.004809507168829441, 0.02960270456969738, 0.0072221471928060055, 0.26489317417144775, 0.009511267766356468, 0.006234964821487665, 0.004097439348697662, 0.004511869978159666, 0.005065465345978737, 0.004092718940228224, 0.004593116231262684, 0.006562323309481144, 0.0035585686564445496, 0.0053267572075128555, 0.006530563347041607, 0.006029420532286167, 0.003511033719405532, 0.13438791036605835, 0.0032456277403980494, 0.6841697096824646, 0.0027170213870704174, 0.0031589651480317116, 0.18255360424518585, 0.003689272329211235, 0.004345215857028961, 0.005835763644427061, 0.006544506177306175, 0.005271037574857473, 0.004220280796289444, 0.0049331774935126305, 0.004378508776426315, 0.3806818723678589, 0.004160817712545395, 0.005938592366874218, 0.09137969464063644, 0.008148863911628723, 0.007812839932739735, 0.006375270429998636, 0.08343081921339035, 0.006151704583317041, 0.009028004482388496, 0.006066069006919861, 0.007709341123700142, 0.01038314774632454, 0.007376616820693016, 0.14213211834430695, 0.006525250617414713, 0.0061134411953389645, 0.010055480524897575, 0.15519565343856812, 0.006175650749355555, 0.008422224782407284, 0.09109634906053543, 0.006475142668932676, 0.2240317016839981, 0.007342288736253977, 0.0404946506023407, 0.005335532128810883, 0.18717226386070251, 0.006595947314053774, 0.006025280803442001, 0.007457440253347158, 0.006272106897085905, 0.00553497951477766, 0.006156465969979763, 0.005231773946434259, 0.004999842029064894, 0.006130645517259836, 0.004878657404333353, 0.0050905728712677956, 0.0048608859069645405, 0.14250941574573517, 0.0051196301355957985, 0.004634753335267305, 0.004368285648524761, 0.0042200894095003605, 0.0038905907422304153, 0.005180825479328632, 0.08039195090532303, 0.003934722859412432, 0.003676858963444829, 0.0036860329564660788, 0.004013373516499996, 0.003791934112086892, 0.13482093811035156, 0.004119312856346369, 0.004467677790671587, 0.00360980536788702, 0.004311166703701019, 0.004125991836190224, 0.004079263191670179, 0.07411458343267441, 0.0038345560897141695, 0.0038722506724298, 0.22212174534797668, 0.0036953540984541178, 0.00396102387458086, 0.003613489679992199, 0.0036661068443208933, 0.00339573179371655, 0.003497237805277109, 0.003761756233870983, 0.0030755125917494297, 0.0031887483783066273, 0.003133907914161682, 0.003086481476202607, 0.003139178967103362, 0.0028076546732336283, 0.003461404936388135, 0.1420571357011795, 0.0027397340163588524, 0.07701977342367172, 0.002640245947986841, 0.15099604427814484, 0.0033197239972651005, 0.17494821548461914, 0.0032479141373187304, 0.0030943192541599274, 0.13089677691459656, 0.14314359426498413, 0.003538127290084958, 0.0040758284740149975, 0.003791271708905697, 0.004208922851830721, 0.004353185649961233, 0.004167909733951092, 0.004302341490983963, 0.004848279058933258, 0.14804495871067047, 0.004640339873731136, 0.004599055275321007, 0.004521558061242104, 0.004322177730500698, 0.11151344329118729, 0.005022612866014242, 0.0046080611646175385, 0.004399489611387253, 0.004586126655340195, 0.0046544973738491535, 0.004971552174538374, 0.004303560592234135, 0.13357707858085632, 0.00451519712805748, 0.0044094473123550415, 0.004640207160264254, 0.00429473165422678, 0.0816648006439209, 0.004294791258871555, 0.004536737222224474, 0.004125569015741348, 0.004045361187309027, 0.004274284467101097, 0.11517304182052612, 0.004085139837116003, 0.1553543210029602, 0.1934538036584854, 0.0044792224653065205, 0.13512703776359558, 0.004800563678145409, 0.3712317645549774, 0.004806588403880596, 0.005493548698723316, 0.07904981076717377, 0.006261576432734728, 0.006339116021990776, 0.007240665145218372, 0.008106162771582603, 0.007943538017570972, 0.007489405106753111, 0.007511632051318884, 0.008000942878425121, 0.1138157919049263, 0.007387575227767229, 0.09696488082408905, 0.007363296113908291, 0.008729241788387299, 0.007683136034756899, 0.0073575302958488464, 0.007409634068608284, 0.12975740432739258, 0.34213948249816895, 0.11027384549379349, 0.007729537785053253, 0.00855707935988903, 0.010487361811101437, 0.00977344624698162, 0.010807611979544163, 0.06133810803294182, 0.00982101820409298, 0.009642004035413265, 0.008681533858180046, 0.00876038521528244, 0.008402340114116669, 0.00930088572204113, 0.009088307619094849, 0.007894380018115044, 0.008111612871289253, 0.007615331560373306, 0.007571930531412363, 0.00689171114936471, 0.006250958889722824, 0.13284587860107422, 0.006143754813820124, 0.0059011997655034065, 0.005732027348130941, 0.00552354846149683, 0.005843256134539843, 0.005051784683018923, 0.7634768486022949, 0.13998141884803772, 0.0063127316534519196, 0.0071891434490680695, 0.007767192553728819, 0.008081825450062752, 0.008773558773100376, 0.1432434767484665, 0.09978880733251572, 0.009469153359532356, 0.01012648269534111, 0.06856540590524673, 0.009624098427593708, 0.07314910739660263, 0.009960507974028587, 0.010471789166331291, 0.01150725968182087, 0.08511897176504135, 0.09069870412349701, 0.06097220256924629, 0.07653211057186127, 0.01028134860098362, 0.01097826473414898, 0.1341622769832611, 0.012302716262638569, 0.010271058417856693, 0.013140011578798294, 0.011678377166390419, 0.010525341145694256, 0.011210590600967407, 0.11897235363721848, 0.00936160795390606, 0.07763828337192535, 0.08087500184774399, 0.008463926613330841, 0.010505793616175652, 0.15287621319293976, 0.008835247717797756, 0.008058242499828339, 0.009655113331973553, 0.007470336277037859, 0.007714776787906885, 0.008120851591229439, 0.006982283666729927, 0.39080336689949036, 0.0068229734897613525, 0.007719430141150951, 0.07610126584768295, 0.08991558849811554, 0.007988332770764828, 0.007927625440061092, 0.2507361173629761, 0.12351962178945541, 0.008526945486664772, 0.00894372258335352, 0.008034946396946907, 0.008027400821447372, 0.0877402052283287, 0.18799413740634918, 0.00837097130715847, 0.010001852177083492, 0.10662679374217987, 0.010786966420710087, 0.007938561961054802, 0.008063300512731075, 0.00895075686275959, 0.009527639485895634, 0.011162731796503067, 0.00936452578753233, 0.007506836671382189, 0.007283322513103485, 0.007235792465507984, 0.09305230528116226, 0.007486805319786072, 0.006813127547502518, 0.18330959975719452, 0.00820650439709425, 0.07611142098903656, 0.08793262392282486, 0.00625437730923295, 0.005958930589258671, 0.0063645364716649055, 0.005623024422675371, 0.007833016104996204, 0.005322843790054321, 0.006047807168215513, 0.005813977215439081, 0.23823578655719757, 0.004782719071954489, 0.005428711883723736, 0.17426708340644836, 0.18180465698242188, 0.09434708952903748, 0.005003300961107016, 0.005276982206851244, 0.00534674571827054, 0.00566492835059762, 0.15362417697906494, 0.4813806116580963, 0.005605391226708889, 0.005889757536351681, 0.006306808907538652, 0.006500357296317816, 0.00694891344755888, 0.006362972781062126, 0.0070299976505339146, 0.46952900290489197, 0.10681196302175522, 0.007977494038641453, 0.15963637828826904, 0.008778447285294533, 0.009280985221266747, 0.11440014094114304, 0.1261574923992157, 0.010640803724527359, 0.010917599312961102, 0.01173350028693676, 0.011310533620417118, 0.10479594022035599, 0.011371167376637459, 0.08289281278848648, 0.011538807302713394, 0.01136390957981348, 0.10982310026884079, 0.0950513631105423, 0.011334461160004139, 0.011073173955082893, 0.010825485922396183, 0.010627293959259987, 0.010273593477904797, 0.009971065446734428, 0.2502785921096802, 0.010076219215989113, 0.01043151505291462, 0.009988660924136639, 0.07852162420749664, 0.11720199882984161, 0.01010577566921711, 0.3593733012676239, 0.0992722436785698, 0.3065403997898102, 0.011767382733523846, 0.014557229354977608, 0.013390379957854748, 0.01409709732979536, 0.015229010954499245, 0.014506475068628788, 0.014715907163918018, 0.01513668056577444, 0.0865815132856369, 0.014341164380311966, 0.07692525535821915, 0.01412281859666109, 0.013995113782584667, 0.013716227374970913, 0.10810815542936325, 0.013206899166107178, 0.1332576423883438, 0.09577926993370056, 0.012039829045534134, 0.15441066026687622, 0.0115438811480999, 0.011474107392132282, 0.011188809759914875, 0.01079808734357357, 0.010060721077024937, 0.010411289520561695, 0.009511570446193218, 0.008742616511881351, 0.009088010527193546, 0.008557159453630447, 0.0078018708154559135, 0.00729760667309165, 0.006834543775767088, 0.0066353376023471355, 0.3841554820537567, 0.006458304822444916, 0.006799224764108658, 0.006554856430739164, 0.006650189403444529, 0.12405458837747574, 0.006496325600892305, 0.0064797233790159225, 0.006387646775692701, 0.08586680144071579, 0.11186521500349045, 0.14328479766845703, 0.007086160127073526, 0.006590979173779488, 0.08738619089126587, 0.12103573977947235, 0.007240767125040293, 0.007211328484117985, 0.007028259802609682, 0.13241028785705566, 0.11852603405714035, 0.07078641653060913, 0.007457563653588295, 0.007794382981956005, 0.007605900522321463, 0.007666599936783314, 0.007614498026669025, 0.0083710215985775, 0.007449556142091751, 0.007597731426358223, 0.007383472751826048, 0.008135429583489895, 0.006811153143644333, 0.007429337594658136, 0.0066383518278598785, 0.006852566730231047, 0.006158993113785982, 0.006151061970740557, 0.005931566935032606, 0.005462477914988995, 0.006125400308519602, 0.005018241237848997, 0.004970808047801256, 0.3374537229537964, 0.004866378847509623, 0.0056473142467439175, 0.005778651684522629, 0.12956653535366058, 0.15668141841888428, 0.005896639544516802, 0.005452713929116726, 0.0059558129869401455, 0.0062609268352389336, 0.006076698657125235, 0.10823523998260498, 0.0058333720080554485, 0.006040075793862343, 0.006321054417639971, 0.11735115945339203, 0.00597825413569808, 0.006591119337826967, 0.005736859515309334, 0.006401767022907734, 0.0764409676194191, 0.005508419591933489, 0.005541786085814238, 0.0059396568685770035, 0.07929766178131104, 0.005704769864678383, 0.005387711804360151, 0.005298879463225603, 0.005479461047798395, 0.0053895446471869946, 0.005282866768538952, 0.004863280337303877, 0.0049591981805861, 0.004773195832967758, 0.006246509030461311, 0.12088610231876373, 0.1461622565984726, 0.0045349691063165665, 0.004520729184150696, 0.14107437431812286, 0.004890617448836565, 0.1969200074672699, 0.05852648988366127, 0.11262396723031998, 0.09731722623109818, 0.005577149335294962, 0.005595310591161251, 0.005915286019444466, 0.005538820289075375, 0.14952746033668518, 0.006191220600157976, 0.10632926970720291, 0.22761553525924683, 0.09810588508844376, 0.0063436697237193584, 0.06148417666554451, 0.007238922640681267, 0.0069965492002666, 0.007291124667972326, 0.007654710207134485, 0.10382039099931717, 0.12970104813575745, 0.007672787178307772, 0.007912405766546726, 0.008887093514204025, 0.0076810866594314575, 0.0080399876460433, 0.007892468012869358, 0.007687521167099476, 0.007549596019089222, 0.008336883038282394, 0.08826540410518646, 0.10728059709072113, 0.006996877491474152, 0.11480072140693665, 0.007135906256735325, 0.006863949354737997, 0.007010874338448048, 0.0069063762202858925, 0.0072420453652739525, 0.006746126804500818, 0.1006273478269577, 0.0063793957233428955, 0.006546842399984598, 0.006236693821847439, 0.0063912770710885525, 0.0061307139694690704, 0.005872614216059446, 0.11679846793413162, 0.005662315525114536, 0.005480787716805935, 0.14017175137996674, 0.0060075148940086365, 0.005171222612261772, 0.005339645314961672, 0.100556880235672, 0.005080508533865213, 0.13738740980625153, 0.0051018353551626205, 0.00499399658292532, 0.0051454282365739346, 0.004986215848475695, 0.12861353158950806, 0.005170080345124006, 0.005250111222267151, 0.005645838566124439, 0.005090994760394096, 0.12124107778072357, 0.005361461080610752, 0.0052405777387320995, 0.005514837335795164, 0.0048609450459480286, 0.0048371246084570885, 0.004704034421592951, 0.13453374803066254, 0.09313398599624634, 0.004848120268434286, 0.00466725742444396, 0.004756340757012367, 0.004837949760258198, 0.0045660086907446384, 0.004588638432323933, 0.004445050377398729, 0.004867339972406626, 0.08424137532711029, 0.004563571885228157, 0.004232930950820446, 0.13281121850013733, 0.004191417712718248, 0.1643981784582138, 0.00448855385184288, 0.107431560754776, 0.004357311874628067, 0.1552276462316513, 0.004976484924554825, 0.0046584210358560085, 0.005048581399023533, 0.004825282841920853, 0.18175390362739563, 0.07551074773073196, 0.1240142434835434, 0.005576029419898987, 0.005566587671637535, 0.11666157096624374, 0.005593054927885532, 0.006194875575602055, 0.005829939153045416, 0.005971438251435757, 0.005960789043456316, 0.13348349928855896, 0.005898183677345514, 0.006022966001182795, 0.11818423122167587, 0.006119855679571629, 0.006493847351521254, 0.1056031808257103, 0.0061487555503845215, 0.005955889821052551, 0.0059042200446128845, 0.005865424405783415, 0.12403170764446259, 0.005843822844326496, 0.006089371163398027, 0.14663080871105194, 0.005991957150399685, 0.11524426192045212, 0.005907018668949604, 0.006172133609652519, 0.0059263515286147594, 0.005858891643583775, 0.10646682977676392, 0.005829382687807083, 0.00589554151520133, 0.3304832875728607, 0.006089250091463327, 0.006359822116792202, 0.0068184565752744675, 0.0072785005904734135, 0.0075218952260911465, 0.13969992101192474, 0.007084880024194717, 0.007199366111308336, 0.12963099777698517, 0.31418415904045105, 0.008318968117237091, 0.008424829691648483, 0.009324155747890472, 0.00926907453685999, 0.00982965249568224, 0.00942255649715662, 0.1099889948964119, 0.09227955341339111, 0.009469602257013321, 0.01033615879714489, 0.009483657777309418, 0.01105843298137188, 0.14525753259658813, 0.009238206781446934, 0.009302970953285694, 0.10694200545549393, 0.09656338393688202, 0.009260829538106918, 0.07248254865407944, 0.18560349941253662, 0.009375367313623428, 0.008910161443054676, 0.00935167632997036, 0.009422059170901775, 0.008839613758027554, 0.13630621135234833, 0.009608037769794464, 0.11001614481210709, 0.008091629482805729, 0.07603759318590164, 0.06284750252962112, 0.008387519977986813, 0.11781954020261765, 0.007968497462570667, 0.08356238156557083, 0.008557352237403393, 0.007896361872553825, 0.00793016143143177, 0.0878683403134346, 0.008098672144114971, 0.44566038250923157, 0.008550867438316345, 0.15240535140037537, 0.11320040374994278, 0.009535415098071098, 0.11736055463552475, 0.049290746450424194, 0.009496822021901608, 0.009838690981268883, 0.13636107742786407, 0.011028471402823925, 0.11095800995826721, 0.011331106536090374, 0.012593504041433334, 0.011220169253647327, 0.010635800659656525, 0.010435011237859726, 0.13157518208026886, 0.010951689444482327, 0.1630174219608307, 0.010537821799516678, 0.0095824571326375, 0.009435493499040604, 0.011395265348255634, 0.010033558122813702, 0.009032901376485825, 0.060975901782512665, 0.008372822776436806, 0.00938401184976101, 0.008480883203446865, 0.007608240470290184, 0.008151177316904068, 0.3862346112728119, 0.0071510085836052895, 0.007571966387331486, 0.07485998421907425, 0.007344354875385761, 0.007477541919797659, 0.0703384131193161, 0.008326218463480473, 0.008022060617804527, 0.00767762353643775, 0.08097036927938461, 0.07814827561378479, 0.007638232316821814, 0.00875417236238718, 0.008180846460163593, 0.008248287253081799, 0.007803956978023052, 0.007506044115871191, 0.007102067116647959, 0.006941675674170256, 0.00678235711529851, 0.006531458348035812, 0.4417339861392975, 0.006501831114292145, 0.22191862761974335, 0.05749256908893585, 0.00674781296402216, 0.009321378543972969, 0.34760797023773193, 0.0486895777285099, 0.07759126275777817, 0.009788340888917446, 0.18494686484336853, 0.010808133520185947, 0.3340904712677002, 0.011700829491019249, 0.01292391400784254, 0.013073095120489597, 0.01320255920290947, 0.1582181602716446, 0.01348292175680399, 0.014676407910883427, 0.014092350378632545, 0.1761200726032257, 0.016729703173041344, 0.01452741026878357, 0.014406796544790268, 0.015045755542814732, 0.014170343987643719, 0.012726008892059326, 0.11982769519090652, 0.15204273164272308, 0.1012091338634491, 0.011514809913933277, 0.011609669774770737, 0.011045136488974094, 0.010832893662154675, 0.010430914349853992, 0.010363871231675148, 0.011584552936255932, 0.009901291690766811, 0.009294816292822361, 0.06930187344551086, 0.008463038131594658, 0.008486667647957802, 0.008395488373935223, 0.007573300041258335, 0.007437161635607481, 0.12776662409305573, 0.006851971615105867, 0.006634273566305637, 0.12877552211284637, 0.00708356499671936, 0.00619932496920228, 0.006142237689346075, 0.006107204128056765, 0.00551167968660593, 0.00563573744148016, 0.005169186741113663, 0.11620902270078659, 0.005453974008560181, 0.004945786669850349, 0.004811107646673918, 0.004839912988245487, 0.004791032522916794, 0.298297643661499, 0.0794801339507103, 0.004866319242864847, 0.005338284652680159, 0.005586619954556227, 0.1306563913822174, 0.00571576738730073, 0.0060393838211894035, 0.005761838052421808, 0.11607097834348679, 0.10094654560089111, 0.006340955849736929, 0.08073174208402634, 0.006203619763255119, 0.006493204738944769, 0.006871062330901623, 0.007130804937332869, 0.09290073066949844, 0.006736374460160732, 0.054234616458415985, 0.006408923305571079, 0.006458602845668793, 0.1415339708328247, 0.007658120710402727, 0.06936144083738327, 0.007373018190264702, 0.006758911069482565, 0.11880003660917282, 0.09890955686569214, 0.09234370291233063, 0.10146316885948181, 0.007384337950497866, 0.00863777194172144, 0.007071213331073523, 0.0074841598980128765, 0.0075583201833069324, 0.08042273670434952, 0.007468965835869312, 0.13119782507419586, 0.17056448757648468, 0.007526134140789509, 0.086820088326931, 0.3686111569404602, 0.11997081339359283, 0.008808973245322704, 0.009326747618615627, 0.010495015420019627, 0.13003063201904297, 0.009477504529058933, 0.010120531544089317, 0.010203481651842594, 0.010132302530109882, 0.010509802959859371, 0.010532602667808533, 0.12234652042388916, 0.010332372970879078, 0.010693873278796673, 0.010409578680992126, 0.009740623645484447, 0.009494906291365623, 0.01090560108423233, 0.009617716073989868, 0.00905266311019659, 0.17177769541740417, 0.008027288131415844, 0.008167687803506851, 0.008661959320306778, 0.007699455600231886, 0.17965982854366302, 0.0709843784570694, 0.007979176938533783, 0.08611030876636505, 0.006876347120851278, 0.10637131333351135, 0.007365440018475056, 0.006755733862519264, 0.10897913575172424, 0.007054499350488186, 0.007029624655842781, 0.007794470991939306, 0.007145412266254425, 0.12901413440704346, 0.13360059261322021, 0.006982885301113129, 0.006607301998883486, 0.0074494690634310246, 0.0676073506474495, 0.0061996146105229855, 0.006316068582236767, 0.007649777922779322, 0.06293421983718872, 0.005938392132520676, 0.006030858960002661, 0.17045892775058746, 0.006712580565363169, 0.007519227918237448, 0.006741249933838844, 0.09394457936286926, 0.10625927150249481, 0.006271067075431347, 0.006092221941798925, 0.005650659091770649, 0.005775740835815668, 0.14645841717720032, 0.0061052520759403706, 0.12354776263237, 0.006040879059582949, 0.005798698402941227, 0.00610622763633728, 0.006448632106184959, 0.005551258567720652, 0.5786167979240417, 0.12983833253383636, 0.006067129783332348, 0.006931134033948183, 0.0067532178945839405, 0.006761437281966209, 0.007004011422395706, 0.0077023860067129135, 0.12020634114742279, 0.06254425644874573, 0.007721735630184412, 0.007595437113195658, 0.14563554525375366, 0.008613464422523975, 0.008396277204155922, 0.007963594980537891, 0.008863414637744427, 0.007688606157898903, 0.11772450059652328, 0.008349177427589893, 0.007491788361221552, 0.1088746041059494, 0.15615233778953552, 0.008131120353937149, 0.007803480606526136, 0.007542429957538843, 0.1065908744931221, 0.17545035481452942, 0.008064080961048603, 0.007395466323941946, 0.0075386096723377705, 0.007300818804651499, 0.16060540080070496, 0.007241320796310902, 0.007714675273746252, 0.0077015371061861515, 0.007511389907449484, 0.13608303666114807, 0.11461030691862106, 0.007319449447095394, 0.11894132941961288, 0.007204372901469469, 0.10556764155626297, 0.007109505590051413, 0.17453238368034363, 0.007047188933938742, 0.07570289820432663, 0.11015746742486954, 0.0078073604963719845, 0.007435170002281666, 0.007378678768873215, 0.00791554432362318, 0.007383790332823992, 0.007504717912524939, 0.08770404011011124, 0.007282498758286238, 0.007577006239444017, 0.007224502973258495, 0.007195526733994484, 0.006801205221563578, 0.38960960507392883, 0.007125004194676876, 0.08169956505298615, 0.007594993803650141, 0.007421386428177357, 0.10001200437545776, 0.007686089724302292, 0.008488914929330349, 0.13927586376667023, 0.008453696966171265, 0.008399325422942638, 0.009171547368168831, 0.008197265677154064, 0.00844599585980177, 0.35458341240882874, 0.008503733202815056, 0.008703297935426235, 0.00903100986033678, 0.00880981981754303, 0.009042360819876194, 0.008905190974473953, 0.13637153804302216, 0.008966319262981415, 0.11398942023515701, 0.009232084266841412, 0.009232242591679096, 0.008934231474995613, 0.009222634136676788, 0.12573619186878204, 0.00871798861771822, 0.10902509838342667, 0.008612210862338543, 0.008645963855087757, 0.11805985867977142, 0.008428525179624557, 0.008344177156686783, 0.008204866200685501, 0.008110319264233112, 0.008026668801903725, 0.00808290857821703, 0.007712731137871742, 0.11742781102657318, 0.007272450719028711, 0.0071196286007761955, 0.007210779469460249, 0.00688121048733592, 0.006712596397846937, 0.0890161544084549, 0.006328881252557039, 0.006490278523415327, 0.006210443563759327, 0.006074077449738979, 0.12953317165374756, 0.005703630391508341, 0.005709970369935036, 0.1525474339723587, 0.005702814552932978, 0.00556988688185811, 0.005504627712070942, 0.1371726244688034, 0.005650573875755072, 0.005440520588308573, 0.00532901706174016, 0.005281103774905205, 0.0054989405907690525, 0.005205073393881321, 0.005066412966698408, 0.0049073174595832825, 0.0048203738406300545, 0.004683906678110361, 0.004601995926350355, 0.004510357975959778, 0.103766068816185, 0.004409639164805412, 0.004346679896116257, 0.004190095234662294, 0.10305684804916382, 0.004140894860029221, 0.14273089170455933, 0.004150306340306997, 0.004140614997595549, 0.004214812070131302, 0.004204729571938515, 0.13184359669685364, 0.004187555052340031, 0.00429771700873971, 0.004289469216018915, 0.004248289857059717, 0.11843696236610413, 0.004460768308490515, 0.004290327429771423, 0.12451254576444626, 0.004391263239085674, 0.0044136736541986465, 0.11416573077440262, 0.0045164162293076515, 0.37869155406951904, 0.10764110088348389, 0.3814562261104584, 0.006121403072029352, 0.09934018552303314, 0.007785105612128973, 0.09440053254365921, 0.00888636615127325, 0.00961072277277708, 0.009896074421703815, 0.010589704848825932, 0.01071469858288765, 0.011147057637572289, 0.01154373213648796, 0.2586950957775116, 0.011925382539629936, 0.01259589847177267, 0.012982129119336605, 0.013092627748847008, 0.01322986837476492, 0.09860195964574814, 0.013204008340835571, 0.013227574527263641, 0.013286635279655457, 0.09525130689144135, 0.013535914942622185, 0.012696001678705215, 0.012406766414642334, 0.012260057963430882, 0.011845780536532402, 0.011703155934810638, 0.010739779099822044, 0.0110493628308177, 0.010172015056014061, 0.010380291379988194, 0.009257977828383446, 0.10333537310361862, 0.11427049338817596, 0.008341818116605282, 0.3603304624557495, 0.07427648454904556, 0.008495382964611053, 0.008718459866940975, 0.009858980774879456, 0.008751032873988152, 0.008709476329386234, 0.008805101737380028, 0.11006137728691101, 0.008860415779054165, 0.1179700493812561, 0.09929906576871872, 0.08058314770460129, 0.008736392483115196, 0.008983258157968521, 0.008795238099992275, 0.008509211242198944, 0.008368067443370819, 0.008343781344592571, 0.008152542635798454, 0.13829639554023743, 0.008163537830114365, 0.1456833779811859, 0.0076970732770860195, 0.007942588068544865, 0.007500434760004282, 0.11584223061800003, 0.007557573262602091, 0.007607176434248686, 0.12781518697738647, 0.007306430488824844, 0.007393506355583668, 0.0069581009447574615, 0.10541219264268875, 0.09846138209104538, 0.11653216183185577, 0.1620876044034958, 0.09195549041032791, 0.00719066709280014, 0.00750716170296073, 0.12731920182704926, 0.007478885352611542, 0.007469859439879656, 0.007462131790816784, 0.10648850351572037, 0.007658842951059341, 0.007631208747625351, 0.10383456200361252, 0.09649617224931717, 0.0076013533398509026, 0.007752383127808571, 0.007953280583024025, 0.0076544033363461494, 0.007581510581076145, 0.13427913188934326, 0.007530021481215954, 0.007629167288541794, 0.007422929164022207, 0.12069164961576462, 0.007341339718550444, 0.007262853905558586, 0.007163722533732653, 0.11687386780977249, 0.007128481287509203, 0.0068517583422362804, 0.007014015223830938, 0.00689654890447855, 0.00651639886200428, 0.006577897816896439, 0.4239177703857422, 0.0065910727716982365, 0.006789050996303558, 0.11739180982112885, 0.00698689091950655, 0.007518189027905464, 0.007314374204725027, 0.007226642221212387, 0.1326674371957779, 0.007295547053217888, 0.007466733921319246, 0.007377760950475931, 0.007448180112987757, 0.11290101706981659, 0.0074007161892950535, 0.11404440551996231, 0.29689526557922363, 0.00784130860120058, 0.007918003015220165, 0.11297079175710678, 0.008332214318215847, 0.10901092737913132, 0.008852175436913967, 0.12580692768096924, 0.00928175263106823, 0.00935121439397335, 0.009906638413667679, 0.009476878680288792, 0.09119615703821182, 0.00961979292333126, 0.009907020255923271, 0.009692400693893433, 0.00965378899127245, 0.009256206452846527, 0.2726093828678131, 0.11444015055894852, 0.009439453482627869, 0.009715307503938675, 0.09856697171926498, 0.10092364251613617, 0.010571814142167568, 0.01083448063582182, 0.010578678920865059, 0.01091867033392191, 0.010398145765066147, 0.010770224966108799, 0.07044386118650436, 0.010460766963660717, 0.12653684616088867, 0.11510083824396133, 0.009670338593423367, 0.009765350259840488, 0.09225039184093475, 0.0814194455742836, 0.009823530912399292, 0.009221945889294147, 0.00942615233361721, 0.009237711317837238, 0.009271804243326187, 0.09226475656032562, 0.07252414524555206, 0.00899917259812355, 0.008430957794189453, 0.00851423665881157, 0.14283089339733124, 0.008074837736785412, 0.008054136298596859, 0.008208797313272953, 0.10707035660743713, 0.007659804541617632, 0.11742980033159256, 0.007622283883392811, 0.2876283824443817, 0.007952490821480751, 0.008137875236570835, 0.009114828892052174, 0.08419646322727203, 0.08083143085241318, 0.008768130093812943, 0.009031145833432674, 0.00893136765807867, 0.00876863207668066, 0.12897837162017822, 0.009370801970362663, 0.009190675802528858, 0.009062414988875389, 0.009254069067537785, 0.009500437416136265, 0.07952003926038742, 0.008475757203996181, 0.00882706418633461, 0.008145070634782314, 0.11443016678094864, 0.008029053919017315, 0.008242413401603699, 0.008750980719923973, 0.007655954919755459, 0.00746560376137495, 0.1400979608297348, 0.007174540776759386, 0.09435085952281952, 0.006664007902145386, 0.007832980714738369, 0.006673889700323343, 0.15431959927082062, 0.006545034237205982, 0.12886008620262146, 0.006410248577594757, 0.007437650114297867, 0.09093562513589859, 0.006613083649426699, 0.006149518769234419, 0.14872847497463226, 0.10080116987228394, 0.006395308300852776, 0.006378382910043001, 0.11624010652303696, 0.006098330952227116, 0.00608519371598959, 0.6914613246917725, 0.007589212153106928, 0.1376701146364212, 0.00874424446374178, 0.09553709626197815, 0.10343406349420547, 0.01015640702098608, 0.010578780435025692, 0.15845848619937897, 0.012372526340186596, 0.012560473755002022, 0.013060805387794971, 0.012375934049487114, 0.012472969479858875, 0.012502998113632202, 0.012821520678699017, 0.01229006890207529, 0.011959448456764221, 0.011755386367440224, 0.011897621676325798, 0.011491737328469753, 0.010868110693991184, 0.011860664933919907, 0.0959983840584755, 0.01003206241875887, 0.12619951367378235, 0.010789552703499794, 0.009394156746566296, 0.01023874245584011, 0.009038995951414108, 0.008523324504494667, 0.008482645265758038, 0.09785362333059311, 0.007952159270644188, 0.008364379405975342, 0.008019683882594109, 0.007434702478349209, 0.10954223573207855, 0.006895188242197037, 0.11180344223976135, 0.007198341190814972, 0.006424970459192991, 0.3554479479789734, 0.07571081817150116, 0.007243244908750057, 0.007185006979852915, 0.007174558937549591, 0.007542701438069344, 0.007360971067100763, 0.007850672118365765, 0.007519417908042669, 0.10996751487255096, 0.12759318947792053]\n",
            "Val loss 0.04059666662632553\n",
            "Val auc roc 0.47826979672849224\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a051a712d3984b488001bde81288a0e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1658.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0430\n",
            "Train Losses : [0.008450712077319622, 0.0075664338655769825, 0.007358574774116278, 0.007309579756110907, 0.007747428957372904, 0.00713754165917635, 0.0073905326426029205, 0.007364872843027115, 0.007387625984847546, 0.007200802210718393, 0.006606667768210173, 0.006514095235615969, 0.006400144658982754, 0.006171651184558868, 0.0061466326005756855, 0.006360003259032965, 0.005707009229809046, 0.005520147737115622, 0.005259479861706495, 0.0051734596490859985, 0.08366905152797699, 0.005096185952425003, 0.004816607106477022, 0.10083598643541336, 0.1309109926223755, 0.004801752977073193, 0.005050624720752239, 0.13361531496047974, 0.1256900429725647, 0.11648068577051163, 0.004907773807644844, 0.005060775205492973, 0.10670412331819534, 0.005117909517139196, 0.07488168030977249, 0.005572371184825897, 0.005533779505640268, 0.10013187676668167, 0.005592992063611746, 0.005636679474264383, 0.005686025135219097, 0.006068324204534292, 0.1122119352221489, 0.00577966682612896, 0.11099699884653091, 0.005878984462469816, 0.006360288243740797, 0.006339243147522211, 0.006124447099864483, 0.00587866734713316, 0.09242678433656693, 0.005949981510639191, 0.00566328689455986, 0.005868714302778244, 0.13302084803581238, 0.006127336993813515, 0.1338544636964798, 0.005687440745532513, 0.0058031752705574036, 0.15149158239364624, 0.005990230478346348, 0.005669806618243456, 0.0061480882577598095, 0.00597713328897953, 0.2124798744916916, 0.12568555772304535, 0.00591266481205821, 0.005716425366699696, 0.005889963358640671, 0.0997396856546402, 0.0672900378704071, 0.005993795581161976, 0.006171098444610834, 0.005994786508381367, 0.006125579122453928, 0.006319522392004728, 0.005922143813222647, 0.0059538171626627445, 0.005888058803975582, 0.14224354922771454, 0.005864390172064304, 0.13293476402759552, 0.005686303600668907, 0.11489300429821014, 0.006068832240998745, 0.005917846225202084, 0.005840436555445194, 0.0057862126268446445, 0.08548730611801147, 0.10395364463329315, 0.005834460258483887, 0.10710477828979492, 0.005911539774388075, 0.09063662588596344, 0.006580186542123556, 0.006199970841407776, 0.006140671670436859, 0.005977298133075237, 0.13135024905204773, 0.006055372301489115, 0.006148010492324829, 0.006024191156029701, 0.006042436696588993, 0.006048242561519146, 0.13061508536338806, 0.0060616168193519115, 0.005910610780119896, 0.005879170261323452, 0.005944077856838703, 0.006232209037989378, 0.005743514280766249, 0.006090078037232161, 0.006095224525779486, 0.0054430877789855, 0.1229192465543747, 0.09093493968248367, 0.005495425779372454, 0.005240923725068569, 0.005202136002480984, 0.005080964416265488, 0.005040687974542379, 0.09109923243522644, 0.004967191256582737, 0.00513633294031024, 0.004977799486368895, 0.1294550597667694, 0.004901534412056208, 0.004967402201145887, 0.004903453402221203, 0.004853785037994385, 0.004848801530897617, 0.1046060100197792, 0.14084941148757935, 0.004718044772744179, 0.10633916407823563, 0.0047956351190805435, 0.004840848036110401, 0.12074629962444305, 0.1200188398361206, 0.11781693249940872, 0.0052886418998241425, 0.005431541241705418, 0.005436742678284645, 0.1249438226222992, 0.005956771317869425, 0.11273176968097687, 0.1644168198108673, 0.005984961055219173, 0.006411484442651272, 0.006457308307290077, 0.00627254880964756, 0.10409568250179291, 0.10362649708986282, 0.006469895131886005, 0.006468192208558321, 0.10382363945245743, 0.006997019052505493, 0.007061413023620844, 0.006909204646945, 0.007244783453643322, 0.006981612183153629, 0.006739291362464428, 0.006747839972376823, 0.10680404305458069, 0.00672091543674469, 0.40137261152267456, 0.007106624078005552, 0.09827426075935364, 0.007302630692720413, 0.00750422477722168, 0.007776458747684956, 0.008293556980788708, 0.00787257682532072, 0.008180440403521061, 0.008498094044625759, 0.12895116209983826, 0.007774158380925655, 0.007994282990694046, 0.00775353517383337, 0.007807048968970776, 0.008281935006380081, 0.10800930857658386, 0.007450934965163469, 0.00752828037366271, 0.007225979585200548, 0.007311070337891579, 0.3734624981880188, 0.09185803681612015, 0.007674635387957096, 0.007898957468569279, 0.007838877849280834, 0.008196466602385044, 0.008235079236328602, 0.007969509810209274, 0.007971473969519138, 0.008197383023798466, 0.3576289415359497, 0.008507291786372662, 0.008659928105771542, 0.00898403488099575, 0.009076706133782864, 0.008878514170646667, 0.009362373501062393, 0.1080455407500267, 0.009050071239471436, 0.008995234034955502, 0.11371559649705887, 0.13685332238674164, 0.0088752256706357, 0.008865974843502045, 0.008916113525629044, 0.009635883383452892, 0.008713017217814922, 0.3030710220336914, 0.008907739073038101, 0.16445153951644897, 0.00933886505663395, 0.10251809656620026, 0.07564981281757355, 0.009818374179303646, 0.09391245245933533, 0.010300968773663044, 0.010330903343856335, 0.010351958684623241, 0.01081437524408102, 0.09726443141698837, 0.010504402220249176, 0.009996932931244373, 0.01009919960051775, 0.009910269640386105, 0.009989003650844097, 0.009851006790995598, 0.009375565685331821, 0.008915076032280922, 0.008786911144852638, 0.1257365196943283, 0.00843843538314104, 0.008066809736192226, 0.10350019484758377, 0.008190263994038105, 0.14339856803417206, 0.007853483781218529, 0.007625692058354616, 0.007394902873784304, 0.08139479160308838, 0.13560214638710022, 0.007081090472638607, 0.00713398726657033, 0.006995257455855608, 0.0973362848162651, 0.006842329632490873, 0.006753783207386732, 0.006760388612747192, 0.006567645352333784, 0.0938878059387207, 0.09566562622785568, 0.006550345569849014, 0.006596457213163376, 0.006217501126229763, 0.00622746953740716, 0.006189108360558748, 0.006803871598094702, 0.006084541790187359, 0.08310890942811966, 0.0058607067912817, 0.005803070496767759, 0.0059067183174192905, 0.005824204534292221, 0.005505228880792856, 0.005670207552611828, 0.08325158059597015, 0.12888051569461823, 0.1096220389008522, 0.005413235165178776, 0.005555919371545315, 0.005505281500518322, 0.005117021966725588, 0.13824130594730377, 0.005632857326418161, 0.005225855857133865, 0.0054120831191539764, 0.0052931299433112144, 0.005348564125597477, 0.00518849678337574, 0.005039240699261427, 0.005133143160492182, 0.0048683444038033485, 0.005239566788077354, 0.004961858503520489, 0.09843012690544128, 0.005181376356631517, 0.1006823480129242, 0.4947390556335449, 0.0049974084831774235, 0.0050544049590826035, 0.005326949059963226, 0.005661966744810343, 0.005929156672209501, 0.10349851846694946, 0.006355419754981995, 0.006138225086033344, 0.006579787936061621, 0.0067288619466125965, 0.3643708825111389, 0.006765918806195259, 0.007130293175578117, 0.007149370852857828, 0.007347873877733946, 0.007570966612547636, 0.00753380823880434, 0.12177840620279312, 0.008253995329141617, 0.008070165291428566, 0.007913406938314438, 0.008136970922350883, 0.008276604115962982, 0.4389748275279999, 0.008848547004163265, 0.1436990648508072, 0.008659603074193, 0.11372297257184982, 0.00912638008594513, 0.009872740134596825, 0.009310638532042503, 0.15910056233406067, 0.009796317666769028, 0.2985379099845886, 0.010160102508962154, 0.010267742909491062, 0.12015267461538315, 0.010935619473457336, 0.011287042871117592, 0.011158718727529049, 0.08930659294128418, 0.011815197765827179, 0.011567545123398304, 0.0908050611615181, 0.011427820660173893, 0.011388223618268967, 0.12273642420768738, 0.09221775829792023, 0.011104698292911053, 0.12215447425842285, 0.011595364660024643, 0.011619305238127708, 0.011071502231061459, 0.08558855950832367, 0.12493406236171722, 0.12239161878824234, 0.11310335993766785, 0.010694943368434906, 0.07941947877407074, 0.011109019629657269, 0.01092586200684309, 0.10923433303833008, 0.010664195753633976, 0.01032979879528284, 0.11952698230743408, 0.08711572736501694, 0.010367541573941708, 0.010137243196368217, 0.00996045395731926, 0.009808366186916828, 0.11127044260501862, 0.009577897377312183, 0.00954589992761612, 0.009226267226040363, 0.009147089906036854, 0.0092091616243124, 0.07910021394491196, 0.008690607734024525, 0.0083867022767663, 0.11635550111532211, 0.14134171605110168, 0.007874950766563416, 0.008226039819419384, 0.35863083600997925, 0.007960555143654346, 0.008167251944541931, 0.008180384524166584, 0.1450432538986206, 0.09828076511621475, 0.008706221356987953, 0.09432873874902725, 0.11432600766420364, 0.10087805986404419, 0.009320325218141079, 0.00933278352022171, 0.1269456148147583, 0.009644143283367157, 0.009893462993204594, 0.009684538468718529, 0.10170231759548187, 0.009628122672438622, 0.009638073854148388, 0.12974517047405243, 0.009572762995958328, 0.009771015495061874, 0.009714276529848576, 0.009338779374957085, 0.00916533824056387, 0.10180022567510605, 0.08422861248254776, 0.009143081493675709, 0.00868431106209755, 0.00860845297574997, 0.008430015295743942, 0.10530499368906021, 0.13531969487667084, 0.008359499275684357, 0.008032099343836308, 0.007938885129988194, 0.008413378149271011, 0.008517072536051273, 0.007974091917276382, 0.007414256222546101, 0.10614410042762756, 0.007346956990659237, 0.007273369934409857, 0.0768904983997345, 0.006954757031053305, 0.006767348852008581, 0.08500362932682037, 0.006601178552955389, 0.006495427805930376, 0.006521284114569426, 0.12168402969837189, 0.006262782495468855, 0.006260238122195005, 0.006233935244381428, 0.005959145724773407, 0.005914873443543911, 0.16644442081451416, 0.005953535903245211, 0.0057475813664495945, 0.005675771739333868, 0.005569275934249163, 0.00582734914496541, 0.005463139154016972, 0.005308009684085846, 0.005317887756973505, 0.005356540437787771, 0.005201615393161774, 0.005153955426067114, 0.004929217975586653, 0.004751233849674463, 0.004573760088533163, 0.00447299936786294, 0.00440738070756197, 0.38305115699768066, 0.004469471052289009, 0.004577526357024908, 0.14616826176643372, 0.08726894110441208, 0.004943150095641613, 0.1279008388519287, 0.005247283726930618, 0.005378234665840864, 0.12371712923049927, 0.00566412229090929, 0.00598470214754343, 0.005823447834700346, 0.10857977718114853, 0.0059633320197463036, 0.006371933035552502, 0.006305756978690624, 0.07989414781332016, 0.006326403468847275, 0.11785832792520523, 0.12958355247974396, 0.07862727344036102, 0.006627472583204508, 0.007189493160694838, 0.006813958752900362, 0.09586112946271896, 0.0070429351180791855, 0.09657678753137589, 0.007283298298716545, 0.007160720881074667, 0.007153185084462166, 0.007155743893235922, 0.007179846987128258, 0.11045260727405548, 0.00712004816159606, 0.007142730988562107, 0.007243942003697157, 0.006996274460107088, 0.006863747723400593, 0.0069016944617033005, 0.006834710948169231, 0.006592331454157829, 0.0067906160838902, 0.006384244188666344, 0.006330581847578287, 0.006434029433876276, 0.10465256124734879, 0.00604697410017252, 0.005781190004199743, 0.005673253443092108, 0.005483098328113556, 0.13245171308517456, 0.005492013413459063, 0.005305114667862654, 0.005238717887550592, 0.005293083377182484, 0.005043914541602135, 0.0052306149154901505, 0.005117794033139944, 0.005079419352114201, 0.004852541722357273, 0.004611422307789326, 0.004689598921686411, 0.10558856278657913, 0.10389649122953415, 0.1164301335811615, 0.3718721270561218, 0.004801396280527115, 0.0049773771315813065, 0.00506568280979991, 0.09699941426515579, 0.005444458220154047, 0.0056937807239592075, 0.005831300280988216, 0.09408453106880188, 0.09308600425720215, 0.006542036309838295, 0.11002805829048157, 0.006986961234360933, 0.006773969158530235, 0.10451002418994904, 0.007142418064177036, 0.007101938594132662, 0.006968219298869371, 0.00736329797655344, 0.007198929786682129, 0.007265645079314709, 0.0937936007976532, 0.007004340644925833, 0.11668483912944794, 0.08947325497865677, 0.0075225429609417915, 0.007433218881487846, 0.007477532606571913, 0.007128263358026743, 0.08447910845279694, 0.006988657172769308, 0.09476041793823242, 0.09253562241792679, 0.007392114493995905, 0.007072354666888714, 0.007546868175268173, 0.007285008206963539, 0.0076749869622290134, 0.08771957457065582, 0.007554184645414352, 0.11673801392316818, 0.007264688145369291, 0.007220176048576832, 0.10498927533626556, 0.13914000988006592, 0.007180740125477314, 0.007227974943816662, 0.006833046209067106, 0.007666011806577444, 0.006875239312648773, 0.11455677449703217, 0.3874388635158539, 0.0072661652229726315, 0.007254834286868572, 0.007307817228138447, 0.007456889841705561, 0.007748674601316452, 0.0077644335106015205, 0.0083563681691885, 0.007934561930596828, 0.008249529637396336, 0.11992303282022476, 0.007704984396696091, 0.3058510422706604, 0.008157164789736271, 0.008714967407286167, 0.08614713698625565, 0.008469178341329098, 0.009080762043595314, 0.1286429464817047, 0.009256226941943169, 0.00912732258439064, 0.0994376540184021, 0.00938007514923811, 0.009474700316786766, 0.009166919626295567, 0.009135013446211815, 0.008962072432041168, 0.009800453670322895, 0.009024929255247116, 0.008884785696864128, 0.00857754796743393, 0.008910128846764565, 0.008298581466078758, 0.07583168894052505, 0.3338514566421509, 0.007943843491375446, 0.008092429488897324, 0.008234482258558273, 0.12656499445438385, 0.008340836502611637, 0.008821142837405205, 0.008366210386157036, 0.008361339569091797, 0.1001851037144661, 0.008765226230025291, 0.008215014822781086, 0.008235776796936989, 0.14319056272506714, 0.008412117138504982, 0.007919883355498314, 0.17076316475868225, 0.008299246430397034, 0.007884269580245018, 0.007823470048606396, 0.0876755639910698, 0.007777844555675983, 0.12424492090940475, 0.007512236014008522, 0.007730303797870874, 0.007502288091927767, 0.007392916828393936, 0.1291673183441162, 0.007840517908334732, 0.3875543475151062, 0.007490514777600765, 0.0077482364140450954, 0.007817394100129604, 0.1477808952331543, 0.008165396749973297, 0.09482588618993759, 0.008326136507093906, 0.008443951606750488, 0.00831611081957817, 0.008940414525568485, 0.008402809500694275, 0.008578605018556118, 0.008489648811519146, 0.008336519822478294, 0.008759230375289917, 0.11921145766973495, 0.007692581042647362, 0.007873003371059895, 0.1041424572467804, 0.007689713966101408, 0.14333610236644745, 0.008265907876193523, 0.0074916621670126915, 0.007161846850067377, 0.007419848348945379, 0.007049761712551117, 0.0071738180704414845, 0.00702858529984951, 0.00673668971285224, 0.006644397974014282, 0.11892297863960266, 0.006409641355276108, 0.09867752343416214, 0.11344978958368301, 0.006012685596942902, 0.006025208625942469, 0.00622705090790987, 0.08003527671098709, 0.005979612469673157, 0.09182731807231903, 0.00590859679505229, 0.005867280066013336, 0.005815965123474598, 0.0060563054867088795, 0.10951639711856842, 0.005913515575230122, 0.005933547858148813, 0.13171736896038055, 0.005865996237844229, 0.0057277986779809, 0.11246936768293381, 0.005647376179695129, 0.0059800599701702595, 0.09952781349420547, 0.12408128380775452, 0.0056715235114097595, 0.1018667072057724, 0.005804032552987337, 0.006046411115676165, 0.08806847780942917, 0.13992013037204742, 0.006143202539533377, 0.12476076930761337, 0.006196924485266209, 0.10733034461736679, 0.00649354699999094, 0.006557460408657789, 0.006632424425333738, 0.006774533540010452, 0.006826373748481274, 0.006573095452040434, 0.11031987518072128, 0.0066469814628362656, 0.006789454724639654, 0.006508344318717718, 0.006703087128698826, 0.006511891260743141, 0.1190263107419014, 0.006445151753723621, 0.14173968136310577, 0.006264298222959042, 0.006164761260151863, 0.006507867947220802, 0.0064047547057271, 0.006230167578905821, 0.127064049243927, 0.006224986165761948, 0.00630518514662981, 0.0061495304107666016, 0.005944590549916029, 0.006220739334821701, 0.005722520407289267, 0.3624906837940216, 0.005774893332272768, 0.005851227790117264, 0.00604328652843833, 0.0063107251189649105, 0.006375509779900312, 0.006408339831978083, 0.006134017836302519, 0.006283080670982599, 0.006447226740419865, 0.2895476520061493, 0.006408659741282463, 0.0067693619057536125, 0.006773330271244049, 0.007508648559451103, 0.0074384682811796665, 0.007708349730819464, 0.0069763995707035065, 0.0069384463131427765, 0.0069118463434278965, 0.007040349300950766, 0.1239335760474205, 0.006794407498091459, 0.006774703972041607, 0.1655750870704651, 0.12148549407720566, 0.1122056320309639, 0.00695037329569459, 0.007625810336321592, 0.0068421135656535625, 0.007178589701652527, 0.10261882841587067, 0.0071448092348873615, 0.1104956641793251, 0.007469643838703632, 0.006916367448866367, 0.007158484775573015, 0.007312738336622715, 0.006999277044087648, 0.006882825866341591, 0.006916650105267763, 0.006713733077049255, 0.007016689516603947, 0.14402686059474945, 0.006533126812428236, 0.0064293877221643925, 0.0061774770729243755, 0.006032656412571669, 0.12342911958694458, 0.123564712703228, 0.005951147526502609, 0.005982852540910244, 0.005832627881318331, 0.006032680161297321, 0.005781011655926704, 0.005993102677166462, 0.00569783104583621, 0.10422937572002411, 0.07558247447013855, 0.005705827847123146, 0.11672208458185196, 0.005683984141796827, 0.005547237582504749, 0.0055170487612485886, 0.07859989255666733, 0.005755169317126274, 0.005598127841949463, 0.7952194809913635, 0.006114400457590818, 0.006810498423874378, 0.11200684309005737, 0.0076337237842381, 0.12265238165855408, 0.007799271494150162, 0.007899442687630653, 0.008581752888858318, 0.00834916066378355, 0.00879400409758091, 0.39034518599510193, 0.008967140689492226, 0.009827726520597935, 0.36298495531082153, 0.010598721913993359, 0.011091136373579502, 0.011125676333904266, 0.011846376582980156, 0.012069758959114552, 0.32586610317230225, 0.012801209464669228, 0.012929373420774937, 0.013226297684013844, 0.013570129871368408, 0.01420180406421423, 0.014660422690212727, 0.014473517425358295, 0.14591191709041595, 0.014071464538574219, 0.01370192226022482, 0.013789385557174683, 0.11484332382678986, 0.013566219247877598, 0.08257567882537842, 0.012815290130674839, 0.012792793102562428, 0.012468203902244568, 0.012405971996486187, 0.13109828531742096, 0.012100568041205406, 0.011429055593907833, 0.011717673391103745, 0.011145827360451221, 0.010651696473360062, 0.010607064701616764, 0.010146569460630417, 0.10959333181381226, 0.009840663522481918, 0.1029617041349411, 0.009432140737771988, 0.29043543338775635, 0.009429342113435268, 0.009368587285280228, 0.009268675930798054, 0.08516648411750793, 0.00950917974114418, 0.00946709606796503, 0.08473030477762222, 0.009316827170550823, 0.009134592488408089, 0.0878993570804596, 0.00908222422003746, 0.009009863249957561, 0.009169220924377441, 0.10251035541296005, 0.009078232571482658, 0.008507943712174892, 0.009013725444674492, 0.008402315899729729, 0.008176840841770172, 0.008044261485338211, 0.10372958332300186, 0.008032962679862976, 0.1121702790260315, 0.007701941765844822, 0.007521733641624451, 0.007373541593551636, 0.10747472196817398, 0.12805604934692383, 0.007272499147802591, 0.00746205635368824, 0.007112251594662666, 0.09879030287265778, 0.08977334946393967, 0.3732551336288452, 0.3948615491390228, 0.007870334200561047, 0.008439049124717712, 0.008824643678963184, 0.00932461116462946, 0.1683918833732605, 0.00957038439810276, 0.009746287949383259, 0.009872926399111748, 0.01007512304931879, 0.010371633805334568, 0.15040671825408936, 0.010305333882570267, 0.010261817835271358, 0.010526861064136028, 0.10516176372766495, 0.010445397347211838, 0.01043777260929346, 0.12902989983558655, 0.10201092064380646, 0.010121160186827183, 0.10074620693922043, 0.010534101165831089, 0.12176143378019333, 0.009944712743163109, 0.00989276822656393, 0.009957177564501762, 0.12171311676502228, 0.10695485025644302, 0.009749836288392544, 0.13363057374954224, 0.2922748029232025, 0.010108139365911484, 0.010352554731070995, 0.010295872576534748, 0.010337884537875652, 0.010543371550738811, 0.010593455284833908, 0.010737098753452301, 0.1228947639465332, 0.010683823376893997, 0.010463501326739788, 0.010167465545237064, 0.09389128535985947, 0.01005981769412756, 0.1394432783126831, 0.00989671889692545, 0.10534346848726273, 0.00987529568374157, 0.009600485675036907, 0.009487406350672245, 0.14527033269405365, 0.009307002648711205, 0.009697296656668186, 0.07907141000032425, 0.10246638208627701, 0.1112835556268692, 0.00904284231364727, 0.008930793963372707, 0.008891305886209011, 0.3054618239402771, 0.009142008610069752, 0.00928446650505066, 0.009323523379862309, 0.11890624463558197, 0.00973551720380783, 0.10731210559606552, 0.009844057261943817, 0.009808141738176346, 0.009699469432234764, 0.0982331782579422, 0.09788142144680023, 0.1496983766555786, 0.08849281072616577, 0.009924265556037426, 0.009798328392207623, 0.009961155243217945, 0.010081200860440731, 0.00978900771588087, 0.009650432504713535, 0.00981123186647892, 0.10293589532375336, 0.00939919799566269, 0.09787272661924362, 0.009149174205958843, 0.10062409937381744, 0.009228356182575226, 0.11945398151874542, 0.10177198797464371, 0.0088748037815094, 0.009285327047109604, 0.00888524018228054, 0.009125838987529278, 0.008877290412783623, 0.008470842614769936, 0.11073800176382065, 0.00847548246383667, 0.008460722863674164, 0.008093847893178463, 0.008000674657523632, 0.008011327125132084, 0.007756696082651615, 0.007574568502604961, 0.1031939834356308, 0.007651477120816708, 0.10938844084739685, 0.007297063712030649, 0.007060933392494917, 0.0069236718118190765, 0.0979822650551796, 0.12283114343881607, 0.006873742211610079, 0.006854929029941559, 0.11826083809137344, 0.006714250426739454, 0.0067382389679551125, 0.13114255666732788, 0.006607538554817438, 0.006763787008821964, 0.006638113874942064, 0.006561205256730318, 0.006492724176496267, 0.1266678422689438, 0.10505407303571701, 0.006541900802403688, 0.0065485043451189995, 0.006316786631941795, 0.3686765730381012, 0.006558030378073454, 0.0067044151946902275, 0.006825496908277273, 0.006917241960763931, 0.1283261626958847, 0.007108719553798437, 0.13930585980415344, 0.0072577595710754395, 0.007422642782330513, 0.007417123299092054, 0.007619522511959076, 0.007426437456160784, 0.007711832877248526, 0.007503988686949015, 0.0077601466327905655, 0.007383763324469328, 0.007207915186882019, 0.1092151403427124, 0.1297316700220108, 0.007161347661167383, 0.0071684191934764385, 0.007108874153345823, 0.09829642623662949, 0.006943732965737581, 0.0069833132438361645, 0.006930983159691095, 0.006823035888373852, 0.006717618089169264, 0.006873901933431625, 0.0066519081592559814, 0.12464402616024017, 0.0063651870004832745, 0.006343781016767025, 0.0062881833873689175, 0.006153906229883432, 0.006130101624876261, 0.006149094086140394, 0.1202678307890892, 0.00585707975551486, 0.10486402362585068, 0.005904399789869785, 0.14425049722194672, 0.11343766003847122, 0.00615586806088686, 0.0059201777912676334, 0.005906799808144569, 0.005937548354268074, 0.0058019873686134815, 0.005752033554017544, 0.00573723902925849, 0.005731023848056793, 0.005720273591578007, 0.00573101919144392, 0.0055240183137357235, 0.005428135395050049, 0.13413754105567932, 0.11438678950071335, 0.005367748439311981, 0.005420270841568708, 0.00528903491795063, 0.0053220209665596485, 0.005209834314882755, 0.005164391826838255, 0.0892425999045372, 0.00517220189794898, 0.00504849199205637, 0.005078424699604511, 0.004965210799127817, 0.004914900753647089, 0.005024658050388098, 0.004861132707446814, 0.004763134755194187, 0.004888192750513554, 0.00470720324665308, 0.13098002970218658, 0.004658869467675686, 0.10624344646930695, 0.004631927236914635, 0.0045784940011799335, 0.004554471466690302, 0.004545604810118675, 0.004455883987247944, 0.004548742901533842, 0.1118125393986702, 0.004532376769930124, 0.0044581033289432526, 0.10068290680646896, 0.0045302072539925575, 0.0044695488177239895, 0.004370176233351231, 0.09363549947738647, 0.004383099731057882, 0.0994325801730156, 0.00445484509691596, 0.11918481439352036, 0.1006811261177063, 0.004644856322556734, 0.11654812097549438, 0.1334822177886963, 0.004883033223450184, 0.004929994232952595, 0.376285582780838, 0.005250779911875725, 0.10387630015611649, 0.005752827040851116, 0.006365020759403706, 0.006173869129270315, 0.006448115687817335, 0.006494975183159113, 0.006703190505504608, 0.12212686240673065, 0.11592192947864532, 0.007047430146485567, 0.007374793291091919, 0.1119517982006073, 0.0073877060785889626, 0.007303300313651562, 0.007632755674421787, 0.007623245473951101, 0.12572269141674042, 0.09946517646312714, 0.10363984107971191, 0.12428911030292511, 0.143416166305542, 0.00789627805352211, 0.008028482086956501, 0.008034629747271538, 0.008207292295992374, 0.008211883716285229, 0.00806280504912138, 0.008142054080963135, 0.09315696358680725, 0.008155970834195614, 0.007948368787765503, 0.36175665259361267, 0.00814073160290718, 0.008435473777353764, 0.008575900457799435, 0.00851471908390522, 0.09742186963558197, 0.09408444166183472, 0.009128749370574951, 0.10779121518135071, 0.14585377275943756, 0.00902628991752863, 0.009175759740173817, 0.009171250276267529, 0.009298477321863174, 0.009415778331458569, 0.11519648134708405, 0.009131849743425846, 0.00909483339637518, 0.00930177140980959, 0.00908940751105547, 0.009139257483184338, 0.008808815851807594, 0.008895819075405598, 0.008466608822345734, 0.008279108442366123, 0.11678919196128845, 0.007978961803019047, 0.007925844751298428, 0.007917392998933792, 0.007635924033820629, 0.0075452737510204315, 0.007327639032155275, 0.007243272848427296, 0.007173262536525726, 0.007106064818799496, 0.3089992105960846, 0.006897883024066687, 0.006877872161567211, 0.0070158569142222404, 0.11320744454860687, 0.006997508928179741, 0.007011453155428171, 0.007103187497705221, 0.007000340148806572, 0.006986360996961594, 0.10216264426708221, 0.006960176397114992, 0.007001204881817102, 0.11485973745584488, 0.0069693406112492085, 0.00710008991882205, 0.006856891792267561, 0.12578339874744415, 0.0067574866116046906, 0.006763613782823086, 0.006752688903361559, 0.006755633279681206, 0.006620930507779121, 0.006508062593638897, 0.006550133228302002, 0.006373950280249119, 0.0063088322058320045, 0.006179632619023323, 0.0062151094898581505, 0.006165140308439732, 0.10462404787540436, 0.005908335093408823, 0.005774966906756163, 0.005763234570622444, 0.11293566226959229, 0.005564527120441198, 0.005706484895199537, 0.0055594719015061855, 0.13415557146072388, 0.005369433667510748, 0.005469925235956907, 0.005343202035874128, 0.1141313761472702, 0.005371053237468004, 0.005310047417879105, 0.11750245094299316, 0.10415875166654587, 0.12060391902923584, 0.005359310656785965, 0.42246782779693604, 0.09448865056037903, 0.0060027348808944225, 0.006073729135096073, 0.006328560411930084, 0.006475520320236683, 0.006613518111407757, 0.0841655358672142, 0.006842301692813635, 0.006935956422239542, 0.11747188866138458, 0.00727121951058507, 0.007123107090592384, 0.10338873416185379, 0.007364859338849783, 0.13107338547706604, 0.007341913413256407, 0.0074928440153598785, 0.007608553394675255, 0.007426438387483358, 0.007431370671838522, 0.007364298216998577, 0.00734406802803278, 0.007292834110558033, 0.0071976641193032265, 0.007246304303407669, 0.007089690770953894, 0.00714524369686842, 0.0068247681483626366, 0.13326548039913177, 0.006667934823781252, 0.006718442775309086, 0.006599452346563339, 0.006458676420152187, 0.0063848034478724, 0.006256964057683945, 0.006281452253460884, 0.006167281419038773, 0.00602367939427495, 0.005913801956921816, 0.005804791115224361, 0.005808277986943722, 0.005663154646754265, 0.005461022257804871, 0.005347899626940489, 0.08760588616132736, 0.005314373876899481, 0.10111799091100693, 0.12387910485267639, 0.005128711462020874, 0.0051146941259503365, 0.005122847389429808, 0.10544494539499283, 0.0050458949990570545, 0.12725596129894257, 0.00505922781303525, 0.005098237190395594, 0.005353555548936129, 0.14408385753631592, 0.005142242647707462, 0.005098841618746519, 0.005177111364901066, 0.0051186466589570045, 0.00514554139226675, 0.005346669349819422, 0.12271338701248169, 0.005071021616458893, 0.005105702672153711, 0.0978173166513443, 0.0050392746925354, 0.005051921587437391, 0.005097629502415657, 0.0050750067457556725, 0.005053195171058178, 0.09904932230710983, 0.13510237634181976, 0.0053497981280088425, 0.005102047696709633, 0.005047232378274202, 0.005015036091208458, 0.005019763950258493, 0.1372050642967224, 0.12319713085889816, 0.0050995624624192715, 0.0050847954116761684, 0.005210647825151682, 0.10444536805152893, 0.12905165553092957, 0.005253218580037355, 0.41526782512664795, 0.005535962525755167, 0.11324766278266907, 0.14072394371032715, 0.10548831522464752, 0.006542470306158066, 0.006607585586607456, 0.0067733945325016975, 0.12202421575784683, 0.10265421122312546, 0.0074109951965510845, 0.007524912245571613, 0.007659695576876402, 0.007688987534493208, 0.007646123878657818, 0.11351574212312698, 0.007904873229563236, 0.007931822910904884, 0.007917730137705803, 0.007808721158653498, 0.007791426032781601, 0.007731986697763205, 0.1239168792963028, 0.007861794903874397, 0.13384436070919037, 0.007886583916842937, 0.1114487275481224, 0.1143573448061943, 0.007595572154968977, 0.00758815323933959, 0.698174774646759, 0.008057115599513054, 0.08884063363075256, 0.008869470097124577, 0.10623853653669357, 0.08965782821178436, 0.09534844756126404, 0.12737812101840973, 0.07324828952550888, 0.08499326556921005, 0.011075872927904129, 0.011394326575100422, 0.011681556701660156, 0.011885914951562881, 0.011897064745426178, 0.012079359032213688, 0.1138821616768837, 0.28224098682403564, 0.0997566357254982, 0.012451805174350739, 0.012616737745702267, 0.01289370097219944, 0.01297647412866354, 0.0129370903596282, 0.01297694817185402, 0.013053377158939838, 0.012831307016313076, 0.26128578186035156, 0.012842143885791302, 0.012917734682559967, 0.01290329359471798, 0.10199999809265137, 0.013556145131587982, 0.013013686053454876, 0.013024798594415188, 0.13235463201999664, 0.012720146216452122, 0.13386009633541107, 0.012400368228554726, 0.01234615221619606, 0.012308559380471706, 0.09075354039669037, 0.011907652951776981, 0.011755179613828659, 0.10415129363536835, 0.01146130170673132, 0.10256346315145493, 0.011119923554360867, 0.10938834398984909, 0.010893143713474274, 0.010875004343688488, 0.010592718608677387, 0.3076830804347992, 0.010744696483016014, 0.010877411812543869, 0.010776962153613567, 0.010594325140118599, 0.010521200485527515, 0.13293597102165222, 0.11840491741895676, 0.010733709670603275, 0.010921640321612358, 0.010664282366633415, 0.01029625628143549, 0.10661241412162781, 0.010334824211895466, 0.3271777629852295, 0.010502523742616177, 0.10348987579345703, 0.0997353345155716, 0.01069182064384222, 0.010873486287891865, 0.010850407183170319, 0.010952443815767765, 0.011140170507133007, 0.01083435583859682, 0.010676064528524876, 0.010743211954832077, 0.13087627291679382, 0.08908440917730331, 0.10288088023662567, 0.01034570299088955, 0.010494362562894821, 0.11974459886550903, 0.10867371410131454, 0.10686828196048737, 0.010335586965084076, 0.010148655623197556, 0.09061340242624283, 0.010516341775655746, 0.09128113090991974, 0.28157874941825867, 0.010400540195405483, 0.11298118531703949, 0.010785186663269997, 0.10521898418664932, 0.010854496620595455, 0.12377987056970596, 0.01113845594227314, 0.011144567281007767, 0.01136738620698452, 0.011212993413209915, 0.011052587069571018, 0.10823804885149002, 0.011303195729851723, 0.010846319608390331, 0.01081292238086462, 0.13667601346969604, 0.010601911693811417, 0.10408885031938553, 0.01046007964760065, 0.09517504274845123, 0.010279083624482155, 0.010365394875407219, 0.01014062948524952, 0.3473619818687439, 0.010072055272758007, 0.010296519845724106, 0.09923360496759415, 0.010878203436732292, 0.01030761655420065, 0.010478721000254154, 0.010354727506637573, 0.010385301895439625, 0.010259110480546951, 0.010071231052279472, 0.11474636197090149, 0.009932694025337696, 0.009783739224076271, 0.009673251770436764, 0.009689678438007832, 0.00946439802646637, 0.009239821694791317, 0.009157376363873482, 0.008983207866549492, 0.09748952835798264, 0.008714783005416393, 0.008607239462435246, 0.10437586158514023, 0.008376609534025192, 0.008249279111623764, 0.008086351677775383, 0.007979891262948513, 0.12188414484262466, 0.007754384074360132, 0.1374436318874359, 0.06957543641328812, 0.10473102331161499, 0.13408994674682617, 0.007656029891222715, 0.11407893896102905, 0.09208143502473831, 0.09641850739717484, 0.11285293102264404, 0.007922940887510777, 0.09260117262601852, 0.008216818794608116, 0.008238375186920166, 0.008067593909800053, 0.008345351554453373, 0.008276659063994884, 0.00810644868761301, 0.007969764061272144, 0.007944532670080662, 0.008148351684212685, 0.09856148064136505, 0.007901937700808048, 0.007768071722239256, 0.007779005449265242, 0.11104785650968552, 0.007816342636942863, 0.007478966843336821, 0.007389505859464407, 0.00738199707120657, 0.007175230886787176, 0.10466945916414261, 0.007144303992390633, 0.007010208442807198, 0.09208746999502182, 0.006870951037853956, 0.007092047017067671, 0.006765873171389103, 0.006696270313113928, 0.00663465540856123, 0.08887510001659393, 0.11872924119234085, 0.006636998150497675, 0.006373991258442402, 0.00638841837644577, 0.09750937670469284, 0.006290088407695293, 0.006473209243267775, 0.006293997634202242, 0.09560590982437134, 0.10300645232200623, 0.0062675513327121735, 0.006200723350048065, 0.00625961646437645, 0.006297299638390541, 0.006108761765062809, 0.1130245104432106, 0.006169052328914404, 0.006084041204303503, 0.11968240886926651, 0.006034356541931629, 0.00619307067245245, 0.006109796464443207, 0.005964186042547226, 0.006098936311900616, 0.006025406066328287, 0.118699811398983, 0.005843630060553551, 0.005788358394056559, 0.09196566790342331, 0.0057726772502064705, 0.005828616674989462, 0.005708344280719757, 0.1182897612452507, 0.0056418986059725285, 0.005652205087244511, 0.0056681386195123196, 0.13719524443149567, 0.005598193034529686, 0.10496152937412262, 0.005681152455508709, 0.005747129675000906, 0.11636337637901306, 0.1192554458975792, 0.11631771922111511, 0.005699662026017904, 0.00587037205696106, 0.005804840940982103, 0.005801609717309475, 0.005887549836188555, 0.005903386976569891, 0.0059109036810696125, 0.005787312984466553, 0.005937546957284212, 0.005725083407014608, 0.00568906357511878, 0.0057775103487074375, 0.09495444595813751, 0.005666231270879507, 0.005548952147364616, 0.005591200664639473, 0.005541511345654726, 0.122260682284832, 0.005466775503009558, 0.005352458916604519, 0.3568746745586395, 0.005551211070269346, 0.1260334998369217, 0.005826157983392477, 0.00580222113057971, 0.006275125313550234, 0.13325804471969604, 0.006138993427157402, 0.006113887298852205, 0.1308060884475708, 0.006250037346035242, 0.0063189235515892506, 0.006333518773317337, 0.13351841270923615, 0.006374797783792019, 0.006614163983613253, 0.006599016021937132, 0.006605381146073341, 0.10588949173688889, 0.006495893467217684, 0.0064576417207717896, 0.0064186276867985725, 0.006591477897018194, 0.006509631406515837, 0.006573162507265806, 0.09779440611600876, 0.006294887978583574, 0.00653734989464283, 0.1096394956111908, 0.006197409238666296, 0.006170634645968676, 0.13478177785873413, 0.006216979585587978, 0.10267290472984314, 0.006222620606422424, 0.006340389605611563, 0.11626861244440079, 0.11210567504167557, 0.006240658462047577, 0.323095440864563, 0.006443042308092117, 0.09845240414142609, 0.006753791123628616, 0.11157920956611633, 0.007165994495153427, 0.007467175368219614, 0.007358018774539232, 0.10135994851589203, 0.007595476694405079, 0.007545648142695427, 0.007589243818074465, 0.00772084342315793, 0.0077642956748604774, 0.00767508102580905, 0.3476998209953308, 0.007794796954840422, 0.007894900627434254, 0.09578751772642136, 0.008279172703623772, 0.008240770548582077, 0.008255910128355026, 0.1339316964149475, 0.008360086008906364, 0.008535175584256649, 0.00841685850173235, 0.008628121577203274, 0.09082279354333878, 0.008424000814557076, 0.00832782220095396]\n",
            "Val loss 0.03884771309982417\n",
            "Val auc roc 0.507671160997422\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4e8a7e45e314b00a9c360318dea89c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1658.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0434\n",
            "Train Losses : [0.11083196103572845, 0.0882907286286354, 0.008339283056557178, 0.008296594023704529, 0.11784207820892334, 0.00837097130715847, 0.13655796647071838, 0.008347718045115471, 0.008281195536255836, 0.008203755132853985, 0.008247902616858482, 0.008175728842616081, 0.008055203594267368, 0.12132016569375992, 0.008027487434446812, 0.007925761863589287, 0.00804451946169138, 0.007837135344743729, 0.007941379211843014, 0.00757242739200592, 0.007482001092284918, 0.356935977935791, 0.007437451276928186, 0.007513415068387985, 0.10352041572332382, 0.09121613204479218, 0.34351617097854614, 0.007994705811142921, 0.008325649425387383, 0.0920092836022377, 0.008560288697481155, 0.008900423534214497, 0.09206018596887589, 0.32007917761802673, 0.11064624041318893, 0.09150435030460358, 0.009908350184559822, 0.010444166138768196, 0.01039092056453228, 0.010628783144056797, 0.011013828217983246, 0.3635912239551544, 0.011146271601319313, 0.011374448426067829, 0.011864598840475082, 0.011713698506355286, 0.3355483412742615, 0.012186366133391857, 0.0128217414021492, 0.012594979256391525, 0.013137871399521828, 0.013062626123428345, 0.09373078495264053, 0.013037418015301228, 0.013209616765379906, 0.39392879605293274, 0.08780316263437271, 0.013423895463347435, 0.013757244683802128, 0.013888266868889332, 0.014280324801802635, 0.013894990086555481, 0.3296963572502136, 0.013962818309664726, 0.014051397331058979, 0.014663707464933395, 0.01426582969725132, 0.014165348373353481, 0.01405732985585928, 0.07037279009819031, 0.08839524537324905, 0.014267071150243282, 0.11171343922615051, 0.0793212428689003, 0.08438188582658768, 0.013609816320240498, 0.11344141513109207, 0.01350630633533001, 0.013565875589847565, 0.013404185883700848, 0.013183771632611752, 0.013159475289285183, 0.013058804906904697, 0.08637932687997818, 0.012398154474794865, 0.012305216863751411, 0.012554975226521492, 0.012101124040782452, 0.011680569499731064, 0.011599927209317684, 0.08196312934160233, 0.01099806372076273, 0.010838366113603115, 0.0962546318769455, 0.010542440228164196, 0.01034421194344759, 0.010299068875610828, 0.010157729499042034, 0.09843295812606812, 0.11580033600330353, 0.009632507339119911, 0.009515849873423576, 0.009361907839775085, 0.10637041926383972, 0.0090992646291852, 0.009171738289296627, 0.008863307535648346, 0.008955957368016243, 0.008922114036977291, 0.008595007471740246, 0.008446261286735535, 0.14831013977527618, 0.11751411855220795, 0.008310304023325443, 0.1364314705133438, 0.007969704456627369, 0.008248665370047092, 0.00801012571901083, 0.007806724868714809, 0.00795181654393673, 0.0077476040460169315, 0.00764124933630228, 0.007812968455255032, 0.007367378566414118, 0.007220426574349403, 0.10813023149967194, 0.0071991002187132835, 0.007248689886182547, 0.007200323510915041, 0.09792701154947281, 0.006867124233394861, 0.00697361072525382, 0.08713597804307938, 0.006678284611552954, 0.006574095226824284, 0.006545725278556347, 0.006575176492333412, 0.006445927079766989, 0.1367754191160202, 0.10824574530124664, 0.006324667949229479, 0.12842731177806854, 0.00631216075271368, 0.11863101273775101, 0.1477329283952713, 0.0063310773111879826, 0.006408353801816702, 0.006434554699808359, 0.11104926466941833, 0.006488016806542873, 0.006623440887778997, 0.006559781730175018, 0.08805719763040543, 0.006448427215218544, 0.00647203903645277, 0.08391811698675156, 0.006376068107783794, 0.006457959767431021, 0.006701468024402857, 0.006466349586844444, 0.006391816306859255, 0.006415575742721558, 0.1254223734140396, 0.006337826140224934, 0.00621306337416172, 0.006294615101069212, 0.11659551411867142, 0.1170782819390297, 0.006148927845060825, 0.006176375783979893, 0.1051635667681694, 0.38229432702064514, 0.006324445828795433, 0.006418515928089619, 0.006739569827914238, 0.006656264420598745, 0.006696587894111872, 0.006800145376473665, 0.007157714571803808, 0.006958897691220045, 0.0069535416550934315, 0.10642662644386292, 0.006882626563310623, 0.006952140014618635, 0.007020683493465185, 0.006856819149106741, 0.006800779141485691, 0.12090151011943817, 0.006830924656242132, 0.0068830205127596855, 0.00675991689786315, 0.006702394224703312, 0.006638230290263891, 0.006861609872430563, 0.12217721343040466, 0.006601185072213411, 0.006558990105986595, 0.08907224237918854, 0.006456534378230572, 0.0064130802638828754, 0.006448650732636452, 0.00633059348911047, 0.006404596846550703, 0.006301982328295708, 0.006516635417938232, 0.00618335884064436, 0.3952961564064026, 0.006248209159821272, 0.006347399204969406, 0.006288678385317326, 0.006306307855993509, 0.006335026118904352, 0.006360877305269241, 0.006418223027139902, 0.0863453596830368, 0.006420305464416742, 0.08314765989780426, 0.006559804081916809, 0.006451363675296307, 0.006452899891883135, 0.12956440448760986, 0.006761309690773487, 0.006469822023063898, 0.006458629388362169, 0.006371135823428631, 0.12049542367458344, 0.006311535835266113, 0.006462903693318367, 0.34425342082977295, 0.006462451536208391, 0.10221874713897705, 0.006614271551370621, 0.13164322078227997, 0.12094608694314957, 0.00695014325901866, 0.007060909643769264, 0.0071487086825072765, 0.10767991840839386, 0.007309370674192905, 0.0073113879188895226, 0.007344131823629141, 0.007441820111125708, 0.13164623081684113, 0.0076940166763961315, 0.34075620770454407, 0.09995189309120178, 0.007926019839942455, 0.3618994951248169, 0.008300979621708393, 0.0895712673664093, 0.008792147040367126, 0.009011696092784405, 0.009250828996300697, 0.1160130575299263, 0.009645831771194935, 0.009842920117080212, 0.00969565287232399, 0.009830824099481106, 0.01033074501901865, 0.00983823835849762, 0.1234833300113678, 0.009875738061964512, 0.010123208165168762, 0.009767375886440277, 0.009778576903045177, 0.009694457985460758, 0.00982019305229187, 0.009808596223592758, 0.009393870830535889, 0.12165189534425735, 0.009360287338495255, 0.00917870458215475, 0.009077982045710087, 0.009121255949139595, 0.008913668803870678, 0.0089985067024827, 0.0877915695309639, 0.00855204090476036, 0.008577653206884861, 0.008365546353161335, 0.10126745700836182, 0.10244913399219513, 0.00812257919460535, 0.09159831702709198, 0.1351565718650818, 0.008038227446377277, 0.008108902722597122, 0.008355000987648964, 0.007924264296889305, 0.10706853121519089, 0.007841920480132103, 0.007832592353224754, 0.007723658811300993, 0.007822657935321331, 0.007687499281018972, 0.0076176198199391365, 0.007497440557926893, 0.0076779453083872795, 0.00744990911334753, 0.007244137115776539, 0.007343390490859747, 0.007130284793674946, 0.006982156541198492, 0.0068949926644563675, 0.006780881434679031, 0.006658690515905619, 0.00665965024381876, 0.00649828277528286, 0.006403657607734203, 0.006420333404093981, 0.006202574819326401, 0.006333271041512489, 0.006090543698519468, 0.005965879652649164, 0.005952621344476938, 0.005760904401540756, 0.33712735772132874, 0.005765897687524557, 0.12792347371578217, 0.005930859595537186, 0.15999171137809753, 0.1239510253071785, 0.005989785306155682, 0.006074057426303625, 0.006337982602417469, 0.006311706732958555, 0.00617421418428421, 0.0061536929570138454, 0.006339575629681349, 0.006161409430205822, 0.006163815967738628, 0.006166695151478052, 0.006225104909390211, 0.006135924719274044, 0.006090178620070219, 0.006042171735316515, 0.005980812478810549, 0.005930339451879263, 0.005805677734315395, 0.1048571914434433, 0.005916016176342964, 0.09023942798376083, 0.005820543970912695, 0.005678432062268257, 0.005737129598855972, 0.005713579244911671, 0.005578418727964163, 0.13498204946517944, 0.13707861304283142, 0.0056143468245863914, 0.005574326030910015, 0.1115335077047348, 0.005541923455893993, 0.005835270043462515, 0.005577651783823967, 0.13983610272407532, 0.005667281337082386, 0.00560686644166708, 0.005619649775326252, 0.005674521438777447, 0.005555859766900539, 0.005723405629396439, 0.00545357633382082, 0.005521370563656092, 0.11207893490791321, 0.005508359055966139, 0.1310097724199295, 0.005459209904074669, 0.0053624724969267845, 0.0054130228236317635, 0.10835247486829758, 0.129847913980484, 0.005401995033025742, 0.14211246371269226, 0.005618737544864416, 0.4147365689277649, 0.005697538144886494, 0.11677899956703186, 0.00586568471044302, 0.006039024330675602, 0.006130733992904425, 0.0062024653889238834, 0.006362677551805973, 0.10866394639015198, 0.00631553353741765, 0.006376146338880062, 0.006651801522821188, 0.006575169041752815, 0.12022605538368225, 0.006577737163752317, 0.0065178037621080875, 0.0066090901382267475, 0.0066408803686499596, 0.10555917769670486, 0.006489820312708616, 0.006520182825624943, 0.006609747186303139, 0.006502390839159489, 0.006600436754524708, 0.006417331285774708, 0.11999168992042542, 0.006337066181004047, 0.12311527878046036, 0.006414500530809164, 0.006403334904462099, 0.11976483464241028, 0.006298786960542202, 0.006319778505712748, 0.11334142833948135, 0.006250905804336071, 0.00625592889264226, 0.00624477444216609, 0.10331059247255325, 0.006194093730300665, 0.006199672352522612, 0.314951628446579, 0.00631320895627141, 0.11118560284376144, 0.0064748357981443405, 0.006513165310025215, 0.10526127368211746, 0.006705625914037228, 0.006871367339044809, 0.006939399056136608, 0.12121263891458511, 0.006963551510125399, 0.00687706284224987, 0.007122063543647528, 0.11311818659305573, 0.0069184741005301476, 0.00698353024199605, 0.10763085633516312, 0.007081953343003988, 0.007016220595687628, 0.007027671206742525, 0.007083487696945667, 0.0069486708380281925, 0.006969284266233444, 0.0069968863390386105, 0.00688546895980835, 0.0067758155055344105, 0.006735662464052439, 0.13461002707481384, 0.006631918717175722, 0.006623543333262205, 0.00679023889824748, 0.3481399118900299, 0.09211093932390213, 0.3162194490432739, 0.11170251667499542, 0.007124163676053286, 0.007314646150916815, 0.007441679015755653, 0.007648038677871227, 0.007977340370416641, 0.007943185046315193, 0.09712442010641098, 0.00789346732199192, 0.11856245994567871, 0.008067631162703037, 0.008194866590201855, 0.008277776651084423, 0.00827735010534525, 0.008148450404405594, 0.00829316210001707, 0.09221410751342773, 0.10353490710258484, 0.1330566555261612, 0.12619182467460632, 0.37441369891166687, 0.008389778435230255, 0.008528134785592556, 0.008651177398860455, 0.008811146020889282, 0.008934492245316505, 0.008981099352240562, 0.009045597165822983, 0.009041199460625648, 0.009003408253192902, 0.008949716575443745, 0.008981239050626755, 0.009030218236148357, 0.008813810534775257, 0.11922089755535126, 0.008749415166676044, 0.00869501382112503, 0.008662138134241104, 0.008716878481209278, 0.0084870345890522, 0.008450432680547237, 0.008423635736107826, 0.008505805395543575, 0.008172865025699139, 0.008138574659824371, 0.007981618866324425, 0.007916421629488468, 0.00782427005469799, 0.00779876159504056, 0.007680539041757584, 0.007510858587920666, 0.10592537373304367, 0.007364608347415924, 0.007299605756998062, 0.007195947226136923, 0.007144077215343714, 0.09907933324575424, 0.006982031743973494, 0.007008180487900972, 0.006829563993960619, 0.006789195351302624, 0.09825923293828964, 0.006878071930259466, 0.006593059282749891, 0.006551502738147974, 0.006533751264214516, 0.0064762067049741745, 0.10225541144609451, 0.006414406932890415, 0.00632846774533391, 0.10485189408063889, 0.13297513127326965, 0.006300705019384623, 0.006271651480346918, 0.006204103119671345, 0.006228609476238489, 0.136746346950531, 0.09857825934886932, 0.1200241968035698, 0.006196636240929365, 0.08673348277807236, 0.11567215621471405, 0.006243061274290085, 0.006516050547361374, 0.006428699009120464, 0.006427112501114607, 0.006359763443470001, 0.0062999422661960125, 0.006290080491453409, 0.006276710890233517, 0.0062486170791089535, 0.006240612827241421, 0.006326271221041679, 0.006238650530576706, 0.006240190472453833, 0.10455014556646347, 0.1263984739780426, 0.006015381310135126, 0.006104816682636738, 0.3856453001499176, 0.006160413380712271, 0.006354671902954578, 0.10709448158740997, 0.006372497882694006, 0.006402175407856703, 0.10143701732158661, 0.006480062380433083, 0.1011689305305481, 0.10941207408905029, 0.006739414297044277, 0.006866620387881994, 0.0957130640745163, 0.0068665966391563416, 0.006842910777777433, 0.10558494925498962, 0.0891951397061348, 0.007044096942991018, 0.12415917962789536, 0.00723228370770812, 0.09202989935874939, 0.0071627735160291195, 0.007186301052570343, 0.007170036435127258, 0.09075837582349777, 0.0071757943369448185, 0.0073438892140984535, 0.6681239604949951, 0.007458120584487915, 0.00758768618106842, 0.08219826221466064, 0.007960967719554901, 0.008046308532357216, 0.008149323053658009, 0.1181645616889, 0.008366638794541359, 0.008462861180305481, 0.008460568264126778, 0.008506118319928646, 0.00864872895181179, 0.008550923317670822, 0.00853800680488348, 0.10125256329774857, 0.008777167648077011, 0.008463656529784203, 0.008813752792775631, 0.008408072404563427, 0.08636561781167984, 0.1007990837097168, 0.008378708735108376, 0.008327127434313297, 0.00835039559751749, 0.008259443566203117, 0.008316104300320148, 0.008191626518964767, 0.008198563009500504, 0.008133569732308388, 0.10616783052682877, 0.008002344518899918, 0.008176861330866814, 0.007939358241856098, 0.007904416881501675, 0.0077390605583786964, 0.007676577195525169, 0.0075314962305128574, 0.10560902208089828, 0.00740761449560523, 0.09334654361009598, 0.007456874940544367, 0.11458873748779297, 0.007342835422605276, 0.09653177112340927, 0.00721911434084177, 0.0074420408345758915, 0.0071695526130497456, 0.0071350825019180775, 0.007096612825989723, 0.007136448286473751, 0.007020731922239065, 0.07747884094715118, 0.0069880411028862, 0.006907208357006311, 0.0069557069800794125, 0.00692931329831481, 0.006896645296365023, 0.006758162751793861, 0.0069342986680567265, 0.006625269539654255, 0.0065906899981200695, 0.006482821889221668, 0.006438444834202528, 0.006518365349620581, 0.006366202142089605, 0.11800327152013779, 0.006287463009357452, 0.006315423175692558, 0.006110611371695995, 0.09536100178956985, 0.006131757516413927, 0.12630173563957214, 0.006077804137021303, 0.0060334824956953526, 0.006149898283183575, 0.005909071769565344, 0.005897236056625843, 0.005882969591766596, 0.11423281580209732, 0.0058656963519752026, 0.005834984127432108, 0.005760181695222855, 0.09723631292581558, 0.005705410148948431, 0.1187502071261406, 0.00569685036316514, 0.3508990705013275, 0.005946120712906122, 0.3787825405597687, 0.0059994240291416645, 0.006236584857106209, 0.1009063720703125, 0.006448075175285339, 0.006833578459918499, 0.006939387414604425, 0.006841522175818682, 0.0068460977636277676, 0.006857914850115776, 0.006853525992482901, 0.006908106151968241, 0.006993190851062536, 0.006894077640026808, 0.007407918106764555, 0.006901228334754705, 0.007153471931815147, 0.006946115754544735, 0.006919425446540117, 0.006898179650306702, 0.006932794116437435, 0.09780628234148026, 0.12989574670791626, 0.006722923368215561, 0.0066498052328825, 0.006675450596958399, 0.08737387508153915, 0.006593531463295221, 0.006672512739896774, 0.006962499115616083, 0.006520602386444807, 0.10622470825910568, 0.0064992718398571014, 0.006457265000790358, 0.34703710675239563, 0.0066775428131222725, 0.006768904160708189, 0.0070283543318510056, 0.006698066368699074, 0.09314047545194626, 0.006777693517506123, 0.006913929712027311, 0.0068418108858168125, 0.00680612912401557, 0.006900264415889978, 0.1547253280878067, 0.006780746392905712, 0.12497810274362564, 0.006791778840124607, 0.13824200630187988, 0.006988671142607927, 0.12308070063591003, 0.006922377739101648, 0.006909606512635946, 0.007158506195992231, 0.006898228544741869, 0.006987832486629486, 0.0070513044483959675, 0.30468660593032837, 0.00710562476888299, 0.10907886177301407, 0.007278068456798792, 0.0072584389708936214, 0.12132459133863449, 0.10360506922006607, 0.007317821029573679, 0.07691404968500137, 0.007495066151022911, 0.007673391606658697, 0.007620542775839567, 0.007516499143093824, 0.007433461491018534, 0.007382488809525967, 0.007377297151833773, 0.007376095280051231, 0.10005854815244675, 0.11633968353271484, 0.08672148734331131, 0.007362599018961191, 0.11417533457279205, 0.007344403769820929, 0.007363683078438044, 0.007415011990815401, 0.11234243214130402, 0.0073594823479652405, 0.1398525983095169, 0.1092485561966896, 0.007543731015175581, 0.007531600538641214, 0.08192788809537888, 0.00757535919547081, 0.0075280447490513325, 0.007429265417158604, 0.007573261857032776, 0.007591749541461468, 0.37929683923721313, 0.007437847089022398, 0.007612364366650581, 0.09011682122945786, 0.11388639360666275, 0.007788939867168665, 0.007760604843497276, 0.008045769296586514, 0.09837991744279861, 0.007785153109580278, 0.1178574189543724, 0.007838484831154346, 0.0079503757879138, 0.007982655428349972, 0.007928130216896534, 0.09881050884723663, 0.007831297814846039, 0.007824437692761421, 0.007841179147362709, 0.007864321582019329, 0.11850211024284363, 0.007957829162478447, 0.008019630797207355, 0.007963605225086212, 0.007704243529587984, 0.007951328530907631, 0.11301062256097794, 0.007573410402983427, 0.007545059081166983, 0.007489354815334082, 0.09786494076251984, 0.007551420945674181, 0.13633055984973907, 0.0074468497186899185, 0.007456912659108639, 0.0074773747473955154, 0.0959487110376358, 0.007293902803212404, 0.10850641131401062, 0.007249011192470789, 0.007278953213244677, 0.0074221850372850895, 0.007187151815742254, 0.007334341760724783, 0.00713333347812295, 0.007163458503782749, 0.0070351348258554935, 0.007424983661621809, 0.0069546024315059185, 0.006900748237967491, 0.006960414815694094, 0.00689654191955924, 0.00685479212552309, 0.006855773273855448, 0.0067716604098677635, 0.1035505011677742, 0.0967118889093399, 0.006786723621189594, 0.10607447475194931, 0.006682919804006815, 0.00652751000598073, 0.006475899368524551, 0.006465644109994173, 0.006469616200774908, 0.0067081875167787075, 0.11043094843626022, 0.006355476565659046, 0.12290707975625992, 0.0065173315815627575, 0.006325250957161188, 0.006297203246504068, 0.08673305809497833, 0.006253670435398817, 0.1255713403224945, 0.006317356135696173, 0.006728221196681261, 0.0063218045979738235, 0.0062902565114200115, 0.006329514551907778, 0.11638543754816055, 0.12849289178848267, 0.006247559562325478, 0.006208544597029686, 0.0062027289532125, 0.006243619602173567, 0.3890628516674042, 0.10626992583274841, 0.006511724554002285, 0.4436597228050232, 0.00656589400023222, 0.0067175342701375484, 0.006737487856298685, 0.007048183586448431, 0.11856558918952942, 0.10857047885656357, 0.12219750881195068, 0.007146076299250126, 0.11290293186903, 0.11804094165563583, 0.0955527201294899, 0.007531948387622833, 0.1398484706878662, 0.007832351140677929, 0.007886967621743679, 0.007884218357503414, 0.008044131100177765, 0.007888801395893097, 0.007829939015209675, 0.008076784200966358, 0.31881260871887207, 0.00815215427428484, 0.008269059471786022, 0.10476842522621155, 0.09867645055055618, 0.008297288790345192, 0.008186371996998787, 0.008301092311739922, 0.00836800504475832, 0.09416919946670532, 0.008354512974619865, 0.00833046529442072, 0.008467454463243484, 0.008569248020648956, 0.008434739895164967, 0.008242183364927769, 0.09000206738710403, 0.32615530490875244, 0.008354883641004562, 0.008542628958821297, 0.12454304844141006, 0.11121747642755508, 0.11176107823848724, 0.008583909831941128, 0.008860687725245953, 0.008662080392241478, 0.008654856123030186, 0.008764776401221752, 0.00869673490524292, 0.008713490329682827, 0.08366315811872482, 0.00871718768030405, 0.10195676237344742, 0.008635723032057285, 0.008592226542532444, 0.00892989058047533, 0.11478084325790405, 0.008883881382644176, 0.008809037506580353, 0.12437063455581665, 0.1176714077591896, 0.008606051094830036, 0.11980132758617401, 0.13072577118873596, 0.008546699769794941, 0.11414515972137451, 0.008593178354203701, 0.2996196746826172, 0.00856139324605465, 0.12843340635299683, 0.08799879252910614, 0.36317041516304016, 0.099410779774189, 0.009185636416077614, 0.009406251832842827, 0.10392490774393082, 0.009410732425749302, 0.009675489738583565, 0.009578170254826546, 0.009846624918282032, 0.010014176368713379, 0.10971039533615112, 0.009807026945054531, 0.11326240003108978, 0.00998733751475811, 0.07671467214822769, 0.009884890168905258, 0.009850606322288513, 0.009817817248404026, 0.11735153943300247, 0.1189703568816185, 0.00996569637209177, 0.010141044855117798, 0.009972945787012577, 0.1284264475107193, 0.009843949228525162, 0.009714198298752308, 0.009871672838926315, 0.009761692956089973, 0.009619617834687233, 0.00974639505147934, 0.3755006194114685, 0.009508137591183186, 0.09841377288103104, 0.10798720270395279, 0.009741918183863163, 0.00962927658110857, 0.009872551076114178, 0.009609298780560493, 0.009591161273419857, 0.009639945812523365, 0.009630773216485977, 0.009716331027448177, 0.1078108698129654, 0.11313521862030029, 0.009461970068514347, 0.009499908424913883, 0.009380764327943325, 0.08985047042369843, 0.00945852231234312, 0.009303329512476921, 0.1040707677602768, 0.009214893914759159, 0.009270532056689262, 0.009259962476789951, 0.009340408258140087, 0.009173465892672539, 0.009309337474405766, 0.08777900040149689, 0.0875111073255539, 0.009204298257827759, 0.009015771560370922, 0.008915922604501247, 0.008884386159479618, 0.00889253243803978, 0.10050559788942337, 0.008727308362722397, 0.008706948719918728, 0.10759474337100983, 0.008618882857263088, 0.008505010977387428, 0.12877315282821655, 0.10220710188150406, 0.1167326346039772, 0.008451909758150578, 0.008428077213466167, 0.09201350063085556, 0.32183146476745605, 0.10575567930936813, 0.008782080374658108, 0.00871787779033184, 0.008660918101668358, 0.11384879052639008, 0.1079191043972969, 0.00875375047326088, 0.11848325282335281, 0.008926047943532467, 0.008884785696864128, 0.009031043387949467, 0.009144110605120659, 0.008929292671382427, 0.008848678320646286, 0.008906870149075985, 0.09826090931892395, 0.13222146034240723, 0.10969296842813492, 0.08456214517354965, 0.008807914331555367, 0.008984759449958801, 0.11603289842605591, 0.09766645729541779, 0.10902046412229538, 0.008891331031918526, 0.10784292966127396, 0.009009215049445629, 0.008863563649356365, 0.009159673936665058, 0.009023470804095268, 0.008950525894761086, 0.11157147586345673, 0.0089809475466609, 0.008977198041975498, 0.008766439743340015, 0.008832319639623165, 0.09453626722097397, 0.07198899984359741, 0.08561434596776962, 0.00872961524873972, 0.008937383070588112, 0.008617715910077095, 0.008592606522142887, 0.30742862820625305, 0.0774461030960083, 0.008711245842278004, 0.008717001415789127, 0.09504659473896027, 0.08968473225831985, 0.28294628858566284, 0.008950748480856419, 0.009327254258096218, 0.009213042445480824, 0.00916176289319992, 0.009301341138780117, 0.009254259057343006, 0.009470425546169281, 0.09674916416406631, 0.33857986330986023, 0.009299187920987606, 0.009371461346745491, 0.009556460194289684, 0.12476005405187607, 0.009555215016007423, 0.009602800011634827, 0.00963938795030117, 0.009912911802530289, 0.00967205036431551, 0.12106520682573318, 0.009842227213084698, 0.009771538898348808, 0.00957543309777975, 0.00969652272760868, 0.009655279107391834, 0.3415200412273407, 0.009539212100207806, 0.009638702496886253, 0.009756043553352356, 0.0096631720662117, 0.10371717810630798, 0.009656698442995548, 0.00971379317343235, 0.00973843690007925, 0.009737323969602585, 0.009621142409741879, 0.010042652487754822, 0.09742103517055511, 0.13579389452934265, 0.009508318267762661, 0.009608476422727108, 0.1243988499045372, 0.09506784379482269, 0.12199555337429047, 0.10660839825868607, 0.009519156068563461, 0.009702229872345924, 0.009838352911174297, 0.009497463703155518, 0.009457949548959732, 0.009471817873418331, 0.009361281991004944, 0.12259085476398468, 0.009489613585174084, 0.0092182457447052, 0.009255447424948215, 0.009127703495323658, 0.08841786533594131, 0.009203855879604816, 0.009142077527940273, 0.009252045303583145, 0.009195218794047832, 0.36040663719177246, 0.009113413281738758, 0.11926848441362381, 0.009302185848355293, 0.11448793113231659, 0.009000738151371479, 0.008995529264211655, 0.009326196275651455, 0.009110011160373688, 0.12641854584217072, 0.120533287525177, 0.009061329998075962, 0.009006732143461704, 0.1205417811870575, 0.009118559770286083, 0.1019032821059227, 0.009251653216779232, 0.009039049036800861, 0.08968403935432434, 0.009107484482228756, 0.009221580810844898, 0.1202753484249115, 0.009109312668442726, 0.009027744643390179, 0.009043475612998009, 0.008985050022602081, 0.09604045003652573, 0.008991412818431854, 0.09251098334789276, 0.00900270789861679, 0.11217363178730011, 0.008897763676941395, 0.008888459764420986, 0.008868147619068623, 0.008777585811913013, 0.008678855374455452, 0.11091656982898712, 0.008705192245543003, 0.008631926029920578, 0.008627668023109436, 0.008535237051546574, 0.008895826525986195, 0.008512038737535477, 0.008751234039664268, 0.008375555276870728, 0.008392306976020336, 0.008305071853101254, 0.008232724852859974, 0.008322635665535927, 0.008250698447227478, 0.37564098834991455, 0.008217147551476955, 0.008278178051114082, 0.008291971869766712, 0.008131998591125011, 0.09462488442659378, 0.00830337405204773, 0.00816347636282444, 0.11757844686508179, 0.008219658397138119, 0.08995141088962555, 0.008215322159230709, 0.1134609505534172, 0.0082744425162673, 0.008313584141433239, 0.00815532635897398, 0.008153577335178852, 0.008150157518684864, 0.08148103207349777, 0.008140101097524166, 0.008285009302198887, 0.00805093813687563, 0.0081439558416605, 0.007964426651597023, 0.007993820123374462, 0.11060579866170883, 0.007863672450184822, 0.10454902052879333, 0.007848696783185005, 0.30336901545524597, 0.11650508642196655, 0.007979029789566994, 0.007905309088528156, 0.007976595312356949, 0.007941334508359432, 0.008197485469281673, 0.008087938651442528, 0.00822767149657011, 0.319497674703598, 0.008111411705613136, 0.13038627803325653, 0.09347612410783768, 0.00816875696182251, 0.11889585852622986, 0.008285649120807648, 0.008439343422651291, 0.008290346711874008, 0.10303635150194168, 0.008296382613480091, 0.008530523627996445, 0.008730260655283928, 0.008419242687523365, 0.09341626614332199, 0.008698576129972935, 0.00853749644011259, 0.00830089021474123, 0.008377458900213242, 0.00839297752827406, 0.00826217420399189, 0.008301859721541405, 0.008236550725996494, 0.008408692665398121, 0.008131632581353188, 0.008163287304341793, 0.008130844682455063, 0.008045211434364319, 0.008052260614931583, 0.008455503731966019, 0.007918927818536758, 0.008119642734527588, 0.007874016650021076, 0.007847778499126434, 0.00778545206412673, 0.12753945589065552, 0.007807927671819925, 0.008097177371382713, 0.0076377554796636105, 0.007604875136166811, 0.1066439226269722, 0.10283302515745163, 0.007557616103440523, 0.007568590342998505, 0.007529749069362879, 0.1218731701374054, 0.007678296882659197, 0.0076125431805849075, 0.11922270804643631, 0.12057981640100479, 0.007404231932014227, 0.007512412499636412, 0.007403773721307516, 0.10209920257329941, 0.12115852534770966, 0.0073664491064846516, 0.007422484923154116, 0.007460500113666058, 0.007577338255941868, 0.007467600516974926, 0.007386126555502415, 0.09172424674034119, 0.007451880257576704, 0.10262735188007355, 0.007319985423237085, 0.00740088801831007, 0.007536794058978558, 0.007393817417323589, 0.11312448978424072, 0.007280351128429174, 0.007311120629310608, 0.13917802274227142, 0.007268858607858419, 0.007273816503584385, 0.00718444399535656, 0.007221866864711046, 0.10197404026985168, 0.007128375582396984, 0.00721256947144866, 0.007179263513535261, 0.3412097990512848, 0.007254639640450478, 0.10180852562189102, 0.374210923910141, 0.007370924111455679, 0.007332093548029661, 0.10674949735403061, 0.1324591189622879, 0.371158629655838, 0.00764361210167408, 0.007730583660304546, 0.08016505837440491, 0.13344185054302216, 0.10423015058040619, 0.008123137056827545, 0.007977654226124287, 0.007994720712304115, 0.008070589043200016, 0.007999815046787262, 0.36236974596977234, 0.10591976344585419, 0.008268610574305058, 0.008401216007769108, 0.008255250751972198, 0.008390526287257671, 0.008478407748043537, 0.09390846639871597, 0.10064976662397385, 0.008462789468467236, 0.008600717410445213, 0.00869804061949253, 0.008402911014854908, 0.00863597821444273, 0.08817512542009354, 0.10968039184808731, 0.0084153451025486, 0.008475115522742271, 0.008550425060093403, 0.12030722200870514, 0.00846460834145546, 0.12725450098514557, 0.10990993678569794, 0.08484999090433121, 0.008571647107601166, 0.008535117842257023, 0.008568208664655685, 0.008548104204237461, 0.09972581267356873, 0.008516880683600903, 0.11607344448566437, 0.008416015654802322, 0.008473403751850128, 0.008421328850090504, 0.008400469087064266, 0.10567755252122879, 0.008776477538049221, 0.10285946726799011, 0.00854787789285183, 0.008654968813061714, 0.008413799107074738, 0.34302568435668945, 0.13222838938236237, 0.3340320885181427, 0.10668572038412094, 0.10072851926088333, 0.008575060404837132, 0.008941537700593472, 0.00880071148276329, 0.008785150945186615, 0.10605496913194656, 0.12426278740167618, 0.008957388810813427, 0.008788247592747211, 0.0972161516547203, 0.1126764640212059, 0.00889620091766119, 0.0088796466588974, 0.008975961245596409, 0.10448090732097626, 0.008919509127736092, 0.1166742816567421, 0.008969208225607872, 0.00903678685426712, 0.11082200706005096, 0.00904082227498293, 0.008901276625692844, 0.009125376120209694, 0.009091046638786793, 0.008874885737895966, 0.00892805028706789, 0.00912269577383995, 0.00902522075921297, 0.008883807808160782, 0.125010684132576, 0.00888630747795105, 0.11265266686677933, 0.008758312091231346, 0.00886881910264492, 0.008905467577278614, 0.008851568214595318, 0.008783855475485325, 0.008813849650323391, 0.10313273221254349, 0.008963043801486492, 0.008602471090853214, 0.008712208829820156, 0.008719067089259624, 0.008839268237352371, 0.00864375475794077, 0.11140742152929306, 0.13558684289455414, 0.008897781372070312, 0.008634640835225582, 0.120463527739048, 0.10641305893659592, 0.008643300272524357, 0.008619623258709908, 0.09701210260391235, 0.10055678337812424, 0.008431579917669296, 0.00849014800041914, 0.008477052673697472, 0.12250570952892303, 0.008492952212691307, 0.008537988178431988, 0.00840799417346716, 0.008350490592420101, 0.008363569155335426, 0.008358243852853775, 0.008425549603998661, 0.008401958271861076, 0.11913389712572098, 0.00840699765831232, 0.008639054372906685, 0.008269884623587132, 0.00824469979852438, 0.008262796327471733, 0.00831077340990305, 0.008289470337331295, 0.10102519392967224, 0.008111326955258846, 0.008132364600896835, 0.0084966029971838, 0.10161925107240677, 0.008140180259943008, 0.0080784996971488, 0.00806709285825491, 0.008319559507071972, 0.008088676258921623, 0.007996651344001293, 0.008229920640587807, 0.3207082748413086, 0.10415826737880707, 0.008056781254708767, 0.008274286985397339, 0.08455948531627655, 0.12511268258094788, 0.09123320877552032, 0.008051871322095394, 0.008006992749869823, 0.29029831290245056, 0.008058938197791576, 0.008178630843758583, 0.008294454775750637, 0.008134198375046253, 0.008213401772081852, 0.008193915709853172, 0.008260891772806644, 0.11807051301002502, 0.10894176363945007, 0.008326645009219646, 0.008176659233868122, 0.008230645209550858, 0.12573368847370148, 0.09101060032844543, 0.00817814376205206, 0.008252082392573357, 0.008403023704886436, 0.008473314344882965, 0.11892419308423996, 0.0083236712962389, 0.00834659393876791, 0.008253727108240128, 0.008234974928200245, 0.008151606656610966, 0.008120845071971416, 0.008188585750758648, 0.10453936457633972, 0.008144697174429893, 0.008142896927893162, 0.008135631680488586, 0.10777071863412857, 0.008181354030966759, 0.008207198232412338, 0.008126305416226387, 0.008091466501355171, 0.008080360479652882, 0.008415832184255123, 0.00814786460250616, 0.08092648535966873, 0.007992822676897049, 0.008097882382571697, 0.008023847825825214, 0.007983044721186161, 0.00791887566447258, 0.007926465012133121, 0.00805523432791233, 0.13237234950065613, 0.007872967049479485, 0.09959695488214493, 0.007865735329687595, 0.008487115614116192, 0.12079352140426636, 0.0081248190253973, 0.369571328163147, 0.007947119884192944, 0.09722910821437836, 0.007916576229035854, 0.007952810265123844, 0.00791463628411293, 0.007898513227701187, 0.008011620491743088, 0.007898342795670033, 0.007940982468426228, 0.008240053430199623, 0.007970018312335014, 0.007955408655107021, 0.3615007698535919, 0.008104851469397545, 0.008230009116232395, 0.11247867345809937, 0.008017366752028465, 0.00830582994967699, 0.007948446087539196, 0.008116161450743675, 0.007906430400907993, 0.00801168940961361, 0.007927021943032742, 0.10920517891645432, 0.12177758663892746, 0.11348949372768402, 0.007980366237461567, 0.008022184483706951, 0.00796936359256506, 0.008085303008556366, 0.09855833649635315, 0.007986726239323616, 0.008050530217587948, 0.007933123037219048, 0.008018327876925468, 0.007869199849665165, 0.008162816986441612, 0.11806483566761017, 0.007923269644379616, 0.1172601506114006, 0.007962463423609734, 0.007966994307935238, 0.007897361181676388, 0.007886768318712711, 0.007849694229662418, 0.3242175877094269, 0.008177565410733223, 0.007848995737731457, 0.008004660718142986, 0.007885579951107502, 0.007971345447003841, 0.008035185746848583, 0.007842466235160828, 0.007915234193205833, 0.12580063939094543, 0.007832441478967667, 0.007822629064321518, 0.007927801460027695, 0.11383956670761108, 0.13729090988636017, 0.007826671935617924, 0.13359196484088898, 0.007884657010436058, 0.008021773770451546, 0.007877388969063759, 0.13628830015659332, 0.007842696271836758, 0.007995091378688812, 0.07682438939809799, 0.007934673689305782, 0.007789562456309795, 0.11399129033088684, 0.007813178934156895, 0.008090581744909286, 0.007919328287243843, 0.12519891560077667, 0.007831591181457043, 0.007842947728931904, 0.007786577567458153, 0.00781550444662571, 0.007848736830055714, 0.00782037153840065, 0.00783927459269762, 0.007786186411976814, 0.007847863249480724, 0.007760951761156321, 0.1051136776804924, 0.008047284558415413, 0.007739052176475525, 0.007813027128577232, 0.007959063164889812, 0.007898673415184021, 0.692317545413971, 0.08208966255187988, 0.007727659773081541, 0.10855749994516373, 0.007742600049823523, 0.007765661459416151, 0.007923758588731289, 0.007943776436150074, 0.09821554273366928, 0.007771066389977932, 0.12836027145385742, 0.007870684377849102, 0.11095567047595978, 0.007789296563714743, 0.00786316953599453, 0.007878117263317108, 0.008138171397149563, 0.007921869866549969, 0.008004452101886272, 0.007861698046326637, 0.007861262187361717, 0.008001459762454033, 0.007809492759406567, 0.007849989458918571, 0.00777287594974041, 0.007826194167137146, 0.007796949241310358, 0.007942963391542435, 0.008466607891023159, 0.008034852333366871, 0.007850337773561478, 0.10814283043146133, 0.008004659786820412, 0.007799201644957066, 0.11424031108617783, 0.007749710697680712, 0.007777244318276644, 0.007819348014891148, 0.00784772727638483, 0.008015464060008526, 0.00792989507317543, 0.007858261466026306, 0.10749337077140808, 0.10432350635528564, 0.007859637960791588, 0.00783602800220251, 0.007892529480159283, 0.00783018209040165, 0.007851683534681797, 0.007790655363351107, 0.007808856200426817, 0.10654009878635406, 0.007871930487453938, 0.09572502225637436, 0.008016986772418022, 0.10017228126525879, 0.11610984802246094, 0.09396784752607346, 0.007797403261065483, 0.007794431876391172, 0.007744526024907827, 0.10685921460390091, 0.11549169570207596, 0.0076994867995381355, 0.12040062993764877, 0.07723662257194519, 0.008043676614761353, 0.007695328909903765, 0.007691704202443361, 0.007981731556355953, 0.007751172874122858, 0.0077154072932899, 0.007852303795516491, 0.007826910354197025, 0.10810305923223495, 0.007701822556555271]\n",
            "Val loss 0.04065404779370198\n",
            "Val auc roc 0.49592310832801434\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}