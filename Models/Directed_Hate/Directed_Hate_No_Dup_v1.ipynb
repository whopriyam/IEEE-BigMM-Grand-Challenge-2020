{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Directed_Hate_No_Dup_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bcc94b9e636e45bb990949d0a7000007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd6ba34748014978a6aa748b7a028198",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0118debf55244aa98d10f975f3d2f299",
              "IPY_MODEL_cc2ae8ab57314bd480d667f2fa948df0"
            ]
          }
        },
        "dd6ba34748014978a6aa748b7a028198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0118debf55244aa98d10f975f3d2f299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a13d10fd7794592a3d1b7c6c20b11cb",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1233f021050461db561820b1da7c3c0"
          }
        },
        "cc2ae8ab57314bd480d667f2fa948df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ffa364fbaa114664818b6927fd4e7222",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:09&lt;00:00, 25.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c8b9f6497f44747a0c5317e9ea928ad"
          }
        },
        "9a13d10fd7794592a3d1b7c6c20b11cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1233f021050461db561820b1da7c3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffa364fbaa114664818b6927fd4e7222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c8b9f6497f44747a0c5317e9ea928ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88ce584e996b4152bf3458b438756504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a7232c59a84843569d9a4b6ebf3bfba2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e3187b2ae13749ff953bf511798a7c2e",
              "IPY_MODEL_8f628d3ad18c4e3fb5c91486a365e822"
            ]
          }
        },
        "a7232c59a84843569d9a4b6ebf3bfba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3187b2ae13749ff953bf511798a7c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_97096ae197e04bfb9aa9d2fc5abc9ac0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_937ca24eb3154ce68f0bcb636f36ef80"
          }
        },
        "8f628d3ad18c4e3fb5c91486a365e822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70a196c08ca84897b6a55862b242abbe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [47:01&lt;00:00,  1.77s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d4a100b420246f988ce5433340f54d9"
          }
        },
        "97096ae197e04bfb9aa9d2fc5abc9ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "937ca24eb3154ce68f0bcb636f36ef80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70a196c08ca84897b6a55862b242abbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d4a100b420246f988ce5433340f54d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5049810f5c6b4ac98224f1bd638d3b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2fcaf991f014529a3c8763dea6c002f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7456489197bb499ba54a521757698715",
              "IPY_MODEL_fb9e9e2ccde247f3969f2ba6d1c5ddcb"
            ]
          }
        },
        "a2fcaf991f014529a3c8763dea6c002f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7456489197bb499ba54a521757698715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf1a2e75ddc644cb85e526dcf79b0626",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5e2b197f6504cdbb9da84d7070b69c2"
          }
        },
        "fb9e9e2ccde247f3969f2ba6d1c5ddcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b375582cf8e40079783b6f578c15996",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [15:16&lt;00:00,  1.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b44f80f3aba4b168820af9938c6d026"
          }
        },
        "bf1a2e75ddc644cb85e526dcf79b0626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5e2b197f6504cdbb9da84d7070b69c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b375582cf8e40079783b6f578c15996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b44f80f3aba4b168820af9938c6d026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16d6bdbcebbd49a7a6ddd6c90dc721f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_278ad7e30ab244f6a4f0c40369078e85",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5d96d6eb23e490fbbb4b0cb7091a3b0",
              "IPY_MODEL_d0040f985f7f4b15a1f850bb11e0d6d1"
            ]
          }
        },
        "278ad7e30ab244f6a4f0c40369078e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5d96d6eb23e490fbbb4b0cb7091a3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3560dde6a1594ac9b436cdb66e6de236",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e29ec30333314faba290fbe324888163"
          }
        },
        "d0040f985f7f4b15a1f850bb11e0d6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cefc3be67b8b40b88d3dcdc52f30dd85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [15:20&lt;00:00,  1.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0088dd7e9d504fa7969741e05f8d71cb"
          }
        },
        "3560dde6a1594ac9b436cdb66e6de236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e29ec30333314faba290fbe324888163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cefc3be67b8b40b88d3dcdc52f30dd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0088dd7e9d504fa7969741e05f8d71cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fc6643c1-88c1-47da-ee1f-af57de236394"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 7.03 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50130764-97d1-4fa7-b4fe-a9196730f369"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "447bf1bd-8661-4e78-c727-aa17b7f1aaf0"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "13a09f5d-bbc9-4fd6-a2ee-cc6b3a6795c5"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7cd150c8-1a43-4e68-dee3-63ecf9d91387"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "49247017-8256-4367-c07d-b00ba06b703c"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 26.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 22.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 15.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a08f05a4-14d9-43bc-91c6-89b7ff2be082"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c8015d91-948f-4c28-eaf1-cbd81e0f944b"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "459d1857-4a85-4369-f882-a00c2bba2960"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f902edf6-65b8-4251-ae10-2bce1ca32c57"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                   Perfect example of #MeToo moment  \n",
              "1       After effect of #MeToo movement. #MeTooIndia  \n",
              "2    When will these girls speak out against Bhusha...\n",
              "3    @sgmanjari @LakshmyRamki @LeenaManimekali @Tam...\n",
              "4    It started with the New York Times report on H...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34d6d385-1cd0-4c62-ba90-cb308681cd86"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:33<00:00, 12091941.56B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a0a1381-a158-4647-dfa0-d52370345ae6"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 260620.79B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "255b3785-2d61-4511-80c2-eb1bad191c8d"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b807886b-9a46-4006-afe1-a55ee77126c2"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        \n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        \n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44fd965d-712b-4d23-9800-fa29dfefe31d"
      },
      "source": [
        "col_name = \"Directed_Hate\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794,
          "referenced_widgets": [
            "bcc94b9e636e45bb990949d0a7000007",
            "dd6ba34748014978a6aa748b7a028198",
            "0118debf55244aa98d10f975f3d2f299",
            "cc2ae8ab57314bd480d667f2fa948df0",
            "9a13d10fd7794592a3d1b7c6c20b11cb",
            "d1233f021050461db561820b1da7c3c0",
            "ffa364fbaa114664818b6927fd4e7222",
            "8c8b9f6497f44747a0c5317e9ea928ad",
            "88ce584e996b4152bf3458b438756504",
            "a7232c59a84843569d9a4b6ebf3bfba2",
            "e3187b2ae13749ff953bf511798a7c2e",
            "8f628d3ad18c4e3fb5c91486a365e822",
            "97096ae197e04bfb9aa9d2fc5abc9ac0",
            "937ca24eb3154ce68f0bcb636f36ef80",
            "70a196c08ca84897b6a55862b242abbe",
            "9d4a100b420246f988ce5433340f54d9",
            "5049810f5c6b4ac98224f1bd638d3b93",
            "a2fcaf991f014529a3c8763dea6c002f",
            "7456489197bb499ba54a521757698715",
            "fb9e9e2ccde247f3969f2ba6d1c5ddcb",
            "bf1a2e75ddc644cb85e526dcf79b0626",
            "d5e2b197f6504cdbb9da84d7070b69c2",
            "2b375582cf8e40079783b6f578c15996",
            "6b44f80f3aba4b168820af9938c6d026",
            "16d6bdbcebbd49a7a6ddd6c90dc721f6",
            "278ad7e30ab244f6a4f0c40369078e85",
            "c5d96d6eb23e490fbbb4b0cb7091a3b0",
            "d0040f985f7f4b15a1f850bb11e0d6d1",
            "3560dde6a1594ac9b436cdb66e6de236",
            "e29ec30333314faba290fbe324888163",
            "cefc3be67b8b40b88d3dcdc52f30dd85",
            "0088dd7e9d504fa7969741e05f8d71cb"
          ]
        },
        "outputId": "59ba443b-4dd3-437f-b049-2a5c562e5e05"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6382\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcc94b9e636e45bb990949d0a7000007",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88ce584e996b4152bf3458b438756504",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0323\n",
            "Train Losses : [0.1771276742219925, 0.27934858202934265, 0.8244031071662903, 0.4836615025997162, 0.31830549240112305, 1.6375733613967896, 0.8021473288536072, 0.43931105732917786, 0.6907944083213806, 0.24384161829948425, 0.09999926388263702, 0.22553092241287231, 0.5029081702232361, 0.1510409712791443, 0.13491694629192352, 0.2048746943473816, 0.1604408621788025, 0.07424572110176086, 0.1251431107521057, 0.029690930619835854, 0.021410249173641205, 0.013538926839828491, 0.009570689871907234, 0.9476567506790161, 0.043617215007543564, 0.030119622126221657, 0.005122208967804909, 0.024721605703234673, 0.025492677465081215, 0.004651411436498165, 0.013179435394704342, 0.011773672886192799, 0.007911549881100655, 0.006842971779406071, 0.006478892173618078, 0.0020617383997887373, 0.1795351803302765, 0.0016103776870295405, 0.0011136558605358005, 0.0011325007071718574, 0.0009627246763557196, 0.007477475330233574, 0.0027572258841246367, 0.0009179093176499009, 0.07697658240795135, 0.0007418538443744183, 0.2976027727127075, 0.002148702275007963, 0.6686652898788452, 0.003679621731862426, 0.020664194598793983, 0.6681665182113647, 0.01979145221412182, 0.006133859045803547, 0.009677702561020851, 0.004711573477834463, 0.016167573630809784, 0.23720404505729675, 0.010932876728475094, 0.011952091939747334, 0.005509440321475267, 0.004048855043947697, 0.06220410019159317, 0.003858492011204362, 0.003373538376763463, 0.004826866090297699, 0.005806577391922474, 0.004112877883017063, 0.0073286909610033035, 0.07173117995262146, 0.06180476397275925, 0.004250357858836651, 0.0747484564781189, 0.00704629672691226, 0.003087598830461502, 0.00850642379373312, 0.011082797311246395, 0.009159618057310581, 0.0033113888930529356, 0.018605371937155724, 0.004251854959875345, 0.003438304178416729, 0.00620309030637145, 0.004094663076102734, 0.0020894960034638643, 0.00461233127862215, 0.005485242698341608, 0.0024611041881144047, 0.0018771986942738295, 0.0018958398140966892, 0.0018703892128542066, 0.003703844267874956, 0.0023400860372930765, 0.0014782329089939594, 0.0011078972602263093, 0.00152784853707999, 0.0017240192973986268, 0.0013352122623473406, 0.0007595946663059294, 0.026333516463637352, 0.0006783865974284708, 0.0006963568739593029, 0.0007201018743216991, 0.38841214776039124, 0.0007694975356571376, 0.2277071177959442, 0.0010119657963514328, 0.16582553088665009, 0.35266125202178955, 0.0010264068841934204, 0.0011707061203196645, 0.0019157285569235682, 0.0020709577947854996, 0.0018522482132539153, 0.002318409737199545, 0.0027570517268031836, 0.0018241455545648932, 0.002616351004689932, 0.003776271129027009, 0.19742842018604279, 0.0022018151357769966, 0.0032237267587333918, 0.0035565767902880907, 0.0034247611183673143, 0.005164496600627899, 0.004630544222891331, 0.06408818811178207, 0.0031092597637325525, 0.004874750506132841, 0.4505942761898041, 0.0037793698720633984, 0.006434196140617132, 0.09577418118715286, 1.502717137336731, 0.004814400337636471, 0.011039693839848042, 0.009285880252718925, 0.014881741255521774, 0.02258334867656231, 0.012244444340467453, 0.010636115446686745, 0.018360959365963936, 0.018771961331367493, 0.011866250075399876, 0.017033642157912254, 0.012854424305260181, 0.022380445152521133, 0.05486505851149559, 0.01677280105650425, 0.014194618910551071, 0.0092927860096097, 0.012237816117703915, 0.008819900453090668, 0.010144345462322235, 0.008340529166162014, 0.009666593745350838, 0.007485606241971254, 0.007165488321334124, 0.0048377495259046555, 0.0053689852356910706, 0.005298474803566933, 0.004289531614631414, 0.06630709767341614, 0.003671289188787341, 0.0037628915160894394, 0.082718126475811, 0.003568895859643817, 0.0033624565694481134, 0.0032301833853125572, 0.005082127638161182, 0.0035183820873498917, 0.0031363717280328274, 0.0026335930451750755, 0.0028776079416275024, 0.0032715476118028164, 0.0023690529633313417, 0.13051484525203705, 0.2920246422290802, 0.002300262451171875, 0.0023897963110357523, 0.0034426781348884106, 0.00290230056270957, 0.00232659000903368, 0.002007651375606656, 0.002746674232184887, 0.0023594999220222235, 0.0019930030684918165, 0.0023663686588406563, 0.22764241695404053, 0.002882600063458085, 0.0019612868782132864, 0.0020935344509780407, 0.002097025979310274, 0.0023697323631495237, 0.0022333709057420492, 0.06742414087057114, 0.0021258306223899126, 0.5072067379951477, 0.00326830823905766, 0.003188172820955515, 0.0036477583926171064, 0.00357867986895144, 0.0037256053183227777, 0.004952410236001015, 0.0968732014298439, 0.003988914657384157, 0.17929571866989136, 0.004558315500617027, 0.11604774743318558, 0.005223326850682497, 0.006753820460289717, 0.005359566770493984, 0.00568573409691453, 0.005937817506492138, 0.09982422739267349, 0.0858740285038948, 0.007284798193722963, 0.09241393953561783, 0.006237129680812359, 0.14633186161518097, 0.012799302116036415, 0.008114596828818321, 0.008805477060377598, 0.008090412244200706, 0.008519073016941547, 0.0063399155624210835, 0.006204148288816214, 0.14089997112751007, 0.00916660763323307, 0.006387428380548954, 0.007483490742743015, 0.007271828129887581, 0.007034259848296642, 0.007015033159404993, 0.005559413693845272, 0.10139069706201553, 0.006086363457143307, 0.4622252881526947, 0.4884091317653656, 0.1051657497882843, 0.1397230625152588, 0.008400708436965942, 0.00944279320538044, 0.013724223710596561, 0.01031775027513504, 0.012187231332063675, 0.28142768144607544, 0.012800070457160473, 0.012710994109511375, 0.013465703465044498, 0.11553128808736801, 0.011839163489639759, 0.01292738039046526, 0.011729976162314415, 0.010019257664680481, 0.009463428519666195, 0.009883801452815533, 0.009215070866048336, 0.008481046184897423, 0.00831050518900156, 0.006881232373416424, 0.007590866647660732, 0.006671591196209192, 0.006928307004272938, 0.08500098437070847, 0.005610379856079817, 0.006296373903751373, 0.08243781328201294, 0.005141936242580414, 0.00486350990831852, 0.004123839549720287, 0.004005358554422855, 0.1876433789730072, 0.0037097418680787086, 0.004154381807893515, 0.004187200218439102, 0.004712709225714207, 0.12090794742107391, 0.0046098013408482075, 0.004293454345315695, 0.003409900702536106, 0.003489777212962508, 0.003371506929397583, 0.08676807582378387, 0.004233659245073795, 0.003656006185337901, 0.003815404837951064, 0.06211360916495323, 0.0039944397285580635, 0.004038830287754536, 0.004042435437440872, 0.0036153774708509445, 0.004706925246864557, 0.003958366811275482, 0.0036262478679418564, 0.0030826940201222897, 0.003445725655183196, 0.0043876320123672485, 0.003250629873946309, 0.22068513929843903, 0.0031557728070765734, 0.0032374667935073376, 0.0958692878484726, 0.003088831901550293, 0.005554025061428547, 0.0029858110938221216, 0.004044846165925264, 0.005729637574404478, 0.0052850088104605675, 0.18359032273292542, 0.0033500781282782555, 0.0032101308461278677, 0.0030482772272080183, 0.003510597161948681, 0.003888907842338085, 0.003142725443467498, 0.003680117428302765, 0.0039250850677490234, 0.11195296794176102, 0.003751659533008933, 0.003500718157738447, 0.003188099479302764, 0.10006805509328842, 0.003760761581361294, 0.004003937356173992, 0.003392743645235896, 0.002983451122418046, 0.003711490426212549, 0.13387413322925568, 0.0035303225740790367, 0.004731525667011738, 0.003994044382125139, 0.0028929472900927067, 0.003685376374050975, 0.0035148775205016136, 0.004006940871477127, 0.0045008878223598, 0.004294271115213633, 0.00405684020370245, 0.004093598108738661, 0.0031856924761086702, 0.002961293328553438, 0.0025714808143675327, 0.0024968355428427458, 0.07651495933532715, 0.13799569010734558, 0.003554633352905512, 0.0038233199156820774, 0.003013238776475191, 0.0039106509648263454, 0.003406606148928404, 0.002643384737893939, 0.0033491828944534063, 0.004876117687672377, 0.0037772615905851126, 0.10594139993190765, 0.002610433381050825, 0.0033956828992813826, 0.002700753742828965, 0.003306533209979534, 0.0031288720201700926, 0.002581316512078047, 0.0035459930077195168, 0.003523285035043955, 0.0032691252417862415, 0.002909672213718295, 0.004078852012753487, 0.0023779605980962515, 0.0029321922920644283, 0.002412936417385936, 0.002433166839182377, 0.0019384383922442794, 0.0026473028119653463, 0.002153767039999366, 0.07537226378917694, 0.002685301238670945, 0.002186586381867528, 0.0035383806098252535, 0.0023992382921278477, 0.00202572881244123, 0.002480569062754512, 0.19790080189704895, 0.1626279056072235, 0.002212603809311986, 0.001889801467768848, 0.1664622277021408, 0.002681930549442768, 0.0026896693743765354, 0.0026837883051484823, 0.002393893664702773, 0.0031878547742962837, 0.003914234694093466, 0.003083599265664816, 0.0029368435498327017, 0.002729661762714386, 0.0036224464420229197, 0.0030553012620657682, 0.002990546403452754, 0.003030381165444851, 0.0032153690699487925, 0.004461732227355242, 0.0030647849198430777, 0.002618250669911504, 0.003962477669119835, 0.0029673073440790176, 0.13155557215213776, 0.0029589871410280466, 0.0035767729859799147, 0.0033959089778363705, 0.003135537263005972, 0.0027410336770117283, 0.003198812948539853, 0.0023495180066674948, 0.003389321267604828, 0.0021524850744754076, 0.0026946705766022205, 0.002312680706381798, 0.0023590545170009136, 0.21444155275821686, 0.002074378775432706, 0.0019782374147325754, 0.0019821207970380783, 0.0021344078704714775, 0.0024456693790853024, 0.002444107551127672, 0.00239748228341341, 0.0028507723473012447, 0.0021165860816836357, 0.002040757331997156, 0.002386527368798852, 0.0018419193802401423, 0.0023396234028041363, 0.0020206242334097624, 0.0018346239812672138, 0.0017686296487227082, 0.0017601462313905358, 0.0019134760368615389, 0.0021437990944832563, 0.0019739253912121058, 0.0016689784824848175, 0.001512183458544314, 0.001969150500372052, 0.0019442382035776973, 0.0017031466122716665, 0.0016309095080941916, 0.20997804403305054, 0.10181493312120438, 0.2545367479324341, 0.0015676431357860565, 0.0016444443026557565, 0.0016999676590785384, 0.002184831304475665, 0.0019847177900373936, 0.002494608052074909, 0.0020689961966127157, 0.17670252919197083, 0.002418539486825466, 0.0023118259850889444, 0.2034347802400589, 0.0024879409465938807, 0.002842513145878911, 0.002836999949067831, 0.003029865212738514, 0.0030840905383229256, 0.003626792225986719, 0.003250691806897521, 0.003013265784829855, 0.003109568962827325, 0.0030680052004754543, 0.0033842362463474274, 0.003093391191214323, 0.0035728507209569216, 0.0030341865494847298, 0.0028703324496746063, 0.0033862239215523005, 0.0029101427644491196, 0.0031022035982459784, 0.0032125788275152445, 0.002814200008288026, 0.002825076226145029, 0.0025149525608867407, 0.002402098849415779, 0.002419201424345374, 0.002482104580849409, 0.002311606192961335, 0.002145596779882908, 0.002445948077365756, 0.22294238209724426, 0.0020068965386599302, 0.0020257497671991587, 0.00204213778488338, 0.0020234815310686827, 0.002082634484395385, 0.002087729750201106, 0.002037822501733899, 0.0023616193793714046, 0.0018587068188935518, 0.0019779799040406942, 0.0018503927858546376, 0.001803512335754931, 0.0018141793552786112, 0.5146291851997375, 0.0021134873386472464, 0.13961873948574066, 0.0024780321400612593, 0.002709249034523964, 0.14356252551078796, 0.003171679563820362, 0.003491627052426338, 0.0036483146250247955, 0.003958755172789097, 0.004040836356580257, 0.004365237895399332, 0.004479294642806053, 0.00465868366882205, 0.0047547901049256325, 0.004762306343764067, 0.004443835001438856, 0.10654199868440628, 0.00464315852150321, 0.004529076628386974, 0.00462209340184927, 0.004590981639921665, 0.004450324457138777, 0.004758565220981836, 0.004649200942367315, 0.00460064085200429, 0.004168052691966295, 0.004167984705418348, 0.003972923848778009, 0.004280435387045145, 0.003939359914511442, 0.003601288655772805, 0.0035553567577153444, 0.003660705639049411, 0.0033253799192607403, 0.0034142923541367054, 0.09082866460084915, 0.003015800379216671, 0.00317936553619802, 0.002963260281831026, 0.0033942298032343388, 0.00281530455686152, 0.0029914381448179483, 0.0026302917394787073, 0.00307516660541296, 0.002634963719174266, 0.12930940091609955, 0.0026539398822933435, 0.0027065949980169535, 0.113868847489357, 0.0027772989124059677, 0.0026978040114045143, 0.002773175248876214, 0.0027958345599472523, 0.13244372606277466, 0.0028256140649318695, 0.18197126686573029, 0.003099753288552165, 0.003589280415326357, 0.003437066450715065, 0.0036734347231686115, 0.0036236229352653027, 0.14304322004318237, 0.0037079316098243, 0.13185185194015503, 0.0039161378517746925, 0.004056800622493029, 0.07515290379524231, 0.004497975576668978, 0.004223726224154234, 0.004497661720961332, 0.004473215434700251, 0.004611633718013763, 0.11494754254817963, 0.004692897666245699, 0.004552379250526428, 0.004955573007464409, 0.0047003645449876785, 0.004740207921713591, 0.004946277476847172, 0.11739755421876907, 0.004536943044513464, 0.11893022805452347, 0.004610743373632431, 0.0047188070602715015, 0.004956230521202087, 0.0051450361497700214, 0.004713547416031361, 0.004814352840185165, 0.004653223790228367, 0.004680642858147621, 0.004475419409573078, 0.004303160589188337, 0.005628553219139576, 0.0044771404936909676, 0.004184957128018141, 0.0038896873593330383, 0.003784248372539878, 0.0037032149266451597, 0.003446814604103565, 0.003897744230926037, 0.003772377735003829, 0.15689410269260406, 0.003539236495271325, 0.003130169352516532, 0.0038370080292224884, 0.002887871814891696, 0.0029781849589198828, 0.003663067938759923, 0.0027341973036527634, 0.0027368320152163506, 0.0027567227371037006, 0.002792306477203965, 0.002711433218792081, 0.002858431078493595, 0.0023735356517136097, 0.002533865161240101, 0.002216709777712822, 0.002159500028938055, 0.002211485058069229, 0.002250045072287321, 0.0023103132843971252, 0.0019111366709694266, 0.0018992266850546002, 0.0019468331011012197, 0.0018064856994897127, 0.0017374271992594004, 0.001874020672403276, 0.0016734463861212134, 0.0018224158557131886, 0.0017825288232415915, 0.0015721051022410393, 0.0015545047353953123, 0.0015138857997953892, 0.0015541629400104284, 0.0014020407106727362, 0.0014542615972459316, 0.12894538044929504, 0.0015847638715058565, 0.0015168533427640796, 0.0014100903645157814, 0.1923392415046692, 0.0014433140167966485, 0.2335820496082306, 0.0016278896946460009, 0.0021793979685753584, 0.0021631254348903894, 0.0020741478074342012, 0.0019576239865273237, 0.0020676078274846077, 0.0026147773023694754, 0.002254202263429761, 0.0021172829438000917, 0.12468486279249191, 0.002549804048612714, 0.0024295011535286903, 0.6089006066322327, 0.12187497317790985, 0.0032594685908406973, 0.0038581981789320707, 0.16890151798725128, 0.004313749261200428, 0.004989242181181908, 0.005350286606699228, 0.12644235789775848, 0.006198125891387463, 0.00646994961425662, 0.00714312307536602, 0.008305514231324196, 0.007451880257576704, 0.10611623525619507, 0.007825126871466637, 0.008306280709803104, 0.0077095357701182365, 0.007823924534022808, 0.008241028524935246, 0.00865640677511692, 0.007454127073287964, 0.007438930682837963, 0.0072316317819058895, 0.008257579058408737, 0.08788757771253586, 0.05272478610277176, 0.006477177608758211, 0.006511123385280371, 0.006284845061600208, 0.005957331508398056, 0.006431531626731157, 0.005496451631188393, 0.006459232419729233, 0.005457327701151371, 0.004931585863232613, 0.005365232937037945, 0.2023840695619583, 0.005219656974077225, 0.004714001435786486, 0.00430412869900465, 0.004216735251247883, 0.00428521865978837, 0.004543078597635031, 0.003957405686378479, 0.003554883413016796, 0.0035600035917013884, 0.18844911456108093, 0.004276625346392393, 0.003161381697282195, 0.0033982242457568645, 0.0033245536033064127, 0.003140257205814123, 0.003212384646758437, 0.0035243784077465534, 0.002802977105602622, 0.002739233197644353, 0.1133556067943573, 0.00284593622200191, 0.002667945809662342, 0.0028794272802770138, 0.002684150356799364, 0.0026809608098119497, 0.0026439703069627285, 0.0026861755177378654, 0.002958569908514619, 0.0028281924314796925, 0.00256593176163733, 0.00261342478916049, 0.002436296781525016, 0.0024965705815702677, 0.002223436953499913, 0.0027497021947056055, 0.002605812158435583, 0.14192545413970947, 0.092815101146698, 0.002242740010842681, 0.11132324486970901, 0.002630282426252961, 0.0028850685339421034, 0.0028821881860494614, 0.0031478151213377714, 0.0029269850347191095, 0.0028848894871771336, 0.0031073372811079025, 0.0030895157251507044, 0.0028639112133532763, 0.002804035320878029, 0.0029476876370608807, 0.003021462354809046, 0.0028893123380839825, 0.002923190826550126, 0.0028604690451174974, 0.002699291566386819, 0.0026543287094682455, 0.002512442646548152, 0.0028376698028296232, 0.12805017828941345, 0.003027430037036538, 0.0023680259473621845, 0.4526829123497009, 0.003027568105608225, 0.0030201685149222612, 0.0035673172678798437, 0.0034610512666404247, 0.17647047340869904, 0.0037823659367859364, 0.004427088424563408, 0.004606849979609251, 0.004336858168244362, 0.004817240405827761, 0.0046173930168151855, 0.005225301254540682, 0.13389815390110016, 0.004871676675975323, 0.139521062374115, 0.005305604077875614, 0.005645573604851961, 0.005401813890784979, 0.006149691995233297, 0.005570527166128159, 0.006061045452952385, 0.005982638336718082, 0.14287924766540527, 0.005043624900281429, 0.005676856730133295, 0.005624642129987478, 0.09442553669214249, 0.07544192671775818, 0.0051326327957212925, 0.004969482310116291, 0.005607196129858494, 0.005121858324855566, 0.005569144152104855, 0.005125766154378653, 0.004935551900416613, 0.004986078944057226, 0.0047837067395448685, 0.00465427478775382, 0.004785862751305103, 0.004436688032001257, 0.004315151367336512, 0.004053257871419191, 0.004151271656155586, 0.003732312237843871, 0.003946112934499979, 0.0035161515697836876, 0.0034517033491283655, 0.08167335391044617, 0.11080469191074371, 0.003610605373978615, 0.1900453418493271, 0.00340586737729609, 0.003976267762482166, 0.003719718661159277, 0.16023141145706177, 0.003572622314095497, 0.0037092571146786213, 0.0038761894684284925, 0.003792775562033057, 0.003864496247842908, 0.003971268888562918, 0.0037863594479858875, 0.0038594917859882116, 0.0036160226445645094, 0.003623604541644454, 0.003490127855911851, 0.00396176241338253, 0.003472961951047182, 0.0036365215200930834, 0.0035464540123939514, 0.0033390983007848263, 0.003315386362373829, 0.0029535668436437845, 0.0030721414368599653, 0.0030547785572707653, 0.0029271934181451797, 0.002642595674842596, 0.002678994555026293, 0.0025559826754033566, 0.1542384773492813, 0.002449845429509878, 0.0025755867827683687, 0.0024737936910241842, 0.0024264133535325527, 0.09336600452661514, 0.0024167897645384073, 0.0024879316333681345, 0.002989852102473378, 0.0026528777088969946, 0.0026172189973294735, 0.0027019015979021788, 0.0024971903767436743, 0.0024249334819614887, 0.0024490077048540115, 0.0025126205291599035, 0.10758781433105469, 0.0026254623662680387, 0.1213669553399086, 0.0024806607980281115, 0.0027972932439297438, 0.18477024137973785, 0.002936839358881116, 0.002801627619192004, 0.12703125178813934, 0.0032261949963867664, 0.0032929021399468184, 0.09735982120037079, 0.0034996953327208757, 0.0035897104535251856, 0.003686281619593501, 0.003907070495188236, 0.003952545579522848, 0.0960584208369255, 0.004016748163849115, 0.004237414803355932, 0.1694110482931137, 0.004560246132314205, 0.004463426303118467, 0.11092143505811691, 0.0047020092606544495, 0.1647759974002838, 0.005379964597523212, 0.005130636040121317, 0.07131537795066833, 0.0053608897142112255, 0.005667559336870909, 0.0059523130767047405, 0.00548089575022459, 0.11298877745866776, 0.0059297229163348675, 0.0059579345397651196, 0.005948537960648537, 0.005560721270740032, 0.006433976348489523, 0.13126720488071442, 0.00609380891546607, 0.0056585087440907955, 0.005701745394617319, 0.005463896784931421, 0.005716474261134863, 0.005248428322374821, 0.005348570179194212, 0.005044020712375641, 0.005016051232814789, 0.004670132417231798, 0.13288797438144684, 0.004559667780995369, 0.004562005866318941, 0.004396736156195402, 0.004714536480605602, 0.004351336043328047, 0.004255335777997971, 0.004101369064301252, 0.004023880232125521, 0.004105148836970329, 0.003748626448214054, 0.004058718215674162, 0.003531853435561061, 0.003420219523832202, 0.0033144266344606876, 0.003194904187694192, 0.0030264724045991898, 0.0029712493997067213, 0.002890805248171091, 0.0028574345633387566, 0.002758277812972665, 0.002598484978079796, 0.0027203746140003204, 0.0023994091898202896, 0.002353896386921406, 0.002426526043564081, 0.0023995840456336737, 0.002237639157101512, 0.14162835478782654, 0.0021510838996618986, 0.00219091703183949, 0.0021462268196046352, 0.0020432418677955866, 0.0021043873857706785, 0.0020910524763166904, 0.0981222465634346, 0.0020605693571269512, 0.002281095599755645, 0.0021702274680137634, 0.15655149519443512, 0.0022848539520055056, 0.0022593187168240547, 0.0022943823132663965, 0.07657644152641296, 0.0023684469051659107, 0.0024106167256832123, 0.002471339423209429, 0.0025465439539402723, 0.0026165167801082134, 0.0028787613846361637, 0.12225519120693207, 0.00263025751337409, 0.003053767140954733, 0.002942248247563839, 0.0028069238178431988, 0.002843517577275634, 0.0031680783722549677, 0.1493251919746399, 0.0029369578696787357, 0.003129689721390605, 0.0031298762187361717, 0.17740722000598907, 0.003316151211038232, 0.0033197738230228424, 0.0033347285352647305, 0.0995599776506424, 0.0034914321731776, 0.003683675779029727, 0.0038034943863749504, 0.4627908766269684, 0.004323003813624382, 0.004462353885173798, 0.00533405551686883, 0.005124656483530998, 0.0057779778726398945, 0.005862196907401085, 0.006001857575029135, 0.005859523545950651, 0.006113576237112284, 0.00641013914719224, 0.006179948337376118, 0.10876225680112839, 0.006856576539576054, 0.006254706997424364, 0.0066627622582018375, 0.11253572255373001, 0.006286583375185728, 0.006240133661776781, 0.006866445764899254, 0.006166491191834211, 0.006036717910319567, 0.005828240420669317, 0.005520935636013746, 0.005432683974504471, 0.005299607757478952, 0.005349638406187296, 0.005194163881242275, 0.16407550871372223, 0.0050254566594958305, 0.004770810715854168, 0.0046384213492274284, 0.004699814599007368, 0.004595018457621336, 0.13356217741966248, 0.004223962780088186, 0.10975861549377441, 0.004476221743971109, 0.004252859856933355, 0.004305602516978979, 0.004368351306766272, 0.00490954052656889, 0.0043020122684538364, 0.004305346868932247, 0.004011285025626421, 0.003988571930676699, 0.003764480585232377, 0.003778133075684309, 0.003621084149926901, 0.003426115959882736, 0.0033879769034683704, 0.0032941624522209167, 0.003408844815567136, 0.0031669652089476585, 0.003060624236240983, 0.003271538531407714, 0.11683588474988937, 0.13676440715789795, 0.0029270239174365997, 0.003071670886129141, 0.003125702030956745, 0.0030351656023412943, 0.0031898014713078737, 0.002897654427215457, 0.002967182546854019, 0.002828876255080104, 0.11966158449649811, 0.0030588870868086815, 0.003042464144527912, 0.13905011117458344, 0.0029661026783287525, 0.003266713349148631, 0.003213156946003437, 0.0030965821351855993, 0.0032949750311672688, 0.0031626452691853046, 0.0031274687498807907, 0.0031931966077536345, 0.0031745778396725655, 0.003081047674641013, 0.003399374894797802, 0.0030347236897796392, 0.0029558208771049976, 0.002997392090037465, 0.0028924127109348774, 0.0028731597121804953, 0.0030637769959867, 0.002681044163182378, 0.002724545542150736, 0.00270376936532557, 0.0029222844168543816, 0.0024483506567776203, 0.002436044393107295, 0.0024469937197864056, 0.002284672111272812, 0.1292744129896164, 0.0022133667953312397, 0.0022689143661409616, 0.002232677536085248, 0.0022902386263012886, 0.0023080960381776094, 0.1428002119064331, 0.002447756240144372, 0.0023689891677349806, 0.0023352960124611855, 0.0022969215642660856, 0.0023158190306276083, 0.0025914027355611324, 0.002373775001615286, 0.17077098786830902, 0.0023957190569490194, 0.08971332013607025, 0.0025518033653497696, 0.002844099886715412, 0.00272134761326015, 0.0028557609766721725, 0.0027952820528298616, 0.0029164848383516073, 0.003069963539019227, 0.0031677584629505873, 0.0029921557288616896, 0.15401220321655273, 0.0029810830019414425, 0.002864267211407423, 0.0032833635341376066, 0.08985182642936707, 0.0030349206645041704, 0.0033662887290120125, 0.0032563158310949802, 0.003202776424586773, 0.003348046215251088, 0.003259809222072363, 0.11351476609706879, 0.0032082272227853537, 0.0032485409174114466, 0.003430295502766967, 0.0033785770647227764, 0.003739359090104699, 0.1275635063648224, 0.003447166411206126, 0.0036629377864301205, 0.003899148665368557, 0.0037433106917887926, 0.003453182289376855, 0.0035044809337705374, 0.00342600978910923, 0.003449575509876013, 0.003722413443028927, 0.0035229951608926058, 0.0034446357749402523, 0.1538262814283371, 0.0033908921759575605, 0.003405231749638915, 0.003623944241553545, 0.003282737685367465, 0.0035434821620583534, 0.13455501198768616, 0.1668372005224228, 0.003329956904053688, 0.003477044403553009, 0.15670594573020935, 0.0037400447763502598, 0.0038702692836523056, 0.004045182839035988, 0.11495055258274078, 0.004074320662766695, 0.00403189193457365, 0.004247420001775026, 0.004241276066750288, 0.004417661111801863, 0.0043783411383628845, 0.004494214430451393, 0.004323404282331467, 0.004650244023650885, 0.08510424196720123, 0.004204098600894213, 0.004482810851186514, 0.004155186004936695, 0.0045214151032269, 0.004186596255749464, 0.004015889018774033, 0.08972165733575821, 0.003857431234791875, 0.003949051257222891, 0.13559727370738983, 0.004001084715127945, 0.003907797858119011, 0.00421460485085845, 0.0037889848463237286, 0.003954580519348383, 0.0039519029669463634, 0.003651814768090844, 0.06809387356042862, 0.004183536395430565, 0.1449233889579773, 0.003660038113594055, 0.0037434659898281097, 0.003907924052327871, 0.003810380818322301, 0.003848229069262743, 0.003971849102526903, 0.004218876361846924, 0.0038830291014164686, 0.003976842388510704, 0.003766826819628477, 0.00347824371419847, 0.003591796848922968, 0.0033959567081183195, 0.003543789964169264, 0.00336944661103189, 0.003402973059564829, 0.17130276560783386, 0.003041906049475074, 0.0034496313892304897, 0.1941034346818924, 0.0032945885322988033, 0.0033663518261164427, 0.0031733938958495855, 0.0032056744676083326, 0.10270176827907562, 0.003577491967007518, 0.003228019457310438, 0.003378448309376836, 0.003223768202587962, 0.0032948998268693686, 0.0032549246679991484, 0.0032497320789843798, 0.0032190990168601274, 0.003309026826173067, 0.0033997984137386084, 0.0835404172539711, 0.10614793747663498, 0.003269531996920705, 0.13563287258148193, 0.0035219211131334305, 0.004115347284823656, 0.003591867396607995, 0.003557213582098484, 0.0036901833955198526, 0.15876495838165283, 0.0037404322065413, 0.0038143713027238846, 0.003938412293791771, 0.17927929759025574, 0.004030325450003147, 0.004141479264944792, 0.004111381247639656, 0.004125818144530058, 0.0043505337089300156, 0.10452674329280853, 0.004154773894697428, 0.004237419925630093, 0.004407866392284632, 0.004557788372039795, 0.004215562716126442, 0.12299222499132156, 0.139764666557312, 0.004585286136716604, 0.004745079204440117, 0.0044998899102211, 0.004546717740595341, 0.004805436823517084, 0.004733564797788858, 0.004543838556855917, 0.004698615055531263, 0.004498457536101341, 0.0044083665125072, 0.0045602815225720406, 0.15518535673618317, 0.004578516818583012, 0.004403752740472555, 0.004194971174001694, 0.15317852795124054, 0.004431932233273983, 0.004464007914066315, 0.004274469800293446, 0.00417943624779582, 0.004199989605695009, 0.004192304331809282, 0.003944932017475367, 0.003994266968220472, 0.0037873215042054653, 0.003839825512841344, 0.0036603037733584642, 0.0036345350090414286, 0.003423920599743724, 0.0035753068514168262, 0.003268270054832101, 0.5035349726676941, 0.1281573623418808, 0.0904642641544342, 0.0039343456737697124, 0.09862090647220612, 0.00464662117883563, 0.004923839587718248, 0.005505590233951807, 0.005798592232167721, 0.00555646326392889, 0.005948890000581741, 0.005880626384168863, 0.005914628971368074, 0.006393862888216972, 0.14443589746952057, 0.006260984111577272, 0.006155977491289377, 0.006186584942042828, 0.12386541813611984, 0.006024476140737534, 0.00611534621566534, 0.006255746353417635, 0.006106182001531124, 0.006002217996865511, 0.005797476973384619, 0.005958485882729292, 0.005723568610846996, 0.0054562087170779705, 0.005184197332710028, 0.10850532352924347, 0.005268183071166277, 0.004921408370137215, 0.004974887706339359, 0.004784407559782267, 0.004652468953281641, 0.004508878104388714, 0.004505356308072805, 0.004309477284550667, 0.004246531054377556, 0.004170835949480534, 0.0038184067234396935, 0.0038342727348208427, 0.0922129899263382, 0.003636731766164303, 0.12941673398017883, 0.0036732645239681005, 0.003646716708317399, 0.16502584517002106, 0.0035761850886046886, 0.11559697985649109, 0.0037420610897243023, 0.0037743740249425173, 0.0038322859909385443, 0.003891115775331855, 0.004018481355160475, 0.004051613621413708, 0.003872680477797985, 0.14458884298801422, 0.003966715652495623, 0.003983072470873594, 0.003949549049139023, 0.0040978239849209785, 0.004021098837256432, 0.004150689113885164, 0.004108996596187353, 0.004001108463853598, 0.0038210267666727304, 0.003949449863284826, 0.0037074934225529432, 0.0036212708801031113, 0.0035044457763433456, 0.003404766321182251, 0.003360552480444312, 0.003297986928373575, 0.0032485704869031906, 0.0031303148716688156, 0.003140430897474289, 0.0029256530106067657, 0.0028340769931674004, 0.0028673859778791666, 0.505492091178894, 0.10552836209535599, 0.0031199713703244925, 0.00335503276437521, 0.0037010691594332457, 0.0037228718865662813, 0.003951651975512505, 0.004022361245006323, 0.11934150755405426, 0.004323074594140053, 0.004756807815283537, 0.004563967697322369, 0.004795387387275696, 0.004874783102422953, 0.004958148580044508, 0.004770618863403797, 0.0047332909889519215, 0.004738941788673401, 0.004703186452388763, 0.004660093225538731, 0.004651170689612627, 0.08444813638925552, 0.004615266807377338, 0.004538468085229397, 0.1392180621623993, 0.0046476637944579124, 0.0045309728011488914, 0.004366904031485319, 0.004363827873021364, 0.004480243660509586, 0.004275492392480373, 0.004472515545785427, 0.004180246032774448, 0.004081476479768753, 0.004008065443485975, 0.003904620883986354, 0.0039043156430125237, 0.0037839419674128294, 0.0036262893117964268, 0.003579175565391779, 0.003561478340998292, 0.1266241818666458, 0.003324921242892742, 0.0034572659060359, 0.0032953552436083555, 0.00323819974437356, 0.09907681494951248, 0.0033344116527587175, 0.0032384302467107773, 0.0031569048296660185, 0.003400823101401329, 0.0031945493537932634, 0.003088533179834485, 0.0031592403538525105, 0.003078946378082037, 0.0030291557777673006, 0.00291695655323565, 0.00309945666231215, 0.0028574569150805473, 0.14394548535346985, 0.0027421836275607347, 0.12322636693716049, 0.15149624645709991, 0.0030138357542455196, 0.11817707866430283, 0.003376754466444254, 0.0034063381608575583, 0.0034964377991855145, 0.0035311768297106028, 0.0038645609747618437, 0.0036120577715337276, 0.0036262781359255314, 0.0036632867995649576, 0.003865398932248354, 0.13539108633995056, 0.003899102797731757, 0.0037871915847063065, 0.003908440005034208, 0.003915917593985796, 0.0040639606304466724, 0.003935785032808781, 0.0038994215428829193, 0.003750719828531146, 0.003715178230777383, 0.0036313775926828384, 0.0035631225910037756, 0.0036018912214785814, 0.0037291941698640585, 0.0033931226935237646, 0.0033155546989291906, 0.0034285697620362043, 0.0031919055618345737, 0.00303700752556324, 0.003025707555934787, 0.12270983308553696, 0.003122812369838357, 0.14223197102546692, 0.00297860661521554, 0.0029496056959033012, 0.00303561519831419, 0.003131273901090026, 0.14037734270095825, 0.0032323873601853848, 0.0032992123160511255, 0.003253998002037406, 0.09247798472642899, 0.0032306204084306955, 0.0033955650869756937, 0.0033043441362679005, 0.12232398241758347, 0.11762877553701401, 0.0036575128324329853, 0.12467795610427856, 0.003988148644566536, 0.004255231469869614, 0.0044884877279400826, 0.004229078534990549, 0.0046791802160441875, 0.004474847577512264, 0.0043907142244279385, 0.004692742135375738, 0.10898921638727188, 0.004856990184634924, 0.004400925245136023, 0.0044449735432863235, 0.004482548218220472, 0.004441460594534874, 0.0043251062743365765, 0.004407304339110851, 0.00473790755495429, 0.11706842482089996, 0.004469708539545536, 0.004687085747718811, 0.366668164730072, 0.0046665603294968605, 0.005208457820117474, 0.005666873883455992, 0.005469535477459431, 0.005647180136293173, 0.0054315063171088696, 0.005662013776600361, 0.005332904867827892, 0.0057317535392940044, 0.005419532302767038, 0.0053710127249360085, 0.005522590596228838, 0.005599083378911018, 0.3406992554664612, 0.005363024305552244, 0.006991928443312645, 0.006637141574174166, 0.006483960896730423, 0.006678424309939146, 0.006840707268565893, 0.08921012282371521, 0.007106468081474304, 0.061926230788230896, 0.12830984592437744, 0.007413802202790976, 0.007129754405468702, 0.007531894836574793, 0.0069708009250462055, 0.006617505103349686, 0.007035810500383377, 0.007715617306530476, 0.0070959050208330154, 0.007976165041327477, 0.007016134448349476, 0.006922329775989056, 0.10489562898874283, 0.005900600925087929, 0.005500632803887129, 0.005331968888640404, 0.006196622736752033, 0.006328881252557039, 0.004991106688976288, 0.1678590625524521, 0.006433739792555571, 0.005572959780693054, 0.0051679592579603195, 0.004956819582730532, 0.005346781108528376, 0.004702281206846237, 0.005080694332718849, 0.004747429862618446, 0.18596090376377106, 0.003984909038990736, 0.004581079352647066, 0.004061372019350529, 0.0039058299735188484, 0.00470980117097497, 0.0040672640316188335, 0.003658072091639042, 0.18328869342803955, 0.0037348426412791014, 0.0036038795951753855, 0.003808852517977357, 0.0038406415842473507, 0.00406896136701107, 0.0035300764720886946, 0.10318339616060257, 0.0034900305327028036, 0.0036431318148970604, 0.13841240108013153, 0.003564446698874235, 0.00360536715015769, 0.003943212796002626, 0.004085843916982412, 0.003973353188484907, 0.0037432194221764803, 0.1484258770942688, 0.0036270732525736094, 0.003609961597248912, 0.0036660681944340467, 0.003805768908932805, 0.0037174788303673267, 0.004156840033829212, 0.003798728110268712, 0.0035095997154712677, 0.003804318606853485, 0.13092149794101715, 0.0034745933953672647, 0.0036557598505169153, 0.003699834458529949, 0.003530637826770544, 0.0035330266691744328, 0.00356746232137084, 0.0034665726125240326, 0.0033895974047482014, 0.0034059600438922644, 0.0034952342975884676, 0.12485535442829132, 0.0033301999792456627, 0.0032208978664129972, 0.1553950011730194, 0.0031707899179309607, 0.0032739138696342707, 0.0033611184917390347, 0.0032455206383019686, 0.0034383158199489117, 0.003356065135449171, 0.0035001011565327644, 0.0034120664931833744, 0.003326363628730178, 0.003263049526140094, 0.09101282060146332, 0.12775155901908875, 0.003324911929666996, 0.11708498746156693, 0.003449952695518732, 0.15304328501224518, 0.0035433038137853146, 0.0038736260030418634, 0.0042948173359036446, 0.0040878052823245525]\n",
            "Val loss 0.021295303079698766\n",
            "Val auc roc 0.4782896161781973\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5049810f5c6b4ac98224f1bd638d3b93",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0248\n",
            "Train Losses : [0.00427624024450779, 0.004169157240539789, 0.004249089397490025, 0.0042780437506735325, 0.004195409826934338, 0.14870071411132812, 0.004311599303036928, 0.004454359412193298, 0.0041771456599235535, 0.004071712028235197, 0.1094416007399559, 0.004098070785403252, 0.0042251767590641975, 0.004150879569351673, 0.004409833811223507, 0.004200699273496866, 0.11949682980775833, 0.10177941620349884, 0.00455264188349247, 0.0047093587927520275, 0.004366017412394285, 0.0045263697393238544, 0.10140889137983322, 0.004359700251370668, 0.004524938762187958, 0.004403478931635618, 0.004461169708520174, 0.004423295613378286, 0.004339493811130524, 0.004379005637019873, 0.15080036222934723, 0.004433596972376108, 0.004291518125683069, 0.17492376267910004, 0.004474044777452946, 0.00432342616841197, 0.004324210342019796, 0.004552124533802271, 0.0042955935932695866, 0.004292478319257498, 0.004340386018157005, 0.004226949065923691, 0.004306175746023655, 0.0043115695007145405, 0.004007646813988686, 0.00411497475579381, 0.003943164832890034, 0.0038357058074325323, 0.0906524509191513, 0.0036414091009646654, 0.0036617263685911894, 0.003990009427070618, 0.003559779142960906, 0.0035505653358995914, 0.0034660398960113525, 0.003339192597195506, 0.00353467115201056, 0.003284766571596265, 0.0032204457093030214, 0.09236856549978256, 0.0031634692568331957, 0.0031211290042847395, 0.0029706466011703014, 0.003080289112403989, 0.002929487731307745, 0.12361860275268555, 0.0029145386070013046, 0.0029822257347404957, 0.0029079122468829155, 0.0031604499090462923, 0.002869622316211462, 0.0028377685230225325, 0.0030772569589316845, 0.002805904718115926, 0.002726943464949727, 0.002892701420933008, 0.12326831370592117, 0.002675320254638791, 0.0032147576566785574, 0.14320573210716248, 0.0028342397417873144, 0.0028527562972158194, 0.003140171756967902, 0.0029030856676399708, 0.1140231341123581, 0.1277441680431366, 0.0031465254724025726, 0.003253873437643051, 0.0033315555192530155, 0.0035389659460633993, 0.0035963603295385838, 0.003703604219481349, 0.0035200633574277163, 0.003459259634837508, 0.0035878298804163933, 0.003822000464424491, 0.09339005500078201, 0.003645162330940366, 0.003642304567620158, 0.0035067570861428976, 0.003482130356132984, 0.0034418811555951834, 0.0034698930103331804, 0.003355413442477584, 0.0033496033865958452, 0.003432221245020628, 0.0033838339149951935, 0.003183584427461028, 0.1348860263824463, 0.003146472852677107, 0.0032307475339621305, 0.10456973314285278, 0.003190005198121071, 0.0032752000261098146, 0.0035223353188484907, 0.10329218208789825, 0.003422060515731573, 0.0036471723578870296, 0.0034319255501031876, 0.1348392218351364, 0.11893509328365326, 0.0035620201379060745, 0.004001822788268328, 0.00420911842957139, 0.003946222364902496, 0.003868004074320197, 0.004183594603091478, 0.004375850316137075, 0.003977494314312935, 0.08749278634786606, 0.00419975258409977, 0.40727075934410095, 0.004584137350320816, 0.12404805421829224, 0.005184539593756199, 0.005288560874760151, 0.005493870470672846, 0.005643602926284075, 0.0065786829218268394, 0.006009693257510662, 0.006330104544758797, 0.006577010732144117, 0.0064239115454256535, 0.47391626238822937, 0.14426381886005402, 0.007506043650209904, 0.007474362850189209, 0.00761067122220993, 0.007892400957643986, 0.008499524556100368, 0.008626872673630714, 0.008678319863975048, 0.08755964785814285, 0.008457801304757595, 0.008683137595653534, 0.008379893377423286, 0.008813319727778435, 0.008306799456477165, 0.008234419859945774, 0.008058358915150166, 0.11207933723926544, 0.0076280939392745495, 0.007356188725680113, 0.007311812601983547, 0.09897588193416595, 0.007104441989213228, 0.0067853559739887714, 0.006906361784785986, 0.10870856046676636, 0.1449429839849472, 0.006297573912888765, 0.007040971424430609, 0.006291794124990702, 0.00670163007453084, 0.07059814035892487, 0.005937999114394188, 0.006346636917442083, 0.0059072114527225494, 0.005843127612024546, 0.005816951394081116, 0.05716705322265625, 0.0055237747728824615, 0.00541585823521018, 0.08040610700845718, 0.005149567034095526, 0.005253020208328962, 0.005332650151103735, 0.004959480371326208, 0.005099296569824219, 0.005002516787499189, 0.004566020332276821, 0.004514589905738831, 0.16006746888160706, 0.004571597091853619, 0.005024096928536892, 0.004586395341902971, 0.004410266876220703, 0.004239617846906185, 0.004130539949983358, 0.07539720833301544, 0.08458613604307175, 0.0043076747097074986, 0.004459756892174482, 0.004258304368704557, 0.004065430723130703, 0.004180591087788343, 0.004011447541415691, 0.004045678768306971, 0.13787585496902466, 0.0038135217037051916, 0.00500140618532896, 0.0038247399497777224, 0.004104451276361942, 0.004189449828118086, 0.004404714331030846, 0.0037451337557286024, 0.003926492761820555, 0.0035582627169787884, 0.0038255280815064907, 0.003658728674054146, 0.0036391206085681915, 0.003559837117791176, 0.003905338468030095, 0.004248056560754776, 0.003081768751144409, 0.0031465135980397463, 0.002865242538973689, 0.0029004146344959736, 0.0028921591583639383, 0.0027002340648323298, 0.002711073961108923, 0.002837057691067457, 0.0024442197754979134, 0.0023822488728910685, 0.17026396095752716, 0.002797472756356001, 0.0023373253643512726, 0.0023289367090910673, 0.0025594905018806458, 0.0024069310165941715, 0.138281911611557, 0.002449232153594494, 0.0024622208438813686, 0.002456408692523837, 0.002408699132502079, 0.002346630906686187, 0.0024115266278386116, 0.002640948398038745, 0.0024230123963207006, 0.0025016143918037415, 0.0025859286542981863, 0.0025756091345101595, 0.516829252243042, 0.0026827072724699974, 0.0029451786540448666, 0.002994701499119401, 0.003122803056612611, 0.003593821544200182, 0.003251758636906743, 0.0033238125033676624, 0.003675444284453988, 0.003501622937619686, 0.15205098688602448, 0.1308000534772873, 0.003919878974556923, 0.1292913407087326, 0.003982326947152615, 0.00439892103895545, 0.004340576473623514, 0.004477217327803373, 0.004588594660162926, 0.004916043486446142, 0.13872630894184113, 0.004904360510408878, 0.005000938195735216, 0.00511150760576129, 0.004958136938512325, 0.1862650215625763, 0.1482083648443222, 0.005139107815921307, 0.0052199047058820724, 0.005506060551851988, 0.006036814302206039, 0.0055173770524561405, 0.0054568820632994175, 0.005555094685405493, 0.12697003781795502, 0.0054243821650743484, 0.005497497506439686, 0.005345267243683338, 0.005312269553542137, 0.0053004007786512375, 0.0052205719985067844, 0.005204015411436558, 0.005191892851144075, 0.12339566648006439, 0.004952153190970421, 0.005072638392448425, 0.004897833336144686, 0.004896802362054586, 0.004993541166186333, 0.004666198045015335, 0.004607068840414286, 0.004450294189155102, 0.004420224577188492, 0.004477006383240223, 0.004422436933964491, 0.46950095891952515, 0.12475351244211197, 0.10706622898578644, 0.004779554903507233, 0.005030211992561817, 0.005632538348436356, 0.0054472447372972965, 0.005498077720403671, 0.005766581743955612, 0.0057441615499556065, 0.005713797174394131, 0.005846421699970961, 0.005696067586541176, 0.005794455297291279, 0.1133657917380333, 0.005852703005075455, 0.005780073348432779, 0.0056374212726950645, 0.005754096899181604, 0.005800601094961166, 0.005616138223558664, 0.005371788516640663, 0.005252158269286156, 0.005144333932548761, 0.11889122426509857, 0.005346238147467375, 0.00522264139726758, 0.004908153321594, 0.004868333227932453, 0.0048878914676606655, 0.13833314180374146, 0.004698514007031918, 0.004647381603717804, 0.0048011913895606995, 0.004552741069346666, 0.004407273605465889, 0.004325277172029018, 0.10239823162555695, 0.1024547591805458, 0.004264204762876034, 0.11469147354364395, 0.00448185158893466, 0.004467546474188566, 0.004640454892069101, 0.004525904078036547, 0.004434654489159584, 0.004489820450544357, 0.004469842649996281, 0.004489525221288204, 0.004415016155689955, 0.004760092124342918, 0.004577034618705511, 0.004203690215945244, 0.004143351688981056, 0.0041565317660570145, 0.003966165240854025, 0.003783675143495202, 0.0037427586503326893, 0.0933704525232315, 0.0036556567065417767, 0.003547209780663252, 0.003694327315315604, 0.0035279467701911926, 0.003615399356931448, 0.0033337885979562998, 0.0033383246045559645, 0.003395708743482828, 0.0031848677899688482, 0.0032974525820463896, 0.0030392357148230076, 0.00317995622754097, 0.0029352272395044565, 0.0029605631716549397, 0.11454593390226364, 0.002880207495763898, 0.002773531712591648, 0.0027561828028410673, 0.0027207082603126764, 0.0026901373639702797, 0.0027776991482824087, 0.0027989353984594345, 0.0027709538117051125, 0.0026051902677863836, 0.002539056120440364, 0.0026978261303156614, 0.00250649475492537, 0.0024191823322325945, 0.0023959504906088114, 0.002405438106507063, 0.0023182816803455353, 0.0024037363473325968, 0.002304352354258299, 0.0022840965539216995, 0.0021679382771253586, 0.002114473842084408, 0.16044069826602936, 0.002116104122251272, 0.1391386240720749, 0.1402720808982849, 0.002218089299276471, 0.002657487988471985, 0.0023908386938273907, 0.002458123955875635, 0.0025465029757469893, 0.0026865678373724222, 0.0025778834242373705, 0.002695838687941432, 0.00267842598259449, 0.0026480956003069878, 0.002679159864783287, 0.12284453958272934, 0.12377705425024033, 0.0027620878536254168, 0.0028768323827534914, 0.0029506543651223183, 0.002962386468425393, 0.003055495209991932, 0.0031990944407880306, 0.003078862326219678, 0.003185512265190482, 0.003200798062607646, 0.003019853262230754, 0.0029917077627032995, 0.003021222073584795, 0.0029622858855873346, 0.0028947920072823763, 0.003291503759101033, 0.002899611135944724, 0.0029000171925872564, 0.0028195299673825502, 0.0027387223672121763, 0.002695872448384762, 0.002603901317343116, 0.002690718974918127, 0.0026218718849122524, 0.1399913877248764, 0.0026420787908136845, 0.11078377068042755, 0.0025604728143662214, 0.002574198180809617, 0.0026073867920786142, 0.002601637737825513, 0.0028137750923633575, 0.0027843713760375977, 0.002689214190468192, 0.0027306154370307922, 0.0026982484851032495, 0.002629295689985156, 0.0025340430438518524, 0.002623054664582014, 0.0024739259388297796, 0.002555043436586857, 0.0026594193186610937, 0.0025047168601304293, 0.002413857029750943, 0.002338360995054245, 0.002353398595005274, 0.16049841046333313, 0.1263452023267746, 0.0023199073038995266, 0.0023851406294852495, 0.002407328924164176, 0.0024416721425950527, 0.002497567795217037, 0.0026156012900173664, 0.0025891438126564026, 0.002524151001125574, 0.002641902072355151, 0.14200492203235626, 0.002584160305559635, 0.0025876404251903296, 0.0026672021485865116, 0.0026243391912430525, 0.002655675634741783, 0.13114593923091888, 0.4964175224304199, 0.10688343644142151, 0.0032070260494947433, 0.0035138255916535854, 0.1249799057841301, 0.00420002406463027, 0.004330684430897236, 0.004609906580299139, 0.004704250022768974, 0.004989930894225836, 0.0050749024376273155, 0.1321832835674286, 0.005474978592246771, 0.0055263713002204895, 0.006062241271138191, 0.0057274354621768, 0.005848489701747894, 0.0059350947849452496, 0.005758895538747311, 0.006033003330230713, 0.005941641982644796, 0.0056695290841162205, 0.1168908104300499, 0.005875684320926666, 0.005904613062739372, 0.005516928154975176, 0.00557487178593874, 0.005955493543297052, 0.005526181776076555, 0.005240819416940212, 0.005453635938465595, 0.005027248058468103, 0.005176973529160023, 0.005031037610024214, 0.1966703087091446, 0.004625477362424135, 0.004758043680340052, 0.004700229503214359, 0.004446691367775202, 0.0044768876396119595, 0.004443922080099583, 0.004520548041909933, 0.004121005069464445, 0.0043065049685537815, 0.13671131432056427, 0.00402600085362792, 0.004086894914507866, 0.11485274136066437, 0.003959038760513067, 0.003974625375121832, 0.0038752739783376455, 0.0040037124417722225, 0.003863532328978181, 0.0039536673575639725, 0.004009699448943138, 0.0037747228052467108, 0.003699671244248748, 0.003635573200881481, 0.003550899913534522, 0.0035326762590557337, 0.0034960422199219465, 0.0033647511154413223, 0.0033551561646163464, 0.159235417842865, 0.003275723895058036, 0.0032908902503550053, 0.003438433399423957, 0.0032032334711402655, 0.0032009738497436047, 0.003287684405222535, 0.0032193579245358706, 0.0030343448743224144, 0.0030520427972078323, 0.003019409254193306, 0.0029332563281059265, 0.002852719509974122, 0.002827876713126898, 0.0028006082866340876, 0.002756881294772029, 0.0026975960936397314, 0.0026221193838864565, 0.0025687203742563725, 0.002566059585660696, 0.002562865847721696, 0.002533981343731284, 0.002438422292470932, 0.0023628489580005407, 0.002381733851507306, 0.0022622188553214073, 0.002231174847111106, 0.002184739103540778, 0.002226835349574685, 0.0021176780574023724, 0.002064010826870799, 0.0021184186916798353, 0.001993977464735508, 0.0019407626241445541, 0.001929987221956253, 0.0019058145117014647, 0.0018577115843072534, 0.0018432496581226587, 0.0018323000986129045, 0.5317927002906799, 0.0018752921605482697, 0.1304066777229309, 0.0021781055256724358, 0.0022533682640641928, 0.002373888622969389, 0.0024998642038553953, 0.0026970296166837215, 0.002717043738812208, 0.002828252734616399, 0.0028416155837476254, 0.0029412894509732723, 0.0029146436136215925, 0.002971750684082508, 0.002996167168021202, 0.0029978668317198753, 0.0030109004583209753, 0.003017864655703306, 0.0030061211436986923, 0.002952788257971406, 0.13473281264305115, 0.0029821095522493124, 0.0030081458389759064, 0.0030054522212594748, 0.0030384135898202658, 0.0030043465085327625, 0.0030097418930381536, 0.003025047481060028, 0.002988390391692519, 0.0029737220611423254, 0.0029346244409680367, 0.003038295079022646, 0.0028996807523071766, 0.002846637973561883, 0.0028360500000417233, 0.0027757843490689993, 0.0027042317669838667, 0.002793008228763938, 0.00264851120300591, 0.002595186233520508, 0.002628506626933813, 0.002573394915089011, 0.002536872634664178, 0.15710745751857758, 0.00242235348559916, 0.12739863991737366, 0.002513283398002386, 0.0025022628251463175, 0.0025312621146440506, 0.0025696554221212864, 0.0026034147012978792, 0.0025856492575258017, 0.0027628871612250805, 0.0025795456022024155, 0.0025855430867522955, 0.0026245478074997663, 0.0025457381270825863, 0.0025432799011468887, 0.0026080815587192774, 0.0025311531499028206, 0.0025274152867496014, 0.0025334362871944904, 0.002449938328936696, 0.0023892729077488184, 0.0023837171029299498, 0.0023505529388785362, 0.002290392527356744, 0.002263361820951104, 0.0022632258478552103, 0.002236780012026429, 0.0021572208497673273, 0.0021107650827616453, 0.0021043221931904554, 0.0020553076174110174, 0.0020485881250351667, 0.0019985262770205736, 0.0020302911289036274, 0.1141766831278801, 0.0019338607089594007, 0.00192558323033154, 0.16579115390777588, 0.0019823305774480104, 0.0020085256546735764, 0.002030742820352316, 0.002064772881567478, 0.002126699313521385, 0.002099303063005209, 0.002182791940867901, 0.0021186843514442444, 0.0021264299284666777, 0.002100960584357381, 0.0021308674477040768, 0.0020678399596363306, 0.002056382829323411, 0.0020861709490418434, 0.0020826461259275675, 0.0020323307253420353, 0.002059648046270013, 0.0019794837571680546, 0.0019838467705994844, 0.13235421478748322, 0.15334628522396088, 0.476140558719635, 0.0022755751851946115, 0.002550203585997224, 0.16431990265846252, 0.12394292652606964, 0.003207166213542223, 0.003538048593327403, 0.4538361430168152, 0.0041305446065962315, 0.004640672821551561, 0.005070042796432972, 0.005386131815612316, 0.005826826673001051, 0.006107348948717117, 0.006352793425321579, 0.006593448109924793, 0.0068404097110033035, 0.007001106161624193, 0.007091819308698177, 0.007246045861393213, 0.007416088599711657, 0.1260911226272583, 0.007574270013719797, 0.00737572368234396, 0.007277337834239006, 0.007351637817919254, 0.007391690276563168, 0.007267526350915432, 0.0070059834979474545, 0.00706385588273406, 0.00679335743188858, 0.1146683469414711, 0.006612963974475861, 0.006586575414985418, 0.006468524690717459, 0.11628454923629761, 0.006584739778190851, 0.0062476699240505695, 0.006225543562322855, 0.0060141128487885, 0.005956799257546663, 0.005775691941380501, 0.12732261419296265, 0.005660077091306448, 0.12002340704202652, 0.005687773693352938, 0.005585642531514168, 0.11637359857559204, 0.005587444175034761, 0.08584889024496078, 0.00562294153496623, 0.1230931505560875, 0.005787608679383993, 0.005701669957488775, 0.1043841615319252, 0.0057500069960951805, 0.005912440828979015, 0.005939543712884188, 0.10685578733682632, 0.10093469172716141, 0.0059523070231080055, 0.006135850679129362, 0.006128544919192791, 0.006431299261748791, 0.10711310803890228, 0.00618496909737587, 0.006140954326838255, 0.006124196574091911, 0.006280334200710058, 0.006034542806446552, 0.14441198110580444, 0.006158378906548023, 0.006026106420904398, 0.006031945813447237, 0.005996808409690857, 0.005749858915805817, 0.09892013669013977, 0.005736662540584803, 0.005784674547612667, 0.0055898199789226055, 0.005531097296625376, 0.0054108682088553905, 0.005416525062173605, 0.005286451894789934, 0.0052215890027582645, 0.005224939901381731, 0.004955335520207882, 0.004879091400653124, 0.00485186604782939, 0.004701904486864805, 0.00454722298309207, 0.0045128087513148785, 0.004272027872502804, 0.004173333756625652, 0.004101005382835865, 0.08455540984869003, 0.0039346287958323956, 0.1247146800160408, 0.004057484213262796, 0.004009952303022146, 0.003972318023443222, 0.0038829271215945482, 0.003760315477848053, 0.0038074010517448187, 0.00384267745539546, 0.003776716534048319, 0.003616510657593608, 0.003514951327815652, 0.0035005940590053797, 0.0033935292158275843, 0.0035888650454580784, 0.0033621424809098244, 0.003249139990657568, 0.0033129353541880846, 0.0031258794479072094, 0.0030595690477639437, 0.003019498661160469, 0.003029211889952421, 0.002937895944342017, 0.002867606468498707, 0.1455232948064804, 0.002796726766973734, 0.0027430946938693523, 0.0028078192844986916, 0.002715012524276972, 0.002764902776107192, 0.002656396012753248, 0.002761148614808917, 0.1212848424911499, 0.002672284608706832, 0.002784030046314001, 0.0026243007741868496, 0.002740877913311124, 0.00266964896582067, 0.0026370675768703222, 0.0026438094209879637, 0.0027371414471417665, 0.00263585289940238, 0.002604580018669367, 0.0025555479805916548, 0.12325012683868408, 0.0025227598380297422, 0.0025479502510279417, 0.0025426337961107492, 0.11324484646320343, 0.002726020524278283, 0.002596630249172449, 0.0026234036777168512, 0.0027278198394924402, 0.0026444722898304462, 0.10656330734491348, 0.0027437128592282534, 0.0028886841610074043, 0.0028188403230160475, 0.002805891912430525, 0.0029212376102805138, 0.1285141408443451, 0.002918427810072899, 0.0029083879198879004, 0.0029191793873906136, 0.15353348851203918, 0.003189695766195655, 0.002989933593198657, 0.003123596776276827, 0.00307561201043427, 0.003151172073557973, 0.0031771776266396046, 0.003089264500886202, 0.07871166616678238, 0.0031050494872033596, 0.0031263825949281454, 0.003222192171961069, 0.0032537912484258413, 0.003323981771245599, 0.003262241603806615, 0.00318734347820282, 0.0032075075432658195, 0.0031535057350993156, 0.0032145660370588303, 0.1241728737950325, 0.0032830473501235247, 0.003082909155637026, 0.15167322754859924, 0.0032181127462536097, 0.0033119588624686003, 0.003371112747117877, 0.0032045897096395493, 0.15406881272792816, 0.0032837926410138607, 0.003301409073174, 0.0036735516041517258, 0.003308515530079603, 0.0033290183637291193, 0.00358352973125875, 0.0035936785861849785, 0.003354174317792058, 0.0035664839670062065, 0.0034038524609059095, 0.0032607614994049072, 0.0031944417860358953, 0.003349422477185726, 0.003163010347634554, 0.15041464567184448, 0.0031306438613682985, 0.0031522116623818874, 0.0031973456498235464, 0.0030509899370372295, 0.003078250680118799, 0.003114172490313649, 0.1506107598543167, 0.11355128884315491, 0.0031076339073479176, 0.0031827192287892103, 0.1235479936003685, 0.13700833916664124, 0.003509062808007002, 0.003540570614859462, 0.0035776959266513586, 0.0037998741026967764, 0.0036943000741302967, 0.0039107343181967735, 0.003856715513393283, 0.003976126201450825, 0.0038222891744226217, 0.0037753586657345295, 0.12685945630073547, 0.003770402166992426, 0.0038409342523664236, 0.12290292233228683, 0.00382462446577847, 0.003982734866440296, 0.00392660079523921, 0.003925865050405264, 0.003961516078561544, 0.00392040703445673, 0.003988791257143021, 0.003871258581057191, 0.0038505378179252148, 0.003827278269454837, 0.003772775875404477, 0.0037871538661420345, 0.00372694106772542, 0.003616978880017996, 0.0036884122528135777, 0.0035470654256641865, 0.11445650458335876, 0.0034992259461432695, 0.0034510260447859764, 0.003562253201380372, 0.0033964423928409815, 0.003497726283967495, 0.0033141288440674543, 0.0032803616486489773, 0.0033509174827486277, 0.0032043028622865677, 0.1440606415271759, 0.003209945745766163, 0.003155773738399148, 0.0031456369906663895, 0.0031775417737662792, 0.003196082077920437, 0.00312445848248899, 0.0031116115860641003, 0.1421108990907669, 0.00302516994997859, 0.0031623495742678642, 0.003042519325390458, 0.003116181818768382, 0.003202937776222825, 0.00316274119541049, 0.10524145513772964, 0.003045828780159354, 0.13265123963356018, 0.15187762677669525, 0.003190435469150543, 0.0033052365761250257, 0.0033910037018358707, 0.0033422212582081556, 0.0034678750671446323, 0.0034680080134421587, 0.1075233444571495, 0.0036005873698741198, 0.003540618810802698, 0.0035868578124791384, 0.003610746469348669, 0.003656594082713127, 0.0036228878889232874, 0.09269379079341888, 0.0036945254541933537, 0.1293063908815384, 0.003733505727723241, 0.13143323361873627, 0.004063652828335762, 0.12789885699748993, 0.00406251847743988, 0.09791530668735504, 0.0971132442355156, 0.004426541272550821, 0.004766029305756092, 0.004691970068961382, 0.0047644199803471565, 0.004829828627407551, 0.004951847717165947, 0.0049007609486579895, 0.1073523461818695, 0.00498384702950716, 0.09515485912561417, 0.005210092756897211, 0.0051400260999798775, 0.10366323590278625, 0.005277080461382866, 0.14259718358516693, 0.005433985963463783, 0.005545401945710182, 0.005636273417621851, 0.12424864619970322, 0.005728380288928747, 0.005859815049916506, 0.005806498695164919, 0.005887050647288561, 0.0057710641995072365, 0.005643601529300213, 0.12923933565616608, 0.09449992328882217, 0.005663286428898573, 0.13897930085659027, 0.1526678502559662, 0.005843956954777241, 0.005883500445634127, 0.006185302510857582, 0.006061771418899298, 0.3889927566051483, 0.006382218096405268, 0.006534182466566563, 0.006888096686452627, 0.006930391304194927, 0.0071283611468970776, 0.11567705869674683, 0.007360747549682856, 0.007481802720576525, 0.1384676694869995, 0.007799949962645769, 0.0077737788669764996, 0.007695740554481745, 0.00776504073292017, 0.00764516880735755, 0.13070350885391235, 0.007661322131752968, 0.007487869821488857, 0.1255526840686798, 0.007479965686798096, 0.09308313578367233, 0.1328348070383072, 0.007704639341682196, 0.007596470415592194, 0.007360414601862431, 0.007438191678375006, 0.11947264522314072, 0.11050937324762344, 0.0074340300634503365, 0.0072663021273911, 0.007270341273397207, 0.007363506127148867, 0.007172383368015289, 0.007087276317179203, 0.006991832051426172, 0.0068534426391124725, 0.14359906315803528, 0.006713731214404106, 0.006532999221235514, 0.006433766335248947, 0.00647939695045352, 0.006345092318952084, 0.006107705645263195, 0.006016903556883335, 0.005874684080481529, 0.0057177236303687096, 0.005623320117592812, 0.00545924436300993, 0.005323865916579962, 0.005182534456253052, 0.005072437226772308, 0.10676361620426178, 0.0048900474794209, 0.004813979845494032, 0.004786321893334389, 0.004682202357798815, 0.004532873164862394, 0.004524840507656336, 0.004370638635009527, 0.11489468812942505, 0.004239065106958151, 0.004229026380926371, 0.004160278011113405, 0.004092841409146786, 0.004068377893418074, 0.004051824565976858, 0.003964908421039581, 0.0038794318679720163, 0.0037951800040900707, 0.13094981014728546, 0.003738013794645667, 0.0036958972923457623, 0.003688740311190486, 0.0037694626953452826, 0.1241980642080307, 0.0036999161820858717, 0.003631466766819358, 0.0035774654243141413, 0.0035887849517166615, 0.0036522371228784323, 0.0035219788551330566, 0.003546998370438814, 0.003505651606246829, 0.0034536165185272694, 0.12407418340444565, 0.0034423680044710636, 0.0033969630021601915, 0.003360246540978551, 0.11926037818193436, 0.0035198333207517862, 0.0034344380255788565, 0.003409147262573242, 0.0034104343503713608, 0.0033754182513803244, 0.003448519157245755, 0.0033462229184806347, 0.0033726694528013468, 0.0033565000630915165, 0.1112947165966034, 0.0033329094294458628, 0.0032888222485780716, 0.0033263801597058773, 0.10968983173370361, 0.13775227963924408, 0.11283759027719498, 0.0034449223894625902, 0.46508073806762695, 0.0038612845819443464, 0.00413153413683176, 0.004312202334403992, 0.004520273767411709, 0.004703136160969734, 0.00487070856615901, 0.005050612613558769, 0.005189985502511263, 0.005309777799993753, 0.00535625871270895, 0.00535785686224699, 0.10113411396741867, 0.0055443826131522655, 0.0056172641925513744, 0.0056271119974553585, 0.11981489509344101, 0.00561246182769537, 0.005619354080408812, 0.005676107946783304, 0.00570919131860137, 0.005654947832226753, 0.0055483016185462475, 0.005633163265883923, 0.005499223712831736, 0.00544494716450572, 0.005417058244347572, 0.005195132922381163, 0.005145627539604902, 0.005051111802458763, 0.00493892515078187, 0.004880490712821484, 0.004770506173372269, 0.004723676480352879, 0.004583090078085661, 0.004465768579393625, 0.0043650902807712555, 0.004369477741420269, 0.004187200218439102, 0.10246715694665909, 0.004030420910567045, 0.10240879654884338, 0.0040282574482262135, 0.004004948772490025, 0.003971393220126629, 0.003950309939682484, 0.0039276923052966595, 0.12400605529546738, 0.1271091103553772, 0.003932060208171606, 0.003950648941099644, 0.09022967517375946, 0.004077508579939604, 0.004043612163513899, 0.0041249701753258705, 0.40667131543159485, 0.10215941071510315, 0.004528696648776531, 0.004782735835760832, 0.004975193180143833, 0.00542618939653039, 0.005303988698869944, 0.0054723466746509075, 0.0054955133236944675, 0.005525556392967701, 0.005735130049288273, 0.0057953838258981705, 0.11792556196451187, 0.005679866299033165, 0.005730473902076483, 0.005762175191193819, 0.1005367785692215, 0.12242772430181503, 0.005953805986791849, 0.005936739966273308, 0.00594969792291522, 0.005899324081838131, 0.006139497738331556, 0.0058616711758077145, 0.005787902045994997, 0.005717815365642309, 0.005853015463799238, 0.0057274349965155125, 0.005559052340686321, 0.005660438910126686, 0.005469584837555885, 0.0054450808092951775, 0.005287297070026398, 0.005127276293933392, 0.13235855102539062, 0.004934411030262709, 0.004960170015692711, 0.004835626110434532, 0.004749485291540623, 0.10214078426361084, 0.0047948830761015415, 0.11939699947834015, 0.004813730251044035, 0.004765319637954235, 0.10773055255413055, 0.004719753284007311, 0.004697491880506277, 0.00461433595046401, 0.004679433535784483, 0.004581938497722149, 0.004596414510160685, 0.004558764863759279, 0.11790785193443298, 0.00459088571369648, 0.15571749210357666, 0.004488913808017969, 0.004617423750460148, 0.004596439190208912, 0.004552809521555901, 0.004677207209169865, 0.1399366706609726, 0.004523873794823885, 0.0046462202444672585, 0.0911443829536438, 0.00463441526517272, 0.004857129417359829, 0.0048528709448874, 0.004667529836297035, 0.004595165140926838, 0.0045193396508693695, 0.0045696585439145565, 0.004452155437320471, 0.004533447325229645, 0.004484157077968121, 0.15193744003772736, 0.004315996076911688, 0.004324068780988455, 0.004266292788088322, 0.004266473930329084, 0.4386448562145233, 0.004400706849992275, 0.004545057658106089, 0.004770305473357439, 0.004753811750560999, 0.0049268449656665325, 0.004944044165313244, 0.0050142682157456875, 0.11481588333845139, 0.005169823300093412, 0.005258351098746061, 0.0052239191718399525, 0.005172278266400099, 0.005309302359819412, 0.005262121558189392, 0.09765853732824326, 0.005142842885106802, 0.005351394414901733, 0.0051412275061011314, 0.005189175717532635, 0.005042052362114191, 0.0050338320434093475, 0.004988858476281166, 0.004933740943670273, 0.004824772011488676, 0.0047467369586229324, 0.0047782668843865395, 0.10050757974386215, 0.004633177071809769, 0.004714177921414375, 0.004517877008765936, 0.004473401233553886, 0.0044250464998185635, 0.004397102631628513, 0.004368210211396217, 0.004348100163042545, 0.004218308255076408, 0.004097198601812124, 0.0040206159465014935, 0.004062838386744261, 0.1332027167081833, 0.003933437168598175, 0.004081656225025654, 0.003907553385943174, 0.0038145247381180525, 0.0038158760871738195, 0.0037262553814798594, 0.003801306476816535, 0.0036291340366005898, 0.0035695743281394243, 0.0036446666345000267, 0.0034635646734386683, 0.0034235105849802494, 0.09656115621328354, 0.003385207848623395, 0.0034802905283868313, 0.0034218430519104004, 0.003360432805493474, 0.0032814531587064266, 0.003457301063463092, 0.003208140842616558, 0.0031465538777410984, 0.0031123091466724873, 0.0030998808797448874, 0.11600857228040695, 0.003010445972904563, 0.0031835180707275867, 0.0030345693230628967, 0.0031450497917830944, 0.002965023275464773, 0.0029574413783848286, 0.00297748320735991, 0.0029345022048801184, 0.12836392223834991, 0.13871468603610992, 0.002986689331009984, 0.15555605292320251, 0.003072586143389344, 0.003118613502010703, 0.0031550207640975714, 0.003238291246816516, 0.003245309693738818, 0.10665717720985413, 0.0033040018752217293, 0.0033527680207043886, 0.003371520433574915, 0.13976001739501953, 0.003562398487702012, 0.0035386094823479652, 0.0036024644505232573, 0.0036601980682462454, 0.0035840515047311783, 0.003560580313205719, 0.0036104314494878054, 0.003863575402647257, 0.003557187970727682, 0.00368433422408998, 0.0035854328889399767, 0.0035254918038845062, 0.0034971002023667097, 0.15838585793972015, 0.003504797350615263, 0.0035337868612259626, 0.003476046957075596, 0.003470292082056403, 0.003437634790316224, 0.0035464907996356487, 0.13135063648223877, 0.0034463622141629457, 0.12686781585216522, 0.0035192088689655066, 0.003612535074353218, 0.003620482049882412, 0.003579171374440193, 0.0036669971887022257, 0.00360652944073081, 0.003737627062946558, 0.0036615997087210417, 0.0035662942100316286, 0.11987129598855972, 0.003547403495758772, 0.003522612852975726, 0.0035529795568436384, 0.0035180544946342707, 0.0035066665150225163, 0.0035150775220245123, 0.003458155319094658, 0.003518295707181096, 0.0034103153739124537, 0.0033742382656782866, 0.003437044797465205, 0.0034312342759221792, 0.0032820773776620626, 0.0034012070391327143, 0.14643706381320953, 0.0032463211100548506, 0.0032193611841648817, 0.0032192503567785025, 0.0032205323223024607, 0.0031978359911590815, 0.0031602662056684494, 0.003117202315479517, 0.0030692717991769314, 0.003146128263324499, 0.003047091420739889, 0.0030254877638071775, 0.0030178409069776535, 0.00291802897118032, 0.0029275629203766584, 0.0028704735450446606, 0.003032257314771414, 0.002788235666230321, 0.0028244294226169586, 0.0027039216365665197, 0.0028280087281018496, 0.0026382370851933956, 0.002620292128995061, 0.0025525372475385666, 0.0025967401452362537, 0.45747119188308716, 0.0026561683043837547, 0.002771755214780569, 0.0028081003110855818, 0.002990158973261714, 0.002917227568104863, 0.0030405670404434204, 0.003029300831258297, 0.12736213207244873, 0.0031514219008386135, 0.0031702863052487373, 0.0032989392057061195, 0.0032988213934004307, 0.0032988106831908226, 0.003345114178955555, 0.14381149411201477, 0.0033619990572333336, 0.0034149102866649628, 0.003445733105763793, 0.003469954477623105, 0.0034606195986270905, 0.003462291555479169, 0.0034843594767153263, 0.12990441918373108, 0.0034896915312856436, 0.11083187162876129, 0.003665344789624214, 0.0036906851455569267, 0.003657642751932144, 0.128977969288826, 0.00372539134696126, 0.003770998679101467, 0.0037632544990628958, 0.003809394547715783, 0.003960596397519112, 0.1153302937746048, 0.0038914517499506474, 0.003974667750298977, 0.003943609539419413, 0.0039970362558960915, 0.0039355019107460976, 0.003961275331676006, 0.003895288798958063, 0.003882068209350109, 0.003954197280108929, 0.003917754627764225, 0.0038417205214500427, 0.0037463088519871235, 0.1217775046825409, 0.0037626237608492374, 0.003714960999786854, 0.00370405288413167, 0.0037536355666816235, 0.0036934022791683674, 0.0036620902828872204, 0.003606157610192895, 0.003663075855001807, 0.11034319549798965, 0.0035662506707012653, 0.003611138556152582, 0.0035485089756548405, 0.4410816729068756, 0.003778021549805999, 0.003789094742387533, 0.00392589857801795, 0.1277131289243698, 0.004089577589184046, 0.004284354392439127, 0.004303456284105778, 0.004357283003628254, 0.004424604121595621, 0.004522763192653656, 0.00464807590469718, 0.004484373610466719, 0.004574538674205542, 0.004503577947616577, 0.004530041944235563, 0.12188923358917236, 0.004596786107867956, 0.004501373507082462, 0.004523234907537699, 0.004573639947921038, 0.0045030247420072556, 0.10416332632303238, 0.11578461527824402, 0.004454892594367266, 0.004474390763789415, 0.0045241848565638065, 0.1261294037103653, 0.004614267498254776, 0.004577519837766886, 0.0047334893606603146, 0.004735986702144146, 0.0048015485517680645, 0.0045717679895460606, 0.004548728931695223, 0.004531501326709986, 0.004479238297790289, 0.004507752135396004, 0.0044089918956160545, 0.004356851801276207, 0.08074817061424255, 0.10440677404403687, 0.004372072871774435, 0.12233389168977737, 0.00444121565669775, 0.004411634057760239, 0.004445879720151424, 0.10200133174657822, 0.004505770280957222, 0.004489854909479618, 0.004610675852745771, 0.004514554049819708, 0.004549016244709492, 0.00451237428933382, 0.004527912009507418, 0.12684482336044312, 0.00447184918448329, 0.004479532595723867, 0.14538291096687317, 0.004441646859049797, 0.004519190173596144, 0.004481423180550337, 0.004555458202958107, 0.004426510538905859, 0.0044702389277517796, 0.1368287205696106, 0.004594562575221062, 0.12718532979488373, 0.004472993779927492, 0.004447636194527149, 0.004496212117373943, 0.0044542644172906876, 0.004468989092856646, 0.004523225128650665, 0.13613387942314148, 0.004521020222455263, 0.004433176014572382, 0.11472558975219727, 0.00452766427770257, 0.004675720352679491, 0.09962978959083557, 0.004564981907606125, 0.004598355386406183, 0.004571596626192331, 0.004632283467799425, 0.004593177232891321, 0.004580499138683081, 0.004534796345978975, 0.004487907979637384, 0.004460552241653204, 0.00443000765517354, 0.004428953863680363, 0.004332795273512602, 0.004292074125260115, 0.004279537592083216, 0.11338666081428528, 0.004200728144496679, 0.004201335366815329, 0.004219613503664732, 0.004118426702916622, 0.00403650151565671, 0.004032472614198923, 0.003999501466751099, 0.003993085585534573, 0.00386488763615489, 0.09718264639377594, 0.0038203666917979717, 0.0037831743247807026, 0.003749232040718198, 0.003844641149044037, 0.0036977280396968126, 0.0036700123455375433, 0.0036380987148731947, 0.0036049536429345608, 0.44273003935813904, 0.0038303781766444445, 0.003756321035325527, 0.1281684786081314]\n",
            "Val loss 0.021274890218462263\n",
            "Val auc roc 0.459628603672925\n",
            "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     2: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16d6bdbcebbd49a7a6ddd6c90dc721f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0237\n",
            "Train Losses : [0.003954366315156221, 0.004013890866190195, 0.003984081093221903, 0.004081584047526121, 0.003994595725089312, 0.004091079346835613, 0.004041242878884077, 0.0041113849729299545, 0.004055722616612911, 0.004069956485182047, 0.004034568555653095, 0.004068260546773672, 0.004021137952804565, 0.004040115512907505, 0.003986782860010862, 0.004087625537067652, 0.11473753303289413, 0.004064737353473902, 0.004048519767820835, 0.003986944444477558, 0.003972122445702553, 0.004018863197416067, 0.003978267777711153, 0.003977583255618811, 0.0041622379794716835, 0.003955143038183451, 0.12346291542053223, 0.003974587190896273, 0.00397515669465065, 0.004008457530289888, 0.003961625508964062, 0.003960876725614071, 0.003943127114325762, 0.0039369952864944935, 0.0039710369892418385, 0.003919927403330803, 0.1269085556268692, 0.003981414251029491, 0.003964425530284643, 0.003968754317611456, 0.09735802561044693, 0.003981613088399172, 0.004031691234558821, 0.003940488677471876, 0.0039516896940767765, 0.0039190188981592655, 0.003951491788029671, 0.003927965182811022, 0.003967944532632828, 0.003933096304535866, 0.0038913143798708916, 0.003944720607250929, 0.0039007344748824835, 0.11382830142974854, 0.0038878300692886114, 0.0038811375852674246, 0.003938705660402775, 0.003951770253479481, 0.00391050148755312, 0.003918493166565895, 0.003896647598594427, 0.12121010571718216, 0.003864734899252653, 0.0038635418750345707, 0.003864483442157507, 0.13665875792503357, 0.0038881769869476557, 0.0038659267593175173, 0.003918404690921307, 0.003875026712194085, 0.0038522970862686634, 0.003888634964823723, 0.003851113375276327, 0.12365729361772537, 0.0039408328011631966, 0.11344274133443832, 0.003927509766072035, 0.0038803627248853445, 0.003883150639012456, 0.003907609730958939, 0.003875992726534605, 0.003884408390149474, 0.003959863446652889, 0.0038951358292251825, 0.003866146318614483, 0.003994042985141277, 0.11367196589708328, 0.003867724444717169, 0.003906975965946913, 0.0038559515960514545, 0.11326896399259567, 0.003856323892250657, 0.0039019896648824215, 0.003853660309687257, 0.0038708047941327095, 0.11754383891820908, 0.003838102100417018, 0.39693593978881836, 0.11353988200426102, 0.0038840612396597862, 0.0038959323428571224, 0.004018289968371391, 0.003952972125262022, 0.003925686702132225, 0.003924194723367691, 0.004075455013662577, 0.12729007005691528, 0.003992681857198477, 0.004007646813988686, 0.00398250762373209, 0.09188582748174667, 0.003987992648035288, 0.004027275368571281, 0.003997841849923134, 0.00401575630530715, 0.00400506192818284, 0.004005654715001583, 0.003997722174972296, 0.11670523136854172, 0.004011329263448715, 0.1392233520746231, 0.004115386866033077, 0.00403495691716671, 0.13173051178455353, 0.003995038103312254, 0.004004905465990305, 0.004072929732501507, 0.004010753706097603, 0.0040513998828828335, 0.004047941882163286, 0.004040529020130634, 0.004006151109933853, 0.00406105350703001, 0.004061879124492407, 0.004008200950920582, 0.004052622243762016, 0.004044624511152506, 0.003994858358055353, 0.0040142107754945755, 0.003980567213147879, 0.003992346581071615, 0.003994377329945564, 0.004043031483888626, 0.003971165511757135, 0.003968788776546717, 0.14462043344974518, 0.14589771628379822, 0.13185754418373108, 0.003980054520070553, 0.004057257901877165, 0.004036348313093185, 0.004034101963043213, 0.09504605084657669, 0.00398246431723237, 0.003986431285738945, 0.003994294907897711, 0.0039965687319636345, 0.004069329239428043, 0.12181966751813889, 0.0039998251013457775, 0.004012943245470524, 0.004003277514129877, 0.003993704449385405, 0.003992895130068064, 0.00397501839324832, 0.004025564994663, 0.004052465315908194, 0.004012696444988251, 0.004066323395818472, 0.11975735425949097, 0.004054292105138302, 0.0040207915008068085, 0.003973462153226137, 0.003977673128247261, 0.003970020916312933, 0.003980336245149374, 0.00413581682369113, 0.003946500830352306, 0.003970746416598558, 0.0040351771749556065, 0.004172970075160265, 0.003984837327152491, 0.003950958140194416, 0.003990390803664923, 0.004056478384882212, 0.0039631882682442665, 0.0039482684805989265, 0.13100691139698029, 0.003999443259090185, 0.004022528883069754, 0.003983457572758198, 0.003975740168243647, 0.0039022290147840977, 0.00391212897375226, 0.003907195758074522, 0.003938189707696438, 0.003913369961082935, 0.00393942603841424, 0.003939807880669832, 0.0039087217301130295, 0.0038528325967490673, 0.15186630189418793, 0.003911868203431368, 0.0038566014263778925, 0.0038857031613588333, 0.003868069499731064, 0.00391010195016861, 0.0038409738335758448, 0.0038307432550936937, 0.003939276095479727, 0.09298548847436905, 0.0038576601073145866, 0.0038441948127001524, 0.0038319893646985292, 0.003905362682417035, 0.003868358675390482, 0.003839158685877919, 0.003809328656643629, 0.0038355281576514244, 0.003810976166278124, 0.003819072851911187, 0.1288170963525772, 0.003918327856808901, 0.0037961371708661318, 0.1178433820605278, 0.0038424183148890734, 0.0038130602333694696, 0.0038316892459988594, 0.11120881885290146, 0.003871331922709942, 0.0038100446108728647, 0.0038295031990855932, 0.003919518552720547, 0.0038150185719132423, 0.003893875749781728, 0.11350857466459274, 0.0038155296351760626, 0.003838619915768504, 0.00395646458491683, 0.003796062897890806, 0.0038020103238523006, 0.003788147121667862, 0.0038970191963016987, 0.00378397386521101, 0.003840650897473097, 0.003831332316622138, 0.003805346554145217, 0.0037818208802491426, 0.0037736992817372084, 0.0038015730679035187, 0.0037661627866327763, 0.0038193874061107635, 0.0038679849822074175, 0.0037462692707777023, 0.0037925960496068, 0.003751746378839016, 0.0038412853609770536, 0.0037454019766300917, 0.12297544628381729, 0.0038165878504514694, 0.003728186944499612, 0.003790827700868249, 0.0037657476495951414, 0.0037169919814914465, 0.003766621695831418, 0.10876664519309998, 0.13770373165607452, 0.0037087281234562397, 0.0037460769526660442, 0.11380428820848465, 0.003885451005771756, 0.0037468615919351578, 0.003740426618605852, 0.003724343841895461, 0.003760782303288579, 0.12190449982881546, 0.003730103373527527, 0.13790515065193176, 0.003731077304109931, 0.0037710857577621937, 0.003815088653936982, 0.0037954330909997225, 0.003764671739190817, 0.0037982866633683443, 0.0037371311336755753, 0.003769533010199666, 0.0038348203524947166, 0.0037595846224576235, 0.0037989302072674036, 0.0037502823397517204, 0.003782115876674652, 0.003812279785051942, 0.003763616317883134, 0.0037402757443487644, 0.003811970818787813, 0.0037368042394518852, 0.003730121999979019, 0.0037566281389445066, 0.003748132847249508, 0.003774539567530155, 0.003771011019125581, 0.0037461041938513517, 0.0037283136043697596, 0.003715750528499484, 0.1086818128824234, 0.0037260004319250584, 0.0037110974080860615, 0.0037147351540625095, 0.003699495457112789, 0.12450145184993744, 0.0037112135905772448, 0.0036864897701889277, 0.003680941415950656, 0.11581308394670486, 0.0037010693922638893, 0.0037416527047753334, 0.0036915417294949293, 0.1412215381860733, 0.0036784608382731676, 0.0036951133515685797, 0.0038792460691183805, 0.09966352581977844, 0.0036956684198230505, 0.0037256155628710985, 0.003793188603594899, 0.11628800630569458, 0.003710194956511259, 0.10379189252853394, 0.0036941636353731155, 0.0037575417663902044, 0.0037053143605589867, 0.0037284856662154198, 0.00370534579269588, 0.0037109104450792074, 0.0037017683498561382, 0.1191527396440506, 0.003731959732249379, 0.10880699753761292, 0.00381353753618896, 0.003736134385690093, 0.003787645837292075, 0.12759076058864594, 0.11673491448163986, 0.0037684068083763123, 0.00384129979647696, 0.003787018358707428, 0.003757540602236986, 0.003755672136321664, 0.12773634493350983, 0.0037835196126252413, 0.0037626514676958323, 0.0038236614782363176, 0.003823351813480258, 0.0037682456895709038, 0.0037994051817804575, 0.003762816544622183, 0.0037855703849345446, 0.0037758813705295324, 0.003771762829273939, 0.0037740166299045086, 0.0037920260801911354, 0.003763785120099783, 0.11203094571828842, 0.003823554841801524, 0.0037637841887772083, 0.0037506921216845512, 0.00377824273891747, 0.0038170863408595324, 0.0037283538840711117, 0.0037586602848023176, 0.003752975258976221, 0.0037602605298161507, 0.003766222158446908, 0.12854817509651184, 0.003735346719622612, 0.0037376093678176403, 0.11723017692565918, 0.003787169000133872, 0.140046164393425, 0.0037671062164008617, 0.0037711714394390583, 0.0037767814937978983, 0.0037375104147940874, 0.003730845171958208, 0.0037921415641903877, 0.003728240728378296, 0.0037513040006160736, 0.003771692980080843, 0.0037734440993517637, 0.00375887518748641, 0.00374178821220994, 0.003741593100130558, 0.003883819095790386, 0.003740786574780941, 0.0037260742392390966, 0.0037328454200178385, 0.0037200800143182278, 0.003700861008837819, 0.0037261599209159613, 0.10686323046684265, 0.003775189397856593, 0.003701587440446019, 0.003703044494614005, 0.0036998658906668425, 0.00370782264508307, 0.0037534728180617094, 0.0037127668038010597, 0.0038341814652085304, 0.43248632550239563, 0.0037483079358935356, 0.11870931088924408, 0.003716080216690898, 0.11586687713861465, 0.0037297590170055628, 0.11726630479097366, 0.003919898997992277, 0.003768314840272069, 0.0037729348987340927, 0.003809932619333267, 0.0038692939560860395, 0.0038227287586778402, 0.0037802928127348423, 0.00386546878144145, 0.0037805589381605387, 0.003797187004238367, 0.1563083678483963, 0.003796556033194065, 0.003920580260455608, 0.003908895421773195, 0.003785607637837529, 0.003797343233600259, 0.003899248084053397, 0.003815945703536272, 0.0038564628921449184, 0.0037834865506738424, 0.003855583956465125, 0.0037778939586132765, 0.003797802608460188, 0.00381734617985785, 0.0037900875322520733, 0.0038767061196267605, 0.0037618912756443024, 0.12208260595798492, 0.15359865128993988, 0.003788331523537636, 0.16109314560890198, 0.09851276129484177, 0.003828147193416953, 0.003807110944762826, 0.0038480788934975863, 0.00380883552134037, 0.0037864530459046364, 0.003935779444873333, 0.003785231150686741, 0.003864547936245799, 0.0037888495717197657, 0.0037975222803652287, 0.0038705538026988506, 0.00390861788764596, 0.0038661821745336056, 0.0038093063049018383, 0.0038384615909308195, 0.003873994806781411, 0.11623101681470871, 0.003851150395348668, 0.003800726495683193, 0.0039079575799405575, 0.0037806881591677666, 0.0038235278334468603, 0.003790818154811859, 0.0037790907081216574, 0.0037601864896714687, 0.003794698044657707, 0.0037904181517660618, 0.003856161143630743, 0.10004757344722748, 0.0037974021397531033, 0.14470872282981873, 0.0037635157350450754, 0.11869112402200699, 0.0037751710042357445, 0.0037666361313313246, 0.003996092826128006, 0.0037853135727345943, 0.00389442453160882, 0.0037600258365273476, 0.0038024475798010826, 0.003791988827288151, 0.003828079206869006, 0.0037422534078359604, 0.11314765363931656, 0.003796813078224659, 0.003760466119274497, 0.126784548163414, 0.0037589434068650007, 0.0037434876430779696, 0.0037686123978346586, 0.0038038711063563824, 0.003738734172657132, 0.003785478649660945, 0.0037514332216233015, 0.0037826879415661097, 0.003745438065379858, 0.003753107972443104, 0.15791331231594086, 0.0037261962424963713, 0.0037663474213331938, 0.0037304712459445, 0.0037492471747100353, 0.003791152499616146, 0.0037796006072312593, 0.003759130835533142, 0.0037654361221939325, 0.003741729538887739, 0.003827097127214074, 0.0038453361485153437, 0.0037227184511721134, 0.0037408226635307074, 0.15343552827835083, 0.003747084643691778, 0.003717660205438733, 0.003708932548761368, 0.0037057495210319757, 0.003804111620411277, 0.0037352615036070347, 0.0037447104696184397, 0.003720618551596999, 0.003765618661418557, 0.003696269355714321, 0.0037872011307626963, 0.003681076457723975, 0.0037768897600471973, 0.0036905002780258656, 0.003721210639923811, 0.0037775307428091764, 0.0037611061707139015, 0.003663461422547698, 0.0036799414083361626, 0.10970868170261383, 0.0036469115875661373, 0.003772216849029064, 0.15852439403533936, 0.13426633179187775, 0.0036878238897770643, 0.12670552730560303, 0.11887279152870178, 0.003691107966005802, 0.003669620491564274, 0.12254439294338226, 0.003689985489472747, 0.0037097556050866842, 0.13578273355960846, 0.0037006342317909002, 0.13236507773399353, 0.0037064964417368174, 0.0037420669104903936, 0.003881661919876933, 0.0038655390962958336, 0.0037642752286046743, 0.0037416652776300907, 0.003728283103555441, 0.003748641349375248, 0.11486653238534927, 0.003754242556169629, 0.0037934111896902323, 0.003744842018932104, 0.003803433384746313, 0.0037545275408774614, 0.11842210590839386, 0.0037852306850254536, 0.0037419579457491636, 0.1177910640835762, 0.0037469302769750357, 0.0037426555063575506, 0.003757396014407277, 0.0037687900476157665, 0.0037431824021041393, 0.10276526212692261, 0.1339777261018753, 0.003768425201997161, 0.003845192724838853, 0.1318686157464981, 0.0037798434495925903, 0.11810608208179474, 0.11372563242912292, 0.003843089332804084, 0.0038371228147298098, 0.0038442974910140038, 0.0037884595803916454, 0.003836399409919977, 0.0038008634001016617, 0.003910121973603964, 0.003802692983299494, 0.1263953000307083, 0.0038529150187969208, 0.0038193671498447657, 0.1096363440155983, 0.0038731941021978855, 0.00384249328635633, 0.0038764742203056812, 0.003837878117337823, 0.12572374939918518, 0.003909440245479345, 0.0038588072638958693, 0.0038623400032520294, 0.003873478388413787, 0.0038202418945729733, 0.003830254077911377, 0.0038377197925001383, 0.0038768190424889326, 0.11637547612190247, 0.10196550190448761, 0.0038378629833459854, 0.0038311786483973265, 0.0038458004128187895, 0.003842199221253395, 0.0038549057208001614, 0.0038511035963892937, 0.0038264687173068523, 0.003815996926277876, 0.10578407347202301, 0.0038665311876684427, 0.0038595942314714193, 0.003875213908031583, 0.00387017079629004, 0.1439555287361145, 0.0038346012588590384, 0.0038478428032249212, 0.0038316515274345875, 0.003837775206193328, 0.0038297635037451982, 0.12166781723499298, 0.0038917886558920145, 0.0038284205365926027, 0.003875315422192216, 0.003846644889563322, 0.0038401458878070116, 0.12923087179660797, 0.0038689877837896347, 0.00391255272552371, 0.003898648312315345, 0.003910285886377096, 0.003854519221931696, 0.0038258491549640894, 0.0038467852864414454, 0.12168028205633163, 0.003827616572380066, 0.0038484008982777596, 0.003836784977465868, 0.0038159505929797888, 0.0038579474203288555, 0.0038107549771666527, 0.0038656892720609903, 0.003815848845988512, 0.003821762278676033, 0.003869681851938367, 0.003947997000068426, 0.003841616213321686, 0.003799832658842206, 0.0037981290370225906, 0.0038015134632587433, 0.0037829033099114895, 0.003831281792372465, 0.0038351949770003557, 0.003805361455306411, 0.0037780103739351034, 0.003827538574114442, 0.003766461042687297, 0.003827360225841403, 0.13219395279884338, 0.003796175355091691, 0.003800563747063279, 0.0037644668482244015, 0.10047982633113861, 0.003802323481068015, 0.003909593913704157, 0.0037679439410567284, 0.10397268086671829, 0.0037558958865702152, 0.003752791089937091, 0.00378421600908041, 0.003749183379113674, 0.003785280976444483, 0.003778834594413638, 0.0038106015417724848, 0.003755618119612336, 0.0037720603868365288, 0.003805631771683693, 0.0038417086470872164, 0.003942499868571758, 0.003778572427108884, 0.0038037209305912256, 0.0037980203051120043, 0.00382851785980165, 0.003859409363940358, 0.003821674967184663, 0.0037313858047127724, 0.003771208692342043, 0.0037151614669710398, 0.0037480024620890617, 0.003696444910019636, 0.0037135884631425142, 0.1178876981139183, 0.0037700815591961145, 0.0037150345742702484, 0.0036984507460147142, 0.003692016238346696, 0.003704556729644537, 0.0037452192045748234, 0.12407461553812027, 0.10790208727121353, 0.11839491128921509, 0.003693757811561227, 0.0036856092046946287, 0.003686701413244009, 0.0037019052542746067, 0.11133085191249847, 0.0037273091729730368, 0.11817122995853424, 0.003720266046002507, 0.003731359727680683, 0.0037493063136935234, 0.003815664676949382, 0.1032586544752121, 0.003809720277786255, 0.0037394489627331495, 0.003760547609999776, 0.003762610722333193, 0.0037645758129656315, 0.003752298653125763, 0.0037294491194188595, 0.0037416890263557434, 0.003725459799170494, 0.11531197279691696, 0.0037445107009261847, 0.003724247682839632, 0.0037239042576402426, 0.0037390654906630516, 0.0987560898065567, 0.0038225387688726187, 0.0037654098123311996, 0.10644515603780746, 0.0037533214781433344, 0.0037381865549832582, 0.0037887166254222393, 0.003782090498134494, 0.0037281992845237255, 0.0037227284628897905, 0.0037943352945148945, 0.00373691669665277, 0.10650385916233063, 0.003796343458816409, 0.003762579057365656, 0.0037606987170875072, 0.0037135521415621042, 0.0037425183691084385, 0.003790963673964143, 0.1298072338104248, 0.0038402159698307514, 0.0037290542386472225, 0.003734646597877145, 0.10532449185848236, 0.11488969624042511, 0.0037874088156968355, 0.0037411008961498737, 0.12236600369215012, 0.003874825779348612, 0.10972822457551956, 0.003841714235022664, 0.0037443183828145266, 0.003848471213132143, 0.0037722571287304163, 0.003741755848750472, 0.0038139938842505217, 0.0037839191500097513, 0.0038121615070849657, 0.003753249067813158, 0.00374100124463439, 0.0037918107118457556, 0.003795093158259988, 0.11938544362783432, 0.003761402564123273, 0.0037424948532134295, 0.0037737886887043715, 0.0038749370723962784, 0.0037707947194576263, 0.003768159309402108, 0.003797061974182725, 0.0037698985543102026, 0.0038101954851299524, 0.0037888872902840376, 0.003807914676144719, 0.15745976567268372, 0.0037730513140559196, 0.0037284325808286667, 0.003782365471124649, 0.0037436215206980705, 0.0037463605403900146, 0.0038458926137536764, 0.003795857075601816, 0.0037585634272545576, 0.0037425770424306393, 0.14953094720840454, 0.0037788893096148968, 0.003725597867742181, 0.0037471898831427097, 0.0037515319418162107, 0.0037364887539297342, 0.00378415291197598, 0.1102810874581337, 0.0037037425208836794, 0.0037075825966894627, 0.0037271284963935614, 0.003699982538819313, 0.0037160213105380535, 0.003761827480047941, 0.003735438920557499, 0.003823805134743452, 0.0036964393220841885, 0.0036974619142711163, 0.0037360116839408875, 0.003697072621434927, 0.0037442271132022142, 0.0037161866202950478, 0.0037614447064697742, 0.003705943003296852, 0.003679612884297967, 0.003668205812573433, 0.10442107170820236, 0.003670875681564212, 0.003709506941959262, 0.0037122005596756935, 0.0037016968708485365, 0.1270904839038849, 0.003662985982373357, 0.1144808903336525, 0.003705147886648774, 0.0036596700083464384, 0.0036943277809768915, 0.003668238176032901, 0.0037127186078578234, 0.003719591535627842, 0.10565005242824554, 0.003737495979294181, 0.0037186485715210438, 0.003683186136186123, 0.1241718977689743, 0.1334141194820404, 0.0036733613815158606, 0.003735546488314867, 0.0037422366440296173, 0.1297568380832672, 0.11085618287324905, 0.003684478346258402, 0.003692083526402712, 0.0037166117690503597, 0.003759053535759449, 0.0037287003360688686, 0.003759880783036351, 0.12955830991268158, 0.0038059873040765524, 0.00384723418392241, 0.0037051804829388857, 0.003743148408830166, 0.12272948771715164, 0.003735615871846676, 0.0038322387263178825, 0.0037949969992041588, 0.0037401688750833273, 0.003707316005602479, 0.11243122071027756, 0.003722377819940448, 0.0037627415731549263, 0.003730658208951354, 0.0037795952521264553, 0.003728763898834586, 0.0038454097229987383, 0.003731435863301158, 0.0037281408440321684, 0.0038823988288640976, 0.11688979715108871, 0.0037175423931330442, 0.003777136793360114, 0.003819257253780961, 0.12839142978191376, 0.003797098994255066, 0.0037332416977733374, 0.003724202513694763, 0.0037374943494796753, 0.00373220001347363, 0.0037484439089894295, 0.003741880413144827, 0.003779485123232007, 0.11074326187372208, 0.003743943525478244, 0.0037577932234853506, 0.003807609900832176, 0.003735506907105446, 0.003723358968272805, 0.10683153569698334, 0.0037132478319108486, 0.0037660396192222834, 0.0037228178698569536, 0.0037047124933451414, 0.003773800330236554, 0.0038468404673039913, 0.003722242545336485, 0.0037307399325072765, 0.0037107341922819614, 0.0038182863499969244, 0.0038504849653691053, 0.003710083430632949, 0.0037170150317251682, 0.0036880827974528074, 0.0036854168865829706, 0.003674489911645651, 0.13854695856571198, 0.0036759725771844387, 0.0036685564555227757, 0.003740382380783558, 0.003712944220751524, 0.0036739278584718704, 0.0037352151703089476, 0.0037402710877358913, 0.003663480281829834, 0.0037313862703740597, 0.003700665896758437, 0.003680031979456544, 0.0036556576378643513, 0.0036958667915314436, 0.0037370221689343452, 0.003747669281437993, 0.003658758709207177, 0.0037362072616815567, 0.003666147356852889, 0.0036590294912457466, 0.0037034121342003345, 0.0036649086978286505, 0.0036928909830749035, 0.003652342827990651, 0.0037062466144561768, 0.003691708203405142, 0.003673439146950841, 0.003669786499813199, 0.00369991990737617, 0.00366032961755991, 0.003663763403892517, 0.0036072733346372843, 0.003681784961372614, 0.0036756114568561316, 0.003626410150900483, 0.003603090299293399, 0.0035913444589823484, 0.1333388239145279, 0.003590998938307166, 0.0035872231237590313, 0.003590487176552415, 0.0035929621662944555, 0.003687557764351368, 0.47853612899780273, 0.0035818442702293396, 0.0036461155395954847, 0.003614416578784585, 0.0036022153217345476, 0.14064593613147736, 0.003657776862382889, 0.003674341831356287, 0.0037083569914102554, 0.0036390863824635744, 0.003637914778664708, 0.11231990903615952, 0.0036936961114406586, 0.0036293172743171453, 0.003673392813652754, 0.0036851554177701473, 0.0036216448061168194, 0.003624705597758293, 0.003745101857930422, 0.003620794741436839, 0.11195117980241776, 0.003644656389951706, 0.0036248082760721445, 0.003658539615571499, 0.12992261350154877, 0.003657497465610504, 0.0036470326595008373, 0.003623035503551364, 0.003663825336843729, 0.0036750612780451775, 0.0036293473094701767, 0.11268462985754013, 0.12898913025856018, 0.0036933021619915962, 0.0036415394861251116, 0.003638483351096511, 0.0036611768882721663, 0.00366132496856153, 0.0036315559409558773, 0.0036977101117372513, 0.13449989259243011, 0.003691586432978511, 0.003635698463767767, 0.003732150187715888, 0.0036868362221866846, 0.003693658160045743, 0.0036729208659380674, 0.003728163428604603, 0.0036375359632074833, 0.0036978712305426598, 0.0036722372751682997, 0.003636382520198822, 0.13505195081233978, 0.003663540119305253, 0.0036919608246535063, 0.003698167158290744, 0.11524144560098648, 0.0037326004821807146, 0.0036260350607335567, 0.0036607645452022552, 0.0036920097190886736, 0.0036595582496374846, 0.0037001280579715967, 0.0037075052969157696, 0.136551171541214, 0.00374100124463439, 0.13454623520374298, 0.0036827039439231157, 0.0036778978537768126, 0.0037365152966231108, 0.003683882998302579, 0.003694390645250678, 0.00365075352601707, 0.0036303119268268347, 0.003925931639969349, 0.003776458790525794, 0.0036828748416155577, 0.003636874258518219, 0.00371882994659245, 0.003722794121131301, 0.003648156300187111, 0.0036278278566896915, 0.0036327519919723272, 0.0036230520345270634, 0.003645542776212096, 0.003650874365121126, 0.0036445138975977898, 0.0036241926718503237, 0.13460376858711243, 0.0036198687739670277, 0.0036700251512229443, 0.0036060246638953686, 0.003634654451161623, 0.1162528470158577, 0.0036530073266476393, 0.0036772629246115685, 0.471600204706192, 0.003643632400780916, 0.0036959031131118536, 0.003639343660324812, 0.11518073081970215, 0.003650400787591934, 0.003699463326483965, 0.0036573426332324743, 0.12358512729406357, 0.0036962416488677263, 0.0036509376950562, 0.0036574015393853188, 0.003644200274720788, 0.003659903071820736, 0.0037502183113247156, 0.0036793474573642015, 0.0037321040872484446, 0.003650015452876687, 0.003772544674575329, 0.003694529877975583, 0.0036613252013921738, 0.003750633215531707, 0.0036524476017802954, 0.003778200363740325, 0.0036737173795700073, 0.0037274686619639397, 0.10777898877859116, 0.0036974987015128136, 0.003721460700035095, 0.00366000272333622, 0.0037238989025354385, 0.003729876596480608, 0.0036571749951690435, 0.0036841905675828457, 0.10146283358335495, 0.003716308856382966, 0.003652299754321575, 0.0036983832251280546, 0.003733736230060458, 0.003648255253210664, 0.12504224479198456, 0.0036861009430140257, 0.0036548080388456583, 0.0036337075289338827, 0.0037083656061440706, 0.0037290211766958237, 0.0036823025438934565, 0.003674557898193598, 0.0036561323795467615, 0.0036528375931084156, 0.003649464575573802, 0.003627112600952387, 0.0037198602221906185, 0.0036361548118293285, 0.003638580674305558, 0.0036524483002722263, 0.003665567608550191, 0.12791089713573456, 0.0036278755869716406, 0.0036555302795022726, 0.47603386640548706, 0.003644862212240696, 0.0036344570107758045, 0.003645597957074642, 0.00365138566121459, 0.0037190434522926807, 0.003694674000144005, 0.0036466384772211313, 0.0036483893636614084, 0.13629375398159027, 0.003757137805223465, 0.0037002062890678644, 0.00368139217607677, 0.0036861232947558165, 0.1159372553229332, 0.0037387204356491566, 0.1251518726348877, 0.14148196578025818, 0.1500740647315979, 0.0036867198068648577, 0.0037088405806571245, 0.0037524541839957237, 0.0037071737460792065, 0.11267486214637756, 0.003711517434567213, 0.003697524545714259, 0.0037012076936662197, 0.12050750106573105, 0.003718563122674823, 0.003713342361152172, 0.0037250786554068327, 0.3930972218513489, 0.0037328789476305246, 0.003701799549162388, 0.003811491886153817, 0.003702053800225258, 0.0037148301489651203, 0.13506285846233368, 0.11502358317375183, 0.09705349057912827, 0.0037350475322455168, 0.00377655029296875, 0.003873314941301942, 0.003732027718797326, 0.0037810918875038624, 0.13396288454532623, 0.0037414764519780874, 0.0037518686149269342, 0.003814537776634097, 0.10393587499856949, 0.003759569488465786, 0.0037929592654109, 0.003810957772657275, 0.003752974094823003, 0.0037536772433668375, 0.003771872026845813, 0.00379456439986825, 0.0037841140292584896, 0.0037882940378040075, 0.0037539638578891754, 0.003789023496210575, 0.0038186004385352135, 0.13101425766944885, 0.0038036557380110025, 0.0037818613927811384, 0.0037395525723695755, 0.0037633494939655066, 0.0037668596487492323, 0.00377472722902894, 0.003790784627199173, 0.13148993253707886, 0.0037548739928752184, 0.10531436651945114, 0.0037699807435274124, 0.0038297350984066725, 0.0037838907446712255, 0.0037703884299844503, 0.0037763172294944525, 0.003778658574447036, 0.0037800546269863844, 0.11822301894426346, 0.0038205464370548725, 0.0037662654649466276, 0.0037588386330753565, 0.1238454207777977, 0.003777110483497381, 0.0038181175477802753, 0.0038086797576397657, 0.003752797609195113, 0.003740226849913597, 0.003766643349081278, 0.0037614167667925358, 0.003822626080363989, 0.09711913764476776, 0.003748164512217045, 0.13790029287338257, 0.0037492152769118547, 0.003743788693100214, 0.003765894565731287, 0.003811124013736844, 0.0037756492383778095, 0.0037604423705488443, 0.003794882446527481, 0.00375725282356143, 0.0037565946113318205, 0.003790969494730234, 0.12588630616664886, 0.0038184758741408587, 0.0037693032063543797, 0.003773589851334691, 0.0037738694809377193, 0.003813998308032751, 0.003769252449274063, 0.003738133003935218, 0.0037529333494603634, 0.003767124842852354, 0.0038362143095582724, 0.003781894687563181, 0.13682948052883148, 0.0037840234581381083, 0.0037557564210146666, 0.0037320491392165422, 0.0037347523029893637, 0.12917844951152802, 0.0037504148203879595, 0.003737956052646041, 0.00394038949161768, 0.0037503058556467295, 0.00374542991630733, 0.003736476181074977, 0.003798792604357004, 0.0037772012874484062, 0.0037884823977947235, 0.1065220981836319, 0.12019554525613785, 0.0037739896215498447, 0.003729021642357111, 0.0037364820018410683, 0.0038323102053254843, 0.0037248244043439627, 0.1297536939382553, 0.0037433691322803497, 0.0037481612525880337, 0.003725015791133046, 0.003725982503965497, 0.0037487715017050505, 0.0037932167761027813, 0.003748962888494134, 0.003803135361522436, 0.003768333001062274, 0.0037625415716320276, 0.0037264965940266848, 0.0038001739885658026, 0.003734168829396367, 0.0038009013514965773, 0.003745540278032422, 0.14101077616214752, 0.003819844452664256, 0.11073850840330124, 0.0037321895360946655, 0.0037199310027062893, 0.0037285953294485807, 0.0037435670383274555, 0.003743930486962199, 0.003811546368524432, 0.0037258132360875607, 0.003743239212781191, 0.0038116949144750834, 0.003737399121746421, 0.1341620534658432, 0.003722500056028366, 0.0037708645686507225, 0.0037364945746958256, 0.0037202872335910797, 0.0038250486832112074, 0.003728058421984315, 0.0038679386489093304, 0.13715693354606628, 0.10781797766685486, 0.1434895396232605, 0.00374875427223742, 0.13112692534923553, 0.0037470757961273193, 0.0038079465739428997, 0.10856156796216965, 0.003730171360075474, 0.0037225689738988876, 0.003778285114094615, 0.0037559466436505318, 0.1461760401725769, 0.003753435332328081, 0.003752901451662183, 0.003777628531679511, 0.0038185729645192623, 0.003737576073035598, 0.1138022318482399, 0.0038037013728171587, 0.0037947355303913355, 0.0037492099218070507, 0.003811390371993184, 0.0037374182138592005, 0.13421626389026642, 0.0037878069560974836, 0.0037365027237683535, 0.003730140859261155, 0.11565414816141129, 0.003735898295417428, 0.0037463558837771416, 0.0037904344499111176, 0.0037744753062725067, 0.0037581396754831076, 0.003794222604483366, 0.0038228053599596024, 0.003745991038158536, 0.003756143618375063, 0.0037401996087282896, 0.003762179985642433, 0.0038581753615289927, 0.0037773947697132826, 0.0037537103053182364, 0.003750450909137726, 0.11987804621458054, 0.0037554451264441013, 0.0037648191209882498, 0.14447176456451416, 0.0037627473939210176, 0.003744683228433132, 0.003745267167687416, 0.003850075649097562, 0.0037688410375267267, 0.003774441545829177, 0.0039492263458669186, 0.004017672501504421, 0.0038213918451219797, 0.003789125708863139, 0.0037812574300915003, 0.10037390887737274, 0.003795322496443987, 0.0037678151857107878, 0.0038346389774233103, 0.0037585231475532055, 0.003790362738072872, 0.003784361993893981, 0.0037679625675082207, 0.0037531033158302307, 0.0037452566903084517, 0.003743962151929736, 0.003755842335522175, 0.0037753090728074312, 0.0037975055165588856, 0.09784087538719177, 0.0037964547518640757, 0.0037778345867991447, 0.003723562229424715, 0.0038640410639345646, 0.003849664004519582, 0.13490431010723114, 0.003761687083169818, 0.0037451330572366714, 0.003738388419151306, 0.0037763179279863834, 0.0037253322079777718, 0.11024490743875504, 0.13640737533569336, 0.0037884123157709837, 0.10903777927160263, 0.0038167773745954037, 0.0037549794651567936, 0.0037868469953536987, 0.10254828631877899, 0.003772496245801449, 0.14819344878196716, 0.10195562243461609, 0.0037698065862059593, 0.1064622551202774, 0.12692484259605408, 0.0037861003074795008, 0.09848154336214066, 0.13018165528774261, 0.0037633643951267004, 0.003765243338420987, 0.003737114369869232, 0.0037809174973517656, 0.0037618139758706093, 0.13636651635169983, 0.14422427117824554, 0.003770782146602869, 0.0037734436336904764, 0.0037427088245749474, 0.12863299250602722, 0.0038326613139361143, 0.0037984061054885387, 0.0037683749105781317, 0.0038452111184597015, 0.003832637332379818, 0.003760141786187887, 0.11278050392866135, 0.0037647804711014032, 0.8886367678642273, 0.0037728797178715467, 0.0038155578076839447, 0.11195115745067596, 0.003772696712985635, 0.0037940943147987127, 0.003785116132348776, 0.003770178649574518, 0.003777049947530031, 0.0038032718002796173, 0.003786591812968254, 0.003843095386400819, 0.0038192530628293753, 0.003871327731758356, 0.003797283163294196, 0.11864280700683594, 0.003794905496761203, 0.0038364457432180643, 0.0037770739290863276, 0.0038502446841448545, 0.003793202806264162, 0.00380820338614285, 0.0038223997689783573, 0.0038356808945536613, 0.0038532146718353033, 0.0038115570787340403, 0.00388452154584229, 0.11995362490415573, 0.003790545742958784, 0.0038219878915697336, 0.00379861774854362, 0.003795195836573839, 0.0038062501698732376, 0.003777422709390521, 0.003847433952614665, 0.0038139375392347574, 0.0038380820769816637, 0.12184414267539978, 0.11863462626934052, 0.4609733819961548, 0.003783964551985264, 0.0038999966345727444, 0.11729425936937332, 0.0038665318861603737, 0.0037833719979971647, 0.003921149764209986, 0.11910269409418106, 0.0038335882127285004, 0.003819085191935301, 0.0038564871065318584, 0.003826832864433527, 0.0038154744543135166, 0.0038255813997238874, 0.0038162460550665855, 0.11564565449953079, 0.08729945868253708, 0.003942249342799187, 0.0037964226212352514, 0.12045868486166, 0.1078290194272995, 0.0038193666841834784, 0.003911130595952272, 0.003802333725616336, 0.0038000119384378195, 0.0039169806987047195, 0.0037942277267575264, 0.0038630447816103697, 0.0038543115369975567, 0.11746052652597427, 0.003876894013956189, 0.003842784557491541, 0.0038196826353669167, 0.003796523669734597, 0.003860475029796362, 0.003874504240229726, 0.0038295318372547626, 0.003961856942623854, 0.0038590861950069666, 0.003895958885550499, 0.0038358059246093035, 0.11883241683244705, 0.12903840839862823, 0.003850282169878483, 0.0038234535604715347, 0.10948359221220016, 0.0038141682744026184, 0.0038141922559589148, 0.13043592870235443, 0.0038412308786064386, 0.0038132930640131235, 0.0038883318193256855, 0.003842264646664262, 0.003831961890682578, 0.003797224024310708, 0.003831069217994809, 0.1011294573545456, 0.003817423479631543, 0.0038235920947045088, 0.0038064385298639536, 0.0038061849772930145, 0.0038308564107865095, 0.003871994325891137, 0.0038743880577385426, 0.003816689597442746, 0.1276722401380539, 0.003829655470326543, 0.003967872355133295, 0.003879489144310355, 0.0038137526717036963, 0.00387296499684453, 0.0038080380763858557, 0.0038487270940095186, 0.003807848785072565, 0.0038152853958308697, 0.0038420092314481735, 0.003796862903982401, 0.0038367186207324266, 0.0038473564200103283, 0.003821253078058362, 0.0038355642464011908, 0.003869415493682027, 0.0038899576757103205, 0.0038063046522438526, 0.0038522190880030394, 0.0037952496204525232, 0.0038525641430169344, 0.003848990425467491, 0.0038226034957915545, 0.0038320214953273535, 0.39798325300216675, 0.003839291865006089, 0.003858291544020176, 0.0037991611752659082, 0.0038036834448575974, 0.11913948506116867, 0.0038110266905277967, 0.10282972455024719, 0.003876333124935627, 0.0038128113374114037, 0.003796142991632223, 0.003952312748879194, 0.003929284866899252, 0.0038082024548202753, 0.003797783050686121, 0.0038784202188253403, 0.11711879074573517, 0.00390884792432189, 0.003798576071858406, 0.003812815761193633, 0.0038181727286428213, 0.003815798321738839, 0.003794611431658268, 0.003872293746098876, 0.0038396159652620554, 0.0038333877455443144, 0.0038160434924066067, 0.0038857413455843925, 0.003838314674794674, 0.0038069398142397404, 0.0038211143109947443, 0.003800417296588421, 0.00383597775362432, 0.0038204726297408342, 0.0038033747114241123, 0.003815160132944584, 0.0038050098810344934, 0.0038747701328247786, 0.0037996075116097927, 0.003817530581727624, 0.003891357686370611, 0.11588586866855621, 0.0038265115581452847, 0.003833151888102293, 0.0038246745243668556, 0.00380145781673491, 0.003827657550573349, 0.0038608848117291927, 0.003826381405815482, 0.003850202541798353, 0.003883304772898555, 0.0037954654544591904, 0.0038179263938218355]\n",
            "Val loss 0.02153753993430532\n",
            "Val auc roc 0.4564139393317602\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-05.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27c3461c-3a25-41b2-8720-a2023fb7c87c"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "807d2353-b7aa-4ac6-f048-950f71544973"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f794bd06-e920-41b7-9fdd-a435935cf8eb"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "8883cedf-b417-4056-ef72-fb1ce676ee68"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Directed_Hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Directed_Hate]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cba2606f-3097-45c8-a11f-b0016ec42863"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-08-06 10:19:55.943694'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}