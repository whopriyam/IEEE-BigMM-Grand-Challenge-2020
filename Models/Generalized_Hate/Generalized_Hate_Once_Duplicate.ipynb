{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generalized_Hate_Once_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92f061f4e39542b4a5361c214eeba830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42accabcb8fd4489a73517d7cfd56cf8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d26920ca4ccd445ea7b443dcd80a7a74",
              "IPY_MODEL_9b9f88ee984a46c1936ae0102ce571f9"
            ]
          }
        },
        "42accabcb8fd4489a73517d7cfd56cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d26920ca4ccd445ea7b443dcd80a7a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_73a906801a244160a7f7f9ce6f510372",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5b33508f8814940ab380d2940e527b9"
          }
        },
        "9b9f88ee984a46c1936ae0102ce571f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0c8902f7d2f4a838244160e0c8b9757",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:10&lt;00:00, 22.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad6f01b97f0a49829a8906567451b391"
          }
        },
        "73a906801a244160a7f7f9ce6f510372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5b33508f8814940ab380d2940e527b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0c8902f7d2f4a838244160e0c8b9757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad6f01b97f0a49829a8906567451b391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d6040a5c07d4bcc87b6ba399c8e2b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f8f53dc3cb946b4ac417efa66ae5561",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a5c00f7610b46a7a74b7b8fba93db7e",
              "IPY_MODEL_966a9030d9324a3d8116045d35c40baf"
            ]
          }
        },
        "2f8f53dc3cb946b4ac417efa66ae5561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a5c00f7610b46a7a74b7b8fba93db7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b3b79724a5044748128be817eed1e7a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1636,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1636,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f2667e49893417ab331452ddfebad40"
          }
        },
        "966a9030d9324a3d8116045d35c40baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8deb786731744561a4aa54b731130491",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1636/1636 [15:01&lt;00:00,  1.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a9c3ce4bc5b4c82a95660adca21f97f"
          }
        },
        "2b3b79724a5044748128be817eed1e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f2667e49893417ab331452ddfebad40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8deb786731744561a4aa54b731130491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a9c3ce4bc5b4c82a95660adca21f97f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72f6fb8aa2514f299b68314fafa9344b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e15026953b740a1bc01f60732451e2e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b10f623b88ce43a2922f3047dfb5f612",
              "IPY_MODEL_128078580ab446f6b5a087d3d4102590"
            ]
          }
        },
        "9e15026953b740a1bc01f60732451e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b10f623b88ce43a2922f3047dfb5f612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c94c3147d8f413d8ef264acb3e7e460",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1636,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1636,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d8ac73b13404dceb9e1fb2ff24fd681"
          }
        },
        "128078580ab446f6b5a087d3d4102590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8245ae5a386b47c098d52d5efd26531d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1636/1636 [15:00&lt;00:00,  1.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab460535854a4fb2932a74b8092df45e"
          }
        },
        "8c94c3147d8f413d8ef264acb3e7e460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d8ac73b13404dceb9e1fb2ff24fd681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8245ae5a386b47c098d52d5efd26531d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab460535854a4fb2932a74b8092df45e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c8d17105eef4631a236968f5ad5ae93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2da4237c1b1749eba78a0080b34735fe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4283cc5184a149fc8402e92128820c84",
              "IPY_MODEL_ec216528ce724bd7ac1761a2e69f553a"
            ]
          }
        },
        "2da4237c1b1749eba78a0080b34735fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4283cc5184a149fc8402e92128820c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e0e2bde65aa4c57bef9d219f642ad0b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1636,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1636,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69e6c5e7badd45958d7d738aefc43328"
          }
        },
        "ec216528ce724bd7ac1761a2e69f553a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_82ec870878ba4ec188a46fd4a7c3d4a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1636/1636 [15:00&lt;00:00,  1.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d0a2fb99f2546b6b83d67e885c20c3f"
          }
        },
        "5e0e2bde65aa4c57bef9d219f642ad0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69e6c5e7badd45958d7d738aefc43328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82ec870878ba4ec188a46fd4a7c3d4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d0a2fb99f2546b6b83d67e885c20c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "bc1d892d-fa00-4ff7-8be2-89b2637e51be"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 7.29 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8df0f7a-54d6-483e-bc54-753cf4ab846f"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db1f187c-1597-4952-989c-1e8ace23acd9"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7522b159-24e5-4490-a6c2-0f7472b4f20f"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "27d2b2a1-12c1-404e-e609-35a848f442df"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "7d6e452d-a2c7-4122-9671-ac634df3b030"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 25.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a9872ee5-3c04-4720-8519-8bfe87b664af"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "23c9e425-4c80-4afe-e63b-b3a55fc06407"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "4105d2d2-426e-4c51-bf31-f7595a392c28"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "170e8999-9b6a-44d1-80c5-c9bab59bc652"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    #MeToo: Sruthi Hariharan finds supporters in P...\n",
              "1                                        ption - no:2 \n",
              "2    College Student Raped Woman After She Attended...\n",
              "3    #MeToo In India Is Just A Tip Of An Iceberg An...\n",
              "4     Four-member panel of retired judges to conduc...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0faae0f1-e20e-490d-d155-8bd6c4c977dc"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:14<00:00, 28192577.77B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab68d7ed-4339-470e-ff21-d37420d8b911"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 668557.05B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c995e602-4122-4a46-ae24-c3c8cfceead3"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55c38a7b-f6d3-421a-f97e-1be83c627b2f"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        df4 = df2.copy().reset_index(drop=True)\n",
        "        df5 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            # random.shuffle(text)\n",
        "            # text3 = ' '.join(text)\n",
        "            # df3['text'][i]=text3\n",
        "            # random.shuffle(text)\n",
        "            # text4 = ' '.join(text)\n",
        "            # df4['text'][i]=text4\n",
        "            # random.shuffle(text)\n",
        "            # text5 = ' '.join(text)\n",
        "            # df5['text'][i]=text5\n",
        "        self.data = self.data.append(df2, ignore_index=True)\n",
        "        # self.data = self.data.append(df3, ignore_index=True)\n",
        "        # self.data = self.data.append(df4, ignore_index=True)\n",
        "        # self.data = self.data.append(df5, ignore_index=True)\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ebbb8fa-60ae-43ac-bc29-b492ba5cec57"
      },
      "source": [
        "col_name = \"Generalized_Hate\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828,
          "referenced_widgets": [
            "92f061f4e39542b4a5361c214eeba830",
            "42accabcb8fd4489a73517d7cfd56cf8",
            "d26920ca4ccd445ea7b443dcd80a7a74",
            "9b9f88ee984a46c1936ae0102ce571f9",
            "73a906801a244160a7f7f9ce6f510372",
            "a5b33508f8814940ab380d2940e527b9",
            "b0c8902f7d2f4a838244160e0c8b9757",
            "ad6f01b97f0a49829a8906567451b391",
            "8d6040a5c07d4bcc87b6ba399c8e2b08",
            "2f8f53dc3cb946b4ac417efa66ae5561",
            "3a5c00f7610b46a7a74b7b8fba93db7e",
            "966a9030d9324a3d8116045d35c40baf",
            "2b3b79724a5044748128be817eed1e7a",
            "7f2667e49893417ab331452ddfebad40",
            "8deb786731744561a4aa54b731130491",
            "6a9c3ce4bc5b4c82a95660adca21f97f",
            "72f6fb8aa2514f299b68314fafa9344b",
            "9e15026953b740a1bc01f60732451e2e",
            "b10f623b88ce43a2922f3047dfb5f612",
            "128078580ab446f6b5a087d3d4102590",
            "8c94c3147d8f413d8ef264acb3e7e460",
            "0d8ac73b13404dceb9e1fb2ff24fd681",
            "8245ae5a386b47c098d52d5efd26531d",
            "ab460535854a4fb2932a74b8092df45e",
            "8c8d17105eef4631a236968f5ad5ae93",
            "2da4237c1b1749eba78a0080b34735fe",
            "4283cc5184a149fc8402e92128820c84",
            "ec216528ce724bd7ac1761a2e69f553a",
            "5e0e2bde65aa4c57bef9d219f642ad0b",
            "69e6c5e7badd45958d7d738aefc43328",
            "82ec870878ba4ec188a46fd4a7c3d4a4",
            "1d0a2fb99f2546b6b83d67e885c20c3f"
          ]
        },
        "outputId": "db672969-ba06-4071-8b63-33698624f751"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6546\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92f061f4e39542b4a5361c214eeba830",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d6040a5c07d4bcc87b6ba399c8e2b08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1636.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0414\n",
            "Train Losses : [0.17847584187984467, 1.2200071811676025, 0.17015506327152252, 0.0292535200715065, 2.024060010910034, 1.729703426361084, 0.04242970421910286, 0.7988905310630798, 0.45760396122932434, 0.15399374067783356, 0.22063954174518585, 0.11955185979604721, 0.08690110594034195, 0.19114094972610474, 0.11055624485015869, 0.18827833235263824, 0.06605647504329681, 0.08384405821561813, 0.05216693505644798, 0.32441458106040955, 0.035716574639081955, 0.024575617164373398, 0.11531364172697067, 0.02327803522348404, 0.07926440238952637, 0.02017957530915737, 0.03985971584916115, 0.010165863670408726, 0.007469499949365854, 0.02163650281727314, 0.02226400002837181, 0.004807757213711739, 0.007022087462246418, 0.291360080242157, 0.06448943167924881, 0.011504960246384144, 0.3914559483528137, 0.005544555373489857, 0.0035318329464644194, 0.0021826880984008312, 0.011486680246889591, 0.01722189038991928, 0.010246113874018192, 0.008912683464586735, 0.011185156181454659, 0.004365895409137011, 0.00515102781355381, 0.41861289739608765, 1.6722491979599, 0.0020346888341009617, 0.004316893871873617, 0.003102028276771307, 0.00806255079805851, 0.04932889714837074, 0.0018348926678299904, 0.014513925649225712, 0.0021789735183119774, 0.009205330163240433, 0.002827523974701762, 0.002541491063311696, 0.0211159810423851, 0.09056614339351654, 0.1361013948917389, 0.0026496693026274443, 0.001417176448740065, 0.0025799700524657965, 0.0071818591095507145, 0.008045227266848087, 0.002018867526203394, 0.44435712695121765, 0.4278160631656647, 0.21110251545906067, 0.003605681238695979, 0.003049906576052308, 0.002008374547585845, 0.0019021104089915752, 0.002531940583139658, 0.008738406002521515, 0.0056014577858150005, 0.007619077805429697, 0.2830641269683838, 0.057435762137174606, 0.17050626873970032, 0.005218603648245335, 0.005788063630461693, 0.016693320125341415, 0.008511989377439022, 0.010598250664770603, 0.005672219209372997, 0.005235921125859022, 0.007960309274494648, 0.0026716338470578194, 0.0032277305144816637, 0.0031844484619796276, 0.05878899618983269, 0.4139728248119354, 0.008037284947931767, 1.1672120094299316, 0.007127261254936457, 0.0029278509318828583, 0.006460950709879398, 0.0033623320050537586, 0.0026965674478560686, 0.004327462054789066, 0.004354075063019991, 0.005926550831645727, 0.0029976421501487494, 0.003225113498046994, 0.0053490265272557735, 0.0033869044855237007, 0.003467381000518799, 0.20093093812465668, 0.09408371895551682, 0.0034816532861441374, 0.0037946184165775776, 0.0035887728445231915, 0.005566957872360945, 0.01071103848516941, 0.13263630867004395, 0.003197111887857318, 0.22186851501464844, 0.00370780355297029, 0.0057520209811627865, 0.0034350776113569736, 0.006827014964073896, 0.004423658363521099, 0.004780481103807688, 0.20858395099639893, 0.21837449073791504, 0.058133576065301895, 0.004302062094211578, 0.00777561217546463, 0.012990128248929977, 0.08350498229265213, 0.09006205946207047, 0.0051735686138272285, 0.8042424321174622, 0.26630234718322754, 0.07872005552053452, 0.005795525852590799, 0.012017722241580486, 0.03553042560815811, 0.018151406198740005, 0.012112753465771675, 0.01529733743518591, 0.013885172083973885, 0.01146173570305109, 0.0906163677573204, 0.008914872072637081, 0.015058924444019794, 0.12927213311195374, 0.02555631287395954, 0.012456456199288368, 0.011717284098267555, 0.02617301233112812, 0.010197056457400322, 0.007091869134455919, 0.01577203907072544, 0.006229593884199858, 0.6135817766189575, 0.006128137465566397, 0.0036946688778698444, 0.004471341613680124, 0.0034880759194493294, 0.0028896108269691467, 0.229557067155838, 0.003815783653408289, 0.0032858424820005894, 0.004312713164836168, 0.003446163609623909, 0.00203610397875309, 0.0019682792481034994, 0.0023952617775648832, 0.0023007034324109554, 0.0023753573186695576, 0.001805633888579905, 0.0025440289173275232, 0.0027682522777467966, 0.001496339333243668, 0.001938673434779048, 0.0019908868707716465, 0.0023847599513828754, 0.0020363323856145144, 0.0024034762755036354, 0.0015587803209200501, 0.15156227350234985, 0.1344536691904068, 0.0014823101228103042, 0.0011716128792613745, 0.0018862298456951976, 0.28340885043144226, 0.0023414362221956253, 0.0017246134812012315, 0.24563473463058472, 0.0015749929007142782, 0.0019098022021353245, 0.002234367886558175, 0.3754783272743225, 0.0024524873588234186, 0.002542859874665737, 0.00423510791733861, 0.279132604598999, 0.006146812811493874, 0.008986502885818481, 0.005250842310488224, 0.007472360506653786, 0.007148397155106068, 0.12541905045509338, 0.21485963463783264, 0.004832055419683456, 0.006600706372410059, 0.0063385809771716595, 0.005758974235504866, 0.00875706598162651, 0.0057045030407607555, 0.0066836136393249035, 0.005349630024284124, 0.005155335646122694, 0.007904254831373692, 0.005062968470156193, 0.005194645840674639, 0.04550832509994507, 0.0816883072257042, 0.004929904825985432, 0.005516095086932182, 0.004987931810319424, 0.0053198630921542645, 0.0053281402215361595, 0.004836108069866896, 0.00417763227596879, 0.004171586595475674, 0.004004971589893103, 0.0036856604274362326, 0.003907929174602032, 0.0034142322838306427, 0.27161920070648193, 0.004971377085894346, 0.0032711056992411613, 0.003479410195723176, 0.003779811318963766, 0.004207455087453127, 0.0027272559236735106, 0.0032090642489492893, 0.0026638912968337536, 0.0028575328178703785, 0.12006279081106186, 0.002475581131875515, 0.1445571780204773, 0.0025546217802911997, 0.003326748963445425, 0.0036538501735776663, 0.0025295154191553593, 0.0039171818643808365, 0.002890158910304308, 0.0030809720046818256, 0.0027793939225375652, 0.07624512165784836, 0.0034631204325705767, 0.07522113621234894, 0.0023575893137604, 0.004277014639228582, 0.002489975420758128, 0.0027488949708640575, 0.004172023385763168, 0.0025785407051444054, 0.003152600722387433, 0.005182745400816202, 0.003715019440278411, 0.00355556420981884, 0.004026917275041342, 0.00410482008010149, 0.005859890952706337, 0.0026334025897085667, 0.06457731127738953, 0.36203715205192566, 0.0038381749764084816, 0.005501439329236746, 0.0027863841969519854, 0.003160224761813879, 0.0065076835453510284, 0.004105019848793745, 0.0036940034478902817, 0.0045402683317661285, 0.10002747923135757, 0.0031080867629498243, 0.0025982342194765806, 0.0026200993452221155, 0.0022955674212425947, 0.0027761515229940414, 0.002507592085748911, 0.14709901809692383, 0.006614123936742544, 0.0028541984502226114, 0.002832548227161169, 0.0024682795628905296, 0.002573310863226652, 0.0032210098579525948, 0.2525092661380768, 0.002099689794704318, 0.0028421238530427217, 0.0028078460600227118, 0.0027335071936249733, 0.004747842438519001, 0.003978264052420855, 0.0032874788157641888, 0.6530857682228088, 0.002755913883447647, 0.0030649604741483927, 0.0032856010366231203, 0.09150058776140213, 0.006512551102787256, 0.19524985551834106, 0.15856710076332092, 0.05652238428592682, 0.1659550964832306, 0.08062031865119934, 0.008229129947721958, 0.011003748513758183, 0.007519221864640713, 0.014571965672075748, 0.006423662882298231, 0.007098446600139141, 0.008814551867544651, 0.007331341505050659, 0.007869740016758442, 0.0075858887284994125, 0.010138078592717648, 0.006787190213799477, 0.1406305432319641, 0.01445700228214264, 0.009366253390908241, 0.1948847621679306, 0.006350446492433548, 0.010780147276818752, 0.007500155828893185, 0.00651145214214921, 0.0053216139785945415, 0.0062655177898705006, 0.0058875312097370625, 0.005632955115288496, 0.0047532436437904835, 0.004089678637683392, 0.005386611446738243, 0.003884740173816681, 0.00409895833581686, 0.004708194639533758, 0.003923404961824417, 0.0037665446288883686, 0.0038597246166318655, 0.2086445838212967, 0.005044786259531975, 0.003147982293739915, 0.002577946987003088, 0.003130081109702587, 0.002856589388102293, 0.0033059176057577133, 0.0024084439501166344, 0.0027243662625551224, 0.002184635028243065, 0.11646246910095215, 0.002043553162366152, 0.0028396190609782934, 0.002530856989324093, 0.0022318302653729916, 0.13590651750564575, 0.548662006855011, 0.0030479501001536846, 0.3025938868522644, 0.04993323236703873, 0.0037121381610631943, 0.004697923082858324, 0.005088141653686762, 0.004483935888856649, 0.004817033186554909, 0.005577845498919487, 0.006010521203279495, 0.005346351303160191, 0.007801659870892763, 0.005795816425234079, 0.4202548563480377, 0.0068959123454988, 0.008916528895497322, 0.00740255368873477, 0.008808653801679611, 0.007408601231873035, 0.009953485801815987, 0.1798245757818222, 0.008377228863537312, 0.008723502978682518, 0.00897386483848095, 0.008555741980671883, 0.00864905584603548, 0.00977888610213995, 0.013316051103174686, 0.007756183855235577, 0.007631503976881504, 0.008233499713242054, 0.006586593575775623, 0.008109914138913155, 0.007416511885821819, 0.006581862457096577, 0.005889683961868286, 0.004936962854117155, 0.005444485694169998, 0.005002562887966633, 0.004787714686244726, 0.004423100501298904, 0.004759420640766621, 0.004072069190442562, 0.003954736050218344, 0.06190365552902222, 0.0036573735997080803, 0.0032438759226351976, 0.0030193584971129894, 0.003942732233554125, 0.0032571256160736084, 0.0028817798011004925, 0.0030604610219597816, 0.003540135221555829, 0.0031107875984162092, 0.0028119406197220087, 0.0022728191688656807, 0.0023668878711760044, 0.0021808044984936714, 0.0022029378451406956, 0.0027847469318658113, 0.0020686169154942036, 0.0019363737665116787, 0.0020872997120022774, 0.0018296544440090656, 0.002952942391857505, 0.0016690784832462668, 0.0017743607750162482, 0.0017091158078983426, 0.002252395963296294, 0.15630166232585907, 0.0017044318374246359, 0.0021975389681756496, 0.0015919983852654696, 0.0015547071816399693, 0.0017476070206612349, 0.4010641574859619, 0.0016176513163372874, 0.002167633967474103, 0.0022134464234113693, 0.0024182626511901617, 0.002675070893019438, 0.0033218732569366693, 0.0026556316297501326, 0.00260081491433084, 0.0030920652206987143, 0.003461188403889537, 0.0028432670515030622, 0.0036655461881309748, 0.0027216298040002584, 0.002803970128297806, 0.0035052329767495394, 0.10943790525197983, 0.49318748712539673, 0.002984005259349942, 0.16615071892738342, 0.0046180193312466145, 0.00492006354033947, 0.00629214383661747, 0.007968159392476082, 0.0056616622023284435, 0.007740391883999109, 0.0063207121565938, 0.006586904171854258, 0.006024186033755541, 0.006382618565112352, 0.006295793689787388, 0.007392507046461105, 0.005641263909637928, 0.007859613746404648, 0.00582391582429409, 0.007799014449119568, 0.005503042135387659, 0.006025468464940786, 0.00502488249912858, 0.005484859924763441, 0.0056757815182209015, 0.005664195865392685, 0.00510497996583581, 0.19400158524513245, 0.00719568133354187, 0.004253325518220663, 0.0038219294510781765, 0.07857892662286758, 0.004071712028235197, 0.0037657341454178095, 0.003964647185057402, 0.051933109760284424, 0.07993004471063614, 0.0034752339124679565, 0.003401772119104862, 0.004900602623820305, 0.0035852722357958555, 0.004588799551129341, 0.003744462737813592, 0.0039036227390170097, 0.3028416037559509, 0.005135676357895136, 0.0036063978914171457, 0.051571719348430634, 0.11061470210552216, 0.0913982018828392, 0.004833466839045286, 0.005423048976808786, 0.08357786387205124, 0.009490637108683586, 0.23567752540111542, 0.006155573297291994, 0.010113069787621498, 0.05646529421210289, 0.007656799163669348, 0.03978288918733597, 0.08559926599264145, 0.007071966305375099, 0.014164019376039505, 0.007301063276827335, 0.06274008005857468, 0.008636354468762875, 0.011320323683321476, 0.00813076738268137, 0.006841631140559912, 0.012947345152497292, 0.0597267709672451, 0.007525957189500332, 0.008453955873847008, 0.24869570136070251, 0.007567614782601595, 0.012007225304841995, 0.013855231925845146, 0.009840387850999832, 0.013883826322853565, 0.08018486201763153, 0.008029931224882603, 0.009433561936020851, 0.006858994252979755, 0.0035259586293250322, 0.09509952366352081, 0.008625770919024944, 0.2738129198551178, 0.0038850305136293173, 0.004998635500669479, 0.16845941543579102, 0.24853375554084778, 0.16282793879508972, 0.004573378711938858, 0.018173376098275185, 0.04122114181518555, 0.005037944298237562, 0.08111704885959625, 0.06654150784015656, 0.004494240041822195, 0.005713040940463543, 0.006367755122482777, 0.005678750108927488, 0.01581503637135029, 0.008406894281506538, 0.006262626964598894, 0.0062955706380307674, 0.006054140627384186, 0.005954419262707233, 0.037317629903554916, 0.006404724903404713, 0.03872041031718254, 0.004688628483563662, 0.0048170629888772964, 0.004420817829668522, 0.21439413726329803, 0.007927868515253067, 0.004356513265520334, 0.009592960588634014, 0.3620348274707794, 0.00515617523342371, 0.012943798676133156, 0.0053848098032176495, 0.00413876585662365, 0.18093466758728027, 0.004764564801007509, 0.0035789452958852053, 0.004193788859993219, 0.2889447510242462, 0.004137286450713873, 0.005046701058745384, 0.004912164527922869, 0.004361668601632118, 0.004445635247975588, 0.004050357732921839, 0.0035228878259658813, 0.003969562705606222, 0.1776924729347229, 0.0037601329386234283, 0.0038081707898527384, 0.003612698521465063, 0.00382851785980165, 0.0033709683921188116, 0.0037440932355821133, 0.003924346063286066, 0.003621239447966218, 0.003354419721290469, 0.0029219489078968763, 0.0034849990624934435, 0.0029427690897136927, 0.003128077369183302, 0.0031629528384655714, 0.0030896037351340055, 0.0029816022142767906, 0.0029865410178899765, 0.0031178928911685944, 0.520714521408081, 0.002933237701654434, 0.0028041687328368425, 0.0030798588413745165, 0.0030811855103820562, 0.00437092175707221, 0.1890207827091217, 0.004009666852653027, 0.004583613947033882, 0.005542342085391283, 0.003785437671467662, 0.004493459593504667, 0.003986753989011049, 0.004034054931253195, 0.0897541269659996, 0.004245035350322723, 0.09749918431043625, 0.003990980330854654, 0.00418179901316762, 0.004255951847881079, 0.004383609630167484, 0.004639256279915571, 0.0042437100782990456, 0.004208225291222334, 0.0043137394823133945, 0.004320921842008829, 0.005486719310283661, 0.004677256569266319, 0.005237317644059658, 0.003838577074930072, 0.0036954705137759447, 0.00395503593608737, 0.003924654796719551, 0.0037931841798126698, 0.003332850756123662, 0.0038609907496720552, 0.0032811611890792847, 0.08374901860952377, 0.003321923315525055, 0.08017529547214508, 0.0035393424332141876, 0.3759689927101135, 0.00332519575022161, 0.0034833145327866077, 0.003637253772467375, 0.35156163573265076, 0.0038147366140037775, 0.00423403549939394, 0.004431761801242828, 0.005675946827977896, 0.005969304591417313, 0.0049755750223994255, 0.0063389744609594345, 0.005771522875875235, 0.17517150938510895, 0.0054627335630357265, 0.004853147082030773, 0.005399217829108238, 0.006397547200322151, 0.006473828107118607, 0.005468862131237984, 0.25045713782310486, 0.005989411845803261, 0.005709283985197544, 0.057687629014253616, 0.14919039607048035, 0.005161092150956392, 0.006055396515876055, 0.29959237575531006, 0.006737446412444115, 0.007152652833610773, 0.007043885532766581, 0.007092196494340897, 0.007911812514066696, 0.006790362298488617, 0.006850154139101505, 0.007770057301968336, 0.007135304622352123, 0.007719204295426607, 0.16347704827785492, 0.007999898865818977, 0.008559457957744598, 0.08898766338825226, 0.006708718836307526, 0.008087488822638988, 0.18443459272384644, 0.006637797225266695, 0.007070137653499842, 0.006887953728437424, 0.007329197134822607, 0.006885162554681301, 0.006417755503207445, 0.006530127953737974, 0.008762006647884846, 0.0062991478480398655, 0.005734079051762819, 0.083974689245224, 0.006029543001204729, 0.11302313208580017, 0.006187654100358486, 0.005096159875392914, 0.005047316662967205, 0.0053877816535532475, 0.005457810591906309, 0.004968420602381229, 0.24035225808620453, 0.0052507733926177025, 0.005149172618985176, 0.004376378376036882, 0.004314693622291088, 0.1780679076910019, 0.004200541414320469, 0.0045507438480854034, 0.14932779967784882, 0.06628311425447464, 0.0044042509980499744, 0.004394680727273226, 0.004449600353837013, 0.18944473564624786, 0.004564792383462191, 0.00493042403832078, 0.0047812992706894875, 0.004867559764534235, 0.11443273723125458, 0.0050076646730303764, 0.005020789336413145, 0.005338731687515974, 0.09778157621622086, 0.005249647423624992, 0.11037924140691757, 0.005804980173707008, 0.005365833640098572, 0.006292601581662893, 0.005321706645190716, 0.005502188112586737, 0.0051642912440001965, 0.005207130219787359, 0.005068540573120117, 0.005222196690738201, 0.005351468455046415, 0.0054672821424901485, 0.18413227796554565, 0.06874077767133713, 0.004870402626693249, 0.005168904550373554, 0.004600124899297953, 0.00467403419315815, 0.00466072466224432, 0.0045472076162695885, 0.004950744099915028, 0.004748975392431021, 0.004464683588594198, 0.0042199380695819855, 0.0042948611080646515, 0.004227365832775831, 0.0038468448910862207, 0.003934676758944988, 0.0036784233525395393, 0.00341892521828413, 0.003338955109938979, 0.18467973172664642, 0.003179284045472741, 0.00322382221929729, 0.0031341449357569218, 0.0033615799620747566, 0.13555553555488586, 0.003783826483413577, 0.003431134857237339, 0.003293990157544613, 0.10625009983778, 0.1198221892118454, 0.0031709601171314716, 0.10578461736440659, 0.0037920076865702868, 0.003713732585310936, 0.1756720095872879, 0.0038377491291612387, 0.18811450898647308, 0.004360463470220566, 0.004470065236091614, 0.004611053969711065, 0.004769973456859589, 0.004845225717872381, 0.005355769768357277, 0.12389151751995087, 0.11123374104499817, 0.11060944944620132, 0.005354458466172218, 0.005571683868765831, 0.0061620003543794155, 0.005697928834706545, 0.006102181971073151, 0.0058732363395392895, 0.00656833965331316, 0.005644540768116713, 0.0059018186293542385, 0.005590113811194897, 0.09980754554271698, 0.0055612134747207165, 0.11425602436065674, 0.00556702958419919, 0.00529238348826766, 0.005938742309808731, 0.005465662572532892, 0.00544825429096818, 0.09252727031707764, 0.005352279637008905, 0.13637934625148773, 0.005083419382572174, 0.11530255526304245, 0.0053536430932581425, 0.11283871531486511, 0.0058580730110406876, 0.00586978904902935, 0.005688456352800131, 0.005323297809809446, 0.005724113900214434, 0.005365172866731882, 0.10768727958202362, 0.005729039665311575, 0.005298348143696785, 0.00572595139965415, 0.0960337445139885, 0.005643215496093035, 0.005651148967444897, 0.08231033384799957, 0.1053377091884613, 0.005781338084489107, 0.005867454223334789, 0.1553698182106018, 0.005724168382585049, 0.005603183060884476, 0.00544445076957345, 0.005525936372578144, 0.006793053820729256, 0.005965822841972113, 0.005145574454218149, 0.005288597196340561, 0.005644249264150858, 0.005562033038586378, 0.004765070974826813, 0.17557953298091888, 0.15118344128131866, 0.005247387569397688, 0.45338746905326843, 0.004991862457245588, 0.16936150193214417, 0.09219112247228622, 0.006466848775744438, 0.0067811687476933, 0.007390729617327452, 0.007402992341667414, 0.008621055632829666, 0.008021733723580837, 0.009165661409497261, 0.008520880714058876, 0.00851355493068695, 0.00826344732195139, 0.009050547145307064, 0.008332795463502407, 0.008852574042975903, 0.007190224714577198, 0.09247476607561111, 0.006850507576018572, 0.0071261110715568066, 0.00724352290853858, 0.006305256392806768, 0.006185282487422228, 0.006457150913774967, 0.12607388198375702, 0.0058393459767103195, 0.00559981120750308, 0.0051059117540717125, 0.005299295298755169, 0.14243027567863464, 0.005287278443574905, 0.169718936085701, 0.0049237897619605064, 0.0048731123097240925, 0.09749582409858704, 0.004686098080128431, 0.005446195136755705, 0.11918475478887558, 0.004928590729832649, 0.00478889187797904, 0.004783942364156246, 0.13077589869499207, 0.005388843826949596, 0.0047209253534674644, 0.00494943093508482, 0.004691767040640116, 0.005009923130273819, 0.11889548599720001, 0.004584173206239939, 0.005904263351112604, 0.0047219982370734215, 0.0048404233530163765, 0.004490056540817022, 0.004989225417375565, 0.10145244002342224, 0.004652942065149546, 0.004437139257788658, 0.004846120718866587, 0.00460186880081892, 0.09881231933832169, 0.004347618203610182, 0.004111726768314838, 0.004280300345271826, 0.005244220606982708, 0.0039391666650772095, 0.00427372008562088, 0.003974036313593388, 0.004452464170753956, 0.09911465644836426, 0.0048654465936124325, 0.0049775103107094765, 0.003712963778525591, 0.0036822743713855743, 0.0038899853825569153, 0.003767848713323474, 0.0036609750241041183, 0.003518682671710849, 0.0035331943072378635, 0.003456143895164132, 0.004235410131514072, 0.0032177006360143423, 0.0029338994063436985, 0.5406538248062134, 0.0917307585477829, 0.004086087923496962, 0.003537495620548725, 0.003741981228813529, 0.0806313008069992, 0.004226414952427149, 0.004514890722930431, 0.004798271227627993, 0.005574349779635668, 0.004914076998829842, 0.004946283996105194, 0.006129864603281021, 0.22092534601688385, 0.006422656122595072, 0.005254464689642191, 0.0060408334247767925, 0.07868693768978119, 0.00554417259991169, 0.15703085064888, 0.0056283436715602875, 0.005749150644987822, 0.0058733620680868626, 0.005759537685662508, 0.00666542025282979, 0.005491066724061966, 0.006621600594371557, 0.0074886418879032135, 0.0053948815912008286, 0.0051113516092300415, 0.00574080366641283, 0.0051283217035233974, 0.19632966816425323, 0.004754060413688421, 0.005177993327379227, 0.004397382959723473, 0.004310701508074999, 0.004467325750738382, 0.004727740306407213, 0.004764209035784006, 0.004666149616241455, 0.004454508423805237, 0.005315881222486496, 0.0035683480091392994, 0.0038067104760557413, 0.004182334523648024, 0.003601419972255826, 0.0037059951573610306, 0.0031433887779712677, 0.003675053594633937, 0.0029102228581905365, 0.0031815655529499054, 0.002666516462340951, 0.1313074678182602, 0.0026736478321254253, 0.06342331320047379, 0.1292080581188202, 0.0027701565995812416, 0.20833028852939606, 0.002936692675575614, 0.002868438372388482, 0.0029586206655949354, 0.0032796375453472137, 0.003117410931736231, 0.0032735872082412243, 0.0042847576551139355, 0.1251521110534668, 0.0034533762373030186, 0.0035202649887651205, 0.11134636402130127, 0.003581447061151266, 0.0037715707439929247, 0.004205494653433561, 0.12199071794748306, 0.12487385421991348, 0.0045625269412994385, 0.004865140654146671, 0.004437829367816448, 0.3067569434642792, 0.004761597141623497, 0.18470904231071472, 0.0057916115038096905, 0.006115500349551439, 0.007248144596815109, 0.007383633870631456, 0.0074501726776361465, 0.00803157314658165, 0.007233175914734602, 0.0076795839704573154, 0.008029686287045479, 0.1348360776901245, 0.008612096309661865, 0.009030953049659729, 0.007108514662832022, 0.0073504457250237465, 0.09534397721290588, 0.09114120900630951, 0.007562453392893076, 0.007698833476752043, 0.13246750831604004, 0.006953869480639696, 0.008123856037855148, 0.00707892794162035, 0.007221309933811426, 0.008543238043785095, 0.1014019027352333, 0.006818676833063364, 0.006389384623616934, 0.007690201513469219, 0.1012636199593544, 0.006094104610383511, 0.005804465152323246, 0.0673968642950058, 0.527429461479187, 0.006742652039974928, 0.007332072593271732, 0.007304738275706768, 0.08952978998422623, 0.008083407767117023, 0.0082518570125103, 0.008182434365153313, 0.00929168239235878, 0.008319380693137646, 0.07188808172941208, 0.008376863785088062, 0.008491052314639091, 0.008835459128022194, 0.00806207675486803, 0.008331076242029667, 0.007769172079861164, 0.00783675629645586, 0.17749574780464172, 0.007206928450614214, 0.007111308630555868, 0.006703563965857029, 0.0073013813234865665, 0.006378723308444023, 0.007668705191463232, 0.006897366605699062, 0.0059291524812579155, 0.0056144921109080315, 0.005595501512289047, 0.005639389622956514, 0.005367819219827652, 0.13054150342941284, 0.05026087909936905, 0.004965138155966997, 0.08200278878211975, 0.006056220270693302, 0.004389808047562838, 0.004767614882439375, 0.004173428285866976, 0.004338163882493973, 0.005360976327210665, 0.004294696729630232, 0.004818025045096874, 0.0038648354820907116, 0.0037738329265266657, 0.0037731961347162724, 0.003585189115256071, 0.003425583941861987, 0.16106151044368744, 0.11992292106151581, 0.12654395401477814, 0.0036691075656563044, 0.003652806393802166, 0.003667742246761918, 0.003970418591052294, 0.0038571739569306374, 0.0037617995403707027, 0.004731140565127134, 0.003792908973991871, 0.0038266305346041918, 0.00371450069360435, 0.0034912012051790953, 0.10751323401927948, 0.003983775619417429, 0.003598737297579646, 0.004091146867722273, 0.0034032834228128195, 0.0038969703018665314, 0.00408981554210186, 0.003404974238947034, 0.0037128145340830088, 0.0035847192630171776, 0.0032191395293921232, 0.0032794305589050055, 0.003595451358705759, 0.0040466575883328915, 0.004012035205960274, 0.004110662266612053, 0.0030029600020498037, 0.002613452263176441, 0.002970973029732704, 0.23376239836215973, 0.0032494720071554184, 0.141579732298851, 1.0195045471191406, 0.003256523283198476, 0.0034201766829937696, 0.06389012187719345, 0.004730341024696827, 0.004942311439663172, 0.005168987903743982, 0.005788168869912624, 0.13908007740974426, 0.10015591233968735, 0.007210055831819773, 0.007162896450608969, 0.17716248333454132, 0.009742898866534233, 0.009618433192372322, 0.008894679136574268, 0.008451148867607117, 0.009167375974357128, 0.008423770777881145, 0.009965084493160248, 0.009525857865810394, 0.008371014147996902, 0.010761297307908535, 0.008011857978999615, 0.12372506409883499, 0.008151995949447155, 0.1262064427137375, 0.12032900005578995, 0.08724071085453033, 0.007399057503789663, 0.007119607180356979, 0.007110373117029667, 0.062128737568855286, 0.007745413109660149, 0.007125756703317165, 0.007763233967125416, 0.006867366377264261, 0.006864294409751892, 0.007950668223202229, 0.006781540811061859, 0.006474372465163469, 0.006077321711927652, 0.006306691560894251, 0.0055013964883983135, 0.005888931453227997, 0.005455418955534697, 0.004760897718369961, 0.004698547534644604, 0.14868877828121185, 0.004801467526704073, 0.005203227512538433, 0.004736022558063269, 0.004127493128180504, 0.004531096667051315, 0.0043570189736783504, 0.08636555820703506, 0.004187648184597492, 0.0038167452439665794, 0.0038905562832951546, 0.0037749686744064093, 0.1659557968378067, 0.004192989785224199, 0.0034377719275653362, 0.0035407505929470062, 0.004023175220936537, 0.09320298582315445, 0.003575536422431469, 0.0038886673282831907, 0.003640015609562397, 0.10418663918972015, 0.09068968892097473, 0.0037265142891556025, 0.41026633977890015, 0.003918267320841551, 0.004613175056874752, 0.005191630683839321, 0.0049506500363349915, 0.006264406722038984, 0.005195697769522667, 0.005326414480805397, 0.00841168686747551, 0.005773070268332958, 0.03323446586728096, 0.006481745280325413, 0.008758818730711937, 0.07555243372917175, 0.006614184007048607, 0.007230174262076616, 0.337066650390625, 0.006533198524266481, 0.00795755535364151, 0.008820272982120514, 0.007929699495434761, 0.007336650509387255, 0.008481156080961227, 0.008257145993411541, 0.008143248036503792, 0.008686810731887817, 0.008128955028951168, 0.008479424752295017, 0.007036451715976, 0.010339366272091866, 0.008157982490956783, 0.00899617001414299, 0.006907723844051361, 0.006584336049854755, 0.006611540447920561, 0.2308192104101181, 0.006132481619715691, 0.005617594346404076, 0.005469251424074173, 0.005022360477596521, 0.006019704043865204, 0.00461979815736413, 0.004821132402867079, 0.004954272881150246, 0.0056296749971807, 0.004155479837208986, 0.004922745283693075, 0.004791669547557831, 0.003999962937086821, 0.004938384518027306, 0.004377448465675116, 0.17549791932106018, 0.08732973039150238, 0.003338252194225788, 0.0034364773891866207, 0.10383419692516327, 0.003900068812072277, 0.1744348555803299, 0.18321412801742554, 0.004100927617400885, 0.0043415529653429985, 0.0776461660861969, 0.004259416833519936, 0.004619339946657419, 0.0044945962727069855, 0.0052534183487296104, 0.004411078058183193, 0.005531914997845888, 0.004270437639206648, 0.004346048925071955, 0.004313568584620953, 0.004117053467780352, 0.27448639273643494, 0.004205109551548958, 0.004897072445601225, 0.004477037116885185, 0.004345578141510487, 0.004534334875643253, 0.005136009771376848, 0.00465713907033205, 0.0047572823241353035, 0.004155152011662722, 0.1156177967786789, 0.00496456865221262, 0.004093713592737913, 0.004674531985074282, 0.003849766217172146, 0.5339698791503906, 0.004624718334525824, 0.139677032828331, 0.004424685146659613, 0.005793895572423935, 0.004962184466421604, 0.14134211838245392, 0.005850867833942175, 0.006520636845380068, 0.005804416257888079, 0.005896514747291803, 0.006450813729315996, 0.0062882439233362675, 0.006701175589114428, 0.15629668533802032, 0.0061836810782551765, 0.006748157553374767, 0.006337395869195461, 0.18685676157474518, 0.006637971848249435, 0.0071390061639249325, 0.006172901950776577, 0.007090588565915823, 0.0071226246654987335, 0.00624157814309001, 0.006896848324686289, 0.005935188382863998, 0.006204633042216301, 0.0060922810807824135, 0.005490393843501806, 0.005425707437098026, 0.0054803271777927876, 0.08690148591995239, 0.004958308767527342, 0.004790304694324732, 0.005385288503021002, 0.11217252910137177, 0.004675605800002813, 0.004628724418580532, 0.005006417632102966, 0.004400630947202444, 0.0042483690194785595, 0.004465462174266577, 0.004225627053529024, 0.003926449920982122, 0.003840765915811062, 0.0042390669696033, 0.09776023775339127, 0.004064780659973621, 0.0038492316380143166, 0.003973826300352812, 0.14351807534694672, 0.0042990995571017265, 0.2384772151708603, 0.003637620946392417, 0.004480903036892414, 0.12452787160873413, 0.004682808183133602, 0.07183346897363663, 0.0038543108385056257, 0.004088789690285921, 0.004708083346486092, 0.004726334474980831, 0.004818954039365053, 0.004065730608999729, 0.09347140789031982, 0.004709294065833092, 0.004361649043858051, 0.004461408127099276, 0.004138358402997255, 0.004577746149152517, 0.004824955947697163, 0.004249026067554951, 0.004156189505010843, 0.004376229830086231, 0.09514732658863068, 0.0038632210344076157, 0.004521907772868872, 0.005362221039831638, 0.0036144922487437725, 0.003615955589339137, 0.004175066947937012, 0.0043166931718587875, 0.0037278402596712112, 0.0036103909369558096, 0.0034338142722845078, 0.0034502383787184954, 0.5349652171134949, 0.0032764675561338663, 0.00390431541018188, 0.0038662576116621494, 0.004404481966048479, 0.004534510429948568, 0.005000602453947067, 0.004462276119738817, 0.005410691257566214, 0.004500055219978094, 0.004611832555383444, 0.15284335613250732, 0.004645876586437225, 0.11352289468050003, 0.005409242119640112, 0.004770801868289709, 0.005120772402733564, 0.005248876288533211, 0.0051873791962862015, 0.004705613479018211, 0.004917950835078955, 0.005224647466093302, 0.004986600484699011, 0.00506257638335228, 0.005454190541058779, 0.004525416065007448, 0.004556490108370781, 0.004296089056879282, 0.004035978578031063, 0.004379538353532553, 0.13095369935035706, 0.004575225990265608, 0.004125842358916998, 0.49198833107948303, 0.004026561509817839, 0.00437419768422842, 0.005423137452453375, 0.005425675306469202, 0.0052519976161420345, 0.005333264824002981, 0.005044630728662014, 0.005230931099504232, 0.005177999846637249, 0.005327572580426931, 0.00508702639490366, 0.00515887001529336, 0.005337510723620653, 0.005488006863743067, 0.13535325229167938, 0.005334991030395031, 0.004964690189808607, 0.0051174103282392025, 0.004970808047801256, 0.0049490369856357574, 0.004923966247588396, 0.004939835984259844, 0.09074725210666656, 0.005461851134896278, 0.005132120568305254, 0.1370115876197815, 0.004442672710865736, 0.10935432463884354, 0.004517897963523865, 0.005180767271667719, 0.005058930721133947, 0.0045122383162379265, 0.08544088155031204, 0.0045085190795362, 0.004899181425571442, 0.28514254093170166, 0.005576616153120995, 0.005171359982341528, 0.12777197360992432, 0.07833454757928848, 0.006373241543769836, 0.006047989707440138, 0.006383191794157028, 0.14792446792125702, 0.008236593566834927, 0.007376314140856266, 0.008007130585610867, 0.0068587930873036385, 0.15523412823677063, 0.007880016230046749, 0.007340259850025177, 0.007247454021126032, 0.007366406265646219, 0.007466779090464115, 0.006898575462400913, 0.008993024937808514, 0.09514041990041733, 0.007900296710431576, 0.007181036751717329, 0.006444020662456751, 0.006502930540591478, 0.006071967538446188, 0.0061506000347435474, 0.006023614667356014, 0.16247740387916565, 0.005991427693516016, 0.005463338457047939, 0.006212940905243158, 0.006015077233314514, 0.006045352667570114, 0.005177012644708157, 0.0049525061622262, 0.0051000360399484634, 0.12500281631946564, 0.004925044719129801, 0.09576047211885452, 0.0059232995845377445, 0.005034005735069513, 0.0047763437032699585, 0.0055099246092140675, 0.004769929684698582, 0.004332960583269596, 0.004108441527932882, 0.004126178100705147, 0.004821066278964281, 0.003944695927202702, 0.08532498776912689, 0.0038934352342039347, 0.003767811693251133, 0.0036268415860831738, 0.003910205326974392, 0.0036285710521042347, 0.003705735318362713, 0.0034716068767011166, 0.003617731621488929, 0.0034130681306123734, 0.0031207881402224302, 0.09818065166473389, 0.003598791779950261, 0.003728208364918828, 0.0030400536488741636, 0.0033058172557502985, 0.1429407298564911, 0.09997093677520752, 0.003665496362373233, 0.003408639458939433, 0.0031593816820532084, 0.003437904641032219, 0.1289462298154831, 0.003634766908362508, 0.0037043511401861906, 0.13721859455108643, 0.003580160439014435, 0.1529284417629242, 0.003692132653668523, 0.0037898763548582792, 0.08150103688240051, 0.004397219512611628, 0.004278053995221853, 0.004605734255164862, 0.004798703361302614, 0.0040581487119197845, 0.004144059959799051, 0.0040741367265582085, 0.17251726984977722, 0.004480542149394751, 0.004685493186116219, 0.004839044529944658, 0.005052561406046152, 0.004493806045502424, 0.004089339170604944, 0.004143443424254656, 0.006131547968834639, 0.004917302168905735, 0.004504616372287273, 0.0038154050707817078, 0.004076739773154259, 0.1417236477136612, 0.0037539515178650618, 0.003629089333117008, 0.004822921007871628, 0.0039008096791803837, 0.003925098571926355, 0.0036939603742212057, 0.003608676604926586, 0.0035559164825826883, 0.0039209164679050446, 0.0036177500151097775, 0.0035582163836807013, 0.0038963479455560446, 0.003079847665503621, 0.00310731353238225, 0.003026933642104268, 0.002920843195170164, 0.00294866063632071, 0.0030872381757944822, 0.002757358131930232, 0.0027978152502328157, 0.1905381977558136, 0.0028675273060798645, 0.0025506799574941397, 0.0027688262052834034, 0.4803535044193268, 0.003134683007374406, 0.46153688430786133, 0.003951156046241522, 0.004661980550736189, 0.00451262854039669, 0.004719829186797142, 0.0060194432735443115, 0.005517919082194567, 0.005849314387887716, 0.006334330420941114, 0.5865504741668701, 0.008611677214503288, 0.007960394024848938, 0.008757730014622211, 0.07903371006250381, 0.04847315698862076, 0.010595407336950302, 0.010016695596277714, 0.010396559722721577, 0.010994414798915386, 0.011246766895055771, 0.011127294972538948, 0.07743953168392181, 0.012285174801945686, 0.012501831166446209, 0.010968039743602276, 0.011025652289390564, 0.010439999401569366, 0.010346136055886745, 0.010983272455632687, 0.009836496785283089, 0.009309705346822739, 0.00901206023991108, 0.008780407719314098, 0.008600869216024876, 0.008650103583931923, 0.008629176765680313, 0.0076736691407859325, 0.007149817887693644, 0.006661303341388702, 0.006300216540694237, 0.007153312675654888, 0.005692240782082081, 0.005484323017299175, 0.0051823630928993225, 0.005581100471317768, 0.004755476489663124, 0.005356768146157265, 0.0926801860332489, 0.1603037416934967, 0.004271725658327341, 0.004247523844242096, 0.00454886956140399, 0.0041907778941094875, 0.0041200825944542885, 0.004021936561912298, 0.004366113804280758]\n",
            "Val loss 0.03784860949963331\n",
            "Val auc roc 0.4791008981229963\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72f6fb8aa2514f299b68314fafa9344b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1636.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0312\n",
            "Train Losses : [0.4558826684951782, 0.10042509436607361, 0.0044730850495398045, 0.0045602344907820225, 0.004820871166884899, 0.005649938248097897, 0.004863939713686705, 0.005508312024176121, 0.005260487087070942, 0.4505155384540558, 0.08026830852031708, 0.006198222748935223, 0.006717856507748365, 0.006899012252688408, 0.00759641919285059, 0.11357569694519043, 0.008050255477428436, 0.008034853264689445, 0.2950693368911743, 0.008980107493698597, 0.009135968051850796, 0.010354469530284405, 0.012181962840259075, 0.011133605614304543, 0.07216094434261322, 0.01045171357691288, 0.011699967086315155, 0.10068771988153458, 0.07933785766363144, 0.011980593204498291, 0.010828182101249695, 0.012119220569729805, 0.012694474309682846, 0.014124947600066662, 0.011355655267834663, 0.010150553658604622, 0.01052618958055973, 0.009632294997572899, 0.06562863290309906, 0.009336389601230621, 0.00896500051021576, 0.008336997590959072, 0.008721735328435898, 0.008665846660733223, 0.007856150157749653, 0.007747906260192394, 0.0074504949152469635, 0.17507103085517883, 0.006572818849235773, 0.12121172994375229, 0.006282937712967396, 0.006683566607534885, 0.0068918573670089245, 0.006700765807181597, 0.11975007504224777, 0.006489521358162165, 0.006306156516075134, 0.005814028438180685, 0.005562182515859604, 0.0050561861135065556, 0.005098012741655111, 0.0051260036416351795, 0.005046554375439882, 0.10765434056520462, 0.004961110185831785, 0.004438625182956457, 0.004555639810860157, 0.004460554104298353, 0.004784786142408848, 0.004704851191490889, 0.0042327712289988995, 0.004066781140863895, 0.0037910430692136288, 0.004625213332474232, 0.004031656309962273, 0.08376863598823547, 0.003649079008027911, 0.003735160455107689, 0.17240306735038757, 0.004101498518139124, 0.14342331886291504, 0.003633918007835746, 0.00356440432369709, 0.19236993789672852, 0.00383521756157279, 0.0037623709067702293, 0.004139764234423637, 0.003771758871152997, 0.18379543721675873, 0.0038367523811757565, 0.004200456198304892, 0.09797705709934235, 0.10329711437225342, 0.4781027138233185, 0.004783774726092815, 0.004829205106943846, 0.3398207724094391, 0.006186868995428085, 0.006423106882721186, 0.10457630455493927, 0.008131314069032669, 0.13468237221240997, 0.008933685719966888, 0.009430170059204102, 0.01010327972471714, 0.011473731137812138, 0.010666311718523502, 0.011901901103556156, 0.01143546961247921, 0.012471097521483898, 0.1871146261692047, 0.010756298899650574, 0.01064118929207325, 0.010877992957830429, 0.011393129825592041, 0.010242077521979809, 0.08865316957235336, 0.01043025590479374, 0.010595896281301975, 0.0926135927438736, 0.009244643151760101, 0.00996245164424181, 0.008949050679802895, 0.009114381857216358, 0.00880995113402605, 0.007966434583067894, 0.007651745807379484, 0.007701036985963583, 0.07629098743200302, 0.007383042946457863, 0.1041157990694046, 0.006501069758087397, 0.007222416810691357, 0.00633632205426693, 0.006851859390735626, 0.0066227600909769535, 0.005657473113387823, 0.005552362650632858, 0.005697757937014103, 0.005454661790281534, 0.00541202537715435, 0.00534914480522275, 0.004969904664903879, 0.004959704354405403, 0.00469138054177165, 0.004694307688623667, 0.004245656076818705, 0.0047317491844296455, 0.004347992595285177, 0.003757741302251816, 0.0039880545809865, 0.004263115115463734, 0.0035148465540260077, 0.09614714980125427, 0.12896312773227692, 0.0033337511122226715, 0.003534858813509345, 0.0033440652769058943, 0.0035137790255248547, 0.10850466787815094, 0.0032654351089149714, 0.00322512979619205, 0.0034455950371921062, 0.003496765159070492, 0.003506297478452325, 0.0036266937386244535, 0.003673047758638859, 0.0031989566050469875, 0.0032048753928393126, 0.0032379240728914738, 0.003133039688691497, 0.002943141385912895, 0.10402021557092667, 0.00298290909267962, 0.0030575606506317854, 0.0031608017161488533, 0.10311851650476456, 0.0031818761490285397, 0.003427926916629076, 0.11796709150075912, 0.003103729570284486, 0.0941629484295845, 0.1436941921710968, 0.003261739853769541, 0.17092938721179962, 0.0035296306014060974, 0.0037059320602566004, 0.0038148665335029364, 0.00413647573441267, 0.0038542135152965784, 0.004365575034171343, 0.00417817709967494, 0.004342283587902784, 0.004434987436980009, 0.004257411230355501, 0.004039414692670107, 0.004134871531277895, 0.004295178223401308, 0.004841684829443693, 0.0042668962851166725, 0.0040518450550735, 0.0038666068576276302, 0.0037941178306937218, 0.45467162132263184, 0.004033656790852547, 0.0052748373709619045, 0.08584092557430267, 0.0044721076264977455, 0.00536453677341342, 0.00526988971978426, 0.005864318925887346, 0.006861601024866104, 0.005070853978395462, 0.00507147004827857, 0.006501482799649239, 0.005452768411487341, 0.005298141855746508, 0.005172975827008486, 0.007093442138284445, 0.0053597064688801765, 0.005954751279205084, 0.004865348804742098, 0.10550731420516968, 0.09899134188890457, 0.13373102247714996, 0.004610386677086353, 0.004797752480953932, 0.00601320993155241, 0.0051654851995408535, 0.005348853766918182, 0.004928259644657373, 0.005247076507657766, 0.11090323328971863, 0.0050352513790130615, 0.005454420577734709, 0.11691278964281082, 0.004537174012511969, 0.0056919013150036335, 0.1466609388589859, 0.00489465519785881, 0.005906830076128244, 0.004996147006750107, 0.0048522064462304115, 0.10761728882789612, 0.0047691985964775085, 0.0866968110203743, 0.0061401198618113995, 0.08557768911123276, 0.005763117223978043, 0.005847313906997442, 0.005008415784686804, 0.00527064548805356, 0.004986138548702002, 0.005845800973474979, 0.004834322724491358, 0.005160392262041569, 0.005113790277391672, 0.00535367289558053, 0.0050401845946908, 0.004894803278148174, 0.004395810887217522, 0.1626879870891571, 0.004590739030390978, 0.006271307356655598, 0.004513999447226524, 0.005431948695331812, 0.0042768255807459354, 0.004218653775751591, 0.004012790508568287, 0.004548791795969009, 0.00479656457901001, 0.004253061953932047, 0.00404710229486227, 0.003579762764275074, 0.004424235783517361, 0.0038957165088504553, 0.0033652132842689753, 0.0033261701464653015, 0.003412906313315034, 0.003231102367863059, 0.003733586287125945, 0.0033308917190879583, 0.11420977115631104, 0.00301312911324203, 0.20653235912322998, 0.0030315129552036524, 0.003216814249753952, 0.003032718552276492, 0.1293017417192459, 0.003166347509250045, 0.003024271922186017, 0.003385194344446063, 0.1820250153541565, 0.003893104614689946, 0.1089542880654335, 0.0038317390717566013, 0.0038012275472283363, 0.0036488960031419992, 0.003544114762917161, 0.0035114220809191465, 0.16079066693782806, 0.004129189066588879, 0.003850884037092328, 0.11543526500463486, 0.003816130803897977, 0.004167279228568077, 0.08629065752029419, 0.004266688600182533, 0.0045907762832939625, 0.004241757560521364, 0.004358879756182432, 0.004201696719974279, 0.004247301258146763, 0.3725273013114929, 0.004535357467830181, 0.004793831612914801, 0.004906833171844482, 0.005175760015845299, 0.0053878468461334705, 0.005409846547991037, 0.005984325427561998, 0.005852635018527508, 0.005699619650840759, 0.10163937509059906, 0.006491692736744881, 0.006955244578421116, 0.006115505937486887, 0.005944059696048498, 0.0061106192879378796, 0.005979588255286217, 0.006581846624612808, 0.005929021164774895, 0.0897684246301651, 0.005602517630904913, 0.1549498438835144, 0.005421224050223827, 0.0057562231086194515, 0.005744447000324726, 0.005461318884044886, 0.005417053587734699, 0.1343650072813034, 0.005626232363283634, 0.13151928782463074, 0.0052372305653989315, 0.005776153411716223, 0.12781593203544617, 0.09433738887310028, 0.18468452990055084, 0.005518089979887009, 0.006780779920518398, 0.005523082800209522, 0.11617335677146912, 0.006785191595554352, 0.005835405085235834, 0.006163039244711399, 0.006009245757013559, 0.005884190555661917, 0.0056943753734230995, 0.006741586606949568, 0.00699858833104372, 0.0069071524776518345, 0.15556925535202026, 0.10010368376970291, 0.10408861190080643, 0.00573236308991909, 0.005592263303697109, 0.005482778884470463, 0.0056332736276090145, 0.06263050436973572, 0.15392827987670898, 0.11069364100694656, 0.07036726176738739, 0.006130639463663101, 0.3450565040111542, 0.006654671858996153, 0.0067108916118741035, 0.007132216822355986, 0.007326604798436165, 0.008367804810404778, 0.00883993599563837, 0.007940711453557014, 0.00799422338604927, 0.008280296809971333, 0.008753716014325619, 0.008214165456593037, 0.08814213424921036, 0.008352418430149555, 0.008130548521876335, 0.00828657578676939, 0.008374221622943878, 0.00798556674271822, 0.008245090022683144, 0.007503793109208345, 0.007151775993406773, 0.0076729231514036655, 0.007276973221451044, 0.007436056155711412, 0.12352259457111359, 0.007622787728905678, 0.006378821562975645, 0.1025378629565239, 0.0064028482884168625, 0.005750434473156929, 0.006023383233696222, 0.05951273813843727, 0.005755584686994553, 0.005688702687621117, 0.0051999748684465885, 0.0057948799803853035, 0.005348684266209602, 0.005260855425149202, 0.005061313975602388, 0.1416397988796234, 0.005124662071466446, 0.17355144023895264, 0.004870758391916752, 0.004785399418324232, 0.00556606613099575, 0.14407551288604736, 0.005460403859615326, 0.10894017666578293, 0.004892113618552685, 0.0047685629688203335, 0.005476855207234621, 0.004662875086069107, 0.004706867504864931, 0.006339890416711569, 0.00479542464017868, 0.004664105828851461, 0.005568752996623516, 0.004498508758842945, 0.11079659312963486, 0.004400554113090038, 0.004936991259455681, 0.004456380847841501, 0.00487288273870945, 0.0043882946483790874, 0.004107906483113766, 0.004246272146701813, 0.004180354531854391, 0.15702730417251587, 0.003947166260331869, 0.004036597441881895, 0.004220874514430761, 0.09984210878610611, 0.08946765959262848, 0.003813766408711672, 0.003897393587976694, 0.003963619936257601, 0.003981609363108873, 0.10292323678731918, 0.004109821282327175, 0.004221146926283836, 0.10209117829799652, 0.004131417255848646, 0.14369480311870575, 0.00415428914129734, 0.11372322589159012, 0.10677137970924377, 0.005115794949233532, 0.004517248831689358, 0.19833123683929443, 0.08931180089712143, 0.08264380693435669, 0.005423770751804113, 0.005476957652717829, 0.005528302397578955, 0.120222307741642, 0.006379217840731144, 0.28657475113868713, 0.006637600716203451, 0.007629323285073042, 0.00692034000530839, 0.007572951726615429, 0.00791223905980587, 0.16047964990139008, 0.008736399933695793, 0.009266920387744904, 0.008814379572868347, 0.007877792231738567, 0.15738782286643982, 0.008414333686232567, 0.00833861157298088, 0.13112132251262665, 0.008501186035573483, 0.007912193424999714, 0.0077561321668326855, 0.008007492870092392, 0.008526494726538658, 0.0075655835680663586, 0.1770726889371872, 0.011331860907375813, 0.008008847944438457, 0.008319646120071411, 0.008117214776575565, 0.007791911251842976, 0.007701822090893984, 0.10016918927431107, 0.007106225471943617, 0.007532215677201748, 0.006234870292246342, 0.006701298989355564, 0.0060502453707158566, 0.005838943179696798, 0.005480616353452206, 0.005466739181429148, 0.005759579129517078, 0.005201996769756079, 0.005419033579528332, 0.005117324180901051, 0.005531360395252705, 0.004844111390411854, 0.004470224026590586, 0.004314804915338755, 0.15898598730564117, 0.004496333189308643, 0.004145872313529253, 0.0046361880376935005, 0.004550578072667122, 0.005026913248002529, 0.003714563325047493, 0.003737275954335928, 0.0035593656357377768, 0.0039012297056615353, 0.003812977811321616, 0.0033456459641456604, 0.003226039232686162, 0.003422241657972336, 0.1197771206498146, 0.4574677050113678, 0.003448347095400095, 0.00351222837343812, 0.12633496522903442, 0.00387914408929646, 0.004437481984496117, 0.004800200928002596, 0.004381949547678232, 0.0045686205849051476, 0.004680916201323271, 0.09667735546827316, 0.13669417798519135, 0.004961084108799696, 0.005346082150936127, 0.005438421852886677, 0.005506708286702633, 0.006031477823853493, 0.005539163947105408, 0.005998925771564245, 0.005226446781307459, 0.00517190620303154, 0.0053866105154156685, 0.35677921772003174, 0.005514897406101227, 0.09800000488758087, 0.006236811634153128, 0.006446948740631342, 0.006124101113528013, 0.006865726318210363, 0.006742071360349655, 0.0074609508737921715, 0.00650758808478713, 0.006794923450797796, 0.006539385765790939, 0.06289111077785492, 0.0072285267524421215, 0.15431785583496094, 0.006485356483608484, 0.12693794071674347, 0.006921072956174612, 0.08404310047626495, 0.006894813850522041, 0.006580674089491367, 0.09126125276088715, 0.4006933271884918, 0.0069365911185741425, 0.007946101948618889, 0.00767144002020359, 0.008866770192980766, 0.008340909145772457, 0.008869155310094357, 0.01107777375727892, 0.008972608484327793, 0.009870177134871483, 0.009177458472549915, 0.009355570189654827, 0.00958375632762909, 0.008277966640889645, 0.007815102115273476, 0.00774806272238493, 0.008114675991237164, 0.1268594115972519, 0.007428524550050497, 0.007167811039835215, 0.007281947415322065, 0.1599101722240448, 0.006862407084554434, 0.0069616446271538734, 0.007287994027137756, 0.007203156594187021, 0.006530289072543383, 0.22992658615112305, 0.005902429576963186, 0.0063243736512959, 0.09869983792304993, 0.10206600278615952, 0.005780122242867947, 0.08428411930799484, 0.005756277125328779, 0.006697617471218109, 0.005966433323919773, 0.13193440437316895, 0.005683138966560364, 0.006132918875664473, 0.005811510141938925, 0.005814815871417522, 0.08977869153022766, 0.00583849148824811, 0.005943953059613705, 0.13803094625473022, 0.0054719033651053905, 0.10014370083808899, 0.005602720659226179, 0.11165504157543182, 0.005950745660811663, 0.005700635723769665, 0.005865866784006357, 0.006263964809477329, 0.005836876109242439, 0.005631878972053528, 0.005726939532905817, 0.005396990571171045, 0.00620080903172493, 0.005629091989248991, 0.00516635412350297, 0.0054564871825277805, 0.005537752527743578, 0.10025008022785187, 0.004747398197650909, 0.004810838028788567, 0.004690208472311497, 0.004776353947818279, 0.004518551751971245, 0.0046278974041342735, 0.0045152027159929276, 0.14587904512882233, 0.004586273804306984, 0.46218493580818176, 0.15117967128753662, 0.08515831083059311, 0.005561674013733864, 0.005497551057487726, 0.005934013053774834, 0.005700393579900265, 0.006399959325790405, 0.0063188569620251656, 0.006466289982199669, 0.006147829350084066, 0.006546353921294212, 0.006394864525645971, 0.0065591647289693356, 0.006866399198770523, 0.006329723633825779, 0.006510978098958731, 0.006649439223110676, 0.006401422433555126, 0.006359920836985111, 0.0058413781225681305, 0.005665491335093975, 0.0055204154923558235, 0.005804579239338636, 0.005417856853455305, 0.005778455641120672, 0.005231884773820639, 0.004983026534318924, 0.005265883170068264, 0.10631155222654343, 0.005303835030645132, 0.004602252971380949, 0.005004664417356253, 0.004529439844191074, 0.1411852091550827, 0.0049092406406998634, 0.004283701069653034, 0.004411425441503525, 0.004046799149364233, 0.0043812887743115425, 0.0044547482393682, 0.003907262347638607, 0.004171542823314667, 0.003971787169575691, 0.0037345648743212223, 0.0037512138951569796, 0.00403174152597785, 0.003673209110274911, 0.003550178138539195, 0.003379851346835494, 0.003692398313432932, 0.0035074211191385984, 0.0031460984610021114, 0.0033092752564698458, 0.00316992006264627, 0.0032421709038317204, 0.003042848315089941, 0.0029112743213772774, 0.0031340511050075293, 0.0027577425353229046, 0.09508395940065384, 0.0026778585743159056, 0.0029652095399796963, 0.0027237036265432835, 0.0026399220805615187, 0.0026266747154295444, 0.0027514053508639336, 0.002728682942688465, 0.0026676030829548836, 0.0025922597851604223, 0.002553412225097418, 0.0025713301729410887, 0.002428977517411113, 0.002488410100340843, 0.0022789770737290382, 0.0023136278614401817, 0.0021788980811834335, 0.0022606479469686747, 0.0021902143489569426, 0.002450586063787341, 0.0021518615540117025, 0.002111703623086214, 0.0020975808147341013, 0.002145408419892192, 0.0021797078661620617, 0.11806241422891617, 0.0020288252271711826, 0.002062499290332198, 0.0019506877288222313, 0.46451565623283386, 0.0023388401605188847, 0.11391511559486389, 0.0023395640309900045, 0.14015114307403564, 0.002952998038381338, 0.13475483655929565, 0.0032519374508410692, 0.003619617549702525, 0.0036014351062476635, 0.0037009003572165966, 0.003957828041166067, 0.11698877066373825, 0.003946451935917139, 0.08332844078540802, 0.004293715115636587, 0.004748351871967316, 0.004846103955060244, 0.004902588669210672, 0.004685412626713514, 0.0052278852090239525, 0.005526021588593721, 0.005160850007086992, 0.004703866317868233, 0.14511528611183167, 0.005200090352445841, 0.0066721742041409016, 0.004989481996744871, 0.00500438641756773, 0.004911121446639299, 0.005579361226409674, 0.00528523325920105, 0.0048287538811564445, 0.00462443009018898, 0.004524159710854292, 0.004605268593877554, 0.004716549068689346, 0.10554178804159164, 0.004317185841500759, 0.005228780675679445, 0.004263617563992739, 0.004783743992447853, 0.004396303556859493, 0.14646485447883606, 0.1449907422065735, 0.004093102645128965, 0.004317758604884148, 0.004539129324257374, 0.21264784038066864, 0.004277385305613279, 0.004533711820840836, 0.00440223840996623, 0.004524926654994488, 0.17078489065170288, 0.004652517382055521, 0.0043707964941859245, 0.004852157086133957, 0.004865845665335655, 0.08860990405082703, 0.005027643404901028, 0.0045389155857264996, 0.004804845899343491, 0.004711016546934843, 0.004506602883338928, 0.13794372975826263, 0.004475434776395559, 0.004401365295052528, 0.15225277841091156, 0.09591107815504074, 0.29044872522354126, 0.00486466009169817, 0.0052785007283091545, 0.005259750410914421, 0.005714475177228451, 0.005820839665830135, 0.006363900378346443, 0.006138146854937077, 0.006055287551134825, 0.006277075968682766, 0.006813462357968092, 0.006144100800156593, 0.0063406373374164104, 0.00630988460034132, 0.0060667372308671474, 0.0064602019265294075, 0.0059601496905088425, 0.006250096019357443, 0.005919781979173422, 0.005621731746941805, 0.005736284423619509, 0.005559153854846954, 0.005417857319116592, 0.005452840588986874, 0.0051289997063577175, 0.00557251600548625, 0.00513825798407197, 0.004980448167771101, 0.005533529911190271, 0.004624261055141687, 0.004435040522366762, 0.004576134029775858, 0.11772044003009796, 0.004207405261695385, 0.004122880287468433, 0.004119234625250101, 0.00416336115449667, 0.004163791425526142, 0.003969627432525158, 0.004165498074144125, 0.14798180758953094, 0.003806479275226593, 0.0039051927160471678, 0.003819149686023593, 0.15454047918319702, 0.0037055963184684515, 0.003576798364520073, 0.0035653780214488506, 0.003926553763449192, 0.003662030678242445, 0.003701792098581791, 0.0036278278566896915, 0.00364829134196043, 0.003744747256860137, 0.0034739782568067312, 0.12102741748094559, 0.0034415842965245247, 0.003550478722900152, 0.0033631243277341127, 0.5773178339004517, 0.004301550332456827, 0.0037778711412101984, 0.0901181623339653, 0.00428039999678731, 0.14307548105716705, 0.004446137696504593, 0.00500081991776824, 0.004818205256015062, 0.004946812521666288, 0.005220005288720131, 0.2843938171863556, 0.005454237572848797, 0.006031375378370285, 0.006229044403880835, 0.006786002777516842, 0.166782945394516, 0.13008709251880646, 0.007265928201377392, 0.007619798183441162, 0.07924284040927887, 0.007641920819878578, 0.007861118763685226, 0.008046177215874195, 0.00791850034147501, 0.23232056200504303, 0.009164373390376568, 0.008727890439331532, 0.009343407116830349, 0.009210165590047836, 0.01016524713486433, 0.00901438295841217, 0.009648994542658329, 0.00942558515816927, 0.009523828513920307, 0.009241266176104546, 0.009600205346941948, 0.09332609176635742, 0.009633783251047134, 0.009591422975063324, 0.008266444317996502, 0.008638549596071243, 0.008204763755202293, 0.008046670816838741, 0.009026767686009407, 0.0729396715760231, 0.18148000538349152, 0.007277532946318388, 0.0070680188946425915, 0.007590423338115215, 0.007373475935310125, 0.006692694034427404, 0.0072284480556845665, 0.00688374787569046, 0.006227536126971245, 0.09772749245166779, 0.00599568011239171, 0.006167406681925058, 0.006309030577540398, 0.006150717381387949, 0.005665473639965057, 0.005451116245239973, 0.005297861061990261, 0.006339197512716055, 0.005883319303393364, 0.00519800977781415, 0.004947999957948923, 0.004918945021927357, 0.004930572584271431, 0.42836812138557434, 0.004703624173998833, 0.10937237739562988, 0.00500494847074151, 0.0051527246832847595, 0.005304029211401939, 0.005777547601610422, 0.10390468686819077, 0.005416207481175661, 0.005836457014083862, 0.00597051065415144, 0.00550162885338068, 0.005809813737869263, 0.005974217317998409, 0.006041373126208782, 0.06758575886487961, 0.00556241674348712, 0.005658216308802366, 0.005548157729208469, 0.005453482270240784, 0.15088461339473724, 0.14233535528182983, 0.00561848608776927, 0.005378398112952709, 0.005328215658664703, 0.16181424260139465, 0.005961354356259108, 0.005538007244467735, 0.005433815065771341, 0.006121876649558544, 0.0054914928041398525, 0.005320981610566378, 0.0053642746061086655, 0.005398118868470192, 0.005781072657555342, 0.11833392828702927, 0.005139678716659546, 0.005728697869926691, 0.005095127038657665, 0.005071858875453472, 0.0052872165106236935, 0.004762119147926569, 0.00485612079501152, 0.005288509652018547, 0.004488433711230755, 0.004728346131742001, 0.1206565722823143, 0.0046325428411364555, 0.07930829375982285, 0.004604152869433165, 0.004567117430269718, 0.004445235710591078, 0.004158847499638796, 0.004325200337916613, 0.4105291962623596, 0.00432179681956768, 0.005169340874999762, 0.005015532951802015, 0.004710453096777201, 0.005038508214056492, 0.0050412858836352825, 0.005411696620285511, 0.005585054866969585, 0.11077290773391724, 0.00503925746306777, 0.005289208143949509, 0.12307232618331909, 0.006329606752842665, 0.005289588589221239, 0.19048981368541718, 0.00532717676833272, 0.005308590363711119, 0.005429064389318228, 0.005322803743183613, 0.14631778001785278, 0.0058948020450770855, 0.005872964393347502, 0.00542846042662859, 0.005560878664255142, 0.005565736908465624, 0.005383247975260019, 0.1365622878074646, 0.13580535352230072, 0.005292470566928387, 0.00540925795212388, 0.0056695290841162205, 0.005287746898829937, 0.11992233991622925, 0.00539765739813447, 0.005366974975913763, 0.3529217541217804, 0.005633189808577299, 0.0058445255272090435, 0.0060971323400735855, 0.00622153002768755, 0.006453909911215305, 0.006302243564277887, 0.006967359688133001, 0.006374198477715254, 0.006422783248126507, 0.007681625429540873, 0.006761185824871063, 0.006308676674962044, 0.006555551663041115, 0.0062096030451357365, 0.006254396867007017, 0.005986730568110943, 0.006115566473454237, 0.005791735835373402, 0.005739765241742134, 0.005981236230581999, 0.005614349152892828, 0.005666316952556372, 0.005813230760395527, 0.005268413573503494, 0.005115806125104427, 0.0049898079596459866, 0.10623110085725784, 0.005146476440131664, 0.004709882661700249, 0.004844709299504757, 0.004577332176268101, 0.004446430131793022, 0.004731352906674147, 0.004268505610525608, 0.0041846525855362415, 0.0042392052710056305, 0.004214292857795954, 0.004008156713098288, 0.12216721475124359, 0.0038494551554322243, 0.0038246142212301493, 0.004170824307948351, 0.0038147312588989735, 0.00379478489048779, 0.003768341848626733, 0.0037160359788686037, 0.0035098434891551733, 0.003443607361987233, 0.2016615867614746, 0.0034445798955857754, 0.003613326232880354, 0.003565497463569045, 0.003500645514577627, 0.0034712685737758875, 0.12714380025863647, 0.0032949044834822416, 0.1057896837592125, 0.00349041516892612, 0.0035524500999599695, 0.0034855541307479143, 0.0033565957564860582, 0.0034374056849628687, 0.0034003104083240032, 0.003642614232376218, 0.0034974138252437115, 0.00345091475173831, 0.003386359428986907, 0.00361420214176178, 0.00324511481449008, 0.003385176882147789, 0.0032597712706774473, 0.0032956856302917004, 0.09011388570070267, 0.0032108351588249207, 0.003205010900273919, 0.0030651947017759085, 0.1016932800412178, 0.0030325616244226694, 0.1741698831319809, 0.0031020077876746655, 0.09751064330339432, 0.0033407409209758043, 0.0032579482067376375, 0.16448785364627838, 0.003521126927807927, 0.003362481715157628, 0.0035001833457499743, 0.16493096947669983, 0.11082044988870621, 0.0037101584021002054, 0.0036899175029248, 0.004074657801538706, 0.0038222994189709425, 0.003998966887593269, 0.004032652825117111, 0.004027045797556639, 0.004238520748913288, 0.004009690135717392, 0.004284198395907879, 0.004188362509012222, 0.004315020516514778, 0.004297517240047455, 0.0038772202096879482, 0.00393634894862771, 0.0037717947270721197, 0.14123326539993286, 0.0038252845406532288, 0.0036638800520449877, 0.00366000272333622, 0.003677044063806534, 0.0037110226694494486, 0.0036884781438857317, 0.0037077448796480894, 0.1707482784986496, 0.0036133751273155212, 0.003689194330945611, 0.0037118163891136646, 0.003988159820437431, 0.0037256567738950253, 0.00357771385461092, 0.09616822004318237, 0.003742913482710719, 0.0035290829837322235, 0.0035696704871952534, 0.3536517322063446, 0.003704374423250556, 0.004186992533504963, 0.09375534951686859, 0.004295858088880777, 0.004438703879714012, 0.004447067156434059, 0.0044730002991855145, 0.1178334429860115, 0.004929487593472004, 0.004722787998616695, 0.0050484538078308105, 0.004922686144709587, 0.005025339312851429, 0.00489691412076354, 0.005210041534155607, 0.005202386062592268, 0.09898390620946884, 0.13180118799209595, 0.0050889672711491585, 0.13001364469528198, 0.005056746304035187, 0.005269198212772608, 0.005497931037098169, 0.005297055002301931, 0.005600344855338335, 0.005363596603274345, 0.005220188293606043, 0.005214572884142399, 0.0051294355653226376, 0.10822486132383347, 0.10003478080034256, 0.11998455226421356, 0.005180333741009235, 0.005678235087543726, 0.005234810058027506, 0.005377614870667458, 0.005215046461671591, 0.13511940836906433, 0.005211105570197105, 0.0052449568174779415, 0.00548678869381547, 0.005580518394708633, 0.005275350995361805, 0.005392454564571381, 0.005105994641780853, 0.005345314275473356, 0.15020376443862915, 0.005315795075148344, 0.12024391442537308, 0.005355672910809517, 0.005276509560644627, 0.12912897765636444, 0.09267172962427139, 0.11487496644258499, 0.005911416374146938, 0.11292368173599243, 0.47461798787117004, 0.005932497791945934, 0.006190971005707979, 0.0997350737452507, 0.006575480569154024, 0.006889021024107933, 0.007497001439332962, 0.007868112064898014, 0.007489190902560949, 0.1179298385977745, 0.007641336880624294, 0.007910757325589657, 0.12054426968097687, 0.11623205244541168, 0.008065495640039444, 0.10604166984558105, 0.008886788040399551, 0.008614273741841316, 0.008480715565383434, 0.008673370815813541, 0.11755114048719406, 0.08768723160028458, 0.10094103962182999, 0.12676922976970673, 0.008817209862172604, 0.14482159912586212, 0.008749933913350105, 0.009618385694921017, 0.008897506631910801, 0.009097001515328884, 0.0781140998005867, 0.00867383275181055, 0.008971639908850193, 0.009907564148306847, 0.008879309520125389, 0.00870556104928255, 0.00850945059210062, 0.008218576200306416, 0.00832957774400711, 0.007915814407169819, 0.008096275851130486, 0.13241001963615417, 0.00730829406529665, 0.00751905795186758, 0.007314489688724279, 0.00706318486481905, 0.0068509834818542, 0.1192483976483345, 0.006685921922326088, 0.3445921242237091, 0.0066846138797700405, 0.006748059764504433, 0.007299437187612057, 0.0075829485431313515, 0.007166336756199598, 0.007293462287634611, 0.007037709001451731, 0.006898269522935152, 0.09802816063165665, 0.007316110655665398, 0.006909753195941448, 0.006797554902732372, 0.0068144123069942, 0.08645781129598618, 0.12208902090787888, 0.0069743674248456955, 0.0067321560345590115, 0.0066840676590800285, 0.006622273940593004, 0.006710456218570471, 0.006856513675302267, 0.006587636657059193, 0.006283941213041544, 0.38421469926834106, 0.006636654958128929, 0.14731000363826752, 0.006797232199460268, 0.007011817302554846, 0.0074546183459460735, 0.10250341147184372, 0.0071863820776343346, 0.007477954495698214, 0.007444797549396753, 0.00759201729670167, 0.007639536168426275, 0.11518845707178116, 0.007489706389605999, 0.007222388871014118, 0.007179933600127697, 0.007081929594278336, 0.007162116002291441, 0.006976692471653223, 0.00723279407247901, 0.006908725015819073, 0.00697622774168849, 0.006593013182282448, 0.0064620343036949635, 0.006852360907942057, 0.006411452312022448, 0.006170520558953285, 0.10103891044855118, 0.00612367270514369, 0.005715890321880579, 0.005704008974134922, 0.005569448694586754, 0.0059822928160429, 0.10256402939558029, 0.1508592665195465, 0.10965317487716675, 0.00540046626701951, 0.10471966117620468, 0.005464500281959772, 0.005363971460610628, 0.005548856221139431, 0.005730017088353634, 0.005426160525530577, 0.005347700323909521, 0.005227592773735523, 0.005402692127972841, 0.005189095623791218, 0.00523676723241806, 0.4512106478214264, 0.005310093984007835, 0.14045129716396332, 0.005766067188233137, 0.005796737503260374, 0.11131853610277176, 0.006039886269718409, 0.006121186539530754, 0.006342142820358276, 0.11588449776172638, 0.006720652338117361, 0.006736359093338251, 0.007068088743835688, 0.00664265314117074, 0.006570819299668074, 0.05871853977441788, 0.006549860816448927, 0.006444290746003389, 0.006521329749375582, 0.0064810048788785934, 0.0064440262503921986, 0.007316454779356718, 0.006188607774674892, 0.006207762751728296, 0.0062397983856499195, 0.006355942226946354, 0.09514866769313812, 0.005881532095372677, 0.005889976397156715, 0.005823933985084295, 0.0059226625598967075, 0.11629429459571838, 0.005711087491363287, 0.005482832435518503, 0.08333530277013779, 0.005434362683445215, 0.005302298814058304, 0.005434499122202396, 0.0056820823810994625, 0.005224073305726051, 0.0052346899174153805, 0.005320216529071331, 0.005238344892859459, 0.14073190093040466, 0.005122678820043802, 0.12259899079799652, 0.005038662813603878, 0.004913315176963806, 0.005198176484555006, 0.004842126276344061, 0.10343090444803238, 0.004948016256093979, 0.004789954517036676, 0.005165512207895517, 0.09335537999868393, 0.10329582542181015, 0.004997259471565485, 0.00477788457646966, 0.0051887608133256435, 0.004831579048186541, 0.005510041490197182, 0.0048759086057543755, 0.12756715714931488, 0.0052496748976409435, 0.08676650375127792, 0.004715855233371258, 0.15959866344928741, 0.12632794678211212, 0.005142814014106989, 0.005877058487385511, 0.005258044693619013, 0.005018920172005892, 0.005353945307433605, 0.00507403165102005, 0.0051055606454610825, 0.004986651241779327, 0.005230116192251444, 0.005071296356618404, 0.004966608714312315, 0.004853632301092148, 0.005049337167292833, 0.005082829389721155, 0.004638100508600473, 0.005047446116805077, 0.00483318604528904, 0.004475626163184643, 0.004439832177013159, 0.004431195557117462, 0.0046402388252317905, 0.06810551136732101, 0.3878462612628937, 0.004543619230389595, 0.004671221133321524, 0.004594829399138689, 0.004815702326595783, 0.004802633076906204, 0.004957197699695826, 0.0049737864173948765, 0.005120726767927408, 0.005415454041212797, 0.005211362615227699, 0.005012168549001217, 0.004958865698426962, 0.004966395441442728, 0.005357735324651003, 0.00479521881788969, 0.10432769358158112, 0.004854792263358831, 0.004952715709805489, 0.004670711234211922, 0.004709791392087936, 0.0056749023497104645, 0.09988270699977875, 0.004950429778546095, 0.0045054759830236435, 0.004522311966866255, 0.004608477000147104, 0.08452709764242172, 0.004491263534873724, 0.004481062293052673, 0.004520433489233255, 0.004506831523030996, 0.004909842740744352, 0.004992479924112558, 0.004347422160208225, 0.004254172556102276, 0.004207727499306202, 0.004357797093689442, 0.0041438378393650055, 0.004033416509628296, 0.004086750093847513, 0.004199303220957518, 0.004157980903983116, 0.004097556695342064, 0.1570868194103241, 0.0036925042513757944, 0.12791863083839417, 0.0037980847992002964, 0.003937410656362772, 0.004252460319548845, 0.0039072344079613686, 0.004027348943054676, 0.0036478927358984947, 0.08187136054039001, 0.0037742822896689177, 0.003732221433892846, 0.0038046645931899548, 0.004037575330585241, 0.0037254325579851866, 0.0036802536342293024, 0.0037995665334165096, 0.003759691957384348, 0.0035092118196189404, 0.0034986420068889856, 0.0036256113089621067, 0.003772829659283161, 0.003980665933340788, 0.0034025453496724367, 0.0033592404797673225, 0.0033137693535536528, 0.0033954621758311987, 0.003434154437854886, 0.4903046488761902, 0.003408249234780669, 0.0035078690852969885, 0.0034201769158244133, 0.0036076195538043976, 0.13263723254203796, 0.004150712862610817, 0.003826265223324299, 0.003893853398039937, 0.004300107713788748, 0.004031781107187271, 0.003956729546189308, 0.1384975165128708, 0.0043617249466478825, 0.004099705722182989, 0.004223320167511702, 0.1929420381784439, 0.004186411388218403, 0.004751238971948624, 0.0042067598551511765, 0.004317538812756538, 0.004604327026754618, 0.13312311470508575, 0.00433306721970439, 0.09887789189815521, 0.004405485466122627, 0.004497158341109753, 0.12194540351629257, 0.00448272842913866, 0.0047231740318238735, 0.004665785934776068, 0.004636047873646021, 0.004858935251832008, 0.00475689023733139, 0.11987735331058502, 0.004772270563989878, 0.1249576210975647, 0.004664062522351742, 0.004855387378484011, 0.0046346792951226234, 0.004983994178473949, 0.004801051691174507, 0.004833039361983538, 0.004674118477851152, 0.10974181443452835, 0.0048203314654529095, 0.004749483894556761, 0.004787498153746128, 0.004833863582462072, 0.09982944279909134, 0.0045381467789411545, 0.09716831892728806, 0.004718990530818701, 0.004634029697626829, 0.004714930895715952, 0.1558886170387268, 0.004740721080452204, 0.00460326112806797, 0.0046759131364524364, 0.004998541437089443, 0.004804105963557959, 0.004608293995261192, 0.004556051455438137, 0.004888690076768398, 0.0046564615331590176, 0.004680580459535122, 0.004594121593981981, 0.10521524399518967, 0.004442600533366203, 0.004434823989868164, 0.004772703163325787, 0.004406357184052467, 0.0045184362679719925, 0.004219395574182272, 0.0043876138515770435, 0.004203274846076965, 0.004046150948852301, 0.004183904267847538, 0.13606300950050354, 0.004049596842378378, 0.004107979126274586, 0.10272884368896484, 0.003909786231815815, 0.0038626790046691895, 0.003916209563612938, 0.004293400794267654, 0.00403117248788476, 0.004030152224004269, 0.003806507680565119, 0.004101922735571861, 0.003734650555998087, 0.003681455971673131, 0.14661294221878052, 0.003647184930741787, 0.1110876128077507, 0.003930551931262016, 0.00403174851089716, 0.003758869366720319, 0.0037753405049443245, 0.07090190052986145, 0.003973752725869417, 0.0037535279989242554, 0.0040896120481193066, 0.003742536995559931, 0.004063595086336136, 0.08756155520677567, 0.003955997060984373, 0.4281373620033264, 0.12239472568035126, 0.00402779271826148, 0.004284863360226154, 0.1132281944155693, 0.00477856257930398, 0.004734433256089687, 0.005241716280579567, 0.00522275548428297, 0.0050190165638923645, 0.005167993251234293, 0.005214711185544729, 0.005612294189631939, 0.00542823551222682, 0.005507368594408035, 0.00539895286783576, 0.005297287832945585, 0.005203215405344963, 0.005223861895501614, 0.12743715941905975, 0.09346630424261093, 0.0050916424952447414, 0.005108580458909273, 0.005244242027401924, 0.005150091368705034, 0.005347047001123428, 0.005328106693923473, 0.005388251040130854, 0.00532376067712903, 0.005112941842526197, 0.0054044658318161964, 0.005436301231384277, 0.005489226896315813, 0.004825432784855366, 0.0047484757378697395, 0.0047398959286510944, 0.004695388488471508, 0.005326235666871071, 0.004525270778685808, 0.004416833631694317, 0.004575784783810377, 0.004695134703069925]\n",
            "Val loss 0.03885501542906232\n",
            "Val auc roc 0.5335511342779531\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c8d17105eef4631a236968f5ad5ae93",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1636.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0304\n",
            "Train Losses : [0.004442374687641859, 0.14959625899791718, 0.004154347348958254, 0.004420398734509945, 0.4708503782749176, 0.004423100966960192, 0.004503650590777397, 0.004387578461319208, 0.004645986948162317, 0.005103495437651873, 0.004717040807008743, 0.005062161013484001, 0.004822248127311468, 0.004932086914777756, 0.004833656828850508, 0.004704474005848169, 0.005230535287410021, 0.004757218062877655, 0.004924885928630829, 0.00489264028146863, 0.0046071442775428295, 0.004844798240810633, 0.0048356628976762295, 0.005055221728980541, 0.004582378081977367, 0.19444721937179565, 0.004647534806281328, 0.14131805300712585, 0.00474962592124939, 0.004548081662505865, 0.004405062645673752, 0.004378525074571371, 0.3208583891391754, 0.004693137016147375, 0.11220669746398926, 0.004773552063852549, 0.004969023168087006, 0.005216685123741627, 0.005188656505197287, 0.07281544804573059, 0.00533632468432188, 0.005384170450270176, 0.005570809356868267, 0.005544501822441816, 0.005416756961494684, 0.005668526981025934, 0.005617257207632065, 0.00554315373301506, 0.005499544087797403, 0.005609620828181505, 0.005581226199865341, 0.005822036415338516, 0.0054137492552399635, 0.0055753556080162525, 0.005092177074402571, 0.08970223367214203, 0.005057783331722021, 0.005007941275835037, 0.00490671256557107, 0.00500412518158555, 0.0050761885941028595, 0.005013064481317997, 0.005019789561629295, 0.005201431922614574, 0.005074209533631802, 0.004759050440043211, 0.004553147591650486, 0.004397946875542402, 0.004557824227958918, 0.004254952538758516, 0.0041666701436042786, 0.0049410187639296055, 0.0044079977087676525, 0.004455560818314552, 0.003960203845053911, 0.0038934119511395693, 0.004357862286269665, 0.004086659289896488, 0.004033854231238365, 0.0038549723103642464, 0.0035198854748159647, 0.0035844985395669937, 0.0036286741960793734, 0.12573136389255524, 0.003441446926444769, 0.0037499454338103533, 0.003431393764913082, 0.003584223100915551, 0.003625851357355714, 0.14385351538658142, 0.003290519118309021, 0.003328565042465925, 0.003196261590346694, 0.0035498144570738077, 0.0034820011351257563, 0.0033916248939931393, 0.0034731857012957335, 0.0031829471699893475, 0.003112844191491604, 0.003103938652202487, 0.003199982922524214, 0.0029902057722210884, 0.003032806096598506, 0.003417790634557605, 0.09806495159864426, 0.16357214748859406, 0.0029856357723474503, 0.0029561426490545273, 0.003098019864410162, 0.0030747198034077883, 0.0029977012891322374, 0.0032898939680308104, 0.003341994248330593, 0.13164757192134857, 0.00333982240408659, 0.00308209634386003, 0.00311383162625134, 0.00354578229598701, 0.003125806339085102, 0.0032088172156363726, 0.13935312628746033, 0.0035851530265063047, 0.15565864741802216, 0.0032246308401226997, 0.003211531788110733, 0.003199714468792081, 0.003554139519110322, 0.10904087126255035, 0.0032869542483240366, 0.38637739419937134, 0.0037889841478317976, 0.003720640204846859, 0.003679271787405014, 0.003969623241573572, 0.0038893651217222214, 0.004088420886546373, 0.14323721826076508, 0.004144274163991213, 0.15635572373867035, 0.004619779530912638, 0.004679656587541103, 0.004551765974611044, 0.0046865930780768394, 0.004667379427701235, 0.004792647901922464, 0.004599556792527437, 0.12377485632896423, 0.0047845859080553055, 0.3287409842014313, 0.005194527097046375, 0.005452951416373253, 0.005479900166392326, 0.005869496148079634, 0.09969735890626907, 0.006096092518419027, 0.0065087624825537205, 0.0061131990514695644, 0.006315760780125856, 0.005975072272121906, 0.11190354824066162, 0.005975682754069567, 0.005900820251554251, 0.0059455931186676025, 0.006220861338078976, 0.006103673484176397, 0.006115779280662537, 0.006043444387614727, 0.13660971820354462, 0.005821694619953632, 0.006457807030528784, 0.09831106662750244, 0.006068929098546505, 0.00601166719570756, 0.1717994660139084, 0.005974575877189636, 0.005820464342832565, 0.12562504410743713, 0.09939104318618774, 0.005844459868967533, 0.005777306389063597, 0.006121631246060133, 0.005915405694395304, 0.006172794848680496, 0.005914387293159962, 0.005810413043946028, 0.3512299060821533, 0.005816946737468243, 0.0065384358167648315, 0.006327670067548752, 0.006746741011738777, 0.006305726245045662, 0.08642164617776871, 0.006409991532564163, 0.0068243141286075115, 0.006578341126441956, 0.00636774767190218, 0.006373240612447262, 0.007284841500222683, 0.11817149817943573, 0.006405444350093603, 0.006999212317168713, 0.006378164980560541, 0.006365724839270115, 0.006332177668809891, 0.0060900188982486725, 0.006169823929667473, 0.00600030180066824, 0.006530508864670992, 0.006477848161011934, 0.0999925509095192, 0.005890419706702232, 0.0057557690888643265, 0.006392434239387512, 0.094207264482975, 0.005569515284150839, 0.00584212364628911, 0.0058715916238725185, 0.12849844992160797, 0.005597659386694431, 0.005405678879469633, 0.005406430456787348, 0.005528350360691547, 0.18321086466312408, 0.005190795287489891, 0.00533159077167511, 0.0051498920656740665, 0.0057689896784722805, 0.005174445919692516, 0.005642345175147057, 0.09623265266418457, 0.3176439702510834, 0.005334899760782719, 0.0052502830512821674, 0.0055884444154798985, 0.005769982933998108, 0.005821680650115013, 0.00559574319049716, 0.005629285238683224, 0.12640205025672913, 0.005737949628382921, 0.006291727069765329, 0.005699114874005318, 0.005839302204549313, 0.11260029673576355, 0.006008053198456764, 0.005807952489703894, 0.005717400461435318, 0.0957869291305542, 0.005893376190215349, 0.005862098187208176, 0.005703108385205269, 0.006041637156158686, 0.0893821194767952, 0.005750385578721762, 0.005772266536951065, 0.09942483901977539, 0.005888163577765226, 0.005913530010730028, 0.006281265057623386, 0.005523901432752609, 0.005767472553998232, 0.0059253862127661705, 0.14757077395915985, 0.005506463348865509, 0.005789492279291153, 0.005737173371016979, 0.005362709052860737, 0.005333881359547377, 0.005212737247347832, 0.005245505832135677, 0.0051000649109482765, 0.0056865704245865345, 0.0050695124082267284, 0.005465538706630468, 0.004941284656524658, 0.004800315015017986, 0.14058610796928406, 0.1037602573633194, 0.004953418858349323, 0.00493713840842247, 0.004748159553855658, 0.10225546360015869, 0.004725388251245022, 0.0047586094588041306, 0.004638210870325565, 0.005041447933763266, 0.004692636895924807, 0.004836673382669687, 0.004620236344635487, 0.11331866681575775, 0.004726517014205456, 0.12162348628044128, 0.004861973691731691, 0.13553039729595184, 0.004532916005700827, 0.004671093076467514, 0.0046769119799137115, 0.004576375707983971, 0.1156768724322319, 0.004701897501945496, 0.005230443086475134, 0.08456315845251083, 0.0047450908459723, 0.1480417549610138, 0.005009716842323542, 0.004916192032396793, 0.0053503806702792645, 0.004831718280911446, 0.005153600592166185, 0.004735298454761505, 0.0890861377120018, 0.004792696330696344, 0.004800434224307537, 0.09966710209846497, 0.12976358830928802, 0.10706903040409088, 0.0049059572629630566, 0.005105205811560154, 0.0053185150027275085, 0.005494310986250639, 0.005144840106368065, 0.005012420006096363, 0.005123253911733627, 0.005765785928815603, 0.004985463805496693, 0.1096741259098053, 0.0051568979397416115, 0.005137923639267683, 0.11087508499622345, 0.005029482301324606, 0.005727512761950493, 0.004928066860884428, 0.44518378376960754, 0.005518007557839155, 0.0052227661944925785, 0.3581959903240204, 0.005682175513356924, 0.005987309385091066, 0.006025436334311962, 0.006337118800729513, 0.006395465228706598, 0.006820501293987036, 0.0066785672679543495, 0.0067537445574998856, 0.08571304380893707, 0.1162765845656395, 0.11703827232122421, 0.006958962418138981, 0.153731107711792, 0.007923614233732224, 0.007534679491072893, 0.007939801551401615, 0.129543736577034, 0.008311512880027294, 0.18874724209308624, 0.10397163033485413, 0.008292856626212597, 0.007959911599755287, 0.00843200832605362, 0.008183393627405167, 0.007797404192388058, 0.13209828734397888, 0.007925393059849739, 0.00792429968714714, 0.11892794072628021, 0.00843745842576027, 0.008095763623714447, 0.07927879691123962, 0.007573301438242197, 0.17495660483837128, 0.00815762672573328, 0.00875493697822094, 0.007819142192602158, 0.007416242267936468, 0.007422389928251505, 0.007370749022811651, 0.12746977806091309, 0.007205124944448471, 0.12228413671255112, 0.007305498700588942, 0.007204859051853418, 0.007171905133873224, 0.00701657822355628, 0.13745194673538208, 0.0070111993700265884, 0.007094108499586582, 0.00707498611882329, 0.701367974281311, 0.007105332333594561, 0.1337037831544876, 0.007585696876049042, 0.007935955189168453, 0.007864956744015217, 0.0082887914031744, 0.008092002011835575, 0.008151506073772907, 0.15147972106933594, 0.37816205620765686, 0.11325012147426605, 0.008819375187158585, 0.008812692016363144, 0.008878657594323158, 0.009003577753901482, 0.008969075046479702, 0.009286435320973396, 0.009475701488554478, 0.00932279508560896, 0.009708470664918423, 0.10176097601652145, 0.00965614803135395, 0.009019668214023113, 0.14434662461280823, 0.00928276777267456, 0.10033762454986572, 0.008950081653892994, 0.06404897570610046, 0.37960559129714966, 0.009264305233955383, 0.13027973473072052, 0.11855059862136841, 0.009604819118976593, 0.009720132686197758, 0.009930944070219994, 0.009940285235643387, 0.11365868151187897, 0.010177127085626125, 0.010005791671574116, 0.010208839550614357, 0.010337915271520615, 0.12234511226415634, 0.009954776614904404, 0.009937566705048084, 0.009900347329676151, 0.10786283761262894, 0.009766696020960808, 0.009524078108370304, 0.009520362131297588, 0.009837360121309757, 0.009635113179683685, 0.009353715926408768, 0.009075438603758812, 0.009047714062035084, 0.008772887289524078, 0.008908094838261604, 0.1191459596157074, 0.008470705710351467, 0.008410214446485043, 0.28613537549972534, 0.008872248232364655, 0.00843346118927002, 0.11541770398616791, 0.009033250622451305, 0.008378143422305584, 0.008407611399888992, 0.008453063666820526, 0.12615737318992615, 0.16205033659934998, 0.008463829755783081, 0.008301548659801483, 0.00836917944252491, 0.15304306149482727, 0.00842657033354044, 0.008231171406805515, 0.008183212950825691, 0.008870950900018215, 0.00847919937223196, 0.008057826198637486, 0.008316200226545334, 0.00810063537210226, 0.007761351298540831, 0.12474645674228668, 0.00776333175599575, 0.007622403558343649, 0.007625149562954903, 0.007727480493485928, 0.007379222195595503, 0.007164674811065197, 0.007445355877280235, 0.007091425359249115, 0.006939498241990805, 0.006962263956665993, 0.0068420590832829475, 0.006582176778465509, 0.006475894246250391, 0.006665190681815147, 0.006307999137789011, 0.09990790486335754, 0.006120367906987667, 0.0062160613015294075, 0.12704049050807953, 0.006145130377262831, 0.006001907866448164, 0.00589741813018918, 0.006270338781177998, 0.00575813977047801, 0.005887436680495739, 0.005720463115721941, 0.005575340241193771, 0.005624379497021437, 0.005604729522019625, 0.00541312200948596, 0.005591345019638538, 0.08958066999912262, 0.10842026025056839, 0.09588098526000977, 0.005256489384919405, 0.005272034090012312, 0.005365172401070595, 0.005240531638264656, 0.005224051419645548, 0.005127914249897003, 0.005021859426051378, 0.0051331669092178345, 0.0049440436996519566, 0.005094350315630436, 0.005148310214281082, 0.004850768018513918, 0.131691575050354, 0.0047506601549685, 0.004822238814085722, 0.11529795825481415, 0.004931475967168808, 0.004803453106433153, 0.004708824213594198, 0.004782568197697401, 0.11884337663650513, 0.004917979706078768, 0.09766345471143723, 0.004843304865062237, 0.004799129907041788, 0.004764333367347717, 0.004720065277069807, 0.004700453486293554, 0.1031045913696289, 0.08043457567691803, 0.12017243355512619, 0.004717081785202026, 0.004724991042166948, 0.004874685313552618, 0.1355418711900711, 0.004853538703173399, 0.0050558955408632755, 0.0051544723100960255, 0.004931905306875706, 0.004847169388085604, 0.12924160063266754, 0.005091497674584389, 0.17590850591659546, 0.005077024456113577, 0.004926025401800871, 0.005102392286062241, 0.005142996087670326, 0.005216657649725676, 0.12082869559526443, 0.00509859761223197, 0.005033148918300867, 0.1428837925195694, 0.005017655901610851, 0.11558565497398376, 0.005188663490116596, 0.005040212534368038, 0.00513109564781189, 0.005297542084008455, 0.005249495152384043, 0.005096457898616791, 0.005097865592688322, 0.10319742560386658, 0.005095471628010273, 0.005026734434068203, 0.00532704871147871, 0.12003365159034729, 0.005095555447041988, 0.0050928425043821335, 0.005015640053898096, 0.005056578665971756, 0.00494008744135499, 0.0051293340511620045, 0.0049951085820794106, 0.004913950338959694, 0.005059877876192331, 0.004803051706403494, 0.005088945850729942, 0.005012473091483116, 0.004920007660984993, 0.0048669204115867615, 0.004596445709466934, 0.004607846029102802, 0.0047774245031178, 0.004466553218662739, 0.0045303236693143845, 0.0045341686345636845, 0.10818382352590561, 0.08610236644744873, 0.004417589865624905, 0.004529258701950312, 0.004329062532633543, 0.1175764948129654, 0.004318929743021727, 0.0044313641265034676, 0.08930118381977081, 0.004360169637948275, 0.004606239963322878, 0.00427553104236722, 0.004361896775662899, 0.12177342176437378, 0.004296874161809683, 0.004313439130783081, 0.08428250253200531, 0.004305619280785322, 0.0043614208698272705, 0.00444078678265214, 0.09973647445440292, 0.14200559258460999, 0.004622157663106918, 0.004470237996429205, 0.004558289889246225, 0.004471118561923504, 0.004781635943800211, 0.004639768972992897, 0.004466817248612642, 0.004689523484557867, 0.004394985735416412, 0.004468489438295364, 0.004546687006950378, 0.00463907653465867, 0.004542588721960783, 0.004309442825615406, 0.004266124218702316, 0.00427474407479167, 0.004457015078514814, 0.004450451582670212, 0.0903574526309967, 0.004291062243282795, 0.004200280643999577, 0.12524878978729248, 0.004215844441205263, 0.004242503084242344, 0.004112425725907087, 0.14859509468078613, 0.0041135698556900024, 0.004225523676723242, 0.0042203799821436405, 0.004194826819002628, 0.004169401712715626, 0.004293209873139858, 0.3580881953239441, 0.09274941682815552, 0.004235945641994476, 0.00456524221226573, 0.004618586972355843, 0.004656623583287001, 0.004559171851724386, 0.0045789373107254505, 0.004583592992275953, 0.004711706656962633, 0.00462599890306592, 0.11298907548189163, 0.004853812512010336, 0.004715160932391882, 0.004694913513958454, 0.004852749407291412, 0.004650606773793697, 0.004892047494649887, 0.004871533252298832, 0.004722490906715393, 0.0048616016283631325, 0.0047052470035851, 0.004586589056998491, 0.3634578287601471, 0.10587572306394577, 0.004822748713195324, 0.005025741644203663, 0.00484977662563324, 0.004918983206152916, 0.005202791653573513, 0.005004793871194124, 0.0051538702100515366, 0.0050389887765049934, 0.005380942486226559, 0.09077665954828262, 0.005018838215619326, 0.005210460163652897, 0.0051246462389826775, 0.005063595715910196, 0.08667010068893433, 0.07512109726667404, 0.005394868087023497, 0.1414947509765625, 0.005184870678931475, 0.005296048708260059, 0.005356056150048971, 0.005334329325705767, 0.005193735938519239, 0.005328279919922352, 0.0055043622851371765, 0.0053508044220507145, 0.005485682748258114, 0.005170290824025869, 0.005130097270011902, 0.08339669555425644, 0.005309433210641146, 0.005225189495831728, 0.004945279564708471, 0.004921026062220335, 0.004966626409441233, 0.004950219299644232, 0.09607608616352081, 0.005123000591993332, 0.004955843091011047, 0.005110294558107853, 0.005079745315015316, 0.08182523399591446, 0.004724104888737202, 0.005059339106082916, 0.005139902234077454, 0.004946367349475622, 0.004787751939147711, 0.004672505427151918, 0.13303761184215546, 0.00470077246427536, 0.004738159943372011, 0.14043836295604706, 0.10394984483718872, 0.004682062193751335, 0.004615830723196268, 0.004603229928761721, 0.00477588502690196, 0.00490019703283906, 0.08797168731689453, 0.00556144118309021, 0.004625746980309486, 0.004685203544795513, 0.08236800134181976, 0.10620073229074478, 0.004787644371390343, 0.004776693880558014, 0.004790379665791988, 0.004808325786143541, 0.00488912733271718, 0.10385320335626602, 0.004954709205776453, 0.004902845714241266, 0.0048833731561899185, 0.005225524306297302, 0.004758527036756277, 0.0050137280486524105, 0.005452299490571022, 0.13889342546463013, 0.0047447108663618565, 0.07851389795541763, 0.004926322493702173, 0.004999025724828243, 0.004694337956607342, 0.00540984608232975, 0.0047769611701369286, 0.0046161781065166, 0.4361874759197235, 0.005000319331884384, 0.004723799414932728, 0.004763415083289146, 0.005539259873330593, 0.12311078608036041, 0.10382739454507828, 0.005304163787513971, 0.0051339720375835896, 0.005242624320089817, 0.0969463661313057, 0.0052412147633731365, 0.005266574677079916, 0.005240388680249453, 0.005207313224673271, 0.005258690565824509, 0.005282172467559576, 0.11576017737388611, 0.005343595519661903, 0.005359378177672625, 0.005275622010231018, 0.00541946105659008, 0.00551899429410696, 0.005400559399276972, 0.005279598757624626, 0.005690582096576691, 0.1090170219540596, 0.005262306425720453, 0.00515720434486866, 0.005740521941334009, 0.005278915166854858, 0.0051858872175216675, 0.005334101617336273, 0.005275638774037361, 0.10900788754224777, 0.18129098415374756, 0.0051031638868153095, 0.18734078109264374, 0.07492934912443161, 0.00535519840195775, 0.005223333835601807, 0.005057328846305609, 0.005605541169643402, 0.005792811047285795, 0.005032941699028015, 0.00516413664445281, 0.14027906954288483, 0.10146482288837433, 0.005097128450870514, 0.16693134605884552, 0.005283557344228029, 0.005259120836853981, 0.005198102444410324, 0.0052288188599050045, 0.005520911421626806, 0.0054099345579743385, 0.11493295431137085, 0.005301229190081358, 0.005551370792090893, 0.0050730579532682896, 0.005212804768234491, 0.0051594022661447525, 0.005242825020104647, 0.10938093811273575, 0.005037076771259308, 0.00532083073630929, 0.08870372921228409, 0.005237482022494078, 0.00508624454960227, 0.005252740811556578, 0.005258748307824135, 0.0051306476816535, 0.005503832828253508, 0.004918703343719244, 0.004999316297471523, 0.004901725333184004, 0.004962211474776268, 0.0050665694288909435, 0.004833586513996124, 0.004748356528580189, 0.004992847330868244, 0.005045905243605375, 0.004772540647536516, 0.08703868091106415, 0.0054184868931770325, 0.00470990315079689, 0.004542069043964148, 0.1010165587067604, 0.004515115171670914, 0.005017392337322235, 0.07634559273719788, 0.004644783213734627, 0.11435946822166443, 0.004577637184411287, 0.004908508621156216, 0.00458443583920598, 0.0045335195027291775, 0.004636237397789955, 0.13242407143115997, 0.004515735432505608, 0.004418367054313421, 0.0046910555101931095, 0.005099067930132151, 0.004756895359605551, 0.004656211473047733, 0.08656265586614609, 0.004608661402016878, 0.004509043414145708, 0.004510471597313881, 0.004383828025311232, 0.11353091150522232, 0.004557047970592976, 0.0045127565972507, 0.15325088798999786, 0.15157273411750793, 0.08230819553136826, 0.004559588152915239, 0.004584688227623701, 0.004573190119117498, 0.004496435634791851, 0.004892632365226746, 0.0046721408143639565, 0.004465444013476372, 0.00453223055228591, 0.0044543850235641, 0.004830344580113888, 0.004965525586158037, 0.004772390238940716, 0.004665685351938009, 0.004651958588510752, 0.004651596769690514, 0.004334812052547932, 0.00435929000377655, 0.004373049363493919, 0.09870165586471558, 0.004399699158966541, 0.1519022285938263, 0.004418896045535803, 0.004431574605405331, 0.004268156364560127, 0.004362680949270725, 0.004494125954806805, 0.0045043486170470715, 0.004291397985070944, 0.10582481324672699, 0.004396274220198393, 0.004123197868466377, 0.0043585579842329025, 0.0041544558480381966, 0.004240306559950113, 0.00453890161588788, 0.004178938455879688, 0.004088438116014004, 0.004048922564834356, 0.004169967491179705, 0.004026159644126892, 0.17165538668632507, 0.004191819578409195, 0.004200831055641174, 0.004240196663886309, 0.09833867102861404, 0.003939388319849968, 0.0039913710206747055, 0.004033506382256746, 0.11686940491199493, 0.12047341465950012, 0.00418845983222127, 0.004123450256884098, 0.0040182615630328655, 0.0042990646325051785, 0.004004752263426781, 0.004108252935111523, 0.003992900718003511, 0.00397232873365283, 0.004579618573188782, 0.10177122056484222, 0.004045667126774788, 0.0039595686830580235, 0.004004925023764372, 0.004059887491166592, 0.004037225618958473, 0.004184397868812084, 0.004179774783551693, 0.004102514591068029, 0.0038982550613582134, 0.004169848281890154, 0.004165914840996265, 0.9208385944366455, 0.004096535500138998, 0.003945526666939259, 0.004183248616755009, 0.004438695963472128, 0.004125180654227734, 0.004505284130573273, 0.0044877477921545506, 0.004373045638203621, 0.0043088034726679325, 0.004305784124881029, 0.12479154765605927, 0.004870014730840921, 0.0043013799004256725, 0.004256252199411392, 0.004501171410083771, 0.004437425639480352, 0.004407844971865416, 0.004541928414255381, 0.004424916114658117, 0.004253297112882137, 0.004264243878424168, 0.004381660372018814, 0.004293300211429596, 0.004306462127715349, 0.004294156096875668, 0.004151621833443642, 0.004216071218252182, 0.004232662729918957, 0.004091804381459951, 0.0041511524468660355, 0.004052955191582441, 0.004449758213013411, 0.004018133040517569, 0.0041787573136389256, 0.004455831367522478, 0.0039493548683822155, 0.004028017167001963, 0.003997030667960644, 0.12383396923542023, 0.0038909558206796646, 0.0038291749078780413, 0.004183053504675627, 0.003928135149180889, 0.003924754448235035, 0.004218534100800753, 0.00376547290943563, 0.004050232004374266, 0.4280164837837219, 0.10488671064376831, 0.004008839372545481, 0.003970475867390633, 0.003921790048480034, 0.11338979005813599, 0.004053839482367039, 0.004037461243569851, 0.0040548029355704784, 0.00406413059681654, 0.0042882501147687435, 0.004133080132305622, 0.10725343972444534, 0.004348506685346365, 0.004338434431701899, 0.004119126126170158, 0.004452073946595192, 0.004454819951206446, 0.12100251764059067, 0.004266642965376377, 0.004176928196102381, 0.004413216840475798, 0.0042995261028409, 0.004285494796931744, 0.0041906628757715225, 0.004289030097424984, 0.004543875344097614, 0.004574344959110022, 0.004174104891717434, 0.004205756355077028, 0.10585400462150574, 0.0042351228184998035, 0.004235222470015287, 0.0042334310710430145, 0.004238412249833345, 0.11566825211048126, 0.0041592977941036224, 0.004224136006087065, 0.004126615822315216, 0.1691652089357376, 0.004085854161530733, 0.004163670353591442, 0.004245567601174116, 0.004099569749087095, 0.004266667179763317, 0.00420777453109622, 0.004069745074957609, 0.004290095530450344, 0.004191981162875891, 0.004224765580147505, 0.4651004672050476, 0.004091670271009207, 0.004170777276158333, 0.004153295885771513, 0.0042344918474555016, 0.0044054388999938965, 0.0045047723688185215, 0.8531198501586914, 0.0045189810916781425, 0.0043917265720665455, 0.004615157376974821, 0.004559785593301058, 0.004798440262675285, 0.004775692708790302, 0.004835870582610369, 0.004758851137012243, 0.004993385635316372, 0.005091281142085791, 0.004996483214199543, 0.004780636169016361, 0.005195909179747105, 0.004795289132744074, 0.005027495324611664, 0.12360218912363052, 0.004938076250255108, 0.08564409613609314, 0.0053521739318966866, 0.00479175103828311, 0.005548913963139057, 0.11520953476428986, 0.005040246527642012, 0.005115359090268612, 0.005083432886749506, 0.00513058714568615, 0.004810133017599583, 0.004850909113883972, 0.004990674555301666, 0.4140256345272064, 0.12570874392986298, 0.005072503350675106, 0.0051382738165557384, 0.0052160886116325855, 0.005118804518133402, 0.005210849456489086, 0.005226395092904568, 0.0848565623164177, 0.005439976695924997, 0.005352924112230539, 0.005310439504683018, 0.005424889270216227, 0.005288681946694851, 0.005327355582267046, 0.12150898575782776, 0.005427041091024876, 0.005371468607336283, 0.005214035976678133, 0.005361431743949652, 0.09247148782014847, 0.005216279998421669, 0.005504611413925886, 0.005223519168794155, 0.005306057631969452, 0.13423624634742737, 0.00534799275919795, 0.005158749874681234, 0.12356894463300705, 0.005549960304051638, 0.005900279618799686, 0.0054323310032486916, 0.005307013634592295, 0.0051641943864524364, 0.13239313662052155, 0.0051207877695560455, 0.005213926546275616, 0.00523639190942049, 0.0056418078020215034, 0.005182869732379913, 0.005146919284015894, 0.00527535006403923, 0.0051864143460989, 0.005249743349850178, 0.1259029358625412, 0.005114472471177578, 0.005167617462575436, 0.005158721003681421, 0.0049767279997467995, 0.004967838060110807, 0.004957069642841816, 0.004979151301085949, 0.13567383587360382, 0.004917730111628771, 0.10459792613983154, 0.0052314880304038525, 0.005069106351584196, 0.005089784972369671, 0.07290353626012802, 0.0052620405331254005, 0.005102415103465319, 0.004957639612257481, 0.10374587029218674, 0.005177217535674572, 0.10042203217744827, 0.004971655085682869, 0.0049397689290344715, 0.005060657858848572, 0.004955949727445841, 0.00489077577367425, 0.005386775359511375, 0.1295725703239441, 0.0051362644881010056, 0.005119042936712503, 0.005138874985277653, 0.004990475717931986, 0.0047937240451574326, 0.004790668375790119, 0.005131332669407129, 0.004957849159836769, 0.0049272156320512295, 0.005145285744220018, 0.09855753928422928, 0.0048260996118187904, 0.09562260657548904, 0.004827371798455715, 0.004804862663149834, 0.004924892447888851, 0.00492396205663681, 0.0051060626283288, 0.08032998442649841, 0.0048376526683568954, 0.099543996155262, 0.004735117312520742, 0.004758184310048819, 0.005442886613309383, 0.0046738372184336185, 0.08340919762849808, 0.1111120730638504, 0.004943635314702988, 0.005010108929127455, 0.005043144803494215, 0.004810454789549112, 0.00466348510235548, 0.004930527415126562, 0.09349755942821503, 0.004788253456354141, 0.004711071494966745, 0.0047415997833013535, 0.004855235107243061, 0.0046751657500863075, 0.004901890642940998, 0.004663093481212854, 0.004649735987186432, 0.004596566315740347, 0.0050539616495370865, 0.0047423336654901505, 0.004574920982122421, 0.004710725042968988, 0.004721596371382475, 0.11290491372346878, 0.004599474370479584, 0.004930291790515184, 0.10315481573343277, 0.004694676026701927, 0.0899415910243988, 0.004492566920816898, 0.12930859625339508, 0.004683752544224262, 0.004750889725983143, 0.004774629604071379, 0.004636099096387625, 0.004500928800553083, 0.004494317341595888, 0.15892483294010162, 0.00449068658053875, 0.004814150743186474, 0.09091440588235855, 0.0045908489264547825, 0.004701262339949608, 0.4765014350414276, 0.004716394003480673, 0.12869778275489807, 0.004846134688705206, 0.005291772074997425, 0.1419488787651062, 0.004866080358624458, 0.004879509564489126, 0.004972113762050867, 0.005033212248235941, 0.005118895787745714, 0.004991646856069565, 0.005096379667520523, 0.005199826322495937, 0.10540518164634705, 0.004906774964183569, 0.005302468314766884, 0.10405852645635605, 0.005039889365434647, 0.0974244773387909, 0.005183604545891285, 0.005045374855399132, 0.005189027637243271, 0.005124768707901239, 0.17230086028575897, 0.005045963451266289, 0.005397740751504898, 0.09064342826604843, 0.005120450630784035, 0.11163142323493958, 0.005336398724466562, 0.005230550654232502, 0.13381175696849823, 0.11524128913879395, 0.005103820003569126, 0.005066356156021357, 0.0673467293381691, 0.08915340155363083, 0.06150209903717041, 0.005285580176860094, 0.005138869397342205, 0.005387086886912584, 0.005237023811787367, 0.10445749759674072, 0.00538885872811079, 0.005254056770354509, 0.005757062695920467, 0.12623420357704163, 0.12962837517261505, 0.005394213367253542, 0.10749534517526627, 0.005381135735660791, 0.0055947257205843925, 0.005353706888854504, 0.005536332726478577, 0.005344736389815807, 0.00535662192851305, 0.005589669570326805, 0.005987511947751045, 0.0053164162673056126, 0.005232037976384163, 0.0977688878774643, 0.0053702411241829395, 0.005301987752318382, 0.005223445128649473, 0.3892103433609009, 0.0053220149129629135, 0.00530525716021657, 0.0054199849255383015, 0.005579913035035133, 0.005617596209049225, 0.005476413760334253, 0.005582876969128847, 0.005959627218544483, 0.005393405444920063, 0.005521399900317192, 0.005416342988610268, 0.005491354968398809, 0.005762229207903147, 0.005425387993454933, 0.005414459854364395, 0.005397394299507141, 0.00539782177656889, 0.005540026817470789, 0.006067738868296146, 0.005543186794966459, 0.005525531247258186, 0.005294863600283861, 0.005511653143912554, 0.0053010364063084126, 0.005324663128703833, 0.005537156015634537, 0.005227026529610157, 0.10788749158382416, 0.005609344225376844, 0.005111249163746834, 0.005234080366790295, 0.0052224877290427685, 0.00522127840667963, 0.005369950085878372, 0.005234445910900831, 0.0050798747688531876, 0.005257629323750734, 0.1179966852068901, 0.10241660475730896, 0.005163453985005617, 0.005480574909597635, 0.1243533119559288, 0.005059246439486742, 0.005230702459812164, 0.004976165015250444, 0.11454181373119354, 0.1128036379814148, 0.07488963752985, 0.00516994995996356, 0.00505742896348238, 0.005131835583597422, 0.005140654742717743, 0.0055154371075332165, 0.1043466180562973, 0.005048803519457579, 0.005177184008061886, 0.005075985100120306, 0.005022579804062843, 0.10089582204818726, 0.14060500264167786, 0.005360942799597979, 0.0056148250587284565, 0.005002867430448532, 0.005143398884683847, 0.004986832849681377, 0.004977935925126076, 0.00510106747969985, 0.005536040291190147, 0.005169261246919632, 0.004969016648828983, 0.004986283369362354, 0.005407705903053284, 0.12197229266166687, 0.005009556654840708, 0.004914522171020508, 0.005185559391975403, 0.005264080595225096, 0.005093961954116821, 0.004909139592200518, 0.005158352665603161, 0.005299359560012817, 0.0050948248244822025, 0.005180088337510824, 0.004910582210868597, 0.00490777799859643, 0.005493664648383856, 0.004801710601896048, 0.004943040199577808, 0.004779278766363859, 0.004815971944481134, 0.004929095972329378, 0.004894671030342579, 0.004807660356163979, 0.0050470647402107716, 0.004831522703170776, 0.004992878995835781, 0.005185344256460667, 0.10594259202480316, 0.004727517254650593, 0.00483066076412797, 0.004866504110395908, 0.10297585278749466, 0.005010080058127642, 0.0046105035580694675, 0.005320974159985781, 0.004768094513565302, 0.004912813659757376, 0.0048258621245622635, 0.14204110205173492, 0.005157563369721174, 0.004627295769751072, 0.004687602631747723, 0.0046297055669128895, 0.004635735880583525, 0.12587891519069672, 0.004700000863522291, 0.004867940675467253, 0.004903530236333609, 0.12982089817523956, 0.004631905350834131, 0.005134010221809149, 0.005015075672417879, 0.004564992152154446, 0.09912101179361343, 0.004638316109776497, 0.004809060599654913, 0.004578776657581329, 0.0046938820742070675, 0.004559974651783705, 0.004541692789644003, 0.004537154454737902, 0.004562098998576403, 0.11280867457389832, 0.004724168684333563, 0.004640322178602219, 0.004717509727925062, 0.004650022368878126, 0.004601443652063608, 0.004888434428721666, 0.00460186367854476, 0.13554823398590088, 0.004489777609705925, 0.004495732020586729, 0.004572385456413031, 0.004515944980084896, 0.004497087094932795, 0.004622985143214464, 0.09410884231328964, 0.004562934394925833, 0.004523296840488911, 0.004654422402381897, 0.0044870744459331036, 0.004502392839640379, 0.00436721695587039, 0.004546009935438633, 0.0046120635233819485, 0.004846069496124983, 0.11506590992212296, 0.004510653205215931, 0.004335934761911631, 0.004336257465183735, 0.004905418027192354, 0.004587458446621895, 0.004556755535304546, 0.004480780102312565, 0.15643709897994995, 0.005010914523154497, 0.11220740526914597, 0.004451066255569458, 0.11884322017431259, 0.004418779630213976, 0.0043576061725616455, 0.004522041417658329, 0.00452274177223444, 0.004576212726533413, 0.004496471025049686, 0.004398452118039131, 0.004332260694354773, 0.004499894101172686, 0.13984611630439758, 0.0047134775668382645, 0.004329475108534098, 0.0044981567189097404, 0.004320574924349785, 0.004397538956254721, 0.004417713265866041, 0.1009712889790535, 0.00442419433966279, 0.004376840312033892, 0.09525977075099945, 0.00457421038299799, 0.004490566439926624, 0.16579987108707428, 0.004619551822543144, 0.004582682158797979, 0.004597846884280443, 0.004464672412723303, 0.004328800365328789, 0.004411847796291113, 0.004578075837343931, 0.0044486564584076405, 0.004342082422226667, 0.0047213612124323845, 0.0044234744273126125, 0.004510072059929371, 0.4960288107395172, 0.00434237951412797, 0.004979959223419428, 0.0046763950958848, 0.004694419447332621, 0.00471584452316165, 0.004377088975161314, 0.004468876402825117, 0.004614104051142931, 0.004627760965377092, 0.004470996558666229, 0.004634378477931023, 0.004393438808619976, 0.004349896218627691, 0.12293963879346848, 0.004432331770658493, 0.004403467755764723, 0.004476544447243214, 0.004901670850813389, 0.0044057550840079784, 0.13365009427070618, 0.004426325671374798, 0.004303440917283297, 0.004330210387706757, 0.004486864432692528, 0.00441626226529479, 0.08847498148679733, 0.13781039416790009, 0.004489280749112368, 0.12694616615772247, 0.005127292592078447, 0.0045149438083171844, 0.004549686331301928, 0.004507504869252443, 0.004459392745047808, 0.004474277142435312, 0.08931059390306473, 0.00481846509501338, 0.004310907796025276, 0.11677827686071396, 0.004346462897956371, 0.004719015676528215, 0.004666017834097147, 0.004759910516440868, 0.11052492260932922, 0.004543484654277563, 0.004385463427752256, 0.004669305868446827, 0.004652898292988539, 0.004490360617637634, 0.004848170094192028, 0.004501094110310078, 0.00458933599293232, 0.004951098468154669, 0.004337134305387735, 0.0045419130474328995, 0.004576040897518396, 0.004624438006430864, 0.00439362321048975, 0.004362574778497219, 0.004405057057738304, 0.004314939491450787, 0.10091637074947357, 0.004286713898181915, 0.09468458592891693, 0.004511807579547167, 0.004298272542655468, 0.004312705248594284, 0.0044117821380496025, 0.0044040014035999775, 0.004567582160234451, 0.004475496243685484, 0.16474610567092896, 0.004266258329153061, 0.0043138558976352215, 0.004481799900531769, 0.12183257937431335, 0.004351204726845026, 0.004303411114960909, 0.0042756423354148865, 0.00459887133911252, 0.004431189503520727, 0.004278882872313261, 0.10027989745140076, 0.004443204030394554, 0.004390256945043802, 0.004544249270111322, 0.00435281777754426, 0.004579844884574413, 0.004309706389904022, 0.004246415104717016, 0.004312198143452406, 0.0042482903227210045, 0.004977288655936718, 0.12140680104494095, 0.004340239334851503, 0.12779155373573303, 0.004372529685497284, 0.004731651861220598, 0.004598760977387428, 0.004463665187358856, 0.004440309479832649, 0.004370273090898991, 0.004371074493974447, 0.1193339079618454, 0.004270228091627359, 0.004391379654407501, 0.004700401332229376, 0.19540679454803467, 0.004457851871848106, 0.004306475166231394, 0.004508265759795904, 0.004254376981407404, 0.004390862304717302, 0.004620342515408993, 0.004326534457504749, 0.004470722749829292, 0.16457180678844452, 0.004378661047667265, 0.0043519288301467896, 0.004449564032256603, 0.09362783282995224, 0.004541274160146713, 0.10387912392616272, 0.004665069282054901, 0.004280491266399622, 0.14910896122455597, 0.12508320808410645, 0.45426860451698303, 0.004546739161014557, 0.004267638083547354, 0.004363318905234337, 0.0044220988638699055, 0.004439663607627153, 0.0045317779295146465, 0.004570546094328165, 0.004376662895083427, 0.00438095023855567, 0.004388100933283567, 0.11300072073936462, 0.09896738827228546, 0.0044684079475700855, 0.0043968926183879375, 0.00429394980892539, 0.004382661543786526, 0.004872898105531931, 0.0042802514508366585]\n",
            "Val loss 0.038691795092003725\n",
            "Val auc roc 0.4753413846266794\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}