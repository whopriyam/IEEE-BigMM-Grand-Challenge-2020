{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generalized_Hate_Double_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "600a0b9b8dbb4ea798325b95a1f33397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f0df3f77b769419796fd54cc510b775c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0a42f997cab54aaebb86d562f1f90ca1",
              "IPY_MODEL_f21f040ff4fe494e8322981fbd009ef1"
            ]
          }
        },
        "f0df3f77b769419796fd54cc510b775c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a42f997cab54aaebb86d562f1f90ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60a336b4d2b542da9e8c7993b76e5164",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cddc47ef7ced4c09903d6a3400ecb399"
          }
        },
        "f21f040ff4fe494e8322981fbd009ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb821c76092a43f3995e8c4276b7b8a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:16&lt;00:00, 14.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bcc5f620ed5496ea28499d48f16591d"
          }
        },
        "60a336b4d2b542da9e8c7993b76e5164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cddc47ef7ced4c09903d6a3400ecb399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb821c76092a43f3995e8c4276b7b8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bcc5f620ed5496ea28499d48f16591d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81819f2a3cda4ec2b75c203781e0e415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7fb5a1f75894446ab175ba69b07b07ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df7065221c1643ac9bfb25b8dac48747",
              "IPY_MODEL_5a0955d4a71340688bb436b48306bb06"
            ]
          }
        },
        "7fb5a1f75894446ab175ba69b07b07ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df7065221c1643ac9bfb25b8dac48747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_64946ef67c58469f9d72caa5ba028d68",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1717,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1717,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d86ab2c7623a400fb6e8b744acb42538"
          }
        },
        "5a0955d4a71340688bb436b48306bb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b26e4db3bedb48378a7b86d94bf60eb6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1717/1717 [15:50&lt;00:00,  1.81it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ce68677102f4acb88dc7b4651ffca99"
          }
        },
        "64946ef67c58469f9d72caa5ba028d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d86ab2c7623a400fb6e8b744acb42538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b26e4db3bedb48378a7b86d94bf60eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ce68677102f4acb88dc7b4651ffca99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ec09e6230334c6bbdbb6986ecf01d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3efabced8cac4da29a8a130db53a8667",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c4899e074974044bf9cb94975d855a5",
              "IPY_MODEL_a44699ac01434ad987b1591dc20f258b"
            ]
          }
        },
        "3efabced8cac4da29a8a130db53a8667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c4899e074974044bf9cb94975d855a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7793ef9fd9564e4c88a330246c22a2f4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1717,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1717,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6513ff806aef42f882bbacaaa361a896"
          }
        },
        "a44699ac01434ad987b1591dc20f258b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b01a4c12c5748adb56e0af2b1bef3df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1717/1717 [16:06&lt;00:00,  1.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c889260371448ee9151a12841757aa2"
          }
        },
        "7793ef9fd9564e4c88a330246c22a2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6513ff806aef42f882bbacaaa361a896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b01a4c12c5748adb56e0af2b1bef3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c889260371448ee9151a12841757aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97e414550561495abf229e569f0bfdde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c5d93135220459aa62cfd84290ad602",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_408089d5881a47b1a91eb28b1116db4c",
              "IPY_MODEL_76a024fa2f504aafbdcd32a39559cf31"
            ]
          }
        },
        "5c5d93135220459aa62cfd84290ad602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "408089d5881a47b1a91eb28b1116db4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a4bcc674c9944a469e8e238dbc86dcdf",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1717,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1717,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46053bccbfd24ff895980a3e3bfe5abe"
          }
        },
        "76a024fa2f504aafbdcd32a39559cf31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e1b9b0819824d12867195530dc124b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1717/1717 [16:04&lt;00:00,  1.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d84a109b386458b888ebf29f678ca0e"
          }
        },
        "a4bcc674c9944a469e8e238dbc86dcdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46053bccbfd24ff895980a3e3bfe5abe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e1b9b0819824d12867195530dc124b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d84a109b386458b888ebf29f678ca0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "282c85a6-67f8-42e2-9960-2c189aa587c3"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 44.67 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0217f4d3-7cb8-433d-c7b5-2d003993132b"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9249b9d4-8c1c-48f1-a9c7-bc1cb7672638"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "48661442-16b2-4cc0-94cc-2a77c0a6f48a"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fff0eded-d554-408e-9b45-fef43a1c2304"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "4a33fad4-639d-4be1-edbb-914f3ea9f52a"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 26.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "619f6a3a-d3bd-43f4-edf8-1bec99216645"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0cd1c791-2d08-49dc-e64d-7b22b86a1a5b"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "1bb00d88-3b11-4271-f761-cf7798ab4874"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e1fc6a8f-28cc-4ed8-d6db-82d2547400c4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      How India's #MeToo campaign different from US  \n",
              "1    What's next for #MeToo after Kavanaugh's confi...\n",
              "2    Fans lose calm as TV personality Mani makes fu...\n",
              "3    Karan johar so painful these days.... Every ac...\n",
              "4    ICYMI - PERRY: The secret lives of sleaze and ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79a78d35-36d0-4ad7-827f-198ec02f7c1d"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:11<00:00, 34551873.12B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d230853b-532f-4bee-a02d-ecd2f6e9d6c5"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 913805.24B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c32f59ae-d6c0-4a27-953f-c62eccc97082"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "101f4d97-cc8d-45c4-f10a-e6719e7e46c6"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            random.shuffle(text)\n",
        "            text3 = ' '.join(text)\n",
        "            df3['text'][i]=text3\n",
        "        self.data = self.data.append(df2, ignore_index=True)\n",
        "        self.data = self.data.append(df3, ignore_index=True)\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e653a2d1-5682-4f77-dc35-5cc5ecdb666c"
      },
      "source": [
        "col_name = \"Directed_Hate\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862,
          "referenced_widgets": [
            "600a0b9b8dbb4ea798325b95a1f33397",
            "f0df3f77b769419796fd54cc510b775c",
            "0a42f997cab54aaebb86d562f1f90ca1",
            "f21f040ff4fe494e8322981fbd009ef1",
            "60a336b4d2b542da9e8c7993b76e5164",
            "cddc47ef7ced4c09903d6a3400ecb399",
            "cb821c76092a43f3995e8c4276b7b8a5",
            "6bcc5f620ed5496ea28499d48f16591d",
            "81819f2a3cda4ec2b75c203781e0e415",
            "7fb5a1f75894446ab175ba69b07b07ad",
            "df7065221c1643ac9bfb25b8dac48747",
            "5a0955d4a71340688bb436b48306bb06",
            "64946ef67c58469f9d72caa5ba028d68",
            "d86ab2c7623a400fb6e8b744acb42538",
            "b26e4db3bedb48378a7b86d94bf60eb6",
            "3ce68677102f4acb88dc7b4651ffca99",
            "2ec09e6230334c6bbdbb6986ecf01d5a",
            "3efabced8cac4da29a8a130db53a8667",
            "5c4899e074974044bf9cb94975d855a5",
            "a44699ac01434ad987b1591dc20f258b",
            "7793ef9fd9564e4c88a330246c22a2f4",
            "6513ff806aef42f882bbacaaa361a896",
            "2b01a4c12c5748adb56e0af2b1bef3df",
            "0c889260371448ee9151a12841757aa2",
            "97e414550561495abf229e569f0bfdde",
            "5c5d93135220459aa62cfd84290ad602",
            "408089d5881a47b1a91eb28b1116db4c",
            "76a024fa2f504aafbdcd32a39559cf31",
            "a4bcc674c9944a469e8e238dbc86dcdf",
            "46053bccbfd24ff895980a3e3bfe5abe",
            "8e1b9b0819824d12867195530dc124b8",
            "1d84a109b386458b888ebf29f678ca0e"
          ]
        },
        "outputId": "2b8e5765-b60b-47f6-ec0d-a1148da1635d"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6870\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "600a0b9b8dbb4ea798325b95a1f33397",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81819f2a3cda4ec2b75c203781e0e415",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1717.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0688\n",
            "Train Losses : [0.21316346526145935, 0.22635063529014587, 1.7162021398544312, 0.48300203680992126, 1.8552532196044922, 0.8492032885551453, 1.6033741235733032, 0.9047961831092834, 0.16785700619220734, 0.08967476338148117, 0.474078893661499, 0.11132801324129105, 0.08506262302398682, 0.4535743296146393, 0.10388510674238205, 0.07986758649349213, 0.6018486618995667, 0.0501110777258873, 0.0982525497674942, 0.18356479704380035, 0.04362544044852257, 0.6399514079093933, 0.03194591403007507, 0.0336143784224987, 0.050022292882204056, 0.014846332371234894, 0.027566520497202873, 0.07793440669775009, 0.11381737887859344, 0.03153838962316513, 0.03542547672986984, 0.004158611875027418, 0.0057831150479614735, 0.0035199029371142387, 0.0029365760274231434, 0.005701578687876463, 0.006277281325310469, 0.002225973643362522, 0.0015300179366022348, 0.00881980825215578, 0.2893702983856201, 0.002183611271902919, 0.0007538489298895001, 0.0007572001195512712, 0.004261211957782507, 0.016114892438054085, 0.0005052824853919446, 0.005110154394060373, 0.3037009835243225, 0.001067010103724897, 0.006718058604747057, 0.0021255984902381897, 0.0005695611471310258, 0.0009388334001414478, 0.051659584045410156, 1.2895126342773438, 0.0009290904272347689, 0.00442748237401247, 0.0009663287783041596, 0.05841989442706108, 0.0018919630674645305, 0.0015512235695496202, 0.0013760030269622803, 0.23525136709213257, 0.011992610059678555, 0.014918539673089981, 0.017500733956694603, 0.008054748177528381, 0.010161330923438072, 0.004152762237936258, 0.37843406200408936, 0.005388899240642786, 0.02119809202849865, 0.01565803773701191, 0.011087999679148197, 0.004196647554636002, 0.007652039639651775, 0.005825095809996128, 0.0045492504723370075, 0.3443465530872345, 0.22876881062984467, 0.2521841824054718, 0.40975838899612427, 0.11467613279819489, 0.12337535619735718, 0.006571363657712936, 0.22279205918312073, 0.12187159061431885, 0.004292097873985767, 0.004376742988824844, 0.5229083299636841, 0.07563009858131409, 0.20346982777118683, 0.009790807962417603, 0.006686962675303221, 0.008992467075586319, 0.015262490138411522, 0.008003050461411476, 0.3736606538295746, 0.00895864237099886, 0.03663772717118263, 0.011987048201262951, 0.01191062480211258, 0.019150616601109505, 0.050891388207674026, 0.015312827192246914, 0.019114190712571144, 0.017017235979437828, 0.042727041989564896, 0.24301929771900177, 0.06652981042861938, 0.030802270397543907, 0.15995730459690094, 0.13981813192367554, 0.011202115565538406, 0.0115959532558918, 0.010973510332405567, 0.26195621490478516, 0.05176416411995888, 0.009165694937109947, 0.014638973399996758, 0.007961173541843891, 0.15210989117622375, 0.04391917586326599, 0.013469048775732517, 0.006649244576692581, 0.15784503519535065, 0.005850355606526136, 0.1839016228914261, 0.0091353515163064, 0.007811686955392361, 0.005401995033025742, 0.005915192421525717, 0.006929675582796335, 0.009816901758313179, 0.005689146462827921, 0.10347634553909302, 0.004896840080618858, 0.003768250113353133, 0.41180112957954407, 0.03338851034641266, 0.004484199453145266, 0.005820093210786581, 0.004657330457121134, 0.004370572976768017, 0.005923949647694826, 0.25776228308677673, 0.0034576579928398132, 0.004245451185852289, 0.007361582480370998, 0.0045063975267112255, 0.11461702734231949, 0.003946466371417046, 0.11331289261579514, 0.003517125267535448, 0.004616152495145798, 0.10589803755283356, 0.24854281544685364, 0.008113617077469826, 0.004665435757488012, 0.004629267379641533, 0.5266197323799133, 0.007366208825260401, 0.006050874944776297, 0.19447652995586395, 0.008378739468753338, 0.0772753655910492, 0.007070187944918871, 0.011907740496098995, 0.009010699577629566, 0.01139847468584776, 0.009433009661734104, 0.010315610095858574, 0.008019236847758293, 0.009122844785451889, 0.007191838230937719, 0.23848304152488708, 0.006581244524568319, 0.13039278984069824, 0.006663861684501171, 0.3065720200538635, 0.007299324031919241, 0.13511905074119568, 0.00853972788900137, 0.00874271523207426, 0.008185220882296562, 0.09074588865041733, 0.0766560286283493, 0.010139464400708675, 0.008293098770081997, 0.008520481176674366, 0.24999800324440002, 0.008959442377090454, 0.07781572639942169, 0.05295366048812866, 0.008989418856799603, 0.010468422435224056, 0.0091227563098073, 0.008300750516355038, 0.14481569826602936, 0.00881372019648552, 0.009390242397785187, 0.007902653887867928, 0.007390787824988365, 0.010481701232492924, 0.3838563859462738, 0.0082671158015728, 0.0074631692841649055, 0.00863785482943058, 0.162918820977211, 0.009692944586277008, 0.010274628177285194, 0.009309099055826664, 0.00870087556540966, 0.5469983816146851, 0.008674412965774536, 0.010765837505459785, 0.008168733678758144, 0.1360432505607605, 0.008697289042174816, 0.008512054570019245, 0.11396702378988266, 0.21229420602321625, 0.1060672327876091, 0.010949964635074139, 0.07133008539676666, 0.01143769919872284, 0.14465099573135376, 0.012355976738035679, 0.09044626355171204, 0.1067979633808136, 0.013435791246592999, 0.012947633862495422, 0.09995287656784058, 0.28796929121017456, 0.01938481070101261, 0.19076889753341675, 0.017636846750974655, 0.01607155241072178, 0.04744071513414383, 0.0191367045044899, 0.017598669975996017, 0.061755843460559845, 0.03969249874353409, 0.12486611306667328, 0.09354876726865768, 0.17195607721805573, 0.015506032854318619, 0.05771373584866524, 0.014255077578127384, 0.08245345950126648, 0.015511884354054928, 0.013945257291197777, 0.012593027204275131, 0.244560107588768, 0.014900688081979752, 0.012976708821952343, 0.08343144506216049, 0.012817386537790298, 0.015488754026591778, 0.010880585759878159, 0.012282776646316051, 0.010860194452106953, 0.010481820441782475, 0.011502791196107864, 0.2329571396112442, 0.33655381202697754, 0.35354557633399963, 0.011923210695385933, 0.14347589015960693, 0.013811114244163036, 0.32733920216560364, 0.014584329910576344, 0.015330435708165169, 0.018495937809348106, 0.015283149667084217, 0.04745034500956535, 0.016072547063231468, 0.01579892821609974, 0.017910998314619064, 0.19536970555782318, 0.018988797441124916, 0.08705459535121918, 0.12229029089212418, 0.018013974651694298, 0.020138047635555267, 0.014636946842074394, 0.013902933336794376, 0.09250878542661667, 0.18282023072242737, 0.2139289528131485, 0.018928607925772667, 0.012126401998102665, 0.011577760800719261, 0.11609107255935669, 0.0738288164138794, 0.17758065462112427, 0.20363390445709229, 0.11879928410053253, 0.00960845872759819, 0.01150623057037592, 0.1466953456401825, 0.008989579044282436, 0.0941975936293602, 0.009928617626428604, 0.4753636121749878, 0.010291572660207748, 0.009916003793478012, 0.1348947137594223, 0.10273738205432892, 0.10291767120361328, 0.1343570500612259, 0.011019155383110046, 0.11111700534820557, 0.10419952124357224, 0.012997912243008614, 0.09663422405719757, 0.09746869653463364, 0.013799302279949188, 0.013833555392920971, 0.013817204162478447, 0.25942060351371765, 0.015438392758369446, 0.1091679260134697, 0.015667157247662544, 0.14919845759868622, 0.014802486635744572, 0.01448136568069458, 0.014237809926271439, 0.014683449640870094, 0.014235070906579494, 0.015111962333321571, 0.013017193414270878, 0.012650706805288792, 0.01266765408217907, 0.010660099796950817, 0.010620390996336937, 0.010217035189270973, 0.11711331456899643, 0.07449318468570709, 0.008037252351641655, 0.1793152540922165, 0.007923572324216366, 0.007614001631736755, 0.06281638145446777, 0.007239374797791243, 0.006531238555908203, 0.11027893424034119, 0.14276516437530518, 0.006337000522762537, 0.12855195999145508, 0.15332087874412537, 0.11523521691560745, 0.09736956655979156, 0.007112068124115467, 0.0068916757591068745, 0.006991109810769558, 0.09036418050527573, 0.007195763289928436, 0.007134933490306139, 0.008757712319493294, 0.00787401758134365, 0.007179176900535822, 0.007219539489597082, 0.13091032207012177, 0.09134934842586517, 0.0066785686649382114, 0.006912498734891415, 0.007601355668157339, 0.006661732215434313, 0.00655916566029191, 0.0068818069994449615, 0.346855491399765, 0.006544285453855991, 0.007132524624466896, 0.008238626644015312, 0.007372322492301464, 0.007124797906726599, 0.0076613216660916805, 0.0073538776487112045, 0.007698812056332827, 0.006723699159920216, 0.007556677330285311, 0.006606768351048231, 0.10463978350162506, 0.006051196716725826, 0.006846733391284943, 0.00630501564592123, 0.006874420214444399, 0.09575322270393372, 0.102505162358284, 0.0054421680979430676, 0.08281576633453369, 0.00546059338375926, 0.4174650311470032, 0.007092450745403767, 0.006160747725516558, 0.11600831151008606, 0.12346166372299194, 0.0861426293849945, 0.3372686505317688, 0.010152362287044525, 0.10384496301412582, 0.012095944955945015, 0.011930502019822598, 0.09901764243841171, 0.15426434576511383, 0.013930614106357098, 0.015041430480778217, 0.015021001920104027, 0.014758254401385784, 0.016918674111366272, 0.016060907393693924, 0.014113632030785084, 0.013844909146428108, 0.013207696378231049, 0.013170856051146984, 0.014577367343008518, 0.012814255431294441, 0.012571554630994797, 0.08330541849136353, 0.08100126683712006, 0.009916601702570915, 0.009320060722529888, 0.010047600604593754, 0.318563848733902, 0.008935606107115746, 0.009893347509205341, 0.1416260004043579, 0.008993199095129967, 0.12264109402894974, 0.25065821409225464, 0.15972623229026794, 0.10616706311702728, 0.011653232388198376, 0.10278178751468658, 0.01286490447819233, 0.01483309268951416, 0.16531114280223846, 0.013573887757956982, 0.21379584074020386, 0.07293079793453217, 0.12501969933509827, 0.012954921461641788, 0.012771805748343468, 0.01446359883993864, 0.012518182396888733, 0.22742275893688202, 0.013577960431575775, 0.013666088692843914, 0.012568792328238487, 0.013120332732796669, 0.06757867336273193, 0.012395564466714859, 0.0956699401140213, 0.012416143901646137, 0.012071376666426659, 0.011066286824643612, 0.09906043112277985, 0.010588138364255428, 0.19001507759094238, 0.010638846084475517, 0.06461451202630997, 0.011111357249319553, 0.09269670397043228, 0.15832404792308807, 0.10181492567062378, 0.009697800502181053, 0.11907383054494858, 0.11340717226266861, 0.00944577343761921, 0.10344255715608597, 0.00966237299144268, 0.009114113636314869, 0.00934739038348198, 0.009644832462072372, 0.008772254921495914, 0.4557143449783325, 0.010879356414079666, 0.00929945893585682, 0.00985302310436964, 0.009294629096984863, 0.011264431290328503, 0.009259331971406937, 0.009967065416276455, 0.06812375038862228, 0.008867462165653706, 0.00919139664620161, 0.08165863901376724, 0.01045237947255373, 0.009343687444925308, 0.12368924915790558, 0.09201455116271973, 0.008077727630734444, 0.008400977589190006, 0.009059702046215534, 0.0079079270362854, 0.007324897684156895, 0.1594482660293579, 0.007539085112512112, 0.006955117452889681, 0.007158154621720314, 0.006814365275204182, 0.007257846649736166, 0.14113475382328033, 0.09144599735736847, 0.0062179346568882465, 0.007227479480206966, 0.006779833696782589, 0.00680516567081213, 0.005820846185088158, 0.006134818308055401, 0.005796229466795921, 0.005644799210131168, 0.005184613633900881, 0.1001998707652092, 0.4572022259235382, 0.005267059430480003, 0.33379286527633667, 0.006463197059929371, 0.006415070034563541, 0.17676693201065063, 0.008060523308813572, 0.0082012340426445, 0.008819585666060448, 0.11599689722061157, 0.00934091117233038, 0.009808492846786976, 0.010041815228760242, 0.4475049674510956, 0.3963465094566345, 0.012601114809513092, 0.16755102574825287, 0.014681621454656124, 0.015456088818609715, 0.016103625297546387, 0.016706466674804688, 0.14252687990665436, 0.018359491601586342, 0.018030712381005287, 0.017527762800455093, 0.017706500366330147, 0.016845036298036575, 0.129872128367424, 0.016001572832465172, 0.0931319072842598, 0.0865195170044899, 0.014741758815944195, 0.014481705613434315, 0.013998249545693398, 0.13203740119934082, 0.07919733226299286, 0.012654760852456093, 0.2591229975223541, 0.1271425038576126, 0.012842327356338501, 0.012859564274549484, 0.10961558669805527, 0.10562261193990707, 0.01315930113196373, 0.1092953011393547, 0.013165492564439774, 0.3156779110431671, 0.12160760909318924, 0.013828516006469727, 0.014579574577510357, 0.09079844504594803, 0.015413030050694942, 0.3302188217639923, 0.08587273955345154, 0.10630366206169128, 0.1315428465604782, 0.01684204302728176, 0.01719869300723076, 0.017611803486943245, 0.01762480102479458, 0.1001201942563057, 0.017007755115628242, 0.10964194685220718, 0.016787385568022728, 0.12959662079811096, 0.015593954361975193, 0.01543342974036932, 0.1127634197473526, 0.40903183817863464, 0.015181301161646843, 0.01497704442590475, 0.13656656444072723, 0.01506596989929676, 0.014370903372764587, 0.08308584243059158, 0.014244326390326023, 0.013795503415167332, 0.3342083990573883, 0.014094575308263302, 0.01397685892879963, 0.01388752181082964, 0.014043518342077732, 0.07562271505594254, 0.013853197917342186, 0.013577723875641823, 0.012932168319821358, 0.012946151196956635, 0.0747770369052887, 0.011816236190497875, 0.011784462258219719, 0.011059196665883064, 0.010583789087831974, 0.1359560787677765, 0.01001610979437828, 0.009585813619196415, 0.11119528114795685, 0.12185249477624893, 0.008723724633455276, 0.008382568135857582, 0.10231740772724152, 0.008032014593482018, 0.007736872415989637, 0.0075185103341937065, 0.007466279901564121, 0.0071933818981051445, 0.11991149932146072, 0.006983383093029261, 0.11601562052965164, 0.006616969592869282, 0.1454017013311386, 0.08754881471395493, 0.11719217896461487, 0.007127601187676191, 0.10809215903282166, 0.006758062168955803, 0.12349648773670197, 0.11749045550823212, 0.11224942654371262, 0.007495617028325796, 0.007768562529236078, 0.09899133443832397, 0.008009186945855618, 0.00803226325660944, 0.1062450110912323, 0.32322958111763, 0.008806711062788963, 0.009374605491757393, 0.009845023043453693, 0.0746535137295723, 0.01069673616439104, 0.011371827684342861, 0.010932398028671741, 0.12620876729488373, 0.011305552907288074, 0.011273383162915707, 0.01145869493484497, 0.010996286757290363, 0.011557337827980518, 0.010486962273716927, 0.010145225562155247, 0.010077343322336674, 0.009592682123184204, 0.00941682793200016, 0.12597618997097015, 0.3294951617717743, 0.008716154843568802, 0.009135209955275059, 0.009204001165926456, 0.009253978729248047, 0.09661241620779037, 0.009357217699289322, 0.10451802611351013, 0.009684635326266289, 0.009293738752603531, 0.009224704466760159, 0.00926551315933466, 0.009751232340931892, 0.008698774501681328, 0.32299402356147766, 0.008998055942356586, 0.009066205471754074, 0.11433836817741394, 0.10305286943912506, 0.08558118343353271, 0.00979149341583252, 0.010356336832046509, 0.010155336000025272, 0.1284404695034027, 0.37753403186798096, 0.010691847652196884, 0.011150904931128025, 0.06796238571405411, 0.012080656364560127, 0.012095965445041656, 0.13786625862121582, 0.11467188596725464, 0.012691526673734188, 0.29808133840560913, 0.01342401560395956, 0.35074976086616516, 0.13448865711688995, 0.01620662398636341, 0.017054833471775055, 0.017917806282639503, 0.0978948250412941, 0.018711261451244354, 0.12526331841945648, 0.019344782456755638, 0.08239711076021194, 0.018642926588654518, 0.018512556329369545, 0.01825912483036518, 0.01808188669383526, 0.017611637711524963, 0.016661953181028366, 0.015800699591636658, 0.014786572195589542, 0.014260156080126762, 0.013600866310298443, 0.01245416421443224, 0.011843636631965637, 0.011092343367636204, 0.01046449039131403, 0.010123624466359615, 0.009134406223893166, 0.008560320362448692, 0.008004161529242992, 0.12731851637363434, 0.0071295686066150665, 0.006835739128291607, 0.006389682646840811, 0.006448996253311634, 0.10898392647504807, 0.0058492012321949005, 0.11974646896123886, 0.10571030527353287, 0.13716287910938263, 0.12771333754062653, 0.00550220999866724, 0.005650227423757315, 0.005588433239609003, 0.0896930992603302, 0.005759041290730238, 0.005666364915668964, 0.15051424503326416, 0.005901612341403961, 0.11833400279283524, 0.00604747561737895, 0.006128239445388317, 0.005960055626928806, 0.0977616012096405, 0.35755109786987305, 0.09286115318536758, 0.0070120831951498985, 0.007692175917327404, 0.12457408756017685, 0.00871200766414404, 0.10747870057821274, 0.009618307463824749, 0.009339308366179466, 0.009438904002308846, 0.07606160640716553, 0.009967487305402756, 0.009977114386856556, 0.31394249200820923, 0.07345813512802124, 0.3707171380519867, 0.01211132574826479, 0.11580071598291397, 0.013910082168877125, 0.10017048567533493, 0.015481698326766491, 0.016853630542755127, 0.016597865149378777, 0.016525764018297195, 0.016719255596399307, 0.01707156002521515, 0.105511873960495, 0.016237499192357063, 0.27782854437828064, 0.016319936141371727, 0.3590153455734253, 0.017244113609194756, 0.08285129070281982, 0.07208692282438278, 0.018763814121484756, 0.02009420469403267, 0.01943391002714634, 0.09187151491641998, 0.0887504369020462, 0.019329167902469635, 0.018636861816048622, 0.11912035197019577, 0.017723998054862022, 0.017539391294121742, 0.017114674672484398, 0.016655821353197098, 0.016008835285902023, 0.09480468928813934, 0.11938841640949249, 0.09594527631998062, 0.013456604443490505, 0.013497010804712772, 0.012524980120360851, 0.011731301434338093, 0.012457155622541904, 0.010840775445103645, 0.1332482248544693, 0.00980418361723423, 0.009863615967333317, 0.009019432589411736, 0.09382655471563339, 0.008518044836819172, 0.008129415102303028, 0.1302216500043869, 0.12299292534589767, 0.00734782125800848, 0.12320233881473541, 0.007485062349587679, 0.36575305461883545, 0.10563836246728897, 0.10390396416187286, 0.008399954065680504, 0.00840023998171091, 0.33953359723091125, 0.0808686763048172, 0.13061971962451935, 0.011143664829432964, 0.011461005546152592, 0.012383811175823212, 0.10811472684144974, 0.012725700624287128, 0.013092637062072754, 0.08553097397089005, 0.1417285054922104, 0.013826245442032814, 0.12009033560752869, 0.109463170170784, 0.1415724754333496, 0.07256609201431274, 0.11415646970272064, 0.014557262882590294, 0.015291101299226284, 0.014348423108458519, 0.20963770151138306, 0.014539850875735283, 0.014682195149362087, 0.11145137250423431, 0.015229035168886185, 0.11354073137044907, 0.014583434909582138, 0.014633851125836372, 0.014689146541059017, 0.014229211024940014, 0.11784730106592178, 0.12942782044410706, 0.013603216037154198, 0.25988641381263733, 0.013162415474653244, 0.013150275684893131, 0.3285787105560303, 0.07103677839040756, 0.014165909960865974, 0.10100173205137253, 0.14656570553779602, 0.11708017438650131, 0.016222501173615456, 0.07202163338661194, 0.016313789412379265, 0.016189981251955032, 0.1355983167886734, 0.01637672632932663, 0.1699526607990265, 0.01588660106062889, 0.01632881909608841, 0.014976476319134235, 0.015514951199293137, 0.014231005683541298, 0.014276917092502117, 0.1061868816614151, 0.10434827208518982, 0.012304646894335747, 0.11214513331651688, 0.011844880878925323, 0.011238531209528446, 0.010804828256368637, 0.010571897961199284, 0.1015402227640152, 0.009674341417849064, 0.009525868110358715, 0.009060299955308437, 0.08379852026700974, 0.00851092766970396, 0.00837109237909317, 0.00809953548014164, 0.007607927545905113, 0.00778013002127409, 0.10997729003429413, 0.007007415872067213, 0.00679846853017807, 0.006508076563477516, 0.006528585217893124, 0.006013088393956423, 0.12589414417743683, 0.3791426420211792, 0.11247020214796066, 0.09396453201770782, 0.006765684112906456, 0.10129409283399582, 0.007613233756273985, 0.007526738569140434, 0.00807721633464098, 0.11581160873174667, 0.13025957345962524, 0.15737447142601013, 0.009250037372112274, 0.008554330095648766, 0.13241083920001984, 0.009202479384839535, 0.11227500438690186, 0.1449476182460785, 0.009823059663176537, 0.09225563704967499, 0.00983442086726427, 0.009859764948487282, 0.010178228840231895, 0.09574655443429947, 0.07881490886211395, 0.010408728383481503, 0.009901108220219612, 0.11959749460220337, 0.010153406299650669, 0.29815906286239624, 0.010242524556815624, 0.1575503796339035, 0.010823301039636135, 0.011543555185198784, 0.1015874519944191, 0.011610569432377815, 0.011708617210388184, 0.011477102525532246, 0.011642574332654476, 0.011561262421309948, 0.011427790857851505, 0.08332782983779907, 0.011138281784951687, 0.010912101715803146, 0.10627129673957825, 0.010706959292292595, 0.00993890780955553, 0.009753693826496601, 0.009463896974921227, 0.009100878611207008, 0.00887992326170206, 0.09884485602378845, 0.00887115765362978, 0.0079870093613863, 0.00800944771617651, 0.12134652584791183, 0.007423426024615765, 0.10017429292201996, 0.08373953402042389, 0.007351245731115341, 0.10651243478059769, 0.006918429397046566, 0.12018190324306488, 0.007229910697788, 0.10968571901321411, 0.007282939739525318, 0.11448146402835846, 0.007048099301755428, 0.10621275007724762, 0.007288252469152212, 0.007389442063868046, 0.0073814415372908115, 0.13319924473762512, 0.007229358423501253, 0.1334199458360672, 0.13946913182735443, 0.007553305476903915, 0.007750988006591797, 0.007647906430065632, 0.14171826839447021, 0.11399927735328674, 0.11207397282123566, 0.00792630948126316, 0.30031582713127136, 0.00855749286711216, 0.008903979323804379, 0.13588324189186096, 0.009786076843738556, 0.009886367246508598, 0.08694593608379364, 0.010487734340131283, 0.12514884769916534, 0.0879070833325386, 0.010827090591192245, 0.012152417562901974, 0.10044404864311218, 0.01105035375803709, 0.011615234427154064, 0.11155162751674652, 0.11597618460655212, 0.09983113408088684, 0.011184626258909702, 0.01160742063075304, 0.01129817496985197, 0.12404777109622955, 0.31938421726226807, 0.011282644234597683, 0.011570747941732407, 0.011928400956094265, 0.012043042108416557, 0.09026845544576645, 0.08946330845355988, 0.012109498493373394, 0.11434684693813324, 0.10457480698823929, 0.11048554629087448, 0.012359497137367725, 0.01280216034501791, 0.01226384099572897, 0.01245809905230999, 0.11611007899045944, 0.011909561231732368, 0.01160477101802826, 0.01137983612716198, 0.1758553385734558, 0.010857575573027134, 0.010799990966916084, 0.2234792709350586, 0.010536104440689087, 0.10683293640613556, 0.010832853615283966, 0.010747626423835754, 0.3219645321369171, 0.011524533852934837, 0.011807396076619625, 0.012379559688270092, 0.012518726289272308, 0.3742777705192566, 0.012903700582683086, 0.11331509798765182, 0.013937171548604965, 0.0142674520611763, 0.014892002567648888, 0.09168659895658493, 0.12468650937080383, 0.1221252903342247, 0.014862606301903725, 0.10537232458591461, 0.014846314676105976, 0.0956515520811081, 0.015080446377396584, 0.014487018808722496, 0.014689469709992409, 0.09779182076454163, 0.08673129230737686, 0.013721835799515247, 0.013435249216854572, 0.14400614798069, 0.086977519094944, 0.012424176558852196, 0.012569059617817402, 0.011968882754445076, 0.011969894170761108, 0.01157399918884039, 0.011304096318781376, 0.010629824362695217, 0.010353785939514637, 0.009753244929015636, 0.09823513776063919, 0.008943740278482437, 0.008552712388336658, 0.6768569350242615, 0.008998379111289978, 0.098134845495224, 0.09433433413505554, 0.011051874607801437, 0.011697051115334034, 0.011757326312363148, 0.011942964047193527, 0.15325160324573517, 0.012549473904073238, 0.2796139419078827, 0.013246802613139153, 0.01365892868489027, 0.01463838666677475, 0.08360393345355988, 0.01480240561068058, 0.1163521409034729, 0.11843830347061157, 0.015218581072986126, 0.015004193410277367, 0.015198010951280594, 0.014981070533394814, 0.014759467914700508, 0.014095875434577465, 0.32196590304374695, 0.013924426399171352, 0.11217216402292252, 0.013965045101940632, 0.014298844151198864, 0.013844090513885021, 0.013881374150514603, 0.01339045725762844, 0.013320100493729115, 0.1169227734208107, 0.01249063853174448, 0.012433301657438278, 0.011858539655804634, 0.09642256796360016, 0.09051945060491562, 0.011084333062171936, 0.37565773725509644, 0.010910914279520512, 0.011578574776649475, 0.011106923222541809, 0.01117044035345316, 0.010984557680785656, 0.13019682466983795, 0.011241445317864418, 0.12370599806308746, 0.010650507174432278, 0.010802408680319786, 0.010462960228323936, 0.010324865579605103, 0.116553895175457, 0.10438024997711182, 0.009914727881550789, 0.009565465152263641, 0.11241491883993149, 0.13484299182891846, 0.10696733742952347, 0.11078093200922012, 0.1197928786277771, 0.12104183435440063, 0.009638248011469841, 0.009574515745043755, 0.009657311253249645, 0.009504642337560654, 0.009443202055990696, 0.009663627482950687, 0.1116168424487114, 0.009074851870536804, 0.34889301657676697, 0.009238645434379578, 0.0094866082072258, 0.009694556705653667, 0.10906771570444107, 0.010143104940652847, 0.0101093128323555, 0.3104785978794098, 0.010685600340366364, 0.11923735588788986, 0.011440642178058624, 0.011679043993353844, 0.012001218274235725, 0.011956067755818367, 0.11787114292383194, 0.012208265252411366, 0.01234134566038847, 0.01206560991704464, 0.011906751431524754, 0.011862678453326225, 0.011548618786036968, 0.30869486927986145, 0.011601930484175682, 0.01179486233741045, 0.011707251891493797, 0.01171115506440401, 0.011666982434689999, 0.011374478228390217, 0.011325571686029434, 0.010956021957099438, 0.3474346697330475, 0.10045062005519867, 0.01131320372223854, 0.10903801023960114, 0.011619792319834232, 0.011728332377970219, 0.011992651037871838, 0.11339421570301056, 0.011804992333054543, 0.12157958000898361, 0.1028761938214302, 0.012029302306473255, 0.1158023253083229, 0.011682478711009026, 0.0998920276761055, 0.31413209438323975, 0.012216918170452118, 0.012505792081356049, 0.10054884105920792, 0.10572335124015808, 0.013204073533415794, 0.28529226779937744, 0.014073196798563004, 0.10677037388086319, 0.0906512588262558, 0.2386113405227661, 0.01655915193259716, 0.017475001513957977, 0.1095280572772026, 0.018388541415333748, 0.11025100201368332, 0.019007589668035507, 0.019242405891418457, 0.01917976513504982, 0.01896608993411064, 0.01889544352889061, 0.111524298787117, 0.10415922105312347, 0.01777929626405239, 0.017306147143244743, 0.016807276755571365, 0.016526920720934868, 0.015952834859490395, 0.10476706922054291, 0.014561384916305542, 0.014064179733395576, 0.013546728529036045, 0.01286911778151989, 0.12825322151184082, 0.011836525984108448, 0.11113881319761276, 0.09640871733427048, 0.010687945410609245, 0.30494821071624756, 0.010506422258913517, 0.3320699632167816, 0.01113561075180769, 0.011509370990097523, 0.012003125622868538, 0.012096639722585678, 0.08894678950309753, 0.012517991475760937, 0.0125240758061409, 0.10729949176311493, 0.012787974439561367, 0.11027859151363373, 0.1211976706981659, 0.012392012402415276, 0.28782203793525696, 0.11085040867328644, 0.013338868506252766, 0.11186107993125916, 0.013924228958785534, 0.014012256637215614, 0.014327899552881718, 0.5755595564842224, 0.01551420334726572, 0.016286615282297134, 0.017336038872599602, 0.017750946804881096, 0.01853007823228836, 0.018688218668103218, 0.018745457753539085, 0.09521680325269699, 0.018772762268781662, 0.12158846855163574, 0.01867615059018135, 0.01838708110153675, 0.018041051924228668, 0.017610745504498482, 0.017314363270998, 0.016583915799856186, 0.01619696244597435, 0.09813102334737778, 0.014870723709464073, 0.0145315732806921, 0.013831152580678463, 0.09864136576652527, 0.012701003812253475, 0.01229969784617424, 0.09663183987140656, 0.01140610035508871, 0.011088251136243343, 0.11970515549182892, 0.010265539400279522, 0.010098297148942947, 0.3254583775997162, 0.09293659031391144, 0.009922623634338379, 0.009963803924620152, 0.009977913461625576, 0.009934613481163979, 0.009998648427426815, 0.009774518199265003, 0.11713311076164246, 0.009486088529229164, 0.009542847983539104, 0.009197539649903774, 0.008996334858238697, 0.008837331086397171, 0.008624798618257046, 0.00853652786463499, 0.008165275678038597, 0.008057772181928158, 0.30432644486427307, 0.007843432947993279, 0.007894533686339855, 0.10259702056646347, 0.08643264323472977, 0.008129997178912163, 0.008176120929419994, 0.008416772820055485, 0.008456009440124035, 0.008181329816579819, 0.008121511898934841, 0.008110200986266136, 0.007862783968448639, 0.008082856424152851, 0.007618364412337542, 0.007694227155297995, 0.08532282710075378, 0.10664746910333633, 0.007053016684949398, 0.006990015972405672, 0.006891975179314613, 0.007012421265244484, 0.10881488025188446, 0.0993892177939415, 0.006616869010031223, 0.10873471200466156, 0.006536074914038181, 0.006519200745970011, 0.11526002734899521, 0.14260466396808624, 0.0761835128068924, 0.006741820834577084, 0.0069474889896810055, 0.006773913744837046, 0.006824931595474482, 0.35004329681396484, 0.00714942067861557, 0.007364965975284576, 0.007627113256603479, 0.007789208088070154, 0.12908999621868134, 0.348827987909317, 0.008626879192888737, 0.009282436221837997, 0.00964052602648735, 0.01015931461006403, 0.010209578089416027, 0.32161495089530945, 0.11622566729784012, 0.31959477066993713, 0.11853761970996857, 0.14107047021389008, 0.01444789208471775, 0.07974549382925034, 0.016450956463813782, 0.11268223822116852, 0.2863534092903137, 0.09855342656373978, 0.11023116111755371, 0.020485656335949898, 0.021889710798859596, 0.022005263715982437, 0.1104193702340126, 0.02263072319328785, 0.12068000435829163, 0.02250584587454796, 0.022599298506975174, 0.11221244186162949, 0.02157365344464779, 0.3052583336830139, 0.02127876877784729, 0.021522024646401405, 0.021174682304263115, 0.10545975714921951, 0.08354923874139786, 0.02061077021062374, 0.11286485195159912, 0.01980653963983059, 0.01922735385596752, 0.07911288738250732, 0.1005290225148201, 0.01781076192855835, 0.14792069792747498, 0.016915258020162582, 0.016401106491684914, 0.015974795445799828, 0.015347572043538094, 0.11961217224597931, 0.014373019337654114, 0.013856807723641396, 0.013408315367996693, 0.012874503619968891, 0.01230832189321518, 0.011982125230133533, 0.011230369098484516, 0.10211300104856491, 0.01033352967351675, 0.1282406896352768, 0.009764972142875195, 0.10530804097652435, 0.009413039311766624, 0.10857225954532623, 0.008778332732617855, 0.008573290891945362, 0.3328588008880615, 0.008478119969367981, 0.11804401129484177, 0.10369237512350082, 0.008992105722427368, 0.009078881703317165, 0.09902983158826828, 0.00924101285636425, 0.3521239757537842, 0.009804866276681423, 0.10303675383329391, 0.01088604237884283, 0.010823549702763557, 0.11362161487340927, 0.011218275874853134, 0.011521480046212673, 0.07908841967582703, 0.011538619175553322, 0.01159626990556717, 0.01153850369155407, 0.12041439861059189, 0.01171921007335186, 0.011537954211235046, 0.011193113401532173, 0.11727917939424515, 0.10762118548154831, 0.09620357304811478, 0.08888808637857437, 0.011060765944421291, 0.010790101252496243, 0.010678673163056374, 0.010622317902743816, 0.08654913306236267, 0.010257447138428688, 0.010208156891167164, 0.009994006715714931, 0.009777069091796875, 0.009577994234859943, 0.009225589223206043, 0.3075488805770874, 0.009227730333805084, 0.009437493979930878, 0.1039423793554306, 0.009536908939480782, 0.34057721495628357, 0.009770176373422146, 0.09155286103487015, 0.5903809666633606, 0.011780336499214172, 0.012861940078437328, 0.013887531124055386, 0.014594226144254208, 0.015558295883238316, 0.0925721824169159, 0.01665893942117691, 0.07806840538978577, 0.0915263295173645, 0.01853257603943348, 0.017896758392453194, 0.018277516588568687, 0.11728402972221375, 0.018225351348519325, 0.018656963482499123, 0.08878536522388458, 0.13401079177856445, 0.01708954945206642, 0.017402736470103264, 0.016633030027151108, 0.1239258274435997, 0.015996534377336502, 0.07778288424015045, 0.12504495680332184, 0.01501661166548729, 0.014528402127325535, 0.10589280724525452, 0.10545014590024948, 0.2486833781003952, 0.0845712423324585, 0.014160048216581345, 0.14427977800369263, 0.014511537738144398, 0.014260970056056976, 0.014251607470214367, 0.35435381531715393, 0.014238875359296799, 0.014475551433861256, 0.25692057609558105, 0.01512888353317976, 0.015836602076888084, 0.016310933977365494, 0.016057468950748444, 0.11835882812738419, 0.0165964737534523, 0.3377571105957031, 0.01699240133166313, 0.0786149874329567, 0.017286544665694237, 0.12394798547029495, 0.24866975843906403, 0.11503945291042328, 0.09653755277395248, 0.09251867234706879, 0.019476376473903656, 0.020084338262677193, 0.01994338259100914, 0.020047210156917572, 0.12823742628097534, 0.09804566949605942, 0.09637431055307388, 0.2588953971862793, 0.253578245639801, 0.02037721872329712, 0.2856665253639221, 0.02223338931798935, 0.12064002454280853, 0.023882891982793808, 0.13285353779792786, 0.11980394273996353, 0.025491777807474136, 0.024872208014130592, 0.024839812889695168, 0.4764929413795471, 0.026019036769866943, 0.11594582349061966, 0.12111746519804001, 0.10875746607780457, 0.028823330998420715, 0.028983140364289284, 0.028519704937934875, 0.12233452498912811, 0.027861323207616806, 0.027436701580882072, 0.08931592106819153, 0.027375370264053345, 0.0253986194729805, 0.024398230016231537, 0.023503564298152924, 0.022565221413969994, 0.08609114587306976, 0.02091084234416485, 0.020031653344631195, 0.01904074102640152, 0.01807941310107708, 0.017199495807290077, 0.27758273482322693, 0.08709880709648132, 0.015516731888055801, 0.015140880830585957, 0.014797213487327099, 0.014440696686506271, 0.09521463513374329, 0.11011586338281631, 0.013476318679749966, 0.013109623454511166, 0.09166453033685684, 0.09817096590995789, 0.012211556546390057, 0.011876345612108707, 0.011679424904286861, 0.011297313496470451, 0.01105301734060049, 0.010867521166801453, 0.09495789557695389, 0.010077056474983692, 0.010186703875660896, 0.009719666093587875, 0.1481267809867859, 0.009127473458647728, 0.009039030410349369, 0.00888048391789198, 0.008373529650270939, 0.008191157132387161, 0.00791459996253252, 0.007791327778249979, 0.007472794037312269, 0.10216835886240005, 0.007318219635635614, 0.1004350483417511, 0.0068374271504580975, 0.006723466794937849, 0.12783591449260712, 0.10310191661119461, 0.08949292451143265, 0.006470378953963518, 0.006598228123039007, 0.4130118489265442, 0.07145214080810547, 0.007239265833050013, 0.12548917531967163, 0.007620596792548895, 0.0078008417040109634, 0.007993421517312527, 0.10708139091730118, 0.3529828190803528, 0.008835908025503159, 0.009246489964425564, 0.009515620768070221, 0.009774877689778805, 0.1270541250705719, 0.10397974401712418, 0.010541249997913837, 0.010838782414793968, 0.010938689112663269, 0.010863378643989563, 0.010908952914178371, 0.011365297250449657, 0.01094633899629116, 0.10512562841176987, 0.31041526794433594, 0.010923314839601517, 0.11537472903728485, 0.10921696573495865, 0.09330108016729355, 0.01210117619484663, 0.012175086885690689, 0.012242717668414116, 0.012528207153081894, 0.11811226606369019, 0.07471313327550888, 0.012390175834298134, 0.09781855344772339, 0.1073974072933197, 0.012451931834220886, 0.012452028691768646, 0.07419051975011826, 0.12929247319698334, 0.10530906915664673, 0.09082471579313278, 0.1005018875002861, 0.01224227249622345, 0.013118299655616283, 0.012480087578296661, 0.31324800848960876, 0.012588797137141228, 0.08556769788265228, 0.013034595176577568, 0.013279549777507782, 0.013267072848975658, 0.013113980181515217, 0.08956437557935715, 0.013368634507060051, 0.1196356788277626, 0.21759048104286194, 0.014384234324097633, 0.015101408585906029, 0.01342302281409502, 0.07628211379051208, 0.013822910375893116, 0.015261013992130756, 0.014412257820367813, 0.014432850293815136, 0.012849283404648304, 0.014306857250630856, 0.015492085367441177, 0.012598652392625809, 0.012985254637897015, 0.012524821795523167, 0.013849759474396706, 0.011245676316320896, 0.01162908785045147, 0.010784703306853771, 0.11843447387218475, 0.5296144485473633, 0.39420196413993835, 0.010061035864055157, 0.010746095329523087, 0.011004630476236343, 0.012907466851174831, 0.07589714229106903, 0.012089431285858154, 0.05275549739599228, 0.15300360321998596, 0.16598765552043915, 0.012165887281298637, 0.011872719042003155, 0.2665970027446747, 0.012868557125329971, 0.013040842488408089, 0.013927740976214409, 0.0999920666217804, 0.01357562467455864, 0.09783042967319489, 0.013616626150906086, 0.09518105536699295, 0.013256017118692398, 0.3543906509876251, 0.01453064288944006, 0.013741741888225079, 0.01414973009377718, 0.014404642395675182, 0.014343197457492352, 0.014180504716932774, 0.01448778621852398, 0.014401422813534737, 0.01406944915652275, 0.013797267340123653, 0.013248428702354431, 0.01287105493247509, 0.012629818171262741, 0.012151327915489674, 0.012280507944524288, 0.011379656381905079, 0.010570070706307888, 0.10160147398710251, 0.009982860647141933, 0.01008650753647089, 0.3072826564311981, 0.010357407853007317, 0.009706022217869759, 0.009414107538759708, 0.009615039452910423, 0.08363974839448929, 0.009874766692519188, 0.13613639771938324, 0.31850847601890564, 0.009661329910159111, 0.009859186597168446, 0.010258070193231106]\n",
            "Val loss 0.06140909271137551\n",
            "Val auc roc 0.5014136942194496\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ec09e6230334c6bbdbb6986ecf01d5a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1717.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0599\n",
            "Train Losses : [0.011162885464727879, 0.32576873898506165, 0.01095900870859623, 0.011148125864565372, 0.012113716453313828, 0.12505492568016052, 0.011876027099788189, 0.011914428323507309, 0.012029627338051796, 0.012025747448205948, 0.011882188729941845, 0.3845832347869873, 0.012534653767943382, 0.01320420578122139, 0.2992425560951233, 0.013370701111853123, 0.013435933738946915, 0.0942876860499382, 0.12709516286849976, 0.2505267262458801, 0.015110122039914131, 0.227778822183609, 0.10078798234462738, 0.22454755008220673, 0.019180575385689735, 0.02013075165450573, 0.02096436358988285, 0.021405581384897232, 0.21123503148555756, 0.02243213541805744, 0.02324015274643898, 0.02408667281270027, 0.11565521359443665, 0.0250236876308918, 0.02602190151810646, 0.024223987013101578, 0.023557884618639946, 0.02313406579196453, 0.022837413474917412, 0.08608660846948624, 0.12366592139005661, 0.02198123000562191, 0.11295544356107712, 0.021517783403396606, 0.01941613480448723, 0.200896754860878, 0.017831951379776, 0.15681761503219604, 0.018448257818818092, 0.17922735214233398, 0.017191531136631966, 0.018246851861476898, 0.017716726288199425, 0.07979928702116013, 0.018148353323340416, 0.018782785162329674, 0.07033368945121765, 0.11201800405979156, 0.09333041310310364, 0.0164272990077734, 0.08538070321083069, 0.015325409360229969, 0.01509650144726038, 0.15102383494377136, 0.18856333196163177, 0.10682271420955658, 0.09149739146232605, 0.014710190705955029, 0.10701537132263184, 0.013535763137042522, 0.1124214306473732, 0.014020764268934727, 0.013501242734491825, 0.012323103845119476, 0.012569695711135864, 0.011958410032093525, 0.011443492956459522, 0.07518533617258072, 0.010986041277647018, 0.19983743131160736, 0.010645795613527298, 0.3917917013168335, 0.010337509214878082, 0.010385995730757713, 0.010920044034719467, 0.011119578033685684, 0.08925408124923706, 0.13095645606517792, 0.010566146112978458, 0.10444681346416473, 0.010521605610847473, 0.010593146085739136, 0.010470696724951267, 0.01033078134059906, 0.09569402039051056, 0.12585113942623138, 0.08286211639642715, 0.009994489140808582, 0.13087041676044464, 0.009925257414579391, 0.010045231319963932, 0.010072216391563416, 0.009810367599129677, 0.11914979666471481, 0.00962030328810215, 0.00955392885953188, 0.00936457421630621, 0.009139899164438248, 0.3220880925655365, 0.35145190358161926, 0.009691673330962658, 0.010315638966858387, 0.010339171625673771, 0.10631144791841507, 0.010964794084429741, 0.08871329575777054, 0.011447462253272533, 0.011491579934954643, 0.12093012034893036, 0.08922425657510757, 0.01206124760210514, 0.011931346729397774, 0.33944278955459595, 0.012569045647978783, 0.33100274205207825, 0.01323937252163887, 0.013846916146576405, 0.014334640465676785, 0.10549050569534302, 0.015179809182882309, 0.2260226309299469, 0.09082309156656265, 0.01622188463807106, 0.016720129176974297, 0.08040699362754822, 0.017280079424381256, 0.017703527584671974, 0.017336804419755936, 0.01755918189883232, 0.13591456413269043, 0.01728508248925209, 0.017212754115462303, 0.016852805390954018, 0.016618981957435608, 0.11966356635093689, 0.09320302307605743, 0.1261792778968811, 0.014991947449743748, 0.01475744228810072, 0.014422008767724037, 0.014122260734438896, 0.014053664170205593, 0.08964040130376816, 0.01326077338308096, 0.012696420773863792, 0.12067968398332596, 0.012375077232718468, 0.11907802522182465, 0.1160869374871254, 0.0993485376238823, 0.01111665554344654, 0.010890903882682323, 0.10222018510103226, 0.010532526299357414, 0.010448293760418892, 0.10343854129314423, 0.010180174373090267, 0.01023092120885849, 0.009834615513682365, 0.010050288401544094, 0.00940901879221201, 0.00910246092826128, 0.009131606668233871, 0.008737176656723022, 0.11966993659734726, 0.09805604815483093, 0.32620230317115784, 0.008405255153775215, 0.10644899308681488, 0.0088962996378541, 0.35428470373153687, 0.09346713870763779, 0.009756853803992271, 0.0877734124660492, 0.010808617807924747, 0.01088404469192028, 0.010934394784271717, 0.011206672526896, 0.011367099359631538, 0.011405322700738907, 0.13733989000320435, 0.0945611223578453, 0.011638651601970196, 0.011463514529168606, 0.0758238211274147, 0.1258278787136078, 0.0113584129139781, 0.09628739207983017, 0.13915614783763885, 0.011327845975756645, 0.011295836418867111, 0.01130866352468729, 0.011400452814996243, 0.09879012405872345, 0.010983897373080254, 0.11196894943714142, 0.010645282454788685, 0.010626323521137238, 0.010355103760957718, 0.31196677684783936, 0.010433364659547806, 0.08375830948352814, 0.10951272398233414, 0.010946417227387428, 0.011179370805621147, 0.1057019755244255, 0.306566447019577, 0.11218541860580444, 0.08746886253356934, 0.012414745055139065, 0.012743029743432999, 0.012864691205322742, 0.013350734487175941, 0.10084229707717896, 0.12758812308311462, 0.013242898508906364, 0.013351043686270714, 0.09971988946199417, 0.013338137418031693, 0.13507108390331268, 0.013500533998012543, 0.013196061365306377, 0.09219829738140106, 0.29571202397346497, 0.013292232528328896, 0.013456272892653942, 0.013826537877321243, 0.11579019576311111, 0.013499891385436058, 0.1238635927438736, 0.013530482538044453, 0.013546204194426537, 0.30918705463409424, 0.12436264008283615, 0.1198912262916565, 0.01417339127510786, 0.0145496167242527, 0.014416457153856754, 0.014475667849183083, 0.08336233347654343, 0.01441959012299776, 0.09706135094165802, 0.014535303227603436, 0.11714892834424973, 0.013897092081606388, 0.10576075315475464, 0.09921468794345856, 0.013741799630224705, 0.11770240217447281, 0.013599827885627747, 0.01337902620434761, 0.013167768716812134, 0.13019564747810364, 0.012776844203472137, 0.012460107915103436, 0.01229337602853775, 0.10398674756288528, 0.011783163994550705, 0.13036765158176422, 0.1340467482805252, 0.011140470393002033, 0.10562587529420853, 0.010883907787501812, 0.0943160206079483, 0.01064439956098795, 0.09483586251735687, 0.010388441383838654, 0.01031714491546154, 0.010127879679203033, 0.08352915942668915, 0.11436261981725693, 0.09996756166219711, 0.09186510741710663, 0.10363931953907013, 0.009824727661907673, 0.1307755410671234, 0.3354400098323822, 0.12437139451503754, 0.010452928021550179, 0.010946310125291348, 0.09559252113103867, 0.01123160868883133, 0.011441546492278576, 0.11753402650356293, 0.011560953222215176, 0.13009890913963318, 0.01173714641481638, 0.01187928207218647, 0.10108506679534912, 0.011785258539021015, 0.08088509738445282, 0.01182284951210022, 0.011796675622463226, 0.011554943397641182, 0.011495961807668209, 0.011304106563329697, 0.01129232905805111, 0.010950300842523575, 0.11257262527942657, 0.010622497648000717, 0.010267827659845352, 0.010050438344478607, 0.0941367819905281, 0.009830807335674763, 0.009539901278913021, 0.00928397849202156, 0.009118038229644299, 0.008929766714572906, 0.0816064402461052, 0.008500638417899609, 0.008320043794810772, 0.008387885056436062, 0.008028521202504635, 0.128513365983963, 0.00772739527747035, 0.007558754645287991, 0.007613301742821932, 0.11086142063140869, 0.007130968850106001, 0.0071728043258190155, 0.08908982574939728, 0.007026495411992073, 0.39755117893218994, 0.10732296854257584, 0.11058779060840607, 0.12126903235912323, 0.007681303657591343, 0.008011448197066784, 0.00831400603055954, 0.008250363171100616, 0.008302914910018444, 0.13731904327869415, 0.11849424242973328, 0.11404605209827423, 0.008701466023921967, 0.008877422660589218, 0.008909760974347591, 0.008882971480488777, 0.00905537512153387, 0.008835328742861748, 0.008841651491820812, 0.10230465978384018, 0.008627237752079964, 0.008546323515474796, 0.08762453496456146, 0.11192367970943451, 0.008413584902882576, 0.008454257622361183, 0.09572460502386093, 0.00827282015234232, 0.008387274108827114, 0.11320021748542786, 0.11262305080890656, 0.008199183270335197, 0.00827118568122387, 0.008114580996334553, 0.008037579245865345, 0.008048320189118385, 0.11980798095464706, 0.09867961704730988, 0.0991361066699028, 0.007787771988660097, 0.007880879566073418, 0.007878880947828293, 0.007820015773177147, 0.007625727914273739, 0.0076455711387097836, 0.10979533195495605, 0.10265251994132996, 0.0747789815068245, 0.007531150244176388, 0.0074194371700286865, 0.007445421069860458, 0.007410489488393068, 0.0073369350284338, 0.007195375394076109, 0.10120711475610733, 0.08485002815723419, 0.10243448615074158, 0.007054775021970272, 0.007088156417012215, 0.09930036216974258, 0.0070665511302649975, 0.1338673084974289, 0.0070031192153692245, 0.007101365830749273, 0.11475445330142975, 0.007139275781810284, 0.007056072819977999, 0.007074235938489437, 0.007158105727285147, 0.006929400376975536, 0.006842418108135462, 0.1104821115732193, 0.11424490809440613, 0.006704775616526604, 0.006756878457963467, 0.006840940564870834, 0.3164609670639038, 0.007056304719299078, 0.10113745927810669, 0.007301996927708387, 0.00759913632646203, 0.13982218503952026, 0.0077445777133107185, 0.007996250875294209, 0.008232668042182922, 0.34339094161987305, 0.11642713844776154, 0.009027144871652126, 0.13923591375350952, 0.009416026063263416, 0.009629047475755215, 0.009833441115915775, 0.3802878260612488, 0.10582207888364792, 0.010810400359332561, 0.011158869601786137, 0.15127210319042206, 0.012044042348861694, 0.01201183907687664, 0.012233930639922619, 0.012287382036447525, 0.012434064410626888, 0.012280518189072609, 0.012384791858494282, 0.012287351302802563, 0.012021682225167751, 0.011946204118430614, 0.011761531233787537, 0.10823287814855576, 0.011221839115023613, 0.011052767746150494, 0.13227777183055878, 0.32389262318611145, 0.10123662650585175, 0.27957582473754883, 0.011496586725115776, 0.12313303351402283, 0.012541159056127071, 0.012641355395317078, 0.11148146539926529, 0.013220580294728279, 0.09682891517877579, 0.013515071012079716, 0.013654399663209915, 0.5821256041526794, 0.09719695895910263, 0.015333423390984535, 0.016342870891094208, 0.0167644452303648, 0.01719379797577858, 0.11134058982133865, 0.01805102825164795, 0.10185389965772629, 0.018183626234531403, 0.5120518803596497, 0.019252944737672806, 0.020145712420344353, 0.021059835329651833, 0.11792942881584167, 0.09769116342067719, 0.26339754462242126, 0.09604072570800781, 0.02378981001675129, 0.024467237293720245, 0.23606158792972565, 0.08733394742012024, 0.12315493077039719, 0.026811596006155014, 0.026630070060491562, 0.026695892214775085, 0.026588497683405876, 0.12518572807312012, 0.025961341336369514, 0.026074055582284927, 0.02520807646214962, 0.09930906444787979, 0.1250188797712326, 0.02356104925274849, 0.02320151776075363, 0.285989373922348, 0.254171758890152, 0.02233678661286831, 0.022395186126232147, 0.2705424726009369, 0.1235036700963974, 0.023333774879574776, 0.023018853738904, 0.09447743743658066, 0.023360567167401314, 0.022915685549378395, 0.02270244061946869, 0.022301459684967995, 0.10594072937965393, 0.0986776202917099, 0.021032018586993217, 0.020552240312099457, 0.02030985616147518, 0.019503461197018623, 0.01915491186082363, 0.01842893473803997, 0.017715008929371834, 0.0174872949719429, 0.1025829017162323, 0.016217565163969994, 0.09867662936449051, 0.014995024539530277, 0.10691642761230469, 0.014137901365756989, 0.1102195531129837, 0.11100751906633377, 0.013022608123719692, 0.012792015448212624, 0.01245118584483862, 0.012049034237861633, 0.09982804954051971, 0.011708918027579784, 0.09461595863103867, 0.10226640105247498, 0.0108804265037179, 0.33784717321395874, 0.34044602513313293, 0.011154732666909695, 0.27089667320251465, 0.11577102541923523, 0.3040369153022766, 0.013768321834504604, 0.014410245232284069, 0.015124267898499966, 0.015821566805243492, 0.016486452892422676, 0.01654941402375698, 0.10481705516576767, 0.017084360122680664, 0.1071523129940033, 0.017736803740262985, 0.10660162568092346, 0.09896502643823624, 0.11460397392511368, 0.017426425591111183, 0.24902905523777008, 0.017701810225844383, 0.01824338734149933, 0.017960844561457634, 0.018280627205967903, 0.10025697946548462, 0.2601616084575653, 0.2862645089626312, 0.018796775490045547, 0.278408944606781, 0.01995101012289524, 0.22584469616413116, 0.021537678316235542, 0.02234962023794651, 0.022847818210721016, 0.08336973935365677, 0.02402636408805847, 0.02397860959172249, 0.29711708426475525, 0.10839347541332245, 0.02469414845108986, 0.025033103302121162, 0.02495400235056877, 0.1245858296751976, 0.024572918191552162, 0.024499282240867615, 0.0246818158775568, 0.023722993209958076, 0.023012837395071983, 0.02242531068623066, 0.09644633531570435, 0.12275207042694092, 0.020977068692445755, 0.1283600926399231, 0.11000824719667435, 0.1077110692858696, 0.018754489719867706, 0.11151858419179916, 0.0181804820895195, 0.1073574423789978, 0.017170149832963943, 0.016830608248710632, 0.12021981179714203, 0.015997692942619324, 0.015686793252825737, 0.12021687626838684, 0.014728719368577003, 0.014590222388505936, 0.013966375030577183, 0.013701179064810276, 0.013188040815293789, 0.012883300893008709, 0.01235812995582819, 0.10729065537452698, 0.0983695387840271, 0.011343332938849926, 0.11077938973903656, 0.316921591758728, 0.09514998644590378, 0.011052481830120087, 0.01125242281705141, 0.011187081225216389, 0.011156048625707626, 0.011048146523535252, 0.011181253008544445, 0.010970674455165863, 0.010880021378397942, 0.010695943608880043, 0.010508705861866474, 0.09384318441152573, 0.010172582231462002, 0.09955098479986191, 0.10213964432477951, 0.009825978428125381, 0.009598424658179283, 0.1058896854519844, 0.00947002787142992, 0.009420550428330898, 0.009211886674165726, 0.0092288414016366, 0.009005744941532612, 0.00880186166614294, 0.008584735915064812, 0.10894984006881714, 0.10053930431604385, 0.00827233586460352, 0.08592397719621658, 0.00814216397702694, 0.00813775509595871, 0.008003712631762028, 0.007941043004393578, 0.10822312533855438, 0.10421913862228394, 0.007692915387451649, 0.007655232213437557, 0.11234430968761444, 0.007755241822451353, 0.007528000045567751, 0.0913868248462677, 0.007454648148268461, 0.007490868214517832, 0.007321265991777182, 0.007340527605265379, 0.00712035084143281, 0.007035021670162678, 0.006975649856030941, 0.00686592748388648, 0.006887251045554876, 0.12518294155597687, 0.006662963889539242, 0.006506284233182669, 0.1092657819390297, 0.0063876924104988575, 0.10566078126430511, 0.00638362392783165, 0.006377882324159145, 0.00630722101777792, 0.11353051662445068, 0.3546989858150482, 0.006422663573175669, 0.09906557947397232, 0.3973124921321869, 0.0074240826070308685, 0.007534618489444256, 0.00791856274008751, 0.008210528641939163, 0.008404760621488094, 0.008710968308150768, 0.008722532540559769, 0.008935628458857536, 0.008943590335547924, 0.3552089333534241, 0.009319478645920753, 0.009564741514623165, 0.009807816706597805, 0.00996579322963953, 0.010232772678136826, 0.010185095481574535, 0.11869222670793533, 0.3055644631385803, 0.33782845735549927, 0.011250783689320087, 0.011772826313972473, 0.012117914855480194, 0.01257320586591959, 0.012918040156364441, 0.013389529660344124, 0.01315215416252613, 0.013409980572760105, 0.10238684713840485, 0.07643036544322968, 0.01356903463602066, 0.01338079385459423, 0.1008775532245636, 0.013325652107596397, 0.12263516336679459, 0.013258922845125198, 0.01323691289871931, 0.012973446398973465, 0.012815400026738644, 0.012606115080416203, 0.012469557113945484, 0.30696550011634827, 0.012264425866305828, 0.11326809227466583, 0.012337257154285908, 0.25361305475234985, 0.10958356410264969, 0.11596094071865082, 0.09847909212112427, 0.013377003371715546, 0.09628748893737793, 0.013907377608120441, 0.09176316112279892, 0.014023593626916409, 0.014269904233515263, 0.014436453580856323, 0.014047488570213318, 0.1213691383600235, 0.01388345006853342, 0.013758513145148754, 0.013599474914371967, 0.013321779668331146, 0.013158694840967655, 0.013210859149694443, 0.10954844206571579, 0.01253938116133213, 0.012183167971670628, 0.01209346018731594, 0.011798136867582798, 0.011441684328019619, 0.11168599873781204, 0.13623541593551636, 0.0991939827799797, 0.0109544163569808, 0.11431171000003815, 0.010366625152528286, 0.010238321498036385, 0.010220720432698727, 0.010108118876814842, 0.009905816987156868, 0.009572761133313179, 0.009395482018589973, 0.00922917015850544, 0.30960485339164734, 0.10532671958208084, 0.009173188358545303, 0.1346147358417511, 0.009331689216196537, 0.10257651656866074, 0.009419034235179424, 0.009494898840785027, 0.09201648831367493, 0.09228695183992386, 0.11320514976978302, 0.10609515011310577, 0.1057266965508461, 0.010026715695858002, 0.010106012225151062, 0.010039006359875202, 0.010082368738949299, 0.009975277818739414, 0.009910280816257, 0.009798577055335045, 0.009768114425241947, 0.009549561887979507, 0.09241806715726852, 0.12768006324768066, 0.00936576072126627, 0.009236038662493229, 0.009094414301216602, 0.11871182173490524, 0.008889956399798393, 0.008811073377728462, 0.00883247796446085, 0.38636431097984314, 0.008899115957319736, 0.11090075969696045, 0.009140498004853725, 0.009204856120049953, 0.009170709177851677, 0.10560312122106552, 0.10442478954792023, 0.12172752618789673, 0.009468807838857174, 0.009462004527449608, 0.1026993840932846, 0.009682673960924149, 0.009611813351511955, 0.009739945642650127, 0.009562110528349876, 0.00945094134658575, 0.009442559443414211, 0.00942305102944374, 0.10313373059034348, 0.10576826333999634, 0.1070728674530983, 0.009026192128658295, 0.3525089621543884, 0.009207562543451786, 0.10757257044315338, 0.3541821539402008, 0.30505743622779846, 0.010625562630593777, 0.011306161060929298, 0.01197519525885582, 0.10814031958580017, 0.012677881866693497, 0.11118099838495255, 0.013461303897202015, 0.1252938210964203, 0.01402117870748043, 0.01408383995294571, 0.10448922216892242, 0.014374998398125172, 0.014462299644947052, 0.014576136134564877, 0.01441403478384018, 0.014377176761627197, 0.11211031675338745, 0.014036965556442738, 0.013920452445745468, 0.09926681220531464, 0.10783427208662033, 0.09645656496286392, 0.13138572871685028, 0.013293109834194183, 0.013074686750769615, 0.013071554712951183, 0.012953696772456169, 0.012591708451509476, 0.012363584712147713, 0.012288359925150871, 0.011906751431524754, 0.011737027205526829, 0.011373782530426979, 0.10950807482004166, 0.010999103076756, 0.10262153297662735, 0.010465261526405811, 0.2957207262516022, 0.010513663291931152, 0.09522595256567001, 0.010528085753321648, 0.010520240291953087, 0.01051440741866827, 0.11151710152626038, 0.010546672157943249, 0.010385583154857159, 0.31108129024505615, 0.123204305768013, 0.1292733997106552, 0.10315806418657303, 0.011167405173182487, 0.011392541229724884, 0.011432238854467869, 0.011571832932531834, 0.011533799581229687, 0.011590683832764626, 0.3255767524242401, 0.011665540747344494, 0.011975855566561222, 0.01200508326292038, 0.012114663608372211, 0.01218570675700903, 0.012236500158905983, 0.11410049349069595, 0.012005503289401531, 0.012022214941680431, 0.01186797022819519, 0.011756299994885921, 0.011497586034238338, 0.011411202140152454, 0.011413494125008583, 0.010965577326714993, 0.010876337066292763, 0.010658401064574718, 0.010493253357708454, 0.10379242151975632, 0.010009908117353916, 0.12955158948898315, 0.10925706475973129, 0.009590438567101955, 0.00940389558672905, 0.009269402362406254, 0.009226303547620773, 0.10362687706947327, 0.13189220428466797, 0.10033799707889557, 0.008972016163170338, 0.008869818411767483, 0.11436008661985397, 0.00868697464466095, 0.008655148558318615, 0.008759185671806335, 0.008439726196229458, 0.00842986349016428, 0.008291220292448997, 0.008125144056975842, 0.008178947493433952, 0.007866943255066872, 0.007717073895037174, 0.10755685716867447, 0.10443402826786041, 0.007501478772610426, 0.0074506038799881935, 0.14343224465847015, 0.0925833061337471, 0.00730779767036438, 0.007297135423868895, 0.007187593262642622, 0.007255482021719217, 0.11188287287950516, 0.09913914650678635, 0.0070646461099386215, 0.3322366178035736, 0.007293006405234337, 0.1081940233707428, 0.007607094943523407, 0.007763837929815054, 0.007911552675068378, 0.008018908090889454, 0.00806571077555418, 0.008031962439417839, 0.11221723258495331, 0.008218949660658836, 0.11795329302549362, 0.008144290186464787, 0.008197564631700516, 0.10092870146036148, 0.12140506505966187, 0.008269348181784153, 0.008225890807807446, 0.1239716187119484, 0.008319164626300335, 0.008337519131600857, 0.00830469187349081, 0.10403992235660553, 0.00819642934948206, 0.11487194150686264, 0.00817708857357502, 0.00826546922326088, 0.008164560422301292, 0.00808033812791109, 0.10277213901281357, 0.007974677719175816, 0.007982339709997177, 0.007853461429476738, 0.007824421860277653, 0.0076874312944710255, 0.007625335827469826, 0.007538840640336275, 0.36531031131744385, 0.00754451984539628, 0.12197881937026978, 0.007746593561023474, 0.007807677146047354, 0.007911582477390766, 0.0079090790823102, 0.007921640761196613, 0.008123916573822498, 0.09760455042123795, 0.007893153466284275, 0.007867329753935337, 0.007891455665230751, 0.007795891724526882, 0.007820552214980125, 0.007641153875738382, 0.007657803129404783, 0.10992385447025299, 0.12803633511066437, 0.10707281529903412, 0.007433724589645863, 0.007442970294505358, 0.0073633985593914986, 0.0073143853805959225, 0.007392768282443285, 0.11960221081972122, 0.12115516513586044, 0.11782226711511612, 0.007200172636657953, 0.1263691782951355, 0.00730096222832799, 0.08685566484928131, 0.00738668953999877, 0.007311306428164244, 0.0072992416098713875, 0.007341593503952026, 0.12200777977705002, 0.1191217303276062, 0.09659028053283691, 0.11442229151725769, 0.007411613129079342, 0.09663421660661697, 0.00752655602991581, 0.11040253192186356, 0.007799957878887653, 0.34209534525871277, 0.007997053675353527, 0.008183159865438938, 0.008347957395017147, 0.008528350852429867, 0.008691927418112755, 0.008718040771782398, 0.008903051726520061, 0.11096002161502838, 0.008854151703417301, 0.00893623661249876, 0.10822290927171707, 0.00894256867468357, 0.008873412385582924, 0.10576484352350235, 0.008911256678402424, 0.11347505450248718, 0.008904961869120598, 0.008840636350214481, 0.11841241270303726, 0.008859503082931042, 0.36141741275787354, 0.009029955603182316, 0.009195929393172264, 0.10018754750490189, 0.11427711695432663, 0.3112458288669586, 0.010016776621341705, 0.010364396497607231, 0.010722014121711254, 0.010982082225382328, 0.011080550029873848, 0.01122881006449461, 0.3365970551967621, 0.011676461435854435, 0.10131774842739105, 0.012251695618033409, 0.09970742464065552, 0.3179994821548462, 0.01307239942252636, 0.10019523650407791, 0.013836393132805824, 0.2925959527492523, 0.1161343976855278, 0.015174737200140953, 0.015722326934337616, 0.015929998829960823, 0.30776748061180115, 0.01673433929681778, 0.017121976241469383, 0.01750650443136692, 0.017675938084721565, 0.01792953535914421, 0.12180794775485992, 0.0181067306548357, 0.01792323775589466, 0.10455656796693802, 0.10360343009233475, 0.017594734206795692, 0.11026383191347122, 0.293441504240036, 0.017537102103233337, 0.28060755133628845, 0.018058335408568382, 0.01828206516802311, 0.018460696563124657, 0.018609004095196724, 0.018618347123265266, 0.01849987916648388, 0.10413952171802521, 0.018300523981451988, 0.10031725466251373, 0.10902269929647446, 0.10790670663118362, 0.01763087511062622, 0.017465859651565552, 0.11816859245300293, 0.10098914057016373, 0.01689746417105198, 0.016573458909988403, 0.016446953639388084, 0.016041191294789314, 0.10976589471101761, 0.10272335261106491, 0.015252644196152687, 0.014953977428376675, 0.09661019593477249, 0.014443054795265198, 0.01416234765201807, 0.013927426189184189, 0.013663442805409431, 0.013420400209724903, 0.01301620900630951, 0.11061425507068634, 0.3259966969490051, 0.012441011145710945, 0.01242862083017826, 0.09840068221092224, 0.012346380390226841, 0.012266683392226696, 0.012263776734471321, 0.12398944795131683, 0.011975410394370556, 0.011842554435133934, 0.11678096652030945, 0.11789218336343765, 0.011540764011442661, 0.011530941352248192, 0.01128753274679184, 0.1071944534778595, 0.011131932027637959, 0.010916242375969887, 0.3197380304336548, 0.010904256254434586, 0.11716252565383911, 0.011071954853832722, 0.10450425744056702, 0.011176981963217258, 0.01123758777976036, 0.011196613311767578, 0.011204058304429054, 0.011153065599501133, 0.011064678430557251, 0.010939748957753181, 0.010762164369225502, 0.010675888508558273, 0.10736295580863953, 0.01037660799920559, 0.010221658274531364, 0.010092083364725113, 0.0999232828617096, 0.009783162735402584, 0.009729515761137009, 0.009542056359350681, 0.11127986013889313, 0.009309116750955582, 0.00915120355784893, 0.009039491415023804, 0.008893747813999653, 0.10415605455636978, 0.008630042895674706, 0.008555653505027294, 0.10575665533542633, 0.008311341516673565, 0.008215949870646, 0.00811932235956192, 0.1089339479804039, 0.34493476152420044, 0.008081895299255848, 0.10707896202802658, 0.0942007377743721, 0.008455930277705193, 0.10078775137662888, 0.0086596654728055, 0.008807970210909843, 0.10713372379541397, 0.008897647261619568, 0.10785862058401108, 0.009084979072213173, 0.11521739512681961, 0.11614665389060974, 0.009271214716136456, 0.10261747241020203, 0.31380903720855713, 0.009656514972448349, 0.10195021331310272, 0.010168725624680519, 0.09184481203556061, 0.11885941028594971, 0.11216709762811661, 0.010892476886510849, 0.10247443616390228, 0.011232435703277588, 0.011354967020452023, 0.10260836780071259, 0.011584732681512833, 0.01156348641961813, 0.01167279202491045, 0.011538103222846985, 0.01151362806558609, 0.0114302858710289, 0.0113242007791996, 0.011167767457664013, 0.1109413132071495, 0.010896816849708557, 0.30197781324386597, 0.1012827455997467, 0.011065674014389515, 0.3136540353298187, 0.09389098733663559, 0.011813163757324219, 0.012059088796377182, 0.012294964864850044, 0.10162860155105591, 0.012760825455188751, 0.012747477740049362, 0.012785551138222218, 0.012816435657441616, 0.012743692845106125, 0.012653809040784836, 0.012631086632609367, 0.012441587634384632, 0.012324056588113308, 0.012215442024171352, 0.2918487787246704, 0.11256638914346695, 0.10534670203924179, 0.012192035093903542, 0.2840370833873749, 0.012512940913438797, 0.10055302083492279, 0.013032220304012299, 0.013188077136874199, 0.10622669756412506, 0.013361143879592419, 0.01348976232111454, 0.013419601134955883, 0.013399939984083176, 0.013289430178701878, 0.013202657923102379, 0.12573643028736115, 0.11621827632188797, 0.10640108585357666, 0.012917166575789452, 0.01274499949067831, 0.012640595436096191, 0.012594114989042282, 0.012371129356324673, 0.07432172447443008, 0.0120943458750844, 0.011905470862984657, 0.011670808307826519, 0.01146405003964901, 0.011368495412170887, 0.011060303077101707, 0.30671003460884094, 0.010926483199000359, 0.11111968010663986, 0.01085798442363739, 0.010862067341804504, 0.010836188681423664, 0.010926680639386177, 0.010730347596108913, 0.010603098198771477, 0.12746478617191315, 0.010441917926073074, 0.01030192244797945, 0.12327613681554794, 0.010208486579358578, 0.010033558122813702, 0.009867514483630657, 0.009801198728382587, 0.00964423082768917, 0.009434819221496582, 0.09169982373714447, 0.00927242636680603, 0.00910190586000681, 0.11874423921108246, 0.008923068642616272, 0.10665787756443024, 0.11325130611658096, 0.10423829406499863, 0.008644125424325466, 0.09706514328718185, 0.008594708517193794, 0.008571548387408257, 0.008508425205945969, 0.008483262732625008, 0.008418031968176365, 0.3532916009426117, 0.008485023863613605, 0.10800281167030334, 0.1320793181657791, 0.008861134760081768, 0.10776388645172119, 0.00898771546781063, 0.009140769019722939, 0.009131623432040215, 0.11799551546573639, 0.009210809133946896, 0.10224682092666626, 0.009322326630353928, 0.009297644719481468, 0.009316272102296352, 0.009261942468583584, 0.009205831214785576, 0.09925329685211182, 0.009169966913759708, 0.009056775830686092, 0.009008962661027908, 0.11921776086091995, 0.008953218348324299, 0.008815432898700237, 0.008693598210811615, 0.00859561562538147, 0.11253990232944489, 0.12057668715715408, 0.008418627083301544, 0.008395910263061523, 0.008293057791888714, 0.09899760782718658, 0.00820886716246605, 0.0081027802079916, 0.00809100829064846, 0.10589902102947235, 0.00798087939620018, 0.12326649576425552, 0.10630303621292114, 0.007814791984856129, 0.007787870708853006, 0.0077758245170116425, 0.007784866262227297, 0.00768509553745389, 0.11896124482154846, 0.37176835536956787, 0.007756543345749378, 0.007846991531550884, 0.008036329410970211, 0.008024943061172962, 0.11268606036901474, 0.11076754331588745, 0.10969749093055725, 0.11816492676734924, 0.008491174317896366, 0.008645409718155861, 0.008624904789030552, 0.10943359136581421, 0.008772286586463451, 0.008718551136553288, 0.008737504482269287, 0.32601743936538696, 0.008947506546974182, 0.3057561218738556, 0.09821765124797821, 0.009803545661270618, 0.010113632306456566, 0.010309131816029549, 0.010590031743049622, 0.010769796557724476, 0.0946229100227356, 0.10604333877563477, 0.1159636452794075, 0.01128519419580698, 0.10941722989082336, 0.011439487338066101, 0.10008218884468079, 0.10481391102075577, 0.011624021455645561, 0.011683568358421326, 0.28191688656806946, 0.012002321891486645, 0.10488244146108627, 0.2815415859222412, 0.012690340168774128, 0.2931460440158844, 0.013551237061619759, 0.013935929164290428, 0.014325355179607868, 0.290326863527298, 0.015282751061022282, 0.01582610048353672, 0.10531680285930634, 0.1083458662033081, 0.1052490696310997, 0.017025180160999298, 0.017151307314634323, 0.017338691279292107, 0.017323598265647888, 0.01751144602894783, 0.01727227307856083, 0.017147544771432877, 0.017143581062555313, 0.01690896786749363, 0.08717478811740875, 0.01643694005906582, 0.0161263570189476, 0.015988266095519066, 0.015559420920908451, 0.015289710834622383, 0.014911213889718056, 0.12866608798503876, 0.01436584535986185, 0.014088674448430538, 0.10813198238611221, 0.2847782373428345, 0.10610328614711761, 0.01351726520806551, 0.01362636312842369, 0.013557910919189453, 0.01332551147788763, 0.09417121112346649, 0.10171965509653091, 0.25000521540641785, 0.01325235515832901, 0.013550969772040844, 0.01344303134828806, 0.013516968116164207, 0.09956120699644089, 0.10834432393312454, 0.013431462459266186, 0.29536134004592896, 0.013602349907159805, 0.01396870892494917, 0.014097665436565876, 0.0139875253662467, 0.013911210000514984, 0.01396788377314806, 0.013906032778322697, 0.013902775943279266, 0.013570510782301426, 0.10280051082372665, 0.10555382072925568, 0.09199683368206024, 0.12257546931505203, 0.013046679086983204, 0.012991076335310936, 0.01278118509799242, 0.012832526117563248, 0.012688047252595425, 0.012400327250361443, 0.012145914137363434, 0.10753171145915985, 0.11573166400194168, 0.01166878268122673, 0.011622292920947075, 0.011490718461573124, 0.09169873595237732, 0.10574834793806076, 0.01109626516699791, 0.010822627693414688, 0.09874382615089417, 0.010625830851495266, 0.0959806963801384, 0.11428911238908768, 0.12208320945501328, 0.010314499028027058, 0.11948841065168381, 0.010369986295700073, 0.01023351401090622, 0.010178429074585438, 0.332581102848053, 0.01012407336384058, 0.10607045888900757, 0.010468849912285805, 0.010451601818203926, 0.010433318093419075, 0.09118350595235825, 0.010449093766510487, 0.08568970113992691, 0.010573645122349262, 0.1114865392446518, 0.10575069487094879, 0.010471891611814499, 0.1122860237956047, 0.01049193274229765, 0.01046900823712349, 0.01046513207256794, 0.01038060337305069, 0.11850472539663315, 0.010382713750004768, 0.010188131593167782, 0.09685082733631134, 0.09967704862356186, 0.010033178143203259, 0.11092676222324371, 0.009969405829906464, 0.11304698139429092, 0.010025826282799244, 0.009899241849780083, 0.3324850797653198, 0.010000328533351421, 0.09252925217151642, 0.12308721244335175, 0.11291839182376862, 0.010664950124919415, 0.01061756070703268, 0.0107710100710392, 0.010625354945659637, 0.010760759003460407, 0.01058876235038042, 0.010625628754496574, 0.12943397462368011, 0.01051460113376379, 0.2763724625110626, 0.010502181015908718, 0.09849235415458679, 0.1007900983095169, 0.10157859325408936, 0.011009412817656994, 0.011359396390616894, 0.011107607744634151, 0.11295303702354431, 0.1075010746717453, 0.011190460063517094, 0.011330262757837772, 0.10307970643043518, 0.011221188120543957, 0.011165284551680088, 0.011274348013103008, 0.11296789348125458, 0.11226960271596909, 0.11641716212034225, 0.01110781915485859, 0.010976561345160007, 0.010943862609565258, 0.010803536511957645, 0.010913076810538769, 0.010665475390851498, 0.010779960080981255, 0.11438373476266861, 0.3009404242038727, 0.10862372070550919, 0.0107521777972579, 0.01060834713280201, 0.010880468413233757, 0.010716449469327927, 0.09691309928894043, 0.010724840685725212, 0.12434057146310806, 0.321427583694458, 0.010942907072603703, 0.09376189112663269, 0.011313565075397491, 0.3310849070549011, 0.011791125871241093, 0.0920116975903511, 0.3149338364601135, 0.012629736214876175, 0.013190778903663158, 0.1275836080312729, 0.013801191933453083, 0.013929937966167927, 0.10398558527231216, 0.014431163668632507, 0.10791441798210144, 0.014574036933481693, 0.014633486978709698, 0.014767274260520935, 0.01460323203355074, 0.014627679251134396, 0.014483066275715828, 0.11157367378473282, 0.014216529205441475, 0.0876319408416748, 0.013983335345983505, 0.013832091353833675, 0.013656405732035637, 0.0134832002222538, 0.12140463292598724, 0.01321024913340807, 0.10402850806713104, 0.01294154766947031, 0.012605239637196064, 0.012486005201935768, 0.11255517601966858, 0.29166507720947266, 0.10971415042877197, 0.11329670250415802, 0.012356988154351711, 0.10262662917375565, 0.11011718958616257, 0.01260219793766737, 0.012609071098268032, 0.10529769212007523, 0.012596267275512218, 0.2923327386379242, 0.012680109590291977, 0.09246297180652618, 0.2948411703109741, 0.01336474809795618, 0.013670656830072403, 0.013921620324254036, 0.014051285572350025, 0.1034066304564476, 0.014377497136592865, 0.01430641021579504, 0.1260506957769394, 0.10775449872016907, 0.014572298154234886, 0.014408063143491745, 0.014280403032898903, 0.01436733826994896, 0.014115771278738976, 0.013929758220911026, 0.10740639269351959, 0.0991939976811409, 0.013501528650522232, 0.11071868240833282, 0.013307117857038975, 0.013178186491131783, 0.2960539758205414, 0.013094045221805573, 0.10657449066638947, 0.5441014170646667, 0.013761172071099281, 0.014171787537634373, 0.10449197143316269, 0.11706364899873734, 0.015293480828404427, 0.09364060312509537, 0.015816010534763336, 0.016018779948353767, 0.11881425231695175, 0.10747198760509491, 0.016520870849490166, 0.016488756984472275, 0.10864867269992828, 0.01660359837114811, 0.016427617520093918, 0.10866998136043549, 0.10773669928312302, 0.01615287736058235, 0.016160082072019577, 0.08507698774337769, 0.015835115686058998, 0.2589486539363861, 0.09042013436555862, 0.015855172649025917, 0.11112969368696213, 0.016159672290086746, 0.11847490817308426, 0.01591344177722931, 0.015825146809220314, 0.015726225450634956, 0.015652617439627647, 0.015584412962198257, 0.015319043770432472, 0.015259088017046452, 0.01483061257749796, 0.10419764369726181, 0.5267432928085327, 0.014885620214045048, 0.015037513338029385, 0.015209955163300037, 0.015491106547415257, 0.015419639647006989, 0.01545300055295229, 0.015386959537863731, 0.10664666444063187, 0.015373037196695805, 0.1111157163977623, 0.015240658074617386, 0.2819081246852875, 0.1048722192645073, 0.015330514870584011, 0.09060417860746384, 0.015572049655020237, 0.015473081730306149, 0.015510272234678268, 0.2805514335632324, 0.015600425191223621, 0.08933136612176895, 0.015803951770067215, 0.015927065163850784, 0.015762055292725563, 0.09440385550260544, 0.015801308676600456, 0.015653109177947044, 0.015971114858984947, 0.015530912205576897, 0.015515772625803947, 0.015067415311932564, 0.014824542216956615, 0.08913011848926544, 0.014607925899326801, 0.2933712303638458, 0.01429932564496994, 0.014245765283703804, 0.014226348139345646, 0.014225744642317295, 0.014238934963941574, 0.01384129747748375, 0.01362673006951809, 0.10995801538228989, 0.013373959809541702, 0.013212057761847973, 0.1210106685757637, 0.012939526699483395, 0.012757153250277042, 0.012613189406692982, 0.012369119562208652, 0.097356416285038, 0.11580279469490051, 0.141170933842659, 0.1032741591334343, 0.0923924595117569, 0.10120020806789398, 0.011766011826694012, 0.09365416318178177, 0.011685202829539776, 0.10756060481071472, 0.011514046229422092, 0.011377681978046894, 0.10321605205535889, 0.011231565847992897, 0.10284008830785751, 0.1120772510766983, 0.09291329979896545, 0.011028229258954525, 0.011072490364313126, 0.01104531716555357, 0.01093378383666277, 0.0107596879824996, 0.010701753199100494, 0.010573857463896275, 0.010472957976162434, 0.09588882327079773, 0.3383011817932129, 0.010354802943766117]\n",
            "Val loss 0.06351499796657026\n",
            "Val auc roc 0.5155120658717781\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97e414550561495abf229e569f0bfdde",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1717.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0591\n",
            "Train Losses : [0.010417573153972626, 0.3111489415168762, 0.010632152669131756, 0.010751987807452679, 0.1194523274898529, 0.011109105311334133, 0.011166242882609367, 0.011293473653495312, 0.011293984018266201, 0.011392391286790371, 0.011227242648601532, 0.011182787828147411, 0.011148023419082165, 0.09136906266212463, 0.01100278738886118, 0.10172824561595917, 0.09537861496210098, 0.12311778217554092, 0.010822698473930359, 0.010833670385181904, 0.01082682330161333, 0.10300618410110474, 0.010650647804141045, 0.010563105344772339, 0.10216698050498962, 0.010463557206094265, 0.09677449613809586, 0.10258357971906662, 0.010251211933791637, 0.12771885097026825, 0.010292377322912216, 0.09445982426404953, 0.010239774361252785, 0.010113842785358429, 0.01006593182682991, 0.08320683240890503, 0.0903138741850853, 0.09992463886737823, 0.3341725766658783, 0.09976881742477417, 0.010282357223331928, 0.01030584704130888, 0.010412038303911686, 0.12471400201320648, 0.10022342205047607, 0.01063286978751421, 0.2988360524177551, 0.01113536860793829, 0.011127527803182602, 0.011199090629816055, 0.011264754459261894, 0.01158391498029232, 0.1100979670882225, 0.10739251971244812, 0.011537705548107624, 0.011498326435685158, 0.07297121733427048, 0.1277412474155426, 0.011564372107386589, 0.011544330045580864, 0.01148257590830326, 0.011647939682006836, 0.011506959795951843, 0.011349188163876534, 0.09625707566738129, 0.01137717254459858, 0.011179391294717789, 0.011205624788999557, 0.12569190561771393, 0.2818349301815033, 0.30616897344589233, 0.011260147206485271, 0.07380732893943787, 0.011684553697705269, 0.10615047067403793, 0.012031813152134418, 0.012029568664729595, 0.012438350357115269, 0.012165253981947899, 0.012160908430814743, 0.012384624220430851, 0.3140670955181122, 0.012334492057561874, 0.08787912130355835, 0.012569824233651161, 0.012630053795874119, 0.12714692950248718, 0.01295450795441866, 0.012723801657557487, 0.10172725468873978, 0.290123850107193, 0.10315953195095062, 0.09528291970491409, 0.3037552237510681, 0.10162977129220963, 0.014004825614392757, 0.10122839361429214, 0.014600754715502262, 0.2802889943122864, 0.08969386667013168, 0.015371997840702534, 0.015735715627670288, 0.0160885788500309, 0.09144027531147003, 0.016151318326592445, 0.13600292801856995, 0.01626201532781124, 0.12434858083724976, 0.016386160627007484, 0.016817545518279076, 0.016636773943901062, 0.09418807923793793, 0.10055842250585556, 0.016133544966578484, 0.1052672490477562, 0.016113756224513054, 0.01614624820649624, 0.015688540413975716, 0.08251675218343735, 0.015493476763367653, 0.015186281874775887, 0.015040977858006954, 0.014870483428239822, 0.01462995819747448, 0.014382799156010151, 0.01429625041782856, 0.09325361251831055, 0.013733790256083012, 0.01366393268108368, 0.013723675161600113, 0.08595802634954453, 0.11641805619001389, 0.012762716971337795, 0.1082020252943039, 0.09807347506284714, 0.012231800705194473, 0.13108274340629578, 0.01205292996019125, 0.012131467461585999, 0.10512217879295349, 0.10850515961647034, 0.011770633980631828, 0.01155560091137886, 0.011465221643447876, 0.11510267108678818, 0.10925441235303879, 0.011206039227545261, 0.6033424139022827, 0.011430609039962292, 0.011570834554731846, 0.011779095977544785, 0.09163175523281097, 0.012214386835694313, 0.11515242606401443, 0.012437664903700352, 0.012852083891630173, 0.01247615460306406, 0.012461783364415169, 0.012565558776259422, 0.01261255331337452, 0.10551071912050247, 0.01236841082572937, 0.012367523275315762, 0.012276975437998772, 0.012217498384416103, 0.09945876151323318, 0.011876584962010384, 0.09990547597408295, 0.08973157405853271, 0.10978179425001144, 0.011700209230184555, 0.011514746583998203, 0.011442498303949833, 0.011386283673346043, 0.011303151957690716, 0.14214451611042023, 0.12986858189105988, 0.011095223017036915, 0.010967696085572243, 0.010811720974743366, 0.10025842487812042, 0.08855841308832169, 0.13045057654380798, 0.010677569545805454, 0.10080258548259735, 0.010481405071914196, 0.11369246244430542, 0.010368873365223408, 0.010591352358460426, 0.32275936007499695, 0.10338207334280014, 0.010483650490641594, 0.01059130672365427, 0.01084074191749096, 0.010794724337756634, 0.010693280957639217, 0.09645338356494904, 0.010720260441303253, 0.010588285513222218, 0.010581379756331444, 0.010576446540653706, 0.12292269617319107, 0.10669037699699402, 0.010515320114791393, 0.3115493357181549, 0.1351490020751953, 0.31583940982818604, 0.09391918033361435, 0.011107093654572964, 0.011329343542456627, 0.011775395832955837, 0.09626925736665726, 0.011931582354009151, 0.1116696447134018, 0.11437208950519562, 0.10989759117364883, 0.012208824045956135, 0.11309298872947693, 0.012383499182760715, 0.012363077141344547, 0.012872307561337948, 0.11070235073566437, 0.012415611185133457, 0.01256156712770462, 0.3330322802066803, 0.11673017591238022, 0.012613832019269466, 0.11362257599830627, 0.012737576849758625, 0.013062626123428345, 0.01288862805813551, 0.013014680705964565, 0.012835483066737652, 0.013155253604054451, 0.13952623307704926, 0.290696918964386, 0.012831700034439564, 0.012845782563090324, 0.012897486798465252, 0.09967382997274399, 0.012933692894876003, 0.012987698428332806, 0.012950994074344635, 0.012901912443339825, 0.1047402024269104, 0.012832030653953552, 0.10312039405107498, 0.012546684592962265, 0.012613577768206596, 0.012416355311870575, 0.11540196090936661, 0.012256146408617496, 0.012378786690533161, 0.11018773168325424, 0.011961433105170727, 0.01182608399540186, 0.11089267581701279, 0.11288625746965408, 0.011504466645419598, 0.11806604266166687, 0.0114058842882514, 0.10948605090379715, 0.011320567689836025, 0.11017874628305435, 0.10467753559350967, 0.011274917982518673, 0.09680602699518204, 0.011013138107955456, 0.3267548680305481, 0.01123384851962328, 0.011196921579539776, 0.011587238870561123, 0.1355244517326355, 0.011264178901910782, 0.08998172730207443, 0.011484316550195217, 0.10950917750597, 0.011456877924501896, 0.011298920027911663, 0.011267010122537613, 0.011492575518786907, 0.08409898728132248, 0.011188147589564323, 0.011102554388344288, 0.31983840465545654, 0.011126916855573654, 0.011211194097995758, 0.011318657547235489, 0.09638014435768127, 0.011312843300402164, 0.10032795369625092, 0.011269837617874146, 0.12361114472150803, 0.011202897876501083, 0.011214991100132465, 0.01116864662617445, 0.11956942081451416, 0.011161518283188343, 0.011148869059979916, 0.11067500710487366, 0.010993309319019318, 0.01091347448527813, 0.011103867553174496, 0.3028847277164459, 0.01085821446031332, 0.010887599550187588, 0.11626934260129929, 0.010983912274241447, 0.010957487858831882, 0.010932796634733677, 0.011039945296943188, 0.3055003583431244, 0.3082273304462433, 0.011217508465051651, 0.011575860902667046, 0.011633522808551788, 0.011783293448388577, 0.011864863336086273, 0.11668364703655243, 0.011984436772763729, 0.012002515606582165, 0.10205598175525665, 0.317947655916214, 0.012280302122235298, 0.012509013526141644, 0.09054593741893768, 0.10360118001699448, 0.012652530334889889, 0.01282064151018858, 0.01299498975276947, 0.1181272342801094, 0.012755288742482662, 0.1136072501540184, 0.11800888180732727, 0.012770270928740501, 0.08627763390541077, 0.09706071764230728, 0.012785700149834156, 0.012887843884527683, 0.11122442781925201, 0.012662489898502827, 0.012745820917189121, 0.012583926320075989, 0.29922616481781006, 0.012640928849577904, 0.012865872122347355, 0.09929013252258301, 0.012717373669147491, 0.1194252148270607, 0.0128505639731884, 0.09947915375232697, 0.012661545537412167, 0.012653852812945843, 0.1005021184682846, 0.012520062737166882, 0.012772212736308575, 0.012420227751135826, 0.09343834221363068, 0.012281845323741436, 0.01218077540397644, 0.3577219843864441, 0.012147273868322372, 0.11042611300945282, 0.10455143451690674, 0.12252674996852875, 0.0998736023902893, 0.012407881207764149, 0.01244874857366085, 0.01262622606009245, 0.012468349188566208, 0.012626678682863712, 0.012497980147600174, 0.10797519981861115, 0.012379112653434277, 0.012186908163130283, 0.012194337323307991, 0.09642074257135391, 0.011997416615486145, 0.011915869079530239, 0.10574707388877869, 0.011651596054434776, 0.011566960252821445, 0.011426184326410294, 0.011331764049828053, 0.01119282003492117, 0.01118666585534811, 0.010942867957055569, 0.010893555358052254, 0.010632309131324291, 0.09633974730968475, 0.010439000092446804, 0.010299344547092915, 0.27882465720176697, 0.10285909473896027, 0.11196356266736984, 0.01026639062911272, 0.010367905721068382, 0.09449601173400879, 0.11910246312618256, 0.010509878396987915, 0.01034961361438036, 0.010508020408451557, 0.010420778766274452, 0.010300216265022755, 0.010320669040083885, 0.01022716797888279, 0.1102401465177536, 0.010022199712693691, 0.009967656806111336, 0.00998244620859623, 0.00988969299942255, 0.11843803524971008, 0.3486047685146332, 0.009880274534225464, 0.009832492098212242, 0.1097559705376625, 0.009983047842979431, 0.10867851972579956, 0.11106853932142258, 0.10908809304237366, 0.010125159285962582, 0.10137264430522919, 0.010279674082994461, 0.010355306789278984, 0.010216787457466125, 0.010144311003386974, 0.0101785184815526, 0.010110834613442421, 0.010161157697439194, 0.01002246979624033, 0.009961912408471107, 0.1062714010477066, 0.009932835586369038, 0.009714742191135883, 0.1117645800113678, 0.009645122103393078, 0.1087307408452034, 0.11015409231185913, 0.009483136236667633, 0.009440791793167591, 0.009373487904667854, 0.09744911640882492, 0.009307079948484898, 0.009272212162613869, 0.10889219492673874, 0.09189645946025848, 0.009306416846811771, 0.009254418313503265, 0.11352729797363281, 0.00903238169848919, 0.00902384240180254, 0.009095612913370132, 0.008909623138606548, 0.10560452938079834, 0.008795490488409996, 0.008778708986938, 0.008744942024350166, 0.00878449622541666, 0.008689318783581257, 0.00853656604886055, 0.10688231140375137, 0.09727185219526291, 0.008380585350096226, 0.008288265205919743, 0.008288809098303318, 0.008281659334897995, 0.3683427572250366, 0.008250793442130089, 0.008250819519162178, 0.008352242410182953, 0.327045202255249, 0.008492184802889824, 0.09574531018733978, 0.008735200390219688, 0.12482455372810364, 0.008953542448580265, 0.12042306363582611, 0.009117784909904003, 0.009126613847911358, 0.009193472564220428, 0.10042072832584381, 0.09687640517950058, 0.009378040209412575, 0.009534919634461403, 0.1107381135225296, 0.009409845806658268, 0.009393338114023209, 0.00947862584143877, 0.009385247714817524, 0.12763506174087524, 0.009352205321192741, 0.009317408315837383, 0.009274445474147797, 0.009258939884603024, 0.09356363862752914, 0.11301030963659286, 0.10945747047662735, 0.009143848903477192, 0.009129591286182404, 0.00904665794223547, 0.09900452196598053, 0.009106971323490143, 0.009048771113157272, 0.008971265517175198, 0.008932896889746189, 0.1240517795085907, 0.09292721003293991, 0.09302371740341187, 0.3399503231048584, 0.008912350051105022, 0.09920309484004974, 0.34904855489730835, 0.009299693629145622, 0.009483188390731812, 0.00978774018585682, 0.00981435552239418, 0.010014638304710388, 0.12930071353912354, 0.010000982321798801, 0.10315044224262238, 0.01024683378636837, 0.09045888483524323, 0.010493039153516293, 0.010381127707660198, 0.01043479610234499, 0.01028242614120245, 0.010293413884937763, 0.010221641510725021, 0.010193931870162487, 0.108631931245327, 0.010133682750165462, 0.11062534898519516, 0.010073092766106129, 0.010005141608417034, 0.009969119913876057, 0.009904137812554836, 0.10732049494981766, 0.111590176820755, 0.10428415983915329, 0.10684158653020859, 0.12051421403884888, 0.00977357104420662, 0.00969211757183075, 0.009679225273430347, 0.009647166356444359, 0.009621561504900455, 0.10635660588741302, 0.09132521599531174, 0.009582390077412128, 0.009561456739902496, 0.10736839473247528, 0.009446367621421814, 0.009413402527570724, 0.009397665970027447, 0.09652064740657806, 0.11623028665781021, 0.00929959025233984, 0.00922909565269947, 0.00924940500408411, 0.009156757965683937, 0.009142870083451271, 0.10064376145601273, 0.008959025144577026, 0.008947083726525307, 0.008840159513056278, 0.008826963603496552, 0.11576467007398605, 0.09895902872085571, 0.10644692927598953, 0.11236906796693802, 0.10255558788776398, 0.008725211024284363, 0.00870218314230442, 0.00867276731878519, 0.00861408095806837, 0.09867900609970093, 0.008591271005570889, 0.11026635766029358, 0.11130925267934799, 0.008574438281357288, 0.008525696583092213, 0.008600085973739624, 0.008555540814995766, 0.00852277036756277, 0.10146275162696838, 0.0085544902831316, 0.008359395898878574, 0.11830819398164749, 0.008323576301336288, 0.008342072367668152, 0.10626611858606339, 0.008231625892221928, 0.008153548464179039, 0.11471997201442719, 0.008117402903735638, 0.11333983391523361, 0.008168202824890614, 0.11154955625534058, 0.09334783256053925, 0.008082490414381027, 0.11053015291690826, 0.12052364647388458, 0.09713821858167648, 0.008201521821320057, 0.008282354101538658, 0.08392950147390366, 0.00824748631566763, 0.008227765560150146, 0.00832622405141592, 0.008325370959937572, 0.008193801157176495, 0.008185011334717274, 0.00806195568293333, 0.008032644167542458, 0.008095912635326385, 0.007939045317471027, 0.007886814884841442, 0.007823962718248367, 0.09370008856058121, 0.007728307042270899, 0.007804342545568943, 0.09829207509756088, 0.102485291659832, 0.0076105971820652485, 0.34092119336128235, 0.007618652191013098, 0.007718884386122227, 0.00772795220836997, 0.31151634454727173, 0.007931881584227085, 0.008057002909481525, 0.09878648817539215, 0.008337358944118023, 0.008325370959937572, 0.008385716006159782, 0.10967337340116501, 0.33871254324913025, 0.12009076774120331, 0.10978440940380096, 0.12139539420604706, 0.009062482044100761, 0.009260166436433792, 0.12120616436004639, 0.009618651121854782, 0.00954605545848608, 0.009565758518874645, 0.11182516813278198, 0.009763131849467754, 0.009698483161628246, 0.009788393042981625, 0.10297753661870956, 0.009770024567842484, 0.0098606301471591, 0.009807556867599487, 0.00969507172703743, 0.009773923084139824, 0.009654304012656212, 0.009619751013815403, 0.009566926397383213, 0.0926830843091011, 0.1040196418762207, 0.00947047770023346, 0.009392624720931053, 0.009288107976317406, 0.009375059977173805, 0.009163039736449718, 0.009206908755004406, 0.11341091245412827, 0.11458559334278107, 0.008974296040832996, 0.09535390883684158, 0.008927518501877785, 0.008908012881875038, 0.008813736028969288, 0.09499257057905197, 0.3451922833919525, 0.3486946225166321, 0.009140439331531525, 0.09445766359567642, 0.009378538466989994, 0.00945541076362133, 0.009554034098982811, 0.009645446203649044, 0.009724675677716732, 0.00977715477347374, 0.3705621063709259, 0.01006336323916912, 0.10448302328586578, 0.0101724648848176, 0.010308901779353619, 0.10387604683637619, 0.010401321575045586, 0.11491420865058899, 0.11284363269805908, 0.10701882094144821, 0.010605954565107822, 0.010681950487196445, 0.010775122791528702, 0.010747833177447319, 0.010813947767019272, 0.01071087270975113, 0.11156295984983444, 0.010755826719105244, 0.010684613138437271, 0.010570150800049305, 0.01052540447562933, 0.11201214045286179, 0.01040459331125021, 0.12110374122858047, 0.1164371594786644, 0.10037081688642502, 0.01031348668038845, 0.010351546108722687, 0.11416149139404297, 0.010239851661026478, 0.2965816855430603, 0.10165296494960785, 0.34749776124954224, 0.010694295167922974, 0.09257244318723679, 0.010922442190349102, 0.01106623187661171, 0.011139113456010818, 0.01125632505863905, 0.10266365855932236, 0.09744103252887726, 0.10742446035146713, 0.09057864546775818, 0.011552629992365837, 0.011574465781450272, 0.01169885415583849, 0.011626145802438259, 0.011552433483302593, 0.01168606523424387, 0.12028969824314117, 0.011557558551430702, 0.011455394327640533, 0.10365402698516846, 0.011402358300983906, 0.31868645548820496, 0.11100078374147415, 0.011494702659547329, 0.12496238201856613, 0.11445175856351852, 0.011621426790952682, 0.10703038424253464, 0.011831887066364288, 0.10881054401397705, 0.011840766295790672, 0.011847336776554585, 0.11256260424852371, 0.09299731254577637, 0.011930921114981174, 0.09364422410726547, 0.011772919446229935, 0.011742138303816319, 0.10124076902866364, 0.011734344996511936, 0.011708586476743221, 0.011633847840130329, 0.011614975519478321, 0.09883235394954681, 0.011458112858235836, 0.011396956630051136, 0.10687689483165741, 0.011356428265571594, 0.011258892714977264, 0.11545423418283463, 0.132616326212883, 0.1022254005074501, 0.011108271777629852, 0.11866813153028488, 0.09984529763460159, 0.010971852578222752, 0.01101426500827074, 0.010936030186712742, 0.12638238072395325, 0.010883222334086895, 0.010841842740774155, 0.010775371454656124, 0.010697976686060429, 0.01064794510602951, 0.11353147774934769, 0.09316922724246979, 0.01045406423509121, 0.010448777116835117, 0.09522821009159088, 0.010320908389985561, 0.010378970764577389, 0.010389869101345539, 0.11759836971759796, 0.010106861591339111, 0.010083353146910667, 0.009961305186152458, 0.11459771543741226, 0.009866222739219666, 0.009814648889005184, 0.1169121116399765, 0.009736726991832256, 0.11777999252080917, 0.009622829034924507, 0.009653078392148018, 0.10753955692052841, 0.009518878534436226, 0.009466767311096191, 0.09750844538211823, 0.11300861835479736, 0.10746324807405472, 0.009356082417070866, 0.009308969601988792, 0.11728665232658386, 0.009251303970813751, 0.00927009992301464, 0.009340355172753334, 0.009180008433759212, 0.10067088156938553, 0.009157833643257618, 0.009133958257734776, 0.10442262887954712, 0.009021683596074581, 0.009067965671420097, 0.008923226036131382, 0.6651661396026611, 0.009023027494549751, 0.009180480614304543, 0.009262388572096825, 0.09459850937128067, 0.00947356317192316, 0.10067261755466461, 0.00955013744533062, 0.106291264295578, 0.009677414782345295, 0.009773789905011654, 0.30184391140937805, 0.009857354685664177, 0.2855929136276245, 0.10594236850738525, 0.010363437235355377, 0.010511783882975578, 0.10330803692340851, 0.10810419917106628, 0.10644177347421646, 0.010920170694589615, 0.11295555531978607, 0.11255290359258652, 0.10482937097549438, 0.011394391767680645, 0.011374020017683506, 0.011406256817281246, 0.011408085934817791, 0.011426117271184921, 0.0941644161939621, 0.011502359062433243, 0.011414933018386364, 0.011410217732191086, 0.2870403230190277, 0.09457611292600632, 0.011492734774947166, 0.09457337856292725, 0.011628749780356884, 0.09372768551111221, 0.011759699322283268, 0.10755836963653564, 0.09755587577819824, 0.011862101964652538, 0.10776246339082718, 0.11827901005744934, 0.01181867066770792, 0.011867150664329529, 0.011790950782597065, 0.011850297451019287, 0.011756058782339096, 0.10827777534723282, 0.011745914816856384, 0.011665462516248226, 0.09438015520572662, 0.11333467811346054, 0.1005203053355217, 0.011694067157804966, 0.11501602083444595, 0.011492457240819931, 0.011473321355879307, 0.11454785615205765, 0.011319217272102833, 0.011303489096462727, 0.10874283313751221, 0.011170448735356331, 0.3613484799861908, 0.011298537254333496, 0.0871676430106163, 0.011380723677575588, 0.011451764032244682, 0.011370518244802952, 0.09151849895715714, 0.10248259454965591, 0.011461214162409306, 0.011311748065054417, 0.5912268757820129, 0.011483565904200077, 0.011754580773413181, 0.1126912459731102, 0.09830034524202347, 0.10736922919750214, 0.29051336646080017, 0.012399525381624699, 0.012641235254704952, 0.5876258611679077, 0.013058587908744812, 0.013360848650336266, 0.013593578711152077, 0.013934407383203506, 0.11276426166296005, 0.014215315692126751, 0.1015724390745163, 0.1088666245341301, 0.014768934808671474, 0.09314244985580444, 0.014682467095553875, 0.01472463458776474, 0.01479958463460207, 0.01492548082023859, 0.12494997680187225, 0.1249949038028717, 0.09691935032606125, 0.12142151594161987, 0.01485022809356451, 0.014783870428800583, 0.10824574530124664, 0.01481255516409874, 0.014671817421913147, 0.014610475860536098, 0.014620881527662277, 0.014490567147731781, 0.01443969551473856, 0.014482170343399048, 0.014271756634116173, 0.10227027535438538, 0.014113858342170715, 0.014142614789307117, 0.013821356929838657, 0.013734589330852032, 0.013757580891251564, 0.01348812784999609, 0.013444933108985424, 0.013231211341917515, 0.013357923366129398, 0.013048681430518627, 0.10478533804416656, 0.012797337025403976, 0.012694263830780983, 0.10928291082382202, 0.01248161867260933, 0.012383990921080112, 0.2930049002170563, 0.09135857969522476, 0.012390382587909698, 0.012256023474037647, 0.012329106219112873, 0.012264793738722801, 0.012182282283902168, 0.012139732949435711, 0.012309234589338303, 0.011999045498669147, 0.012183250859379768, 0.011888671666383743, 0.011772475205361843, 0.011754818260669708, 0.01178587693721056, 0.011523902416229248, 0.011440868489444256, 0.0964522585272789, 0.0976853221654892, 0.28474923968315125, 0.011228443123400211, 0.011238454841077328, 0.011291144415736198, 0.011277475394308567, 0.011284471489489079, 0.011185554787516594, 0.011202095076441765, 0.1129002571105957, 0.3591739237308502, 0.01117406040430069, 0.10623987764120102, 0.011197133921086788, 0.011383170261979103, 0.12897513806819916, 0.01135118119418621, 0.011394690722227097, 0.31351056694984436, 0.09747149795293808, 0.2945781350135803, 0.09653171896934509, 0.011870614252984524, 0.09506383538246155, 0.012078692205250263, 0.012026523239910603, 0.012104092165827751, 0.012210092507302761, 0.012215893715620041, 0.10120079666376114, 0.012227406725287437, 0.1063830628991127, 0.11175437271595001, 0.09155140817165375, 0.01229150127619505, 0.012287994846701622, 0.11982464045286179, 0.10033077001571655, 0.012346473522484303, 0.012279631569981575, 0.01227307878434658, 0.012230103835463524, 0.012200651690363884, 0.10321791470050812, 0.01207138504832983, 0.012080819346010685, 0.09562887996435165, 0.012074070982635021, 0.011968334205448627, 0.011880556121468544, 0.011957695707678795, 0.09307075291872025, 0.011708307079970837, 0.01163469534367323, 0.011570884846150875, 0.011558891274034977, 0.011422153562307358, 0.30260661244392395, 0.10885395854711533, 0.011405544355511665, 0.29737550020217896, 0.09536934643983841, 0.011532237753272057, 0.11117492616176605, 0.011747203767299652, 0.011744076386094093, 0.011775272898375988, 0.011759043671190739, 0.011729845777153969, 0.10952755808830261, 0.011749282479286194, 0.011727086268365383, 0.011760232038795948, 0.011697500012814999, 0.09838169068098068, 0.011597219854593277, 0.10102339833974838, 0.011634529568254948, 0.011587638407945633, 0.011453487910330296, 0.011407624930143356, 0.10318497568368912, 0.011324875988066196, 0.011372200213372707, 0.011264880187809467, 0.12132163345813751, 0.2987295091152191, 0.336103230714798, 0.11092326045036316, 0.011381566524505615, 0.011484947055578232, 0.01171482540667057, 0.011535375379025936, 0.10647723823785782, 0.09944683313369751, 0.01171535812318325, 0.011665873229503632, 0.011662808246910572, 0.011723906733095646, 0.09215075522661209, 0.011649226769804955, 0.011660062707960606, 0.011788987554609776, 0.097345270216465, 0.011578086763620377, 0.011607508175075054, 0.01148274913430214, 0.011574545875191689, 0.011462979018688202, 0.011361801065504551, 0.011305318213999271, 0.011323542334139347, 0.10419777780771255, 0.11809780448675156, 0.011136423796415329, 0.29346176981925964, 0.011131291277706623, 0.011093026958405972, 0.2992347180843353, 0.10678738355636597, 0.1147439107298851, 0.0113370381295681, 0.011388278566300869, 0.01150798425078392, 0.09502231329679489, 0.011476135812699795, 0.011589312925934792, 0.011569879949092865, 0.011551197618246078, 0.011440633796155453, 0.011490349657833576, 0.011394398286938667, 0.01147338654845953, 0.12325192242860794, 0.09803571552038193, 0.11345677822828293, 0.011317768134176731, 0.09219851344823837, 0.011381497606635094, 0.011191201396286488, 0.011233200319111347, 0.011209902353584766, 0.011109715327620506, 0.011144268326461315, 0.011071756482124329, 0.01097997184842825, 0.011069432832300663, 0.09200941771268845, 0.010840645991265774, 0.010869136080145836, 0.010712857358157635, 0.01084379106760025, 0.010700632818043232, 0.010535508394241333, 0.11977235972881317, 0.010513858869671822, 0.01039103977382183, 0.10896804183721542, 0.010285708121955395, 0.09949426352977753, 0.010179507546126842, 0.11135783046483994, 0.09505496174097061, 0.010116873309016228, 0.01024636346846819, 0.10844803601503372, 0.12283824384212494, 0.01002309937030077, 0.010134750977158546, 0.01002204604446888, 0.00997223611921072, 0.010064186528325081, 0.11534201353788376, 0.009911674074828625, 0.009861231781542301, 0.11349274218082428, 0.31422126293182373, 0.009914903901517391, 0.009840468876063824, 0.009885958395898342, 0.009907083585858345, 0.00987614132463932, 0.11038841307163239, 0.01000427920371294, 0.00991186872124672, 0.009904194623231888, 0.11638156324625015, 0.009905521757900715, 0.00984157808125019, 0.0098426453769207, 0.09616586565971375, 0.009774480015039444, 0.009716330096125603, 0.11812393367290497, 0.00967913493514061, 0.009737429209053516, 0.009651368483901024, 0.12664587795734406, 0.009606984443962574, 0.11203673481941223, 0.009651070460677147, 0.09500935673713684, 0.009590019471943378, 0.009537898935377598, 0.09905819594860077, 0.1050703302025795, 0.10814480483531952, 0.6315531730651855, 0.00955822691321373, 0.00970072764903307, 0.09110324084758759, 0.9957261681556702, 0.08747808635234833, 0.10199832916259766, 0.010517002083361149, 0.10869640856981277, 0.6136025190353394, 0.011089537292718887, 0.011297707445919514, 0.10816793888807297, 0.011612451635301113, 0.011894527822732925, 0.10307081043720245, 0.012266435660421848, 0.012163561768829823, 0.10100503265857697, 0.0906699076294899, 0.29698318243026733, 0.012820200994610786, 0.012658136896789074, 0.11055188626050949, 0.012851770967245102, 0.012894097715616226, 0.013000048696994781, 0.013047653250396252, 0.013182048685848713, 0.11502406001091003, 0.09553604573011398, 0.013109403662383556, 0.013086071237921715, 0.10642305016517639, 0.10683334618806839, 0.10221108794212341, 0.13431432843208313, 0.10713658481836319, 0.013130680657923222, 0.09823740273714066, 0.013084574602544308, 0.013093765825033188, 0.013121137395501137, 0.10420062392950058, 0.09621870517730713, 0.01302403025329113, 0.10257284343242645, 0.012960493564605713, 0.11820610612630844, 0.09314819425344467, 0.01304034423083067, 0.01293695904314518, 0.11201687157154083, 0.013105606660246849, 0.12488387525081635, 0.01290627010166645, 0.1041208952665329, 0.01278326939791441, 0.012900631874799728, 0.01290213130414486, 0.012712436728179455, 0.01268107257783413, 0.012652792036533356, 0.10280932486057281, 0.10046752542257309, 0.012446911074221134, 0.10504916310310364, 0.01243465207517147, 0.10151216387748718, 0.012518609873950481, 0.012467154301702976, 0.012376785278320312, 0.012287217192351818, 0.10956733673810959, 0.012189519591629505, 0.10759049654006958, 0.0121821453794837, 0.09998402744531631, 0.012238300405442715, 0.1014443039894104, 0.01203107088804245, 0.2947939932346344, 0.012016749940812588, 0.012104850262403488, 0.012040798552334309, 0.012007646262645721, 0.11488812416791916, 0.011946803890168667, 0.012020273134112358, 0.09874488413333893, 0.011946205049753189, 0.3154216408729553, 0.11294285207986832, 0.011940116062760353, 0.11562217026948929, 0.01208276953548193, 0.1179613471031189, 0.08170820772647858, 0.012116972357034683, 0.10192663222551346, 0.09503038227558136, 0.12229089438915253, 0.10913579910993576, 0.01223266962915659, 0.012225954793393612, 0.01214334275573492, 0.012193047441542149, 0.012138139456510544, 0.012125508859753609, 0.012139396741986275, 0.01211538165807724, 0.012103290297091007, 0.103676937520504, 0.012069492600858212, 0.10884733498096466, 0.11835715919733047, 0.10051930695772171, 0.011864214204251766, 0.10583091527223587, 0.011942198500037193, 0.01187123917043209, 0.011856415309011936, 0.011759155429899693, 0.011813484132289886, 0.011901190504431725, 0.09978153556585312, 0.011624608188867569, 0.011621176265180111, 0.011628580279648304, 0.01158637460321188, 0.011476254090666771, 0.011596303433179855, 0.011386608704924583, 0.011348199099302292, 0.011331843212246895, 0.01127417478710413, 0.011258859187364578, 0.011426924727857113, 0.11921300739049911, 0.011090355925261974, 0.011114150285720825, 0.10605145245790482, 0.09885436296463013, 0.010990790091454983, 0.09913983941078186, 0.010898057371377945, 0.010894463397562504, 0.010847442783415318, 0.10363490134477615, 0.010764301754534245, 0.010774151422083378, 0.010737849399447441, 0.010736376978456974, 0.10750675201416016, 0.01068832166492939, 0.08758989721536636, 0.010602656751871109, 0.11939678341150284, 0.010536199435591698, 0.01055624708533287, 0.010525107383728027, 0.01051228679716587, 0.0105254165828228, 0.10344483703374863, 0.0103883296251297, 0.0998670682311058, 0.330404132604599, 0.010427211411297321, 0.01036912016570568, 0.11013483256101608, 0.01039604377001524, 0.10883689671754837, 0.01043578889220953, 0.11315452307462692, 0.010441858321428299, 0.09537065774202347, 0.01045376155525446, 0.010505127720534801, 0.0104825459420681, 0.010448414832353592, 0.08182111382484436, 0.010449165478348732, 0.32797232270240784, 0.010505191050469875, 0.010517792776226997, 0.09735366702079773, 0.010523023083806038, 0.010449925437569618, 0.010484169237315655, 0.12110577523708344, 0.010614462196826935, 0.010501936078071594, 0.010495657101273537, 0.010512558743357658, 0.31184065341949463, 0.010483325459063053, 0.010528498329222202, 0.11480145156383514, 0.010577335953712463, 0.010595785453915596, 0.10916085541248322, 0.010605585761368275, 0.010623135603964329, 0.1156022921204567, 0.010649297386407852, 0.010563423857092857, 0.010645384900271893, 0.0105014368891716, 0.010557187721133232, 0.10889533907175064, 0.010539577342569828, 0.32436850666999817, 0.09172772616147995, 0.1133892685174942, 0.01055553276091814, 0.10183791816234589, 0.010559963062405586, 0.010593324899673462, 0.09957369416952133, 0.010708599351346493, 0.010629458352923393, 0.010602239519357681, 0.3071398138999939, 0.09070039540529251, 0.010597635991871357, 0.0957428440451622, 0.010713577270507812, 0.010672119446098804, 0.1028977558016777, 0.01081169955432415, 0.12116263806819916, 0.010687736794352531, 0.010724821127951145, 0.10298281162977219, 0.010825431905686855, 0.010850346647202969, 0.1020592674612999, 0.09851090610027313, 0.11248088628053665, 0.010734255425632, 0.10635107010602951, 0.010685996152460575, 0.010825932025909424, 0.010775881819427013, 0.010709100402891636, 0.010696498677134514, 0.10863307863473892, 0.09873009473085403, 0.0985938310623169, 0.01069848332554102, 0.010725341737270355, 0.010636376217007637, 0.3076317608356476, 0.010616849176585674, 0.10130669176578522, 0.11014705896377563, 0.010759087279438972, 0.010740181431174278, 0.010723887011408806, 0.10777541995048523, 0.3077307641506195, 0.010760902427136898, 0.010801308788359165, 0.010750493966042995, 0.010783389210700989, 0.01077068131417036, 0.010800349526107311, 0.010777129791676998, 0.01086083147674799, 0.10525587201118469, 0.010790015570819378, 0.010807830840349197, 0.010785669088363647, 0.09597734361886978, 0.010810592211782932, 0.01077723503112793, 0.10686048120260239, 0.010717298835515976, 0.010715534910559654, 0.010705149732530117, 0.6387021541595459, 0.010763991624116898, 0.010787504725158215, 0.010881385765969753, 0.010792478919029236, 0.010845555923879147, 0.010830823332071304, 0.011022375896573067, 0.011044078506529331, 0.010874041356146336, 0.010815274901688099, 0.010942531749606133, 0.3052905201911926, 0.010890874080359936, 0.010881403461098671, 0.29825863242149353, 0.10774026066064835, 0.10925702005624771, 0.011024998500943184, 0.011053454130887985, 0.09397761523723602, 0.011124162003397942, 0.011066393926739693, 0.01104386243969202, 0.31000202894210815, 0.011077447794377804, 0.011139859445393085, 0.10464151948690414, 0.3030448853969574, 0.10723362118005753, 0.11441919952630997, 0.011278395541012287, 0.11326605081558228, 0.011322615668177605, 0.011386954225599766, 0.5672169923782349, 0.011445880867540836, 0.11237958818674088, 0.09510483592748642, 0.011540052480995655, 0.011577180586755276, 0.011641728691756725, 0.10617859661579132, 0.1102033481001854, 0.011717569082975388, 0.31462931632995605, 0.011801573447883129, 0.3306169807910919, 0.11497783660888672, 0.011965381912887096, 0.011947556398808956, 0.09737738221883774, 0.012188456952571869, 0.10866761952638626, 0.012061763554811478, 0.012122428975999355, 0.31387102603912354, 0.09785587340593338, 0.012231733649969101, 0.30528730154037476, 0.10701001435518265, 0.11366161704063416, 0.10419223457574844, 0.012369032949209213, 0.012389018200337887, 0.10689263045787811, 0.2970200181007385, 0.012514379806816578, 0.01246877945959568, 0.012565011158585548, 0.11741860955953598, 0.012544207274913788, 0.012576641514897346, 0.012737490236759186, 0.012740397825837135, 0.012654399499297142, 0.2669388949871063, 0.11904752999544144, 0.012709417380392551, 0.09626144170761108, 0.012692746706306934, 0.012714335694909096, 0.012711946852505207, 0.012686618603765965, 0.10799256712198257, 0.012879100628197193, 0.01267979945987463, 0.012673897668719292, 0.012663569301366806, 0.012675296515226364, 0.11443617194890976, 0.012607412412762642, 0.012671970762312412, 0.012831260450184345, 0.09521859884262085, 0.11135132610797882, 0.012579796835780144, 0.2970033884048462, 0.10207796841859818, 0.28760889172554016, 0.012646125629544258, 0.01264357753098011, 0.012661579065024853, 0.012631670571863651, 0.012628771364688873, 0.10078258067369461, 0.10463831573724747, 0.012659025378525257, 0.10325460880994797, 0.10205569118261337, 0.11603115499019623, 0.012660984881222248, 0.012904224917292595, 0.012720688246190548, 0.314773291349411, 0.012666672468185425, 0.012764915823936462, 0.012896585278213024, 0.09512356668710709, 0.012726297602057457, 0.012698890641331673, 0.012741358950734138, 0.12078139930963516, 0.012818367220461369, 0.012815535999834538, 0.01271104160696268, 0.012647449038922787, 0.012637809850275517, 0.012751479633152485, 0.01264229603111744, 0.012632513418793678, 0.1117190271615982, 0.12199863791465759, 0.10740569978952408, 0.10128694027662277, 0.012573103420436382, 0.09555395692586899, 0.012752365320920944, 0.10749776661396027, 0.1070786863565445, 0.012588100507855415, 0.012546515092253685, 0.012691094540059566, 0.0983913466334343, 0.2974778115749359, 0.012691083364188671, 0.012505453079938889, 0.0844348892569542, 0.01254059374332428, 0.10138924419879913, 0.012615479528903961, 0.11988473683595657, 0.012546905316412449, 0.0994904413819313, 0.012531166896224022, 0.012518384493887424, 0.10614567995071411, 0.012531528249382973, 0.012539750896394253, 0.012571343220770359, 0.01263258047401905, 0.012620658613741398, 0.01251463033258915, 0.28812021017074585, 0.012613506056368351, 0.012501560151576996, 0.10523881763219833, 0.09526022523641586, 0.012471548281610012, 0.012492557056248188, 0.012609004974365234, 0.012535279616713524, 0.09166720509529114, 0.012480014003813267, 0.012501812539994717, 0.012467175722122192, 0.012508939951658249, 0.012432906776666641, 0.012677332386374474, 0.012405899353325367, 0.1253986358642578, 0.012472627684473991, 0.012419238686561584, 0.11028970032930374, 0.012443749234080315, 0.3337850272655487, 0.3194179832935333, 0.0877644494175911, 0.012536237947642803, 0.01248046662658453, 0.2847130298614502, 0.012574426829814911, 0.012545580044388771, 0.012424992397427559, 0.012500429525971413, 0.012453828006982803, 0.3132515251636505, 0.09692326933145523, 0.012553589418530464, 0.28257107734680176, 0.012510973960161209, 0.01249762624502182, 0.012506850063800812, 0.012553763575851917, 0.012534872628748417, 0.0942876785993576, 0.012508752755820751, 0.10014820843935013, 0.1158873662352562, 0.012581842020154, 0.01253489125519991, 0.0954323336482048, 0.01258999202400446, 0.012591172009706497, 0.01269900519400835, 0.012540467083454132, 0.012570595368742943, 0.11623185873031616, 0.10561273247003555, 0.3104268014431, 0.11094681918621063, 0.012513813562691212, 0.012589304707944393, 0.012711510062217712, 0.012532473541796207, 0.2603996694087982, 0.01260768435895443, 0.0926942303776741, 0.012627852149307728, 0.012534994632005692, 0.012693129479885101, 0.012602238915860653, 0.11324714124202728, 0.2988151013851166, 0.1041291356086731, 0.01261570118367672, 0.012809719890356064, 0.012666311115026474, 0.11120275408029556, 0.012539468705654144, 0.10071319341659546, 0.2901383340358734, 0.10807906091213226, 0.012591615319252014, 0.012548660859465599, 0.012677233666181564, 0.012602756731212139, 0.10112770646810532, 0.01255277544260025, 0.012812118977308273, 0.012668006122112274, 0.012578909285366535, 0.01263265311717987, 0.01256545353680849, 0.012634935788810253, 0.012600456364452839, 0.012650708667933941, 0.012794438749551773, 0.012558693997561932]\n",
            "Val loss 0.06188882995405496\n",
            "Val auc roc 0.5397175965521288\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f56c5b4b-545d-446e-8c8e-66183f78debe"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "357c2392-bc11-45e1-f848-c50db680606f"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "437c1435-63d2-418e-e4de-ff1e629b5b9c"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "7923ecbb-7f8e-4f8c-d336-447f315eae5e"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Generalized_Hate]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ec32c9b8-06be-4aa3-b409-dac1a64be2f3"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-07-28 11:14:53.792686'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}