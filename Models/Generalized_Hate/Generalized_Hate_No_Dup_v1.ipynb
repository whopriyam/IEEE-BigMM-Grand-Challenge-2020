{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generalized_Hate_No_Dup_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a34db648a6a245d89dfc54f35badc2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e4b1d721778c4456891cc3b1afc871f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c7a9e30bfc646749a61ff6bfd9b80ae",
              "IPY_MODEL_2b64dcf971f14bb09f1c2a23a0778659"
            ]
          }
        },
        "e4b1d721778c4456891cc3b1afc871f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c7a9e30bfc646749a61ff6bfd9b80ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a219f4375b74abd9628acadd8710533",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_938f5dfefc454e56bbec1c7b97abecb2"
          }
        },
        "2b64dcf971f14bb09f1c2a23a0778659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43890549ae6b46c7903e109f09ead7ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:16&lt;00:00, 14.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0bc6c45a124457c9b6d1c6f6d3921cf"
          }
        },
        "1a219f4375b74abd9628acadd8710533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "938f5dfefc454e56bbec1c7b97abecb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43890549ae6b46c7903e109f09ead7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0bc6c45a124457c9b6d1c6f6d3921cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afccd9a360ca4cdeb2ddd3d710ed6e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10b4cfcc8e9d424fb8c219896891f292",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca130e06c77640f0995b090bdf21e479",
              "IPY_MODEL_5232a0f18b894f8dbd661c7f0c098b3e"
            ]
          }
        },
        "10b4cfcc8e9d424fb8c219896891f292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca130e06c77640f0995b090bdf21e479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c0d59aefa5f640f4aff36551565194f3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b89d36c4f8064f82a48e32cef7b2d862"
          }
        },
        "5232a0f18b894f8dbd661c7f0c098b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3bc6cc09bdd49a59a7a01237bbb4d72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [45:58&lt;00:00,  1.73s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53ef43bff4e44b7fb5330f74c23b1081"
          }
        },
        "c0d59aefa5f640f4aff36551565194f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b89d36c4f8064f82a48e32cef7b2d862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3bc6cc09bdd49a59a7a01237bbb4d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53ef43bff4e44b7fb5330f74c23b1081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c2cb18c70aa4d2689f9a74220eadfdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce3f87f2e37143eb8005b14bd2eeec25",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8713956c49fc4e4899a0fc6ff0803ef1",
              "IPY_MODEL_9916a296e07d4da3a52269c29edfab64"
            ]
          }
        },
        "ce3f87f2e37143eb8005b14bd2eeec25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8713956c49fc4e4899a0fc6ff0803ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e05d7f8895f84504bca3322dad444f9f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c16e067848c458b85c1f3ffaa5b05aa"
          }
        },
        "9916a296e07d4da3a52269c29edfab64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_12515122f33a4e45afd0d971d4f64545",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [14:50&lt;00:00,  1.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0c73d7bf744444c9e940d150be8d0de"
          }
        },
        "e05d7f8895f84504bca3322dad444f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c16e067848c458b85c1f3ffaa5b05aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12515122f33a4e45afd0d971d4f64545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0c73d7bf744444c9e940d150be8d0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5898783f2916410ab8f4ff4477bde873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6d16c3d3842463bb578f177ed0b08cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_233000771d18452f9b010a99a935e470",
              "IPY_MODEL_2e38255e6f994401a7ac7dcb77207184"
            ]
          }
        },
        "f6d16c3d3842463bb578f177ed0b08cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "233000771d18452f9b010a99a935e470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ec85afc97052470fb6370bddb0ac1af1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3eddc773ee85421a9aab8acf0cb06209"
          }
        },
        "2e38255e6f994401a7ac7dcb77207184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bbacf5739db4d7f852ba194aafae970",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [14:46&lt;00:00,  1.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c584496c53842bdb90c5c69f6e16c9f"
          }
        },
        "ec85afc97052470fb6370bddb0ac1af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3eddc773ee85421a9aab8acf0cb06209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bbacf5739db4d7f852ba194aafae970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c584496c53842bdb90c5c69f6e16c9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e608ae65-cf86-45e2-81af-8d2880243e6a"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 17.77 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec5d3a39-902f-4a7e-b910-a21acfb39557"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0f66e96-a34b-4941-c839-745d68b4f9e4"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "324d97cf-1f22-442c-8081-6385961be378"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "430b009d-3fad-41bb-b2a9-6dfb6512a092"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "6435b6fa-6c89-4a63-ba64-e908299d55dd"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "de7431d0-91aa-49b3-9de2-fd3255a7bdde"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ecfdbac2-6d51-4161-e520-776e5e284965"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "4937d5f7-2c33-4888-9cc2-9e946d620530"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2ede4764-60a8-46f6-86e8-a085336c44ed"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                        ption - no:2 \n",
              "1    I am blessed and thankful despite all the trau...\n",
              "2    What irks me is the number of people supportin...\n",
              "3                    good #metoo save girl and women  \n",
              "4    So respecting ladies is in blood of @INCIndia ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "011c97b6-2f0b-4bc4-dcc5-091dbdbd6210"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:13<00:00, 30247756.38B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60ffbc0a-d0f7-420e-ddf9-49e18119119e"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 897557.89B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "8b1c3be4-d52d-4881-8ae4-594d9b190890"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7206a05e-03b5-4f4d-fc3d-942492ae8e01"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        \n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        \n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d78e1d9-ad53-4287-b8a3-74888a98b912"
      },
      "source": [
        "col_name = \"Generalized_Hate\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760,
          "referenced_widgets": [
            "a34db648a6a245d89dfc54f35badc2d7",
            "e4b1d721778c4456891cc3b1afc871f5",
            "0c7a9e30bfc646749a61ff6bfd9b80ae",
            "2b64dcf971f14bb09f1c2a23a0778659",
            "1a219f4375b74abd9628acadd8710533",
            "938f5dfefc454e56bbec1c7b97abecb2",
            "43890549ae6b46c7903e109f09ead7ae",
            "b0bc6c45a124457c9b6d1c6f6d3921cf",
            "afccd9a360ca4cdeb2ddd3d710ed6e23",
            "10b4cfcc8e9d424fb8c219896891f292",
            "ca130e06c77640f0995b090bdf21e479",
            "5232a0f18b894f8dbd661c7f0c098b3e",
            "c0d59aefa5f640f4aff36551565194f3",
            "b89d36c4f8064f82a48e32cef7b2d862",
            "b3bc6cc09bdd49a59a7a01237bbb4d72",
            "53ef43bff4e44b7fb5330f74c23b1081",
            "8c2cb18c70aa4d2689f9a74220eadfdf",
            "ce3f87f2e37143eb8005b14bd2eeec25",
            "8713956c49fc4e4899a0fc6ff0803ef1",
            "9916a296e07d4da3a52269c29edfab64",
            "e05d7f8895f84504bca3322dad444f9f",
            "4c16e067848c458b85c1f3ffaa5b05aa",
            "12515122f33a4e45afd0d971d4f64545",
            "d0c73d7bf744444c9e940d150be8d0de",
            "5898783f2916410ab8f4ff4477bde873",
            "f6d16c3d3842463bb578f177ed0b08cc",
            "233000771d18452f9b010a99a935e470",
            "2e38255e6f994401a7ac7dcb77207184",
            "ec85afc97052470fb6370bddb0ac1af1",
            "3eddc773ee85421a9aab8acf0cb06209",
            "7bbacf5739db4d7f852ba194aafae970",
            "8c584496c53842bdb90c5c69f6e16c9f"
          ]
        },
        "outputId": "3d5b0e82-1206-4353-9c55-2ed31e6c0c04"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6382\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a34db648a6a245d89dfc54f35badc2d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afccd9a360ca4cdeb2ddd3d710ed6e23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0256\n",
            "Train Losses : [0.17120198905467987, 0.2650688886642456, 1.1951639652252197, 1.0490105152130127, 1.9972823858261108, 0.697160005569458, 0.8598031401634216, 0.10595322400331497, 0.12536734342575073, 0.36074739694595337, 0.4346578121185303, 0.2286132276058197, 0.4096285104751587, 1.3237942457199097, 0.22196482121944427, 0.07698658108711243, 0.05819404870271683, 0.11710261553525925, 0.046442270278930664, 0.03572043031454086, 0.04315657913684845, 0.025576964020729065, 0.026841096580028534, 0.057716455310583115, 0.025128085166215897, 0.034589216113090515, 0.13621337711811066, 0.13460278511047363, 0.00783828180283308, 0.0046683712862432, 0.005741453263908625, 0.0025902693159878254, 0.007611775770783424, 0.09399440884590149, 0.0020735003054142, 0.0036996942944824696, 0.0021429769694805145, 0.0010382782202214003, 0.003244772320613265, 0.0006822937284596264, 0.0005353202577680349, 0.004039898980408907, 0.000556762155611068, 0.0023839869536459446, 0.0014266162179410458, 0.00030841169063933194, 0.002543640322983265, 0.001998116262257099, 0.0010751493973657489, 0.0012323169503360987, 0.00044847646495327353, 0.0015902388840913773, 0.0004427586100064218, 0.00019213823543395847, 0.0001706118491711095, 0.00028836476849392056, 0.0002891487965825945, 0.00045036606024950743, 0.00015757422079332173, 0.00018171980627812445, 0.0019680499099195004, 0.00027107703499495983, 0.0004916550824418664, 0.000333380710799247, 0.23151297867298126, 0.0001952043967321515, 0.42534077167510986, 0.00029584363801404834, 0.000582561653573066, 0.0004167167062405497, 0.00042680336628109217, 0.0005876460927538574, 0.0011379467323422432, 0.0011800864012911916, 0.0014590667560696602, 0.0007574515184387565, 0.002402178943157196, 0.0005848815198987722, 0.0012632388388738036, 0.0011933364439755678, 0.0020060359966009855, 0.13607127964496613, 0.006319505162537098, 0.002337022451683879, 0.0007475537713617086, 0.0005085660377517343, 0.0010769478976726532, 0.4877112805843353, 0.000674720446113497, 0.0012099946616217494, 0.0007919542258605361, 0.0013724664459004998, 0.0019087016116827726, 0.008659113198518753, 0.027852389961481094, 0.00495311850681901, 0.0026905895210802555, 0.0037382931914180517, 0.004730186890810728, 0.0016219507670029998, 0.0012673968449234962, 0.7118145823478699, 0.0038752832915633917, 0.001013618428260088, 0.002089413348585367, 0.00179496209602803, 0.0010759708238765597, 0.0009383440483361483, 0.0013809079537168145, 0.001110593555495143, 0.0009734333143569529, 0.0018833770882338285, 0.00079881283454597, 0.0009517192956991494, 0.19713957607746124, 0.0014129049377515912, 0.0013691589701920748, 0.0013694498920813203, 0.0010594389168545604, 0.003073072759434581, 0.0010899074841290712, 0.4383842349052429, 0.001500049140304327, 0.0013727187179028988, 0.0014327585231512785, 0.002971357200294733, 0.0017964680446311831, 0.001729099196381867, 0.001888191676698625, 0.11641800403594971, 0.0013524525566026568, 0.21903739869594574, 0.002160805044695735, 0.0018148957751691341, 0.0019052770221605897, 0.0019559573847800493, 0.0023499291855841875, 0.003402051283046603, 0.002999942982569337, 0.23200437426567078, 0.0021003219299018383, 0.002469743136316538, 0.1249493733048439, 0.002180443610996008, 0.0026878896169364452, 0.0024731995072215796, 0.0024721312802284956, 0.0029603540897369385, 0.06945313513278961, 0.003053541760891676, 0.002957891207188368, 0.002762105781584978, 0.004700543824583292, 0.004096456803381443, 0.0035897146444767714, 0.003577245632186532, 0.005956654902547598, 0.22711819410324097, 0.0055851261131465435, 0.0031396823469549417, 0.003111250000074506, 0.0030612684786319733, 0.0025596553459763527, 0.0035732409451156855, 0.0038746348582208157, 0.002965551568195224, 0.003817654214799404, 0.0030938952695578337, 0.0032761760521680117, 0.003028025384992361, 0.0028443571645766497, 0.003236097050830722, 0.0028919437900185585, 0.0031438402365893126, 0.002087065950036049, 0.0019816735293716192, 0.002392528345808387, 0.0014470736496150494, 0.0018322245450690389, 0.001431718934327364, 0.0023436504416167736, 0.003478047903627157, 0.0020237865392118692, 0.0012435578973963857, 0.0020372052676975727, 0.002576243132352829, 0.0012128350790590048, 0.0011508942116051912, 0.0013696656096726656, 0.0009294552728533745, 0.0009628001716919243, 0.0012559599708765745, 0.0009193252772092819, 0.0007571543101221323, 0.0007820983300916851, 0.0007877573370933533, 0.0006941093597561121, 0.0013122600503265858, 0.0011308994144201279, 0.16104215383529663, 0.0007873604772612453, 0.0009356368100270629, 0.0849689468741417, 0.0011947480961680412, 0.0011182008311152458, 0.0010558358626440167, 0.0009974183049052954, 0.0016851231921464205, 0.0013759369030594826, 0.0011634841794148088, 0.001121010398492217, 0.0012458503479138017, 0.0018656115280464292, 0.0010580661473795772, 0.0027849189937114716, 0.0034232656471431255, 0.0016845291247591376, 0.0025678507518023252, 0.004195154644548893, 0.2676861882209778, 0.0013001601910218596, 0.003244988387450576, 0.0016055804444476962, 0.0018056200351566076, 0.002689566696062684, 0.0011650357628241181, 0.0014626968186348677, 0.0013191421749070287, 0.6704440712928772, 0.001824146369472146, 0.0033339206129312515, 0.0020764300134032965, 0.0015824149595573545, 0.0020399056375026703, 0.0015954967821016908, 0.004830437712371349, 0.004769821651279926, 0.001921220333315432, 0.002716868417337537, 0.0027509606443345547, 0.004384377971291542, 0.0026152629870921373, 0.0021507295314222574, 0.0021810668986290693, 0.0017666330095380545, 0.002211227547377348, 0.002131939399987459, 0.0019577783532440662, 0.0029953543562442064, 0.0026992391794919968, 0.0027227329555898905, 0.0016104384558275342, 0.0028851234819740057, 0.0019643655978143215, 0.0027770991437137127, 0.002561995992437005, 0.0016339058056473732, 0.0023773997090756893, 0.0027496174443513155, 0.0014421932864934206, 0.0013016118900850415, 0.06482642889022827, 0.0014108920004218817, 0.0014511856716126204, 0.001119367778301239, 0.0013570134760811925, 0.0028045722283422947, 1.0363117456436157, 0.001459954772144556, 0.0026345287915319204, 0.002822786569595337, 0.0023855064064264297, 0.0021174990106374025, 0.0019239928806200624, 0.0021353999618440866, 0.04818245396018028, 0.0026625676546245813, 0.0034988042898476124, 0.0037929636891931295, 0.00294408667832613, 0.0028961205389350653, 0.00307599944062531, 0.002398482756689191, 0.13337497413158417, 0.005117245949804783, 0.003244213992729783, 0.004478934220969677, 0.1919078230857849, 0.0031269541941583157, 0.0026485223788768053, 0.004110629204660654, 0.003480250248685479, 0.1370251327753067, 0.0031644515693187714, 0.0033380507957190275, 0.0037123600486665964, 0.0035405138041824102, 0.004714536480605602, 0.217269167304039, 0.14771731197834015, 0.0033367439173161983, 0.004030190873891115, 0.005400505848228931, 0.0037981844507157803, 0.005177274812012911, 0.0038672725204378366, 0.004687889479100704, 0.09958822280168533, 0.005245081149041653, 0.2553403079509735, 0.0037340957205742598, 0.005232588853687048, 0.004246327094733715, 0.0053590647876262665, 0.0050163110718131065, 0.004382716026157141, 0.004378336016088724, 0.004308863077312708, 0.003640136681497097, 0.0037011585664004087, 0.0047221435233950615, 0.004005396738648415, 0.003848875407129526, 0.0033116028644144535, 0.0037809398490935564, 0.003013316774740815, 0.003836951218545437, 0.0032094037160277367, 0.0029026195406913757, 0.0029653210658580065, 0.002572576981037855, 0.0026699474547058344, 0.0031144300010055304, 0.002169568557292223, 0.0021076519042253494, 0.0021674802992492914, 0.002283966401591897, 0.001985405571758747, 0.002091784030199051, 0.10365235060453415, 0.2085244059562683, 0.0018881014548242092, 0.0019580861553549767, 0.002372174523770809, 0.0026852800510823727, 0.001997876912355423, 0.002738772891461849, 0.00222565745934844, 0.002757831010967493, 0.002890905598178506, 0.0029026842676103115, 0.0025359056890010834, 0.16696029901504517, 0.002936580451205373, 0.0028810615185648203, 0.0022768755443394184, 0.002552091609686613, 0.10667946934700012, 0.0021624849177896976, 0.0024709838908165693, 0.0023236414417624474, 0.0023046608548611403, 0.23528045415878296, 0.002596083329990506, 0.0026584635488688946, 0.002731801476329565, 0.0029175987001508474, 0.003191954456269741, 0.0027611292898654938, 0.0029588520992547274, 0.0028740440029650927, 0.0029423136729747057, 0.002763967029750347, 0.0029806236270815134, 0.0028976311441510916, 0.0027596985455602407, 0.002816104795783758, 0.003224434796720743, 0.0028035230934619904, 0.0029463726095855236, 0.002625851659104228, 0.002795021515339613, 0.00219419552013278, 0.002472471911460161, 0.0029396284371614456, 0.1642105132341385, 0.0021523686591535807, 0.0026736620347946882, 0.002249417593702674, 0.0021078716963529587, 0.002271314151585102, 0.002320671919733286, 0.0019668876193463802, 0.002392940456047654, 0.0019056991441175342, 0.0022232390474528074, 0.0023321204353123903, 0.0019930307753384113, 0.1661117672920227, 0.001838971977122128, 0.0018595593282952905, 0.0019726702012121677, 0.17395302653312683, 0.0019378913566470146, 0.12923739850521088, 0.0020984294824302197, 0.15653403103351593, 0.002401607343927026, 0.002450057305395603, 0.002826579613611102, 0.002827061340212822, 0.0033734627068042755, 0.003063110401853919, 0.0030395230278372765, 0.003178562503308058, 0.20240382850170135, 0.0033502220176160336, 0.0033768408466130495, 0.11670655012130737, 0.0035778237506747246, 0.003845884930342436, 0.003847518004477024, 0.004096767399460077, 0.003933181520551443, 0.1553979367017746, 0.0038821131456643343, 0.004085714928805828, 0.003967639058828354, 0.004075720440596342, 0.004495604895055294, 0.004044337198138237, 0.004170841537415981, 0.004638605751097202, 0.0038076501805335283, 0.0037475537974387407, 0.0036289640702307224, 0.003614170476794243, 0.1348920464515686, 0.0034437780268490314, 0.1474040299654007, 0.0038297728169709444, 0.0034866160713136196, 0.003607876366004348, 0.0034166760742664337, 0.0034210465382784605, 0.0035128104500472546, 0.0033287156838923693, 0.0033890188205987215, 0.0032480494119226933, 0.0032499555964022875, 0.0033579329028725624, 0.0029887075070291758, 0.12617632746696472, 0.003231229493394494, 0.003120285691693425, 0.0031697996892035007, 0.003372875740751624, 0.0031057989690452814, 0.0028504200745373964, 0.0027922990266233683, 0.0028359554708003998, 0.002699915785342455, 0.0027490665670484304, 0.0031443177722394466, 0.002804161747917533, 0.10348640382289886, 0.00269212550483644, 0.0027127587236464024, 0.0028042742051184177, 0.0025254564825445414, 0.0025184752885252237, 0.08080779761075974, 0.0028027226217091084, 0.002764434088021517, 0.002825087634846568, 0.002572988858446479, 0.0025931987911462784, 0.1759224683046341, 0.0025667131412774324, 0.002893180353567004, 0.003474026219919324, 0.14998787641525269, 0.002722739242017269, 0.002868020674213767, 0.003357036504894495, 0.0028892296832054853, 0.0030843212734907866, 0.0032879088539630175, 0.003502729581668973, 0.0030084787867963314, 0.0031049407552927732, 0.0031093843281269073, 0.003202771535143256, 0.0027514242101460695, 0.0030388259328901768, 0.002955188974738121, 0.0030745489057153463, 0.0028173024766147137, 0.0027150611858814955, 0.002574208891019225, 0.002445230260491371, 0.08120738714933395, 0.002602493390440941, 0.0023774406872689724, 0.002577036852017045, 0.0843217670917511, 0.002496499801054597, 0.0027618096210062504, 0.0026476874481886625, 0.0030291315633803606, 0.0031172018498182297, 0.0026476955972611904, 0.0025101792998611927, 0.0023772066924721003, 0.12650489807128906, 0.002504258882254362, 0.0023765582591295242, 0.0027626720257103443, 0.0027786146383732557, 0.0027748928405344486, 0.09874632209539413, 0.0023950100876390934, 0.002730833599343896, 0.00257057580165565, 0.09623979777097702, 0.0028162116650491953, 0.0027007756289094687, 0.0026519163511693478, 0.15384575724601746, 0.0031816838309168816, 0.003285567043349147, 0.003032128093764186, 0.004425563383847475, 0.003243854967877269, 0.003443753346800804, 0.003629539627581835, 0.004001503810286522, 0.003971069119870663, 0.0046168300323188305, 0.0037501549813896418, 0.003598320297896862, 0.0028651882894337177, 0.002728013787418604, 0.09040594100952148, 0.0031150439754128456, 0.00274947308935225, 0.002646089531481266, 0.003446586662903428, 0.0028423427138477564, 0.002703346312046051, 0.0026119397953152657, 0.0030705733224749565, 0.0027176139410585165, 0.0035772579722106457, 0.004051323048770428, 0.0028371661901474, 0.002340839244425297, 0.0033037890680134296, 0.0023371996358036995, 0.0020640587899833918, 0.002379687037318945, 0.002561607863754034, 0.0019099629716947675, 0.13156723976135254, 0.0021094640251249075, 0.002016604645177722, 0.0021239507477730513, 0.19116097688674927, 0.0020876044873148203, 0.1264818012714386, 0.0025085252709686756, 0.0032326921354979277, 0.0030006328597664833, 0.003466939087957144, 0.002689892193302512, 0.002519000321626663, 0.0025299175176769495, 0.12601102888584137, 0.0026897492352873087, 0.0028103336226195097, 0.25698864459991455, 0.00292904581874609, 0.003727882169187069, 0.0033059644047170877, 0.003375317668542266, 0.003531352151185274, 0.0031666194554418325, 0.0036038048565387726, 0.0033117246348410845, 0.0043420009315013885, 0.003168753581121564, 0.0032812415156513453, 0.0034315609373152256, 0.0030154085252434015, 0.18031993508338928, 0.003092625178396702, 0.003384751733392477, 0.0029411546420305967, 0.0031634769402444363, 0.00322984647937119, 0.09862353652715683, 0.09294066578149796, 0.003061687806621194, 0.0031829264480620623, 0.0032109632156789303, 0.0030959502328187227, 0.0031848065555095673, 0.0034242761321365833, 0.0038468725979328156, 0.00328385503962636, 0.0031051530968397856, 0.003130944212898612, 0.0031259115785360336, 0.0036826133728027344, 0.0029225260950624943, 0.180171936750412, 0.003008726518601179, 0.0034491352271288633, 0.0028426831122487783, 0.0029897033236920834, 0.16254284977912903, 0.0028363901656121016, 0.0031001525931060314, 0.00342563446611166, 0.0032702540047466755, 0.002990484004840255, 0.002976946532726288, 0.0029801123309880495, 0.003316552145406604, 0.12841583788394928, 0.002919216640293598, 0.0036667778622359037, 0.003069475060328841, 0.0032194594386965036, 0.0029376810416579247, 0.003205936634913087, 0.0032399531919509172, 0.003315126523375511, 0.002887181006371975, 0.00270627299323678, 0.0025812454987317324, 0.0025981443468481302, 0.002745042322203517, 0.0035732316318899393, 0.0026683765463531017, 0.0028597943019121885, 0.0025805498007684946, 0.0022385846823453903, 0.0021447264589369297, 0.002437971066683531, 0.002000997541472316, 0.0023634752724319696, 0.002132904250174761, 0.0026331921108067036, 0.0018019259441643953, 0.002106193220242858, 0.0020102348644286394, 0.0015945956110954285, 0.0017386284889653325, 0.001544451923109591, 0.001679895562119782, 0.001435047946870327, 0.0014779168413951993, 0.0016712327487766743, 0.0013349346118047833, 0.001389833865687251, 0.001698853331618011, 0.1449194699525833, 0.0013774040853604674, 0.0014822330558672547, 0.0012739268131554127, 0.001298529445193708, 0.0012969757663086057, 0.0012630585115402937, 0.1666930615901947, 0.0013928946573287249, 0.0013842700282111764, 0.0015112698310986161, 0.1240549087524414, 0.0015335484640672803, 0.0017461422830820084, 0.17024628818035126, 0.0018123083282262087, 0.0019225955475121737, 0.0021561880130320787, 0.0024550985544919968, 0.002554940991103649, 0.15221990644931793, 0.0027732159942388535, 0.0026940128300338984, 0.002675591967999935, 0.0027981733437627554, 0.003201645566150546, 0.003149487776681781, 0.0028870857786387205, 0.002877076854929328, 0.003448683535680175, 0.0030224297661334276, 0.0032763686031103134, 0.0030638808384537697, 0.0028757103718817234, 0.003358609275892377, 0.08823737502098083, 0.0029035264160484076, 0.0029091844335198402, 0.0030181666370481253, 0.0029748626984655857, 0.003614668734371662, 0.0031578484922647476, 0.002958042314276099, 0.0029589419718831778, 0.19466689229011536, 0.0027812861371785402, 0.0030421242117881775, 0.00264377542771399, 0.002817066852003336, 0.002797971246764064, 0.0030303813982754946, 0.0032637373078614473, 0.09875837713479996, 0.0026190325152128935, 0.002818961162120104, 0.002789579564705491, 0.0026525368448346853, 0.0030376925133168697, 0.0029187987092882395, 0.0026559079997241497, 0.003001537173986435, 0.10191775113344193, 0.0028105780947953463, 0.003072172636166215, 0.0027770129963755608, 0.002676482545211911, 0.002619602018967271, 0.002988344058394432, 0.0032783690840005875, 0.0025706321466714144, 0.002673149574548006, 0.0028945663943886757, 0.002544755581766367, 0.17670510709285736, 0.0026868542190641165, 0.0028362649027258158, 0.0026893133763223886, 0.00279465620405972, 0.002498592948541045, 0.00315347732976079, 0.1451805830001831, 0.002792482264339924, 0.0025352013763040304, 0.0029508937150239944, 0.0025158782955259085, 0.002581316977739334, 0.10327852517366409, 0.002525812014937401, 0.0026590144261717796, 0.0025782613083720207, 0.0028055747970938683, 0.003355310996994376, 0.0028884506318718195, 0.0029352575074881315, 0.0035580855328589678, 0.002598024904727936, 0.0027881197165697813, 0.002625684719532728, 0.09629099816083908, 0.0030216826125979424, 0.0027946261689066887, 0.002719055861234665, 0.1655527651309967, 0.002879606792703271, 0.002760980511084199, 0.002796935150399804, 0.0026892481837421656, 0.0029363830108195543, 0.0027944957837462425, 0.0029539219103753567, 0.002767462283372879, 0.0029350381810218096, 0.00288194022141397, 0.002726459875702858, 0.002711918205022812, 0.0025307380128651857, 0.002772953826934099, 0.0025430817622691393, 0.0024091575760394335, 0.0025066935922950506, 0.0024554634001106024, 0.002609721850603819, 0.002173545304685831, 0.0025726971216499805, 0.1319918930530548, 0.002135907532647252, 0.0024233749136328697, 0.00205653696320951, 0.002085252432152629, 0.13884477317333221, 0.0024529520887881517, 0.0023640887811779976, 0.00212641223333776, 0.002230525016784668, 0.4002724885940552, 0.0025088805705308914, 0.002895084908232093, 0.0033553210087120533, 0.0037422962486743927, 0.0036571265663951635, 0.003593794070184231, 0.0037603690288960934, 0.003873971989378333, 0.00383328297175467, 0.004751492291688919, 0.21983425319194794, 0.0047013177536427975, 0.1428103893995285, 0.004329481162130833, 0.0045091318897902966, 0.005951397120952606, 0.004822429735213518, 0.004888291470706463, 0.00543519901111722, 0.004850801080465317, 0.004929217975586653, 0.00471047917380929, 0.004738442599773407, 0.00433048140257597, 0.004299821797758341, 0.004092041868716478, 0.004120826721191406, 0.0043363724835217, 0.06923926621675491, 0.0036310511641204357, 0.003932757768779993, 0.003625362180173397, 0.0036618472076952457, 0.0036575293634086847, 0.003650209167972207, 0.003272942965850234, 0.003181925043463707, 0.0036011002957820892, 0.003020942211151123, 0.0032385678496211767, 0.003102091606706381, 0.0030824465211480856, 0.002703058533370495, 0.002492703963071108, 0.0024367060977965593, 0.0022736384999006987, 0.002222948707640171, 0.002403009682893753, 0.0021297712810337543, 0.002196291461586952, 0.0020456486381590366, 0.002165571553632617, 0.0019141037482768297, 0.0026274342089891434, 0.002528143348172307, 0.0017851676093414426, 0.0016177109209820628, 0.19115762412548065, 0.0016719945706427097, 0.0018996824510395527, 0.0016707971226423979, 0.001619904418475926, 0.0016775442054495215, 0.001594951143488288, 0.0016309545608237386, 0.0018007653998211026, 0.0015972647815942764, 0.001570998108945787, 0.001657004002481699, 0.16420792043209076, 0.0017578719416633248, 0.12981241941452026, 0.0016630982281640172, 0.0018034594831988215, 0.001886124606244266, 0.001886669546365738, 0.19225282967090607, 0.0021570087410509586, 0.0021808622404932976, 0.002235247055068612, 0.002668358152732253, 0.0023908347357064486, 0.002820266643539071, 0.002503747120499611, 0.002557453466579318, 0.002382719423621893, 0.0027759061194956303, 0.0023958932142704725, 0.0023930338211357594, 0.17425408959388733, 0.10651011765003204, 0.0026313080452382565, 0.0025701418053358793, 0.0027057190891355276, 0.0027747827116400003, 0.00321423658169806, 0.2010331153869629, 0.003331295447424054, 0.003016794566065073, 0.0031801199074834585, 0.0032804671209305525, 0.00322544714435935, 0.0034481920301914215, 0.003260459052398801, 0.0036102489102631807, 0.0032810240518301725, 0.003402523696422577, 0.0031586976256221533, 0.00320259528234601, 0.0030283911619335413, 0.003098803572356701, 0.0031742474529892206, 0.0030245636589825153, 0.0028830640949308872, 0.0028052390553057194, 0.0027635120786726475, 0.0025908153038471937, 0.0027025986928492785, 0.0024640136398375034, 0.002479841932654381, 0.0024841376580297947, 0.0024595174472779036, 0.002188106533139944, 0.0025447169318795204, 0.002173300366848707, 0.002334345132112503, 0.0019659490790218115, 0.0021362488623708487, 0.0018994526471942663, 0.0018785543506965041, 0.001885540783405304, 0.0017444423865526915, 0.001658334513194859, 0.0017701337346807122, 0.001581856282427907, 0.0016094209859147668, 0.0014913954073563218, 0.0014567967737093568, 0.0014911001781001687, 0.001401298912242055, 0.0014707391383126378, 0.14590078592300415, 0.17320437729358673, 0.0014336162712424994, 0.0015707938000559807, 0.0015914172399789095, 0.0019832798279821873, 0.22691422700881958, 0.0018038194393739104, 0.0018800165271386504, 0.0019910847768187523, 0.002001448068767786, 0.002049968345090747, 0.0022467314265668392, 0.002259025350213051, 0.002272009616717696, 0.09918171912431717, 0.002545739058405161, 0.002437528222799301, 0.1292366087436676, 0.11568626761436462, 0.002700400771573186, 0.0029008241835981607, 0.003021655138581991, 0.003215074073523283, 0.0032147325109690428, 0.0032502985559403896, 0.003342048730701208, 0.003395339008420706, 0.1291794627904892, 0.0034687905572354794, 0.0035656336694955826, 0.0036460740957409143, 0.0036585440393537283, 0.0038429240230470896, 0.0038282861933112144, 0.0039211539551615715, 0.0040285359136760235, 0.11533326655626297, 0.003840733552351594, 0.003774703945964575, 0.0037805575411766768, 0.003683860646560788, 0.0037360975984483957, 0.11376558989286423, 0.0036731816362589598, 0.003644231939688325, 0.003971515689045191, 0.0036832524929195642, 0.0037295406218618155, 0.003956369590014219, 0.003670718055218458, 0.07562986016273499, 0.003475310280919075, 0.0035583616700023413, 0.0039130887016654015, 0.003614007728174329, 0.003430173499509692, 0.11116661876440048, 0.0032496126368641853, 0.003267239313572645, 0.003709215670824051, 0.0032679045107215643, 0.0033895729575306177, 0.003120651002973318, 0.0030755603220313787, 0.003280783072113991, 0.0031218347139656544, 0.002957705408334732, 0.002964152954518795, 0.002967630513012409, 0.11118154972791672, 0.002770219696685672, 0.0027534111868590117, 0.002901631873100996, 0.0029443735256791115, 0.0027867762837558985, 0.0027790602762252092, 0.0025470799300819635, 0.0025827218778431416, 0.0025570013094693422, 0.0024897889234125614, 0.0024799704551696777, 0.0023976401425898075, 0.002373872324824333, 0.002381305443122983, 0.0021928325295448303, 0.0021233754232525826, 0.00217975745908916, 0.0022349373903125525, 0.0020615740213543177, 0.0021314772311598063, 0.001978072104975581, 0.001971622696146369, 0.12908178567886353, 0.0021292755845934153, 0.0019133982714265585, 0.0018664291128516197, 0.0022119497880339622, 0.001852619694545865, 0.0018510683439671993, 0.0018891871441155672, 0.0019255480729043484, 0.001841577934101224, 0.001836347859352827, 0.18184615671634674, 0.001905352808535099, 0.0019647404551506042, 0.1237480565905571, 0.001950772712007165, 0.00261952867731452, 0.002550192642956972, 0.0022313790395855904, 0.002521177753806114, 0.002352108946070075, 0.0021913230884820223, 0.0023464029654860497, 0.002507260302081704, 0.0024140363093465567, 0.0028548347763717175, 0.0023009381256997585, 0.0022736520040780306, 0.002165453042834997, 0.10616269707679749, 0.002244354458525777, 0.0024550254456698895, 0.0024095717817544937, 0.002248282777145505, 0.0024815620854496956, 0.0023111156187951565, 0.0021709955763071775, 0.0026871527079492807, 0.00247972272336483, 0.002218407578766346, 0.0028346183244138956, 0.0020498891826719046, 0.002025534166023135, 0.002129452535882592, 0.0021935938857495785, 0.0022785624023526907, 0.0019099889323115349, 0.0021304739639163017, 0.001923692412674427, 0.0018251913134008646, 0.0019481766503304243, 0.0018964895280078053, 0.0018956199055537581, 0.0016233751084655523, 0.0017824842361733317, 0.001691514509730041, 0.0015160302864387631, 0.0014595385873690248, 0.0015798417152836919, 0.0015252107987180352, 0.001359901623800397, 0.0013898889301344752, 0.17459847033023834, 0.0016104448586702347, 0.0016188864829018712, 0.0015553199918940663, 0.001388242468237877, 0.0014681867323815823, 0.20167839527130127, 0.0016005630604922771, 0.0016055275918915868, 0.0016620563110336661, 0.001648559351451695, 0.0016515960451215506, 0.10350494831800461, 0.00183780281804502, 0.0019129407592117786, 0.0020745405927300453, 0.002231271006166935, 0.0020139121916145086, 0.0021147511433809996, 0.002089782850816846, 0.0020332743879407644, 0.0020752372220158577, 0.0026567981112748384, 0.002036212245002389, 0.0023671879898756742, 0.001992429606616497, 0.0022636204957962036, 0.22928686439990997, 0.002026892499998212, 0.00219343276694417, 0.0021406151354312897, 0.0020727578084915876, 0.0021865551825612783, 0.0021368160378187895, 0.0021932250820100307, 0.0020842335652559996, 0.0021370386239141226, 0.11782194674015045, 0.002189129823818803, 0.0022433497942984104, 0.14220179617404938, 0.0024261216167360544, 0.0024257120676338673, 0.002512766979634762, 0.0025525365490466356, 0.0026117758825421333, 0.0025754286907613277, 0.002532906597480178, 0.0026910060551017523, 0.002595283091068268, 0.002660872181877494, 0.002605296904221177, 0.0027386301662772894, 0.12683652341365814, 0.0028794535901397467, 0.002758064540103078, 0.0027935695834457874, 0.18098856508731842, 0.002712721936404705, 0.002977319760248065, 0.11207984387874603, 0.0028302508872002363, 0.0030237562023103237, 0.1693703681230545, 0.0032294215634465218, 0.09745953232049942, 0.003608877304941416, 0.15871553122997284, 0.004605922847986221, 0.004130358342081308, 0.004731825552880764, 0.0046723573468625546, 0.004616998601704836, 0.004773769527673721, 0.004985501989722252, 0.004921546671539545, 0.2712976932525635, 0.0052926139906048775, 0.00574033847078681, 0.005648474209010601, 0.005911603104323149, 0.006179979536682367, 0.006524034775793552, 0.006714643444865942, 0.15975654125213623, 0.12235506623983383, 0.007206066977232695, 0.006761498749256134, 0.006829715799540281, 0.007280372548848391, 0.007286690641194582, 0.006616720464080572, 0.00686830747872591, 0.0065428451634943485, 0.0063276104629039764, 0.00608853017911315, 0.006293619051575661, 0.005734537728130817, 0.005780159030109644, 0.005627106409519911, 0.005465185735374689, 0.005356592126190662, 0.004967959132045507, 0.004907645750790834, 0.004429342690855265, 0.004229575861245394, 0.004023363348096609, 0.003788748988881707, 0.003947416786104441, 0.0035562331322580576, 0.0034693789202719927, 0.0031525774393230677, 0.003283689497038722, 0.00308665307238698, 0.0031238014344125986, 0.002901849104091525, 0.002959291450679302, 0.0027212919667363167, 0.00239064684137702, 0.0024640716146677732, 0.002344368491321802, 0.00213790824636817, 0.0023229990620166063, 0.0020125964656472206, 0.001953844679519534, 0.0018746221903711557, 0.0018952058162540197, 0.001730263466015458, 0.001697501982562244, 0.0017563645960763097, 0.0017636489355936646, 0.001566220074892044, 0.0016413290286436677, 0.001619009068235755, 0.17664186656475067, 0.0015436663525179029, 0.0015570148825645447, 0.11741580814123154, 0.0016454531578347087, 0.0015632354188710451, 0.09434932470321655, 0.001792554627172649, 0.001830107532441616, 0.0019019112223759294, 0.002115554641932249, 0.0019858363084495068, 0.002056701574474573, 0.0020066332072019577, 0.002060830360278487, 0.0020088355522602797, 0.00214638514444232, 0.002030749339610338, 0.00241311127319932, 0.0020867118146270514, 0.0021704912651330233, 0.0020694357808679342, 0.002019644482061267, 0.002428439212962985, 0.0019289851188659668, 0.002319562714546919, 0.00191150710452348, 0.0018458919366821647, 0.0018291830783709884, 0.0018481760052964091, 0.1382952630519867, 0.0018806790467351675, 0.0019249817123636603, 0.0018017094116657972, 0.002108534099534154, 0.0019511597929522395, 0.0018691192381083965, 0.0018331622704863548, 0.0018281785305589437, 0.0018806530861184, 0.0019230848411098123, 0.0019511210266500711, 0.0017979819094762206, 0.00183207169175148, 0.0020563348662108183, 0.0017903851112350821, 0.14837194979190826, 0.0017875699559226632, 0.00192760128993541, 0.001875383546575904, 0.0017601466970518231, 0.001882807700894773, 0.002031367737799883, 0.1589450091123581, 0.0018300262745469809, 0.0020512619521468878, 0.0022117961198091507, 0.0023386881221085787, 0.00222776853479445, 0.002033470431342721, 0.0020833483431488276, 0.001989535056054592, 0.0019889213144779205, 0.002182158874347806, 0.0977570191025734, 0.002005938207730651, 0.14196673035621643, 0.002280982444062829, 0.0023771387059241533, 0.002396026160567999, 0.002421705750748515, 0.0024767383001744747, 0.002541057765483856, 0.0024478824343532324, 0.183185875415802, 0.0028141015209257603, 0.11758929491043091, 0.0028910834807902575, 0.00288747763261199, 0.002860855311155319, 0.0035119052045047283, 0.003447408089414239, 0.003092145314440131, 0.0031445613130927086, 0.0031500901095569134, 0.0033863261342048645, 0.003369132289662957, 0.003252710448578, 0.003362912917509675, 0.003457373473793268, 0.003113172948360443, 0.003204851411283016, 0.0030882004648447037, 0.0030028061009943485, 0.003401556285098195, 0.12598955631256104, 0.1575145721435547, 0.0028519390616565943, 0.0030410881154239178, 0.002969724591821432, 0.0033629133831709623, 0.0032795045990496874, 0.0029874462634325027, 0.003068047808483243, 0.003329014638438821, 0.0030241061467677355, 0.003308272687718272, 0.002960830694064498, 0.0029154676012694836, 0.002894168719649315, 0.0028298511169850826, 0.002785111777484417, 0.002890117233619094, 0.0026871731970459223, 0.002553745871409774, 0.0024475257378071547, 0.0025394298136234283, 0.15988518297672272, 0.00235810992307961, 0.002370447851717472, 0.002583247609436512, 0.002506149234250188, 0.0024095603730529547, 0.0023630550131201744, 0.0023285469505935907, 0.0022999360226094723, 0.0024098511785268784, 0.002207969082519412, 0.0022110939025878906, 0.0024408989120274782, 0.0022731435019522905, 0.0020623106975108385, 0.0021364064887166023, 0.0020391689613461494, 0.0020143967121839523, 0.10432002693414688, 0.00207363348454237, 0.002317773876711726, 0.002168037695810199, 0.0019692943897098303, 0.0019519305787980556, 0.0019529075361788273, 0.001972866477444768, 0.0020582950673997402, 0.0019231552723795176, 0.001856571645475924, 0.0018884040182456374, 0.0017968588508665562, 0.001780967228114605, 0.0018258438212797046, 0.0016944133676588535, 0.0017303553177043796, 0.0016195083735510707, 0.0016121447551995516, 0.0016716796671971679, 0.001762889907695353, 0.0015447059413418174, 0.0015430166386067867, 0.001501927967183292, 0.001670311437919736, 0.0016474411822855473, 0.001446350128389895, 0.0014356228057295084, 0.0013274874072521925, 0.0014684585621580482, 0.0013341825688257813, 0.0013040697667747736, 0.11641790717840195, 0.12705686688423157, 0.0014737227465957403, 0.0016204380663111806, 0.001420445740222931, 0.16493970155715942, 0.0015632903669029474, 0.0017685919301584363, 0.0017687886720523238, 0.0018850788474082947, 0.0019255403894931078, 0.1334109753370285, 0.002017039805650711, 0.0023891115561127663, 0.002377155004069209, 0.12717927992343903, 0.0026039709337055683, 0.0026538572274148464, 0.002658071229234338, 0.002882804488763213, 0.00281912530772388, 0.0029815947636961937, 0.0032488470897078514, 0.0028979035560041666, 0.003050218103453517, 0.002912417985498905, 0.0031342855654656887, 0.0028987983241677284, 0.002980710007250309, 0.0029815565794706345, 0.0029146394226700068, 0.0028034821152687073, 0.002848028903827071, 0.0027842088602483273, 0.1248248890042305, 0.002981808502227068, 0.002822172362357378, 0.0027369640301913023, 0.0026549503672868013, 0.09940369427204132, 0.14032436907291412, 0.002782749477773905, 0.0029585191514343023, 0.003402939299121499, 0.16350027918815613, 0.0034010768868029118, 0.003233756171539426, 0.0033842201810330153, 0.0036707171238958836, 0.0036695413291454315, 0.0035995885264128447, 0.11332091689109802, 0.00360692641697824, 0.0038978802040219307, 0.003759368322789669, 0.0036691271234303713, 0.0037677239160984755, 0.13234752416610718, 0.00389225990511477, 0.0038330727256834507, 0.003844422521069646, 0.004025603178888559, 0.0038158539682626724, 0.004012507386505604, 0.003789129899814725, 0.0038190402556210756, 0.003873654641211033, 0.003910044673830271, 0.10293020308017731, 0.003715414321050048, 0.0036210438702255487, 0.004169142805039883, 0.0035077440552413464, 0.0034904293715953827, 0.0037366391625255346, 0.0036289154086261988, 0.20280246436595917, 0.003447124268859625, 0.11610513925552368, 0.003699946217238903, 0.0033647511154413223, 0.11945906281471252, 0.0035283348988741636, 0.00379734905436635, 0.0037727435119450092, 0.0037547419779002666, 0.16420471668243408, 0.003962255548685789, 0.004040793050080538, 0.004230715800076723, 0.004108008462935686, 0.004251287318766117, 0.1100422814488411, 0.004353090655058622, 0.0041636256501078606, 0.004437712952494621, 0.00428772484883666, 0.004165386315435171, 0.0040861451998353004, 0.004177081398665905, 0.004288874566555023, 0.004005975089967251, 0.004017318598926067, 0.0037280055694282055, 0.0038195843808352947, 0.00385382235981524, 0.0036304155364632607, 0.003713375423103571, 0.0035849851556122303, 0.0032557561062276363, 0.003267809748649597, 0.0031422520987689495, 0.003000692930072546, 0.002977043157443404, 0.0029850462451577187, 0.10048570483922958, 0.0027342934627085924, 0.002743183169513941, 0.002955724485218525, 0.002529194811359048, 0.002709262305870652, 0.002530512399971485, 0.002565851667895913, 0.0027243588119745255, 0.0025880904868245125, 0.1048603430390358, 0.0026236579287797213, 0.0025772270746529102, 0.0024741904344409704, 0.0024063480086624622, 0.002325322711840272, 0.0024168372619897127, 0.002271618926897645, 0.002308659953996539, 0.002244040137156844, 0.002180317649617791, 0.0022179419174790382, 0.002399291144683957, 0.002291027456521988, 0.002001722576096654, 0.0020525699947029352, 0.0022648517042398453, 0.001982375979423523, 0.0019253510981798172, 0.001800816971808672, 0.0017694694688543677, 0.0017845450202003121, 0.002041867235675454, 0.0017279796302318573, 0.0016172375762835145, 0.12511886656284332, 0.0017800003988668323, 0.0019234780920669436, 0.16515925526618958, 0.002054723212495446, 0.0018158365273848176, 0.0976172387599945, 0.0019326576730236411, 0.002023846609517932, 0.12906283140182495, 0.0021410591434687376, 0.002264082431793213, 0.0023666243068873882, 0.002700546756386757, 0.0025617177598178387, 0.002615455538034439, 0.20696958899497986, 0.002885782392695546, 0.0028863619081676006, 0.0029416345059871674, 0.0029554797802120447, 0.0032651147339493036, 0.00299081951379776, 0.0037652309983968735, 0.0031609521247446537, 0.11803696304559708, 0.0033997781574726105, 0.0031691233161836863, 0.003267364576458931, 0.0035991016775369644, 0.003130254102870822, 0.0031237578950822353, 0.0037492047995328903, 0.0035146716982126236, 0.0035527804866433144, 0.0030057234689593315, 0.0032042451202869415, 0.0033995257690548897, 0.0029474750626832247, 0.0034438217990100384, 0.14515672624111176, 0.1027027890086174, 0.0037124098744243383, 0.0034938701428472996, 0.0032748256344348192, 0.0029289331287145615]\n",
            "Val loss 0.028978588348978145\n",
            "Val auc roc 0.4782117812061711\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c2cb18c70aa4d2689f9a74220eadfdf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0175\n",
            "Train Losses : [0.002942473627626896, 0.0030605453066527843, 0.0033682428766041994, 0.0033801430836319923, 0.09218242019414902, 0.0030795354396104813, 0.0032739443704485893, 0.0032764673233032227, 0.003094523446634412, 0.0030574826523661613, 0.0030811592005193233, 0.0030173207633197308, 0.002968951128423214, 0.0028767187613993883, 0.3673757016658783, 0.003343187505379319, 0.003470291616395116, 0.09694115072488785, 0.0041228714399039745, 0.0038568456657230854, 0.004026278853416443, 0.13794159889221191, 0.00492757698521018, 0.31373149156570435, 0.005716969259083271, 0.007735983468592167, 0.006647524889558554, 0.007444096263498068, 0.0071357074193656445, 0.007674947381019592, 0.007519800681620836, 0.007668051868677139, 0.007199872750788927, 0.007959716953337193, 0.007387164048850536, 0.007747485302388668, 0.008450872264802456, 0.007861793972551823, 0.0485256053507328, 0.00712481839582324, 0.00836968794465065, 0.007319118361920118, 0.006792799104005098, 0.006336301565170288, 0.007194132078438997, 0.0060586463660001755, 0.006534575950354338, 0.0071505107916891575, 0.09063456952571869, 0.00593619653955102, 0.005369044840335846, 0.00464134244248271, 0.004827778320759535, 0.0048966482281684875, 0.004544864874333143, 0.004506614990532398, 0.003938677720725536, 0.003993339370936155, 0.004282290115952492, 0.0041853939183056355, 0.004087264183908701, 0.0036214091815054417, 0.003482153406366706, 0.003380383597686887, 0.003326879581436515, 0.003215429373085499, 0.003077843924984336, 0.003046525176614523, 0.0029735162388533354, 0.002711957786232233, 0.0024424674920737743, 0.002810745034366846, 0.002838956192135811, 0.0027679221238940954, 0.0022782410960644484, 0.002095622941851616, 0.002401628065854311, 0.002278919331729412, 0.0024400739930570126, 0.0021724936086684465, 0.0019169675651937723, 0.0018822492565959692, 0.0018325636629015207, 0.0017973302165046334, 0.0017223235918208957, 0.08188679814338684, 0.0017805759562179446, 0.0016559865325689316, 0.001850066939368844, 0.001896701636724174, 0.0015349278692156076, 0.0015755658969283104, 0.0018306997371837497, 0.0016385766211897135, 0.0015584470238536596, 0.0015174603322520852, 0.0017932127229869366, 0.0015476037515327334, 0.10368312895298004, 0.0018649800913408399, 0.0017156103858724236, 0.0016874740831553936, 0.0019365018233656883, 0.0018194871954619884, 0.2639077603816986, 0.0015616207383573055, 0.001784048043191433, 0.001919069909490645, 0.0020896766800433397, 0.001639270456507802, 0.0018561114557087421, 0.0018543355399742723, 0.0019587762653827667, 0.0022761200089007616, 0.0016731524374336004, 0.0016377365682274103, 0.0018356825457885861, 0.17331339418888092, 0.0016976273618638515, 0.0017007734859362245, 0.0018620850751176476, 0.0018794162897393107, 0.0019681795965880156, 0.0019474242581054568, 0.002271184464916587, 0.002091242466121912, 0.0022479998879134655, 0.002145936246961355, 0.0017803378868848085, 0.002037578262388706, 0.1234133243560791, 0.002021334832534194, 0.0023063465487211943, 0.0019221208058297634, 0.002250369405373931, 0.0023216118570417166, 0.0019590300507843494, 0.002119032433256507, 0.13729648292064667, 0.0020487518049776554, 0.0020515299402177334, 0.002133542438969016, 0.0023725118953734636, 0.0021303093526512384, 0.0022469977848231792, 0.37912502884864807, 0.140264093875885, 0.003042902797460556, 0.0028407808858901262, 0.0029687206260859966, 0.003336604218930006, 0.004406030289828777, 0.00479913642629981, 0.1576734185218811, 0.004165384918451309, 0.0055173286236822605, 0.0042578005231916904, 0.12608155608177185, 0.0047416649758815765, 0.004579504486173391, 0.005272891838103533, 0.006041412707418203, 0.004789342638105154, 0.005452832672744989, 0.004998530261218548, 0.005011305212974548, 0.005284234881401062, 0.00526698911562562, 0.005138462409377098, 0.10672803223133087, 0.00464537413790822, 0.004782423377037048, 0.004462395329028368, 0.005366242490708828, 0.005910841748118401, 0.00422896072268486, 0.004663023632019758, 0.004861758090555668, 0.004079505801200867, 0.004769674967974424, 0.005474386736750603, 0.14606674015522003, 0.0038773035630583763, 0.004470640793442726, 0.005376418121159077, 0.0047065638937056065, 0.062435004860162735, 0.003564104437828064, 0.003772284369915724, 0.0035241718869656324, 0.10201974958181381, 0.004244185984134674, 0.08895395696163177, 0.0037224083207547665, 0.004160215146839619, 0.0039790621958673, 0.0038294149562716484, 0.003946196753531694, 0.0034140092320740223, 0.004349441733211279, 0.00394028564915061, 0.0038103063125163317, 0.19078093767166138, 0.004756078124046326, 0.00343066337518394, 0.0037544446531683207, 0.004166194703429937, 0.003575621172785759, 0.003580549731850624, 0.003808689070865512, 0.0031751184724271297, 0.0034675931092351675, 0.0033944910392165184, 0.003226988948881626, 0.0035284480545669794, 0.0028172610327601433, 0.002914323005825281, 0.052078649401664734, 0.0031463447958230972, 0.16184155642986298, 0.0030782290268689394, 0.0031752355862408876, 0.0026700571179389954, 0.0028193627949804068, 0.0037440129090100527, 0.0033214488066732883, 0.0028336700052022934, 0.12507297098636627, 0.003135197563096881, 0.003204474225640297, 0.002645288361236453, 0.002645963802933693, 0.0031473299022763968, 0.002760921837761998, 0.07325530052185059, 0.0034681104589253664, 0.0028192014433443546, 0.0031418432481586933, 0.003897658549249172, 0.002761495066806674, 0.0027808728627860546, 0.11702181398868561, 0.0028637018986046314, 0.0028274101205170155, 0.0027675924357026815, 0.003098276676610112, 0.003038998693227768, 0.0029277964495122433, 0.0033112599048763514, 0.07215209305286407, 0.0030853471253067255, 0.0032896525226533413, 0.003360577393323183, 0.003190484829246998, 0.0029289526864886284, 0.0038671602960675955, 0.2612699866294861, 0.0029389613773673773, 0.003886974649503827, 0.00353730795904994, 0.003628326812759042, 0.00336188031360507, 0.005212024785578251, 0.004075777716934681, 0.004093388095498085, 0.0037677523214370012, 0.0038573481142520905, 0.004640340339392424, 0.004172843415290117, 0.0033464981243014336, 0.003854830749332905, 0.004841156769543886, 0.004262302070856094, 0.004491714760661125, 0.003302566008642316, 0.004076045472174883, 0.00368332932703197, 0.0048378752544522285, 0.0030022275168448687, 0.0031046117655932903, 0.0572952963411808, 0.0032119709067046642, 0.0030036845710128546, 0.0029929971788078547, 0.003241191618144512, 0.24373942613601685, 0.003381546353921294, 0.0036654514260590076, 0.00278284284286201, 0.0025385564658790827, 0.0025344721507281065, 0.002810936886817217, 0.0033889508340507746, 0.003313899040222168, 0.0036827167496085167, 0.0029498001094907522, 0.0026259878650307655, 0.003450889140367508, 0.0032980574760586023, 0.0025887966621667147, 0.002161677461117506, 0.0021655019372701645, 0.002552227582782507, 0.0020993254147469997, 0.002697225194424391, 0.0021048043854534626, 0.0025301706045866013, 0.002457801951095462, 0.1517198085784912, 0.0019267488969489932, 0.002051370916888118, 0.001947325887158513, 0.002158071845769882, 0.0022482089698314667, 0.0023888854775577784, 0.002095392905175686, 0.002373369410634041, 0.0025382875464856625, 0.001889604958705604, 0.0026630605570971966, 0.0022006691433489323, 0.0019941222853958607, 0.0019893706776201725, 0.0021733599714934826, 0.0019333800300955772, 0.0020653398241847754, 0.12845012545585632, 0.0020989382173866034, 0.0017814695602282882, 0.00203530746512115, 0.0017451837193220854, 0.0019875946454703808, 0.0017883304972201586, 0.18222278356552124, 0.0017816777108237147, 0.0021552385296672583, 0.002028754213824868, 0.002523789182305336, 0.0023943667765706778, 0.0018791004549711943, 0.00240202434360981, 0.002491691615432501, 0.0020009030122309923, 0.0019236953230574727, 0.0018325384007766843, 0.0018083282047882676, 0.0019310846691951156, 0.12915797531604767, 0.0018817061791196465, 0.001973066246137023, 0.0023264745250344276, 0.0020997824613004923, 0.0024569551460444927, 0.0021023426670581102, 0.002288206247612834, 0.1627611219882965, 0.0020217266865074635, 0.002510503400117159, 0.0020746742375195026, 0.0024678045883774757, 0.002049194648861885, 0.002497588051483035, 0.0020080965477973223, 0.002552203368395567, 0.002408021129667759, 0.0025880474131554365, 0.0020306692458689213, 0.002448239829391241, 0.002285305643454194, 0.0022873575799167156, 0.001890446525067091, 0.002017159014940262, 0.0021029901690781116, 0.0018476612167432904, 0.0019218438537791371, 0.0023456725757569075, 0.0021262946538627148, 0.0024116954300552607, 0.0017263094196096063, 0.0019595951307564974, 0.1747487336397171, 0.001973881619051099, 0.0018078990979120135, 0.001753326621837914, 0.0021249118726700544, 0.001961667323485017, 0.0018503000028431416, 0.002055836608633399, 0.0023140152916312218, 0.0017722039483487606, 0.0017158500850200653, 0.002179719740524888, 0.001895377179607749, 0.0018351783510297537, 0.0022819857113063335, 0.0016306304605677724, 0.0016394235426560044, 0.001862970064394176, 0.0018003309378400445, 0.0016019841423258185, 0.0016462714411318302, 0.0015758725348860025, 0.0016264459118247032, 0.0015357676893472672, 0.001442278502508998, 0.0018827677704393864, 0.0016510600689798594, 0.001614012406207621, 0.0014574166852980852, 0.0014301191549748182, 0.001459143590182066, 0.0014464266132563353, 0.1709880828857422, 0.0016928737750276923, 0.0013539642095565796, 0.0013397122966125607, 0.0015515829436481, 0.0015774425119161606, 0.0013839437160640955, 0.0015499049331992865, 0.001500824000686407, 0.0014111341442912817, 0.0015929442597553134, 0.001554725575260818, 0.21314343810081482, 0.0014502168633043766, 0.09614074230194092, 0.13343928754329681, 0.0018092724494636059, 0.0016761863371357322, 0.18298399448394775, 0.0020681428723037243, 0.0019828001968562603, 0.0025255533400923014, 0.002279080683365464, 0.0025682447012513876, 0.002812171820551157, 0.07060996443033218, 0.0029211912769824266, 0.002833255333825946, 0.0030221936758607626, 0.00295897270552814, 0.0031332536600530148, 0.0032804699148982763, 0.0036288441624492407, 0.0032604271546006203, 0.00314528145827353, 0.0027777485083788633, 0.0028852324467152357, 0.0031559402123093605, 0.003333853092044592, 0.002938757883384824, 0.0029768210370093584, 0.0035541621036827564, 0.0027397035155445337, 0.00288457702845335, 0.09424129873514175, 0.0033966859336942434, 0.12311399728059769, 0.12542083859443665, 0.0028185073751956224, 0.0030597520526498556, 0.0030290756840258837, 0.002962414175271988, 0.003104219911620021, 0.18737661838531494, 0.0030389640014618635, 0.0035209411289542913, 0.0034400583244860172, 0.0035252568777650595, 0.0034393961541354656, 0.0035069496370851994, 0.0034266081638634205, 0.003486569505184889, 0.003573016729205847, 0.003593617118895054, 0.0034733591601252556, 0.003150002332404256, 0.003743789391592145, 0.003227441804483533, 0.0031442870385944843, 0.0035394872538745403, 0.0031594624742865562, 0.1186014786362648, 0.0033332628663629293, 0.003620672971010208, 0.003281473880633712, 0.002840881934389472, 0.003326463745906949, 0.00297928461804986, 0.002817358821630478, 0.0027791631873697042, 0.0026852507144212723, 0.003159597748890519, 0.19127127528190613, 0.0025593505706638098, 0.002753277076408267, 0.002837151288986206, 0.00275197415612638, 0.0028025927022099495, 0.0028131091967225075, 0.002554310718551278, 0.002730865962803364, 0.002513009821996093, 0.0025856380816549063, 0.0025270001497119665, 0.5495228171348572, 0.0025498003233224154, 0.10279113799333572, 0.08021876215934753, 0.0032819630578160286, 0.003401385387405753, 0.10563815385103226, 0.0037226362619549036, 0.004239626694470644, 0.004503116011619568, 0.004290011711418629, 0.005116885062307119, 0.005441822577267885, 0.004836684092879295, 0.12853913009166718, 0.0056057823821902275, 0.005028577987104654, 0.005498902872204781, 0.005080625880509615, 0.005695287138223648, 0.005892336368560791, 0.005392266437411308, 0.005714158061891794, 0.004992550704628229, 0.00509942090138793, 0.005257365293800831, 0.004964148625731468, 0.004682000260800123, 0.004781931173056364, 0.004440840799361467, 0.004235533997416496, 0.00452555064111948, 0.0041512795723974705, 0.0038925663102418184, 0.003975218627601862, 0.004127089399844408, 0.0036317561753094196, 0.0037692475598305464, 0.0037666442804038525, 0.0032863121014088392, 0.003219188656657934, 0.0035324683412909508, 0.003050685627385974, 0.0030991490930318832, 0.1483507603406906, 0.00374281732365489, 0.0029756107833236456, 0.002862510969862342, 0.0029535535722970963, 0.0027318198699504137, 0.0032653447706252337, 0.0026689469814300537, 0.003004173981025815, 0.0026957036461681128, 0.0030005432199686766, 0.002763918833807111, 0.0025488226674497128, 0.002787795616313815, 0.09699614346027374, 0.0023826283868402243, 0.00257526314817369, 0.0024419506080448627, 0.002331322990357876, 0.0022522169165313244, 0.12574687600135803, 0.002274588216096163, 0.12860064208507538, 0.002436195034533739, 0.0027363174594938755, 0.11615198850631714, 0.00278675789013505, 0.0028445275966078043, 0.0030276160687208176, 0.0028205886483192444, 0.002980566583573818, 0.002756021684035659, 0.0028178435750305653, 0.0029400656931102276, 0.003192142816260457, 0.0031403645407408476, 0.002911127870902419, 0.0032034709583967924, 0.0027631232514977455, 0.0033187454100698233, 0.002975942101329565, 0.002642785431817174, 0.002831874880939722, 0.0028216915670782328, 0.002631009090691805, 0.003560916054993868, 0.002609219867736101, 0.0025635322090238333, 0.002685799030587077, 0.09644623100757599, 0.002310391515493393, 0.0024368807207792997, 0.0026151027996093035, 0.0022385430056601763, 0.002757477341219783, 0.0025109578855335712, 0.0021978106815367937, 0.002398640615865588, 0.0021778829395771027, 0.0023665891494601965, 0.14645643532276154, 0.002245105803012848, 0.002182514639571309, 0.00293134362436831, 0.0024055198300629854, 0.0022555869072675705, 0.00232795556075871, 0.0026064706034958363, 0.002399896504357457, 0.0025578963104635477, 0.0025202499236911535, 0.16033990681171417, 0.0021660132333636284, 0.002701468300074339, 0.12188176810741425, 0.002287546405568719, 0.002942183054983616, 0.0028637831564992666, 0.002813815837725997, 0.0025104780215770006, 0.0028033473063260317, 0.002682646969333291, 0.002671867609024048, 0.002831388497725129, 0.0024833865463733673, 0.0026701248716562986, 0.0025356661062687635, 0.002892696065828204, 0.0027358431834727526, 0.002361210761591792, 0.002512468723580241, 0.0022433502599596977, 0.0027873553335666656, 0.0023032184690237045, 0.0023053428158164024, 0.002325276145711541, 0.002162787364795804, 0.10192983597517014, 0.0020783301442861557, 0.002435271628201008, 0.002106219530105591, 0.002713763853535056, 0.0020733997225761414, 0.002023812849074602, 0.0021875605452805758, 0.002015837235376239, 0.0023803997319191694, 0.002315404126420617, 0.0020660576410591602, 0.002141071716323495, 0.001999261789023876, 0.0025857090950012207, 0.002250759396702051, 0.0018370816251263022, 0.0021647592075169086, 0.0019888351671397686, 0.00179423694498837, 0.0017313417047262192, 0.0019953493028879166, 0.0019867075607180595, 0.0016479225596413016, 0.17073118686676025, 0.4746696949005127, 0.0020334518048912287, 0.0020116453524678946, 0.11966057121753693, 0.002252045786008239, 0.0024917004629969597, 0.002950607566162944, 0.1234624981880188, 0.003267435124143958, 0.003108062781393528, 0.0035863881930708885, 0.0034873634576797485, 0.1863342523574829, 0.0038311604876071215, 0.003769469214603305, 0.0037786599714308977, 0.12199965864419937, 0.004245571326464415, 0.004052160773426294, 0.004832907114177942, 0.004268178716301918, 0.004402962513267994, 0.11920078098773956, 0.005013553891330957, 0.11393708735704422, 0.005015221890062094, 0.005129873286932707, 0.004743247292935848, 0.004903828259557486, 0.005602059420198202, 0.005112360697239637, 0.005624319892376661, 0.00502471998333931, 0.005065344739705324, 0.005245381500571966, 0.0046338876709342, 0.004770779050886631, 0.42362672090530396, 0.004877334926277399, 0.004751551430672407, 0.005124769639223814, 0.005651094950735569, 0.00630847318097949, 0.10953723639249802, 0.005277705378830433, 0.005954840686172247, 0.006327343173325062, 0.006073975469917059, 0.005754691082984209, 0.006457317154854536, 0.06062323972582817, 0.005984118673950434, 0.10401478409767151, 0.005990683101117611, 0.006271542515605688, 0.0066906665451824665, 0.006045384332537651, 0.005930846091359854, 0.005220676306635141, 0.005558496806770563, 0.005145712289959192, 0.00570916710421443, 0.005580105818808079, 0.0050846366211771965, 0.004854890052229166, 0.005760596599429846, 0.004810279700905085, 0.004710664972662926, 0.004647804889827967, 0.004876789636909962, 0.004267957992851734, 0.004020202439278364, 0.0038029414135962725, 0.003937593661248684, 0.0037098687607795, 0.0034479452297091484, 0.003482217900454998, 0.003608080791309476, 0.0033520241267979145, 0.003166668815538287, 0.003369827987626195, 0.0036007510498166084, 0.0035235369578003883, 0.0030041630379855633, 0.0027204719372093678, 0.002806928241625428, 0.003029943211004138, 0.0028331431094557047, 0.00274786539375782, 0.0027416544035077095, 0.002831123536452651, 0.002260093344375491, 0.0023403698578476906, 0.17585644125938416, 0.0022703565191477537, 0.0024624306242913008, 0.0024252906441688538, 0.002217506757006049, 0.002462084637954831, 0.002367940731346607, 0.002277498133480549, 0.4528981149196625, 0.002836080500856042, 0.0027184374630451202, 0.23556022346019745, 0.11606146395206451, 0.1371040791273117, 0.0030198371969163418, 0.003352188039571047, 0.0038210267666727304, 0.003603769699111581, 0.004414518363773823, 0.004052223637700081, 0.004337270278483629, 0.004617736674845219, 0.0912851095199585, 0.004869823344051838, 0.004586825612932444, 0.004955633077770472, 0.004852477926760912, 0.005167205817997456, 0.004763385746628046, 0.004683982115238905, 0.004495867993682623, 0.004668452311307192, 0.0045614526607096195, 0.0043617794290184975, 0.09506577253341675, 0.005127608310431242, 0.004543098155409098, 0.0043930839747190475, 0.004628945142030716, 0.0046956343576312065, 0.00421460997313261, 0.004168402403593063, 0.0039532785303890705, 0.004350796341896057, 0.004433532245457172, 0.0037687267176806927, 0.003754951525479555, 0.003846872830763459, 0.0036740002688020468, 0.0036685243248939514, 0.003934656735509634, 0.003506565233692527, 0.00371910585090518, 0.10224628448486328, 0.0035450244322419167, 0.003153880825266242, 0.003106360323727131, 0.003216296900063753, 0.0031356296967715025, 0.003530466463416815, 0.003098368179053068, 0.0031715012155473232, 0.0032228222116827965, 0.0030348733998835087, 0.0029422708321362734, 0.002744607860222459, 0.0030841263942420483, 0.002903127344325185, 0.0029952723998576403, 0.00266334624029696, 0.0026489393785595894, 0.002885041991248727, 0.0025966414250433445, 0.11623168736696243, 0.0025624698027968407, 0.08996407687664032, 0.0025576509069651365, 0.0028000024612993, 0.0024433888029307127, 0.0027683505322784185, 0.002399429911747575, 0.0026231613010168076, 0.0024561325553804636, 0.0025544012896716595, 0.0023747095838189125, 0.0024946406483650208, 0.002645467408001423, 0.07464572042226791, 0.00304464646615088, 0.0022937501780688763, 0.002302196342498064, 0.002576434751972556, 0.0027242093347012997, 0.002337545854970813, 0.0025273566134274006, 0.00248981942422688, 0.0028436847496777773, 0.0022731246426701546, 0.0025371666997671127, 0.0022705409210175276, 0.002304928842931986, 0.0021009084302932024, 0.002190126571804285, 0.002151635941118002, 0.0024425936862826347, 0.0023676203563809395, 0.0021470338106155396, 0.0021337007638067007, 0.0024452402722090483, 0.0020223662722855806, 0.11977095901966095, 0.0020233984105288982, 0.0020037509966641665, 0.12669825553894043, 0.0022919196635484695, 0.0024786400608718395, 0.0021554995328187943, 0.0020525960717350245, 0.0020189150236546993, 0.0021389273460954428, 0.002325753914192319, 0.002149547915905714, 0.061829473823308945, 0.002030719770118594, 0.002585730282589793, 0.0029200816061347723, 0.0021802764385938644, 0.002370864385738969, 0.0023224125616252422, 0.0022862153127789497, 0.002075732219964266, 0.0021233565639704466, 0.0023656294215470552, 0.002066944958642125, 0.0020938499365001917, 0.0020001675002276897, 0.0021687131375074387, 0.0021301202941685915, 0.0020956043154001236, 0.09120127558708191, 0.001911784172989428, 0.10338400304317474, 0.002062507439404726, 0.0024057587143033743, 0.0020265544299036264, 0.0022740568965673447, 0.002449691528454423, 0.0022052584681659937, 0.10500160604715347, 0.002298884792253375, 0.09004852175712585, 0.0022443351335823536, 0.0027405701112002134, 0.002520713023841381, 0.002512275008484721, 0.003005686681717634, 0.002772062085568905, 0.0028268618043512106, 0.0024989007506519556, 0.0025023294147104025, 0.00251736375503242, 0.0031437722500413656, 0.0027091321535408497, 0.002910116221755743, 0.0025897216983139515, 0.0027344978880137205, 0.003200911683961749, 0.0022579971700906754, 0.002359815640375018, 0.002325138309970498, 0.00258156331256032, 0.002414572285488248, 0.003403288312256336, 0.0022838558070361614, 0.0020926923025399446, 0.00201331521384418, 0.002708693267777562, 0.0021703685633838177, 0.002831528428941965, 0.0020858333446085453, 0.002035298617556691, 0.0018981784814968705, 0.0019066473469138145, 0.0021555323619395494, 0.002116409596055746, 0.002312183380126953, 0.001664479379542172, 0.0018076520645990968, 0.001791406306438148, 0.0019731877837330103, 0.0016959449276328087, 0.12069453299045563, 0.0016649585450068116, 0.0017234317492693663, 0.0015632936265319586, 0.002044947352260351, 0.001828840235248208, 0.0015906840562820435, 0.0017030780436471105, 0.0017973913345485926, 0.0018855863017961383, 0.0016325281467288733, 0.0016346245538443327, 0.17166797816753387, 0.001732572796754539, 0.0017308791866526008, 0.001967519288882613, 0.0018079793080687523, 0.0017075699288398027, 0.0017079974059015512, 0.0018651807913556695, 0.0015661100624129176, 0.0016826242208480835, 0.0015885898610576987, 0.001655267784371972, 0.002053795615211129, 0.0016161551466211677, 0.001831959467381239, 0.0017939506797119975, 0.0019402221078053117, 0.1830114871263504, 0.13343802094459534, 0.0018210761481896043, 0.001960656838491559, 0.0018806814914569259, 0.11786334216594696, 0.0019877564627677202, 0.002361223567277193, 0.0022705283481627703, 0.0023398599587380886, 0.0022511521819978952, 0.0027989097870886326, 0.002259222324937582, 0.2516765594482422, 0.0023272300604730844, 0.0027277204208076, 0.14187346398830414, 0.14018526673316956, 0.20912662148475647, 0.003294354071840644, 0.0028112775180488825, 0.0033572069369256496, 0.15698449313640594, 0.0030644244980067015, 0.0035827429965138435, 0.003775336779654026, 0.004005115944892168, 0.003858799347653985, 0.004780304152518511, 0.003854231210425496, 0.0039050381164997816, 0.00371839408762753, 0.0038767727091908455, 0.003898597788065672, 0.003967710770666599, 0.004079394042491913, 0.0040962351486086845, 0.003950083162635565, 0.004410364665091038, 0.004043430555611849, 0.004023195244371891, 0.0035864929668605328, 0.0036409664899110794, 0.003523490857332945, 0.0038261080626398325, 0.0037216648925095797, 0.003415617160499096, 0.0031196419149637222, 0.003175907302647829, 0.0035854321904480457, 0.0035859625786542892, 0.003068589838221669, 0.07621736824512482, 0.003026496386155486, 0.0031455554999411106, 0.002774480963125825, 0.003041516523808241, 0.0031390725634992123, 0.0026594942901283503, 0.0027449640911072493, 0.20377320051193237, 0.17249856889247894, 0.0026993448846042156, 0.002796994987875223, 0.0027892431244254112, 0.0029993997886776924, 0.0028475034050643444, 0.0033528520725667477, 0.002830557292327285, 0.003152707125991583, 0.0033454487565904856, 0.0033562961034476757, 0.002883926732465625, 0.0031435543205589056, 0.0031544198282063007, 0.1129022091627121, 0.0026940128300338984, 0.0029892928432673216, 0.003128598676994443, 0.05695313960313797, 0.0027750602457672358, 0.0033913464285433292, 0.0031158472411334515, 0.10897289961576462, 0.0030054862145334482, 0.002844512928277254, 0.0030773889739066362, 0.003257302800193429, 0.0028687031008303165, 0.0031055498402565718, 0.0029790066182613373, 0.0031585670076310635, 0.0030806735157966614, 0.0031772598158568144, 0.003455787431448698, 0.002820749767124653, 0.0029107171576470137, 0.002676130272448063, 0.0029712088871747255, 0.002643908141180873, 0.11043594777584076, 0.0025515793822705746, 0.002684050239622593, 0.0027137116994708776, 0.0025620257947593927, 0.002859044587239623, 0.0024909190833568573, 0.0026560674887150526, 0.002550738397985697, 0.002651614835485816, 0.002480994677171111, 0.0024119035806506872, 0.002477225847542286, 0.15306679904460907, 0.0026433232706040144, 0.0025150347501039505, 0.0023636037949472666, 0.002400393597781658, 0.0024929398205131292, 0.0023834859021008015, 0.18957476317882538, 0.002467961749061942, 0.002837233478203416, 0.0026747516822069883, 0.0025493756402283907, 0.0027135147247463465, 0.0027770388405770063, 0.0024502037558704615, 0.002724930876865983, 0.002877259161323309, 0.002895471639931202, 0.0025402430910617113, 0.0027819478418678045, 0.002582876943051815, 0.0025334537494927645, 0.0024676225148141384, 0.0026033816393464804, 0.002379013691097498, 0.002437804825603962, 0.0022814529947936535, 0.16024552285671234, 0.002229117089882493, 0.12262352555990219, 0.002232963452115655, 0.002386209089308977, 0.0023950545582920313, 0.002434385009109974, 0.0024207609239965677, 0.002491201274096966, 0.00257023423910141, 0.0027194595895707607, 0.002567207207903266, 0.0023835923057049513, 0.002549733966588974, 0.002487592864781618, 0.15390518307685852, 0.002487638033926487, 0.002389421220868826, 0.0025151807349175215, 0.002431803848594427, 0.0027147987857460976, 0.002420500386506319, 0.002399023389443755, 0.07760481536388397, 0.0026491042226552963, 0.12318208068609238, 0.0027844528667628765, 0.0029603231232613325, 0.002760497620329261, 0.0028143045492470264, 0.0026110499165952206, 0.002590882359072566, 0.0027866188902407885, 0.0025462000630795956, 0.0025880218017846346, 0.0029315920546650887, 0.0027305143885314465, 0.002874170197173953, 0.0027956217527389526, 0.002694827737286687, 0.0026685784105211496, 0.00260834745131433, 0.0027048191986978054, 0.002708642976358533, 0.002556909341365099, 0.002304013120010495, 0.002415959257632494, 0.0025158615317195654, 0.0023043558467179537, 0.0024047864135354757, 0.0021981431636959314, 0.0021881668362766504, 0.0022333464585244656, 0.12987865507602692, 0.0021413720678538084, 0.0021871731150895357, 0.002240232191979885, 0.0021056279074400663, 0.002307072514668107, 0.002267319243401289, 0.0021394183859229088, 0.0020428032148629427, 0.12341183423995972, 0.0021099161822348833, 0.002242213347926736, 0.002200691495090723, 0.0023177245166152716, 0.0022443155758082867, 0.0022966344840824604, 0.002087659202516079, 0.002195425797253847, 0.08607642352581024, 0.0021736109629273415, 0.0021447944454848766, 0.11545024812221527, 0.0024289779830724, 0.002425434999167919, 0.002352643758058548, 0.0023854959290474653, 0.002382929902523756, 0.0024195807054638863, 0.0022691399790346622, 0.10959924757480621, 0.002431451575830579, 0.002488757949322462, 0.002384425373747945, 0.002605825662612915, 0.002550424076616764, 0.0026703064795583487, 0.002517873654142022, 0.0023779282346367836, 0.0024892252404242754, 0.0023887241259217262, 0.002422034740447998, 0.002433938207104802, 0.002702389843761921, 0.0026225359179079533, 0.002551307436078787, 0.0025153118185698986, 0.002432272769510746, 0.0026070785243064165, 0.002360060578212142, 0.0021271829027682543, 0.0022433686535805464, 0.002168097998946905, 0.00238528149202466, 0.002005667658522725, 0.19110196828842163, 0.0021555779967457056, 0.0021420689299702644, 0.14812792837619781, 0.002270036144182086, 0.0021212559659034014, 0.002269809367135167, 0.1673888862133026, 0.002297391649335623, 0.002383659826591611, 0.0025966123212128878, 0.0026020598597824574, 0.002473005559295416, 0.002455066656693816, 0.0026123872958123684, 0.0023872661404311657, 0.002560768974944949, 0.0023978836834430695, 0.002371261827647686, 0.002648051828145981, 0.0026488853618502617, 0.0023800295311957598, 0.11816992610692978, 0.002415828639641404, 0.0024784612469375134, 0.0024800109677016735, 0.0023971961345523596, 0.0025767686311155558, 0.0025186906568706036, 0.002419201424345374, 0.002466502133756876, 0.0024077550042420626, 0.0024810326285660267, 0.14291803538799286, 0.002513241721317172, 0.19088320434093475, 0.0028356395196169615, 0.0024514279793947935, 0.0026173724327236414, 0.0025356870610266924, 0.002827102318406105, 0.00253696134313941, 0.002779620001092553, 0.0026627914048731327, 0.0026067690923810005, 0.0027347595896571875, 0.002657973673194647, 0.0026175726670771837, 0.0025400258600711823, 0.0025785360485315323, 0.002521591493859887, 0.002523041097447276, 0.0027317923959344625, 0.002505540382117033, 0.002488035475835204, 0.002782579744234681, 0.002439319621771574, 0.00247972272336483, 0.15428294241428375, 0.002329394454136491, 0.0024342359974980354, 0.002480506431311369, 0.002537480788305402, 0.16758684813976288, 0.0025230625178664923, 0.002416840987280011, 0.0026444336399435997, 0.0025124342646449804, 0.002723146928474307, 0.002456644317135215, 0.0024757145438343287, 0.11627385020256042, 0.002557365922257304, 0.002593706361949444, 0.0024682285729795694, 0.0025495693553239107, 0.0025437036529183388, 0.4402703046798706, 0.0026944968849420547, 0.00284336949698627, 0.0029954947531223297, 0.00326374638825655, 0.0032833637669682503, 0.0035526349674910307, 0.11078130453824997, 0.003509273286908865, 0.003455884987488389, 0.0037969332188367844, 0.003566740546375513, 0.003929003141820431, 0.0036647552624344826, 0.00401777820661664, 0.0038570307660847902, 0.0042703719809651375, 0.003911125008016825, 0.0037745574954897165, 0.003770082723349333, 0.004022892564535141, 0.0038524384144693613, 0.0037236041389405727, 0.0036470871418714523, 0.0034997316543012857, 0.0036594578996300697, 0.003459495957940817, 0.0034374925307929516, 0.003752045100554824, 0.0033494678791612387, 0.0033612626139074564, 0.0034366799518465996, 0.09537146240472794, 0.003256217110902071, 0.0033356708008795977, 0.0031092360150069, 0.003099143970757723, 0.003067417535930872, 0.0031949824187904596, 0.0030636542942374945, 0.0034088650718331337, 0.0031551907304674387, 0.0030723244417458773, 0.003150669625028968, 0.002859632484614849, 0.003028265433385968, 0.00277387211099267, 0.002950912807136774, 0.002668430795893073, 0.0027671188581734896, 0.0025496494490653276, 0.0025841931346803904, 0.0025215859059244394, 0.002580644330009818, 0.0026242188178002834, 0.0026648584753274918, 0.002419290831312537, 0.0023563916329294443, 0.0022649464663118124, 0.0024702262599021196, 0.0022069751285016537, 0.12172562628984451, 0.002312680706381798, 0.0022426596842706203, 0.002506973221898079, 0.0022484727669507265, 0.0023122187703847885, 0.002093430608510971, 0.0023024841211736202, 0.002151552587747574, 0.0021532464306801558, 0.002078552031889558, 0.002055800287052989, 0.0020564994774758816, 0.0021619312465190887, 0.002069284440949559, 0.001988454256206751, 0.0019535887986421585, 0.0019530560821294785, 0.0019199986709281802, 0.0019528786651790142, 0.0019983425736427307, 0.0019510366255417466, 0.0018879068084061146, 0.0018638144247233868, 0.0019317800179123878, 0.0017846951959654689, 0.0017658319557085633, 0.0017992275534197688, 0.0017143678851425648, 0.0017411686712875962, 0.0018484601750969887, 0.0017118551768362522, 0.0017423969693481922, 0.0016343374736607075, 0.0016555165639147162, 0.0017113243229687214, 0.0017310433322563767, 0.0016820232849568129, 0.001553356065414846, 0.0015872081276029348, 0.001530633307993412, 0.0923040360212326, 0.0016141152009367943, 0.001595205976627767, 0.14308924973011017, 0.0015881925355643034, 0.0015456420369446278, 0.12775687873363495, 0.0018039214191958308, 0.0019065067172050476, 0.0017535275546833873, 0.0017112384084612131, 0.0020146090537309647, 0.0018173352582380176, 0.0018035895191133022, 0.0017726358491927385, 0.0020905935671180487, 0.0019131797598674893, 0.0018295182380825281, 0.1678490936756134, 0.0018416388193145394, 0.15393728017807007, 0.0021001468412578106, 0.0020721463952213526, 0.0020563420839607716, 0.0021025133319199085, 0.0021611202973872423, 0.0021350195165723562, 0.0021423993166536093, 0.0022407828364521265, 0.002443617209792137, 0.0022506271488964558, 0.14231836795806885, 0.002323583234101534, 0.002381205093115568, 0.09671062231063843, 0.0023345116060227156, 0.0024179411120712757, 0.0025251733604818583, 0.0024437399115413427, 0.0026219007559120655, 0.0030068899504840374, 0.002518249675631523, 0.002566217677667737, 0.002654526149854064, 0.00285750231705606, 0.0026690377853810787, 0.15215744078159332, 0.0025100219063460827, 0.0027476774994283915, 0.14223121106624603, 0.002639914397150278, 0.0028206869028508663, 0.002961701015010476, 0.18187525868415833, 0.0027861620765179396, 0.14529800415039062, 0.0032383622601628304, 0.0030232053250074387, 0.0031296424567699432, 0.0030512830708175898, 0.0031066653318703175, 0.0030966789927333593, 0.003337919944897294, 0.003201513085514307, 0.003302839118987322, 0.0032957473304122686, 0.0033363308757543564, 0.09950713068246841, 0.0031603146344423294, 0.003202590858563781, 0.003232502145692706, 0.0032471646554768085, 0.0032480459194630384, 0.0033267238177359104, 0.003392850048840046, 0.0031660543754696846, 0.00326842674985528, 0.20309580862522125, 0.003132228972390294, 0.0031326040625572205, 0.003176002763211727, 0.003160465508699417, 0.003083799732849002, 0.003138656262308359, 0.0031369186472147703, 0.0033309527207165956, 0.003190887626260519, 0.003276712726801634, 0.0029392626602202654, 0.0029644521418958902, 0.0029933524783700705, 0.0028565831016749144, 0.0028757741674780846, 0.0028076169546693563, 0.0028123927768319845, 0.002940972801297903, 0.0027746297419071198, 0.0028152859304100275, 0.002596985548734665, 0.00266796862706542, 0.0025586625561118126, 0.0025697099044919014, 0.002481983508914709, 0.0025764647871255875, 0.0024445096496492624, 0.002389789093285799, 0.0024335505440831184, 0.17280365526676178, 0.0024128819350153208, 0.002429949352517724, 0.12672901153564453, 0.002416500123217702, 0.002431170316413045, 0.0025465087965130806, 0.0023973160423338413, 0.1042880043387413, 0.002683138707652688, 0.002471686340868473, 0.002505712443962693, 0.00279910652898252, 0.00266806548461318, 0.0026055220514535904, 0.15527600049972534, 0.002612415933981538, 0.0027670918498188257, 0.002818671753630042, 0.002665184671059251, 0.002726998645812273, 0.002700244542211294, 0.002795505104586482, 0.002781040733680129, 0.0026849466376006603, 0.123569056391716, 0.002700626151636243, 0.0027493545785546303, 0.16237589716911316, 0.002749953418970108, 0.002742320066317916, 0.002877848921343684, 0.002838043263182044, 0.002869507297873497, 0.0029201428405940533, 0.002914477838203311, 0.002867329865694046, 0.0029838515911251307, 0.0028406595811247826, 0.10659650713205338, 0.1748984307050705, 0.0029015790205448866, 0.0030560658778995275, 0.003105846233665943, 0.0031679694075137377, 0.0030369418673217297, 0.0032340516336262226, 0.003117266111075878, 0.0030908863991498947, 0.003306185593828559, 0.13265360891819, 0.003314037574455142, 0.0031623640097677708, 0.0033509128261357546, 0.003161892294883728, 0.0033258970361202955, 0.0031366157345473766, 0.0033062328584492207, 0.003191877156496048, 0.0030321546364575624, 0.003235538024455309, 0.00307843997143209, 0.002961894264444709, 0.0031290610786527395, 0.0029417830519378185, 0.002949044108390808, 0.002991698682308197, 0.10837169736623764, 0.0028422782197594643, 0.0029176061507314444, 0.10493898391723633, 0.002823649439960718, 0.0030059758573770523, 0.0028970649000257254, 0.07963718473911285, 0.0029802850913256407, 0.002960835350677371]\n",
            "Val loss 0.018493953785908065\n",
            "Val auc roc 0.5021458625525946\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5898783f2916410ab8f4ff4477bde873",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0174\n",
            "Train Losses : [0.002993641421198845, 0.0030901790596544743, 0.0029668055940419436, 0.00296173058450222, 0.0030133973341435194, 0.002987317508086562, 0.002929573878645897, 0.0029180103447288275, 0.002868821145966649, 0.0028575831092894077, 0.002907609334215522, 0.11399226635694504, 0.0028390309307724237, 0.0028723569121211767, 0.1287742406129837, 0.0030475747771561146, 0.0028991412837058306, 0.11792238056659698, 0.0029405856039375067, 0.003229270689189434, 0.0031173182651400566, 0.0031124420929700136, 0.003075632266700268, 0.00320444512180984, 0.0032142396084964275, 0.0030303022358566523, 0.15703581273555756, 0.0030943595338612795, 0.003080844646319747, 0.003178596030920744, 0.003167985239997506, 0.0031096998136490583, 0.0031739352270960808, 0.003075090702623129, 0.0031004054471850395, 0.0035068229772150517, 0.0030353073962032795, 0.003127319971099496, 0.003107747295871377, 0.0030157221481204033, 0.0029766897205263376, 0.0029348793905228376, 0.0030519207939505577, 0.002854645485058427, 0.002865150570869446, 0.0028140076901763678, 0.0030474583618342876, 0.002806281205266714, 0.002691500587388873, 0.0026843720115721226, 0.0027250770945101976, 0.002740178955718875, 0.00261887488886714, 0.002547429408878088, 0.0025344681926071644, 0.002460425952449441, 0.0024512060917913914, 0.002397773554548621, 0.0023718983866274357, 0.002383442595601082, 0.0023024443071335554, 0.002294737147167325, 0.002378882374614477, 0.00219982978887856, 0.00222626025788486, 0.0022191531024873257, 0.0021802508272230625, 0.0021801127586513758, 0.0020593067165464163, 0.12459515780210495, 0.0020572456996887922, 0.0020900319796055555, 0.002154373098164797, 0.0021883684676140547, 0.0022221419494599104, 0.002040392253547907, 0.0021101057063788176, 0.0020772069692611694, 0.002053638221696019, 0.002009156160056591, 0.0020557690877467394, 0.002043257700279355, 0.002070210874080658, 0.0019881613552570343, 0.00195932574570179, 0.002020113170146942, 0.0019172735046595335, 0.001928234938532114, 0.0018518853466957808, 0.1563476324081421, 0.001912532141432166, 0.001972491154447198, 0.002023231005296111, 0.0018534200498834252, 0.0018695954931899905, 0.0019211394246667624, 0.0018918266287073493, 0.001855761045590043, 0.14276081323623657, 0.0019717446994036436, 0.0018620395567268133, 0.001873912988230586, 0.0019337392877787352, 0.13155218958854675, 0.0019644219428300858, 0.0020260915625840425, 0.1307242214679718, 0.002121607307344675, 0.1204923763871193, 0.0022195596247911453, 0.0022079532500356436, 0.0022476855665445328, 0.002367331413552165, 0.002355402335524559, 0.0024286408443003893, 0.002414954826235771, 0.0024217842146754265, 0.12288756668567657, 0.0025301494169980288, 0.1457725316286087, 0.11350920796394348, 0.0026862728409469128, 0.12938763201236725, 0.0028630918823182583, 0.0029161705169826746, 0.0030977714341133833, 0.0030891236383467913, 0.0032206187024712563, 0.0031589320860803127, 0.00331009179353714, 0.0033337431959807873, 0.09689253568649292, 0.0033875086810439825, 0.0034675588831305504, 0.0034309301991015673, 0.003474260214716196, 0.003400500863790512, 0.16383127868175507, 0.0034785501193255186, 0.0035986830480396748, 0.003576525952666998, 0.003604972967877984, 0.003511326387524605, 0.11800255626440048, 0.0037814362440258265, 0.0036989247892051935, 0.10587822645902634, 0.003686778247356415, 0.003747778246179223, 0.0038959872908890247, 0.0038620883133262396, 0.0037907809019088745, 0.0037618426140397787, 0.003733815159648657, 0.003685475792735815, 0.0036917177494615316, 0.003643136704340577, 0.003587506478652358, 0.0036849614698439837, 0.10095781087875366, 0.0035262354649603367, 0.0036508343182504177, 0.003501098370179534, 0.0036126638296991587, 0.0035828757099807262, 0.0037235997151583433, 0.003501102328300476, 0.003578194184228778, 0.003449508920311928, 0.11261886358261108, 0.0034766204189509153, 0.0034980815835297108, 0.003384960815310478, 0.00341561296954751, 0.003358889603987336, 0.15408733487129211, 0.0033058077096939087, 0.0033718871418386698, 0.0035447455011308193, 0.0032983834389597178, 0.003433152800425887, 0.003381490707397461, 0.003332710824906826, 0.11408255994319916, 0.00338964955881238, 0.003226454136893153, 0.003416534746065736, 0.00325892586261034, 0.0032186296302825212, 0.0032845677342265844, 0.0032399077899754047, 0.0031811511144042015, 0.003277398878708482, 0.15569569170475006, 0.00344433868303895, 0.13108952343463898, 0.0032596418168395758, 0.0037291808985173702, 0.003519898047670722, 0.0033051022328436375, 0.003459618426859379, 0.003441120497882366, 0.003432092722505331, 0.0032764344941824675, 0.003295607166364789, 0.0033054298255592585, 0.0032151599880307913, 0.003247178392484784, 0.0031985186506062746, 0.003237701952457428, 0.0031300296541303396, 0.0031896261498332024, 0.12664230167865753, 0.0030570460949093103, 0.003038478549569845, 0.0030584903433918953, 0.0031300722621381283, 0.0030092827510088682, 0.0030144250486046076, 0.11763034015893936, 0.002990140812471509, 0.0032023575622588396, 0.0030730769503861666, 0.0030391737818717957, 0.0030259015038609505, 0.003024818142876029, 0.0031796421390026808, 0.003092435421422124, 0.0029706198256462812, 0.0029833365697413683, 0.002943348605185747, 0.0028980551287531853, 0.002842007903382182, 0.002835181076079607, 0.0028809127397835255, 0.002836004365235567, 0.002828493481501937, 0.002738796640187502, 0.0027054643724113703, 0.0027129079680889845, 0.0026929182931780815, 0.002576921135187149, 0.0026371937710791826, 0.0027202123310416937, 0.12134689092636108, 0.002486523473635316, 0.0024930937215685844, 0.002555012935772538, 0.002492432715371251, 0.002554874634370208, 0.002500284928828478, 0.0024305868428200483, 0.0024217867758125067, 0.0024606387596577406, 0.002459513721987605, 0.002356976503506303, 0.002383184852078557, 0.1440456062555313, 0.0023484393022954464, 0.0024464731104671955, 0.0023495652712881565, 0.0024334280751645565, 0.0023859068751335144, 0.0024002830032259226, 0.002405688166618347, 0.0023295050486922264, 0.002369482535868883, 0.002343899104744196, 0.002275734208524227, 0.0023076781071722507, 0.0022746652830392122, 0.0023629553616046906, 0.0022730273194611073, 0.0022214879281818867, 0.0021885803434997797, 0.0021521863527595997, 0.0022435677237808704, 0.131611168384552, 0.0022032076958566904, 0.0021304029505699873, 0.002198886126279831, 0.0021805150900036097, 0.002154882065951824, 0.002254204824566841, 0.002150588668882847, 0.002152135595679283, 0.0021253644954413176, 0.13990037143230438, 0.0021539079025387764, 0.0021314879413694143, 0.0022275925148278475, 0.0022062482312321663, 0.0022166091948747635, 0.0021365454886108637, 0.0022190501913428307, 0.09695838391780853, 0.0022062717471271753, 0.002226416952908039, 0.002184163313359022, 0.11040746420621872, 0.0022853747941553593, 0.0023942594416439533, 0.0023516921792179346, 0.10368232429027557, 0.0024332008324563503, 0.0023873921018093824, 0.0023915821220725775, 0.1065916046500206, 0.0027313141617923975, 0.0025242201518267393, 0.002588655799627304, 0.0027261332143098116, 0.0026588968466967344, 0.0026595676317811012, 0.002574110170826316, 0.0026448387652635574, 0.0026115200016647577, 0.0027552456595003605, 0.0026131963822990656, 0.0026849249843508005, 0.002591753378510475, 0.0027476518880575895, 0.0025330183561891317, 0.002572413766756654, 0.002524863462895155, 0.0025871307589113712, 0.0024874696973711252, 0.12620091438293457, 0.0024583793710917234, 0.002545850584283471, 0.002431799890473485, 0.00243798503652215, 0.002493437146767974, 0.002444263780489564, 0.0024690325371921062, 0.0024193075951188803, 0.0023845755495131016, 0.09317458420991898, 0.0024179324973374605, 0.002507298719137907, 0.002452560467645526, 0.002544606802985072, 0.0024717827327549458, 0.002442756202071905, 0.002377336146309972, 0.0024336250498890877, 0.002467094687744975, 0.0023436867631971836, 0.16879014670848846, 0.002371367998421192, 0.002437151735648513, 0.002494575222954154, 0.0025254315696656704, 0.0023938906379044056, 0.0024851246271282434, 0.002429352840408683, 0.0024641132913529873, 0.0024565865751355886, 0.002424121368676424, 0.0023751237895339727, 0.002371370792388916, 0.0023896561469882727, 0.00234698923304677, 0.0024192696437239647, 0.0023108436726033688, 0.0022289406042546034, 0.002247554250061512, 0.002358217490836978, 0.0022194168996065855, 0.00220666010864079, 0.0023537715896964073, 0.0021564809139817953, 0.0020813504233956337, 0.002076885662972927, 0.002071879105642438, 0.00204669451341033, 0.0020198433194309473, 0.002054371405392885, 0.002025045221671462, 0.0020237776916474104, 0.0020017933566123247, 0.00222570332698524, 0.0020185986068099737, 0.1488872915506363, 0.0018956235144287348, 0.0019964943639934063, 0.002121512545272708, 0.0019568991847336292, 0.001966585638001561, 0.001979150576516986, 0.0018908469937741756, 0.001970575423911214, 0.14422908425331116, 0.16943369805812836, 0.0020472658798098564, 0.0019832446705549955, 0.002022434724494815, 0.0021345997229218483, 0.002061128383502364, 0.002068218542262912, 0.002158984774723649, 0.0021038870327174664, 0.0021232618018984795, 0.0021341468673199415, 0.0021025286987423897, 0.002142147859558463, 0.12215632945299149, 0.0021340171806514263, 0.002126610605046153, 0.0021407578606158495, 0.0023118911776691675, 0.12610195577144623, 0.0021850704215466976, 0.0022376400884240866, 0.0022753714583814144, 0.002240524161607027, 0.0024719617795199156, 0.1268855482339859, 0.0023124946746975183, 0.13078615069389343, 0.13221785426139832, 0.0024499620776623487, 0.0025814175605773926, 0.0025823297910392284, 0.002624076558277011, 0.002651388291269541, 0.0027569292578846216, 0.12437736243009567, 0.002780014183372259, 0.0027965311892330647, 0.002947677858173847, 0.002814479172229767, 0.0030725658871233463, 0.002964118029922247, 0.00292662694118917, 0.0029641769360750914, 0.0030199154280126095, 0.0030041856225579977, 0.0029664598405361176, 0.002932588569819927, 0.0029566248413175344, 0.002852599136531353, 0.0028626779094338417, 0.0028342315927147865, 0.002967084990814328, 0.1132398471236229, 0.002856805920600891, 0.002950537484139204, 0.002784055657684803, 0.002817243803292513, 0.002857483923435211, 0.0027588214725255966, 0.002855034777894616, 0.0027454919181764126, 0.002783479169011116, 0.0027137466240674257, 0.0028266545850783587, 0.003038445021957159, 0.002642652252689004, 0.002717372728511691, 0.0026531931944191456, 0.0026212255470454693, 0.0025974216405302286, 0.0025129877030849457, 0.002739377086982131, 0.002487118588760495, 0.002589515410363674, 0.0024234119337052107, 0.0024701307993382215, 0.0024831052869558334, 0.12451138347387314, 0.0023941544350236654, 0.0024817571975290775, 0.0024709091521799564, 0.0025901985354721546, 0.002388325287029147, 0.002322860062122345, 0.0023481976240873337, 0.0024013121146708727, 0.0024834563955664635, 0.0025165921542793512, 0.09827083349227905, 0.002463742857798934, 0.002343056257814169, 0.0023192730732262135, 0.0024247111286967993, 0.002337512793019414, 0.002292020246386528, 0.0022665406577289104, 0.002309068338945508, 0.0022409057710319757, 0.0022459409665316343, 0.002213646424934268, 0.002219340531155467, 0.0023414597380906343, 0.08813614398241043, 0.00230772839859128, 0.0022335315588861704, 0.002218229230493307, 0.1762463003396988, 0.00220821937546134, 0.0023166744504123926, 0.002300247084349394, 0.002274176338687539, 0.0023594354279339314, 0.002268347190693021, 0.002260728972032666, 0.0022701267153024673, 0.002315953141078353, 0.002269465709105134, 0.12161432206630707, 0.002349578309804201, 0.002368832239881158, 0.0025694018695503473, 0.11578807234764099, 0.0024287994019687176, 0.0024128982331603765, 0.002455998444929719, 0.002481458941474557, 0.5493226051330566, 0.0024753264151513577, 0.002591133816167712, 0.0028044688515365124, 0.10590341687202454, 0.0028254438657313585, 0.0029059648513793945, 0.002997936448082328, 0.0030642070341855288, 0.003172799712046981, 0.003127272240817547, 0.0031943311914801598, 0.00334315188229084, 0.0034456958528608084, 0.003310066880658269, 0.0033344244584441185, 0.0034075072035193443, 0.0033688999246805906, 0.0033813933841884136, 0.0033193889539688826, 0.003308529034256935, 0.0033469873014837503, 0.003216515062376857, 0.11955909430980682, 0.003495272947475314, 0.0031918524764478207, 0.00326540507376194, 0.003213821677491069, 0.0032313864212483168, 0.0032062812242656946, 0.0031531164422631264, 0.003295780858024955, 0.0031294359359890223, 0.003149872412905097, 0.21590982377529144, 0.0031572235748171806, 0.0031422683969140053, 0.0030949271749705076, 0.0032090763561427593, 0.0031889404635876417, 0.0031591919250786304, 0.0031513061840087175, 0.0031192598398774862, 0.0030517783015966415, 0.1607840210199356, 0.0031137745827436447, 0.0030369271989911795, 0.0030193766579031944, 0.0030589865054935217, 0.0030333823524415493, 0.003066422650590539, 0.003104611998423934, 0.0029835598543286324, 0.0030112217646092176, 0.003051060950383544, 0.002940719248726964, 0.0029757546726614237, 0.15197019279003143, 0.0029179512057453394, 0.0030089744832366705, 0.0029958856757730246, 0.003020190866664052, 0.0028951941058039665, 0.0028658127412199974, 0.00288335420191288, 0.0028559251222759485, 0.0029437514021992683, 0.11820438504219055, 0.002872923854738474, 0.002865749644115567, 0.002820175839588046, 0.002846115967258811, 0.0028549297712743282, 0.0028639149386435747, 0.0028363296296447515, 0.0028232589829713106, 0.0028065177612006664, 0.002817843807861209, 0.0027548347134143114, 0.002817742293700576, 0.0029571191407740116, 0.0027552528772503138, 0.0028942464850842953, 0.0026735879946500063, 0.002736604306846857, 0.0026396350003778934, 0.0026282365433871746, 0.0736033245921135, 0.12885423004627228, 0.002567955758422613, 0.0026347385719418526, 0.002615374745801091, 0.0026895173359662294, 0.0026307469233870506, 0.0026541738770902157, 0.002659472869709134, 0.0026628451887518167, 0.0026784951332956553, 0.11645692586898804, 0.002839325461536646, 0.12684474885463715, 0.0028750337660312653, 0.0026985371951013803, 0.002663379767909646, 0.0028830759692937136, 0.0028398192953318357, 0.002728026593104005, 0.002753437263891101, 0.002822995651513338, 0.002763863420113921, 0.0027484260499477386, 0.1080690324306488, 0.002731133485212922, 0.002707247156649828, 0.00275333970785141, 0.0028600175864994526, 0.0027486616745591164, 0.002746874000877142, 0.0028293426148593426, 0.0027144865598529577, 0.09306645393371582, 0.0027435142546892166, 0.0027558114379644394, 0.0027322066016495228, 0.0028288806788623333, 0.0027190553955733776, 0.002844402566552162, 0.0027283814270049334, 0.0027125754859298468, 0.0027451966889202595, 0.0026838325429707766, 0.002692936919629574, 0.002846076153218746, 0.0026541196275502443, 0.00261805416084826, 0.0027015777304768562, 0.002586822723969817, 0.0026490050368010998, 0.002572565106675029, 0.0025378402788192034, 0.002497715875506401, 0.0025267445016652346, 0.002572456141933799, 0.0025241621769964695, 0.0027108737267553806, 0.002524047391489148, 0.0023718485608696938, 0.0024508542846888304, 0.0024108425714075565, 0.0023225280456244946, 0.002397475065663457, 0.002353664254769683, 0.0023119808174669743, 0.12812523543834686, 0.1371375173330307, 0.0022635268978774548, 0.002325800247490406, 0.0023162190336734056, 0.002413772977888584, 0.0025978474877774715, 0.002396151190623641, 0.0024267828557640314, 0.0023505815770477057, 0.0023722643963992596, 0.0023429873399436474, 0.0024454621598124504, 0.002327665453776717, 0.14650864899158478, 0.0023851278237998486, 0.0023162777069956064, 0.002377858152613044, 0.002334210090339184, 0.002351408125832677, 0.0023271588142961264, 0.002490494167432189, 0.002580400789156556, 0.1165100708603859, 0.0023339143954217434, 0.0024305216502398252, 0.0025191104505211115, 0.0024066346231848, 0.10196767747402191, 0.0024962069001048803, 0.002415767405182123, 0.002410843037068844, 0.002424105303362012, 0.002478193724527955, 0.002485203556716442, 0.002559248823672533, 0.0024734088219702244, 0.0024702574592083693, 0.0023985584266483784, 0.0025699557736516, 0.0025616048369556665, 0.002441579010337591, 0.002473212080076337, 0.002384735969826579, 0.002371501410380006, 0.0025163465179502964, 0.002371592679992318, 0.0022981471847742796, 0.0023595585953444242, 0.002366904867812991, 0.002455674111843109, 0.0023479294031858444, 0.0022554125171154737, 0.0023498230148106813, 0.0024782412219792604, 0.0022020942997187376, 0.002339808037504554, 0.0021973522379994392, 0.0021470182109624147, 0.0021684332750737667, 0.0021340269595384598, 0.002149638021364808, 0.0021167027298361063, 0.002174968831241131, 0.002069273265078664, 0.002091282280161977, 0.0022054582368582487, 0.0020290557295084, 0.0020739533938467503, 0.002009052550420165, 0.002042302628979087, 0.0020417580381035805, 0.001965415431186557, 0.001941980211995542, 0.0019536465406417847, 0.0018961804453283548, 0.001946483738720417, 0.001873041270300746, 0.0019007624359801412, 0.1418483406305313, 0.001878459588624537, 0.0019414228154346347, 0.002064793137833476, 0.0019531301222741604, 0.0019749808125197887, 0.0019955860916525126, 0.0018575700232759118, 0.0018996383296325803, 0.14747218787670135, 0.001863852608948946, 0.001910768449306488, 0.001963339513167739, 0.0018947182688862085, 0.0019179857335984707, 0.0019049098482355475, 0.001958925276994705, 0.0019957488402724266, 0.0018825654406100512, 0.0018949131481349468, 0.0020202137529850006, 0.001979358494281769, 0.001964814495295286, 0.0018608059035614133, 0.0018924636533483863, 0.0018438438419252634, 0.13495689630508423, 0.0019170161103829741, 0.0019376750569790602, 0.0018911556107923388, 0.001917896792292595, 0.0019562202505767345, 0.0019635139033198357, 0.001973890233784914, 0.0019182978430762887, 0.0019270090851932764, 0.0019806150812655687, 0.11682279407978058, 0.002002007095143199, 0.0018944389885291457, 0.001944674993865192, 0.4754219353199005, 0.10899645835161209, 0.0020346958190202713, 0.11295904219150543, 0.002338589169085026, 0.002266430528834462, 0.0024059414863586426, 0.0023456683848053217, 0.002448210958391428, 0.0025969918351620436, 0.002515781205147505, 0.0025227018631994724, 0.0025171134620904922, 0.002562113804742694, 0.47643032670021057, 0.11168695241212845, 0.002865132177248597, 0.002846742980182171, 0.003139772219583392, 0.002983814338222146, 0.11566769331693649, 0.003093387931585312, 0.0031827192287892103, 0.12372986972332001, 0.0033074149396270514, 0.0035106332506984472, 0.0034243164118379354, 0.0036035433877259493, 0.0035509259905666113, 0.003515912452712655, 0.003771816845983267, 0.0035706586204469204, 0.0037952715065330267, 0.003543232800439, 0.0036326004192233086, 0.0036840145476162434, 0.0036241228226572275, 0.003558902768418193, 0.0036326816771179438, 0.0036785986740142107, 0.0037291222251951694, 0.1550123244524002, 0.0036567365750670433, 0.0035625549498945475, 0.0036569840740412474, 0.14391474425792694, 0.0036093960516154766, 0.0035636199172586203, 0.00360816135071218, 0.11374341696500778, 0.003576215822249651, 0.0036757993511855602, 0.12621423602104187, 0.0040810126811265945, 0.16209402680397034, 0.1416456550359726, 0.003797398414462805, 0.0037473225966095924, 0.0038728718645870686, 0.0038699335418641567, 0.0038475417532026768, 0.0038942869286984205, 0.003914685919880867, 0.0040283771231770515, 0.003927670884877443, 0.003951311577111483, 0.003841336816549301, 0.0038559280801564455, 0.15334086120128632, 0.003912713378667831, 0.003984172362834215, 0.004092221148312092, 0.0038497759960591793, 0.0039705755189061165, 0.003974230960011482, 0.003955880645662546, 0.0038893509190529585, 0.003970993682742119, 0.003811935894191265, 0.0038093707989901304, 0.004058809485286474, 0.003876921720802784, 0.0037698079831898212, 0.003705149283632636, 0.003717222949489951, 0.0037569189444184303, 0.0037587108090519905, 0.0038358198944479227, 0.003573064226657152, 0.0035718418657779694, 0.003510811133310199, 0.0035097997169941664, 0.00345693901181221, 0.003557477844879031, 0.003517996985465288, 0.0033836127258837223, 0.003350461833178997, 0.0034284398425370455, 0.0033255943562835455, 0.003310488536953926, 0.0033369038719683886, 0.0033921271096915007, 0.003361515235155821, 0.0032775576692074537, 0.0032653193920850754, 0.0031525238882750273, 0.003180191619321704, 0.0031627549324184656, 0.00315305357798934, 0.0030877699609845877, 0.0030795964412391186, 0.003105549141764641, 0.0030037304386496544, 0.002966298023238778, 0.10290291160345078, 0.0029868916608393192, 0.002923337509855628, 0.002927370136603713, 0.0029474287293851376, 0.003047438571229577, 0.47234460711479187, 0.0031006131321191788, 0.0031254084315150976, 0.003177866106852889, 0.0030679521150887012, 0.003095840336754918, 0.0032717299181967974, 0.003197914222255349, 0.0033292032312601805, 0.00325588951818645, 0.12922990322113037, 0.003183412365615368, 0.0032220366410911083, 0.09499887377023697, 0.40414464473724365, 0.0033679711632430553, 0.003679843619465828, 0.0034573120065033436, 0.003493459429591894, 0.0035715943668037653, 0.003571860259398818, 0.0037299811374396086, 0.0037699441891163588, 0.0037247107829898596, 0.0037906519137322903, 0.003928058780729771, 0.0037721830885857344, 0.00388448778539896, 0.00380718894302845, 0.003952306229621172, 0.00401994027197361, 0.003818799974396825, 0.004082259722054005, 0.003772815689444542, 0.0036334358155727386, 0.1363428682088852, 0.003710666438564658, 0.003645368618890643, 0.003798512276262045, 0.003695062827318907, 0.003703450784087181, 0.00377919664606452, 0.0036490110214799643, 0.003814616473391652, 0.0036087878979742527, 0.0036262127105146646, 0.0037243252154439688, 0.0038511452730745077, 0.004128805361688137, 0.0036382682155817747, 0.003560960292816162, 0.0036136473063379526, 0.0035250899381935596, 0.0034050343092530966, 0.0035044571850448847, 0.0034873164258897305, 0.003404804039746523, 0.00342928571626544, 0.0033037210814654827, 0.0033663774374872446, 0.003276126692071557, 0.0032975939102470875, 0.003271982306614518, 0.0033474008087068796, 0.003248703433200717, 0.003374433610588312, 0.0031810635700821877, 0.0032193041406571865, 0.003376000327989459, 0.0031720413826406, 0.0031056494917720556, 0.0030726382974535227, 0.0034077081363648176, 0.0030150660313665867, 0.0032065098639577627, 0.002990011591464281, 0.002966102911159396, 0.0031452488619834185, 0.0029991574119776487, 0.002999760676175356, 0.16829709708690643, 0.14094561338424683, 0.0029551556799560785, 0.003232120769098401, 0.0031356471590697765, 0.00316612864844501, 0.0030167519580572844, 0.15296074748039246, 0.0030012044589966536, 0.0030353390611708164, 0.0030221694614738226, 0.0030158355366438627, 0.0030503373127430677, 0.0031662185210734606, 0.0030911292415112257, 0.0030647984240204096, 0.0029826583340764046, 0.002970148343592882, 0.002924742177128792, 0.0029934735503047705, 0.002989004133269191, 0.002900812542065978, 0.0030597439035773277, 0.0029526676516979933, 0.0029371699783951044, 0.0030266374815255404, 0.003005977487191558, 0.002949272748082876, 0.13277310132980347, 0.002833498176187277, 0.14877741038799286, 0.0031439221929758787, 0.002944303909316659, 0.5101266503334045, 0.002981375902891159, 0.0030604463536292315, 0.0030723626259714365, 0.003217348363250494, 0.00323647353798151, 0.003164873691275716, 0.0032192543148994446, 0.0032174603547900915, 0.0031402974855154753, 0.003176458878442645, 0.003181896870955825, 0.0032102474942803383, 0.003370316233485937, 0.00320479366928339, 0.003211966482922435, 0.0032325845677405596, 0.003221839666366577, 0.003200327744707465, 0.003243987215682864, 0.0032230804208666086, 0.003115406259894371, 0.003225828753784299, 0.003107791766524315, 0.003128439886495471, 0.0032534226775169373, 0.0031384543981403112, 0.0031135210301727057, 0.0030624219216406345, 0.0032242576126009226, 0.0030569343362003565, 0.0030194795690476894, 0.0031482663471251726, 0.003002629615366459, 0.13405705988407135, 0.10599308460950851, 0.1020311489701271, 0.003049912629649043, 0.003215111093595624, 0.003183285938575864, 0.10153170675039291, 0.0031986122485250235, 0.0031191345769912004, 0.0031272436026483774, 0.003198179416358471, 0.0032444577664136887, 0.15423056483268738, 0.0031416306737810373, 0.0032411268912255764, 0.0031491322442889214, 0.0031262291595339775, 0.0031959384214133024, 0.003315952606499195, 0.003145878203213215, 0.11028856039047241, 0.0032949838787317276, 0.003233401570469141, 0.003250081092119217, 0.00321308639831841, 0.10656261444091797, 0.003459353232756257, 0.1096666157245636, 0.0034949956461787224, 0.0033537186682224274, 0.003208346199244261, 0.0034058974124491215, 0.0034376815892755985, 0.003220216603949666, 0.003260550554841757, 0.003224459942430258, 0.0033099898137152195, 0.0033023206051439047, 0.003424406982958317, 0.0033391539473086596, 0.0033446152228862047, 0.0034430180676281452, 0.1399790644645691, 0.003229368245229125, 0.0031766619067639112, 0.0032224804162979126, 0.0032366793602705, 0.00319721014238894, 0.0035792419221252203, 0.0034977386239916086, 0.003217520657926798, 0.0035838624462485313, 0.003149844706058502, 0.0033350095618516207, 0.419544517993927, 0.0031691528856754303, 0.00319752492941916, 0.0032697110436856747, 0.003231234848499298, 0.0032297635916620493, 0.0032577954698354006, 0.10462018102407455, 0.0033076514955610037, 0.0034916577860713005, 0.003498538862913847, 0.003373567946255207, 0.003411571029573679, 0.0034464949276298285, 0.003527875989675522, 0.12778884172439575, 0.003422212554141879, 0.003539369208738208, 0.1586267203092575, 0.0034103563521057367, 0.0034710385370999575, 0.0033985821064561605, 0.0034188844729214907, 0.003602596465498209, 0.0034284801222383976, 0.0034956298768520355, 0.0033917513210326433, 0.0034027465153485537, 0.0034691786859184504, 0.0034884256310760975, 0.15406575798988342, 0.0034162411466240883, 0.0034672163892537355, 0.003410614561289549, 0.003402737667784095, 0.1263965219259262, 0.0034532586578279734, 0.0035680399741977453, 0.0034401139710098505, 0.0034029993694275618, 0.003456531558185816, 0.0034744369331747293, 0.003422283800318837, 0.0035083305556327105, 0.0033783731050789356, 0.003443723311647773, 0.0034422471653670073, 0.0034017472062259912, 0.0035455224569886923, 0.0034017472062259912, 0.0034678601659834385, 0.11247668415307999, 0.0033214956056326628, 0.0033642679918557405, 0.0033604472409933805, 0.003296361304819584, 0.0034285306464880705, 0.0033698738552629948, 0.12679393589496613, 0.0033659108448773623, 0.0033022291027009487, 0.003348307451233268, 0.003472414566203952, 0.14513878524303436, 0.003485536901280284, 0.0033471309579908848, 0.0034378068521618843, 0.0033960663713514805, 0.003331803483888507, 0.003440101630985737, 0.12594391405582428, 0.003409758908674121, 0.0033937201369553804, 0.003478681668639183, 0.003459440777078271, 0.003343911375850439, 0.003382677910849452, 0.15367679297924042, 0.003365840297192335, 0.003482811851426959, 0.003537623444572091, 0.0033437395468354225, 0.003464701119810343, 0.003319195471704006, 0.14441797137260437, 0.0033198792953044176, 0.003358393907546997, 0.003376623149961233, 0.003370128571987152, 0.0034503196366131306, 0.0032856909092515707, 0.003312943736091256, 0.0033250651322305202, 0.15868301689624786, 0.0033740513026714325, 0.10147427767515182, 0.14864887297153473, 0.0035304317716509104, 0.003427390241995454, 0.09359021484851837, 0.0033708661794662476, 0.0034003404434770346, 0.0033969494979828596, 0.0034173633903265, 0.10769835859537125, 0.0036333282478153706, 0.0034707721788436174, 0.003426862647756934, 0.0034764758311212063, 0.003444875590503216, 0.003495498327538371, 0.0035719801671802998, 0.0035397843457758427, 0.003434505546465516, 0.0037453840486705303, 0.0034380764700472355, 0.003462282009422779, 0.003507455810904503, 0.003436592873185873, 0.003457908984273672, 0.003468941431492567, 0.003412896767258644, 0.0034178695641458035, 0.003484342945739627, 0.0034426564816385508, 0.0033805742859840393, 0.0034934175200760365, 0.0033277785405516624, 0.003413537982851267, 0.003323587588965893, 0.0034155668690800667, 0.0033401763066649437, 0.0034022731706500053, 0.0033440296538174152, 0.003387383883818984, 0.0033233752474188805, 0.0033409404568374157, 0.003228356596082449, 0.00335355824790895, 0.003314501838758588, 0.0033148254733532667, 0.0031596655026078224, 0.0031676918733865023, 0.0031350578647106886, 0.003131286008283496, 0.0032886976841837168, 0.0031399624422192574, 0.0031981084030121565, 0.0033660419285297394, 0.003086325479671359, 0.4992169737815857, 0.003084592055529356, 0.003175301942974329, 0.003171200631186366, 0.003220385406166315, 0.0032460070215165615, 0.003226578002795577, 0.003175671910867095, 0.003198379185050726, 0.003178343176841736, 0.003186643123626709, 0.003245870815590024, 0.00316649884916842, 0.0034553075674921274, 0.003255868097767234, 0.0032235339749604464, 0.0031555420719087124, 0.0031733110081404448, 0.003185605863109231, 0.0033739665523171425, 0.17083966732025146, 0.003204073989763856, 0.003282648278400302, 0.12533172965049744, 0.15288680791854858, 0.00318822986446321, 0.0031651456374675035, 0.0032850676216185093, 0.003285393351688981, 0.0033020114060491323, 0.003225108841434121, 0.0033131660893559456, 0.10923052579164505, 0.0031940501648932695, 0.00321430922485888, 0.003212414216250181, 0.0032425052486360073, 0.003418348729610443, 0.0032346865627914667, 0.0032491907477378845, 0.003294127993285656, 0.13135549426078796, 0.003252317663282156, 0.003256020834669471, 0.003215550910681486, 0.17785488069057465, 0.1027735099196434, 0.0035049342550337315, 0.0033655259758234024, 0.0033229815308004618, 0.003267854917794466, 0.0033788944128900766, 0.00328358868137002, 0.0032793621066957712, 0.003305257298052311, 0.003335068002343178, 0.12179531157016754, 0.003490518545731902, 0.0033293338492512703, 0.0034552779980003834, 0.003399783978238702, 0.0032567044254392385, 0.003260285360738635, 0.003325661877170205, 0.003410422010347247, 0.003309044288471341, 0.003348556812852621, 0.0034142970107495785, 0.003272435860708356, 0.0033386896830052137, 0.003363589756190777, 0.0032314322888851166, 0.12472385168075562, 0.003295087954029441, 0.11747895181179047, 0.0032270431984215975, 0.003258325392380357, 0.0033535195980221033, 0.003310706466436386, 0.0033278537448495626, 0.0034109987318515778, 0.0032425341196358204, 0.11581423878669739, 0.003318465780466795, 0.0032763187773525715, 0.003280690871179104, 0.003238571574911475, 0.0032443555537611246, 0.0032809616532176733, 0.0032987806480377913, 0.00322473025880754, 0.0032458885107189417, 0.003248996566981077, 0.10621186345815659, 0.0033353043254464865, 0.0032107627484947443, 0.0033061436843127012, 0.003208313835784793, 0.003254135837778449, 0.003340780269354582, 0.0032221192959696054, 0.10783778876066208, 0.0032046670094132423, 0.003242253791540861, 0.0032265991903841496, 0.003297459101304412, 0.0034407037310302258, 0.003214937401935458, 0.0031825602054595947, 0.0034627472050487995, 0.13533149659633636, 0.0032563828863203526, 0.003232656279578805, 0.0032365252263844013, 0.003263609018176794, 0.0032813693396747112, 0.0033992864191532135, 0.1302681416273117, 0.003195791272446513, 0.0032943114638328552, 0.0033497989643365145, 0.003206342225894332, 0.0032016250770539045, 0.0032652406953275204, 0.003275952534750104, 0.003170798299834132, 0.0031676115468144417, 0.0031727503519505262, 0.003230996197089553, 0.0031518316827714443, 0.0031767424661666155, 0.0033294474706053734, 0.13474200665950775, 0.0031736453529447317, 0.12268980592489243, 0.12423522770404816, 0.0032012811861932278, 0.003213188610970974, 0.003153355559334159, 0.0032657431438565254, 0.0031998688355088234, 0.0031880750320851803, 0.0031993172597140074, 0.0032053629402071238, 0.003385571762919426, 0.003163756337016821, 0.0033546527847647667, 0.003438472980633378, 0.0033488068729639053, 0.003243120852857828, 0.003304121783003211, 0.10714268684387207, 0.0031863320618867874, 0.003144532674923539, 0.003288388717919588, 0.003148213727399707, 0.003140531713142991, 0.003161780769005418, 0.0031601039227098227, 0.0031668473966419697, 0.0032408330589532852, 0.003199991537258029, 0.13118623197078705, 0.0031447261571884155, 0.0031221802346408367, 0.0034159300848841667, 0.0032626562751829624, 0.003176608355715871, 0.13757048547267914, 0.003254730487242341, 0.003228134009987116, 0.0032393354922533035, 0.0031848964281380177, 0.09619508683681488, 0.0032034385949373245, 0.0032446603290736675, 0.139914408326149, 0.0031860789749771357, 0.00318724662065506, 0.0031621726229786873, 0.0033311101142317057, 0.0033041362185031176, 0.0032994840294122696, 0.003245334606617689, 0.0031479056924581528, 0.0033004183787852526, 0.003150427248328924, 0.003190079238265753, 0.0032054977491497993, 0.0031540642958134413, 0.003143246518447995, 0.003195991273969412, 0.003201216459274292, 0.0033022284042090178, 0.003307612147182226, 0.003171587362885475, 0.00323850242421031, 0.08992141485214233, 0.0031188458669930696, 0.003110844874754548, 0.00318243820220232, 0.003299360629171133, 0.0033928381744772196, 0.003150960197672248, 0.0032138803508132696, 0.003132693935185671, 0.003115735948085785, 0.13259507715702057, 0.00311574200168252, 0.003111804137006402, 0.003132830373942852, 0.0031536458991467953, 0.003139073960483074, 0.0031570822466164827, 0.0031305530574172735, 0.0030820490792393684, 0.003104869043454528, 0.0031023682095110416, 0.0030663632787764072, 0.0032337771262973547, 0.003132983110845089, 0.003219546750187874, 0.003142192028462887, 0.0031422448810189962, 0.0031248009763658047, 0.003066065488383174, 0.0031395822297781706, 0.003074806882068515, 0.0030622801277786493, 0.0030867562163621187, 0.0031185809057205915, 0.003064920660108328, 0.0030397966038435698, 0.0030859883408993483, 0.003040900221094489, 0.003026180900633335, 0.0031280131079256535, 0.0031075815204530954, 0.003074867185205221, 0.0030703230295330286, 0.0030216306913644075, 0.13583984971046448, 0.0030187356751412153, 0.0031626203563064337, 0.0030764255207031965, 0.003025861456990242, 0.003013906767591834, 0.15103209018707275, 0.0030566847417503595, 0.11814254522323608, 0.0030778145883232355, 0.0030754173640161753, 0.003086871700361371, 0.12156493961811066, 0.003050507279112935, 0.12159828096628189, 0.0030733097810298204, 0.0030346678104251623, 0.0031102574430406094, 0.0031706730369478464, 0.00307190278545022, 0.0030779698863625526, 0.003117753192782402, 0.003019502619281411, 0.0030505184549838305, 0.003061405848711729, 0.0030536174308508635, 0.0030263352673500776, 0.003104676026850939, 0.09326549619436264, 0.0030790416058152914, 0.0032841088250279427, 0.10976972430944443, 0.14314036071300507, 0.0030585851054638624, 0.0030384743586182594, 0.0030958307906985283, 0.003101922804489732, 0.0030618738383054733, 0.0032333810813724995, 0.0030989404767751694, 0.003063233569264412, 0.0030932717490941286, 0.0030511762015521526, 0.0031131806317716837, 0.0031827189959585667, 0.0030800180975347757, 0.0030596356373280287, 0.003043717471882701, 0.0030838712118566036, 0.003032140666618943, 0.0030251890420913696, 0.0032252767123281956, 0.0030910936184227467, 0.0031046243384480476, 0.0030365183483809233, 0.003086149226874113, 0.0030165226198732853, 0.0030983909964561462, 0.003147253068163991, 0.003109936835244298, 0.0030600973404943943, 0.0030150392558425665, 0.0030829368624836206, 0.0030935711693018675, 0.003013109788298607, 0.0030482029542326927, 0.003009177278727293, 0.0031106527894735336, 0.0031200966332107782, 0.0030433370266109705, 0.003038217080757022, 0.11387911438941956, 0.0030479233246296644, 0.003087007673457265, 0.003069276222959161, 0.00309358024969697, 0.0031447189394384623, 0.0031314147636294365, 0.0029951976612210274, 0.0030300274956971407, 0.003063792595639825, 0.003061093622818589, 0.003007745835930109, 0.003064013784751296, 0.00300790648907423, 0.14641140401363373, 0.0030744171235710382, 0.003081689588725567, 0.0030697693582624197, 0.003275462193414569, 0.0031011663377285004]\n",
            "Val loss 0.017485026968059533\n",
            "Val auc roc 0.42109396914446\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "297c9351-a390-4df0-b515-f30bc606ea00"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4a4a75b-17e4-425b-acfd-2cbf5a41b13e"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fff5f74a-898f-45fb-b6a7-c748e733f42e"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "a3a0617a-6a33-44fb-b03c-b4cd8e54da1d"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Generalized_Hate]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5221c241-fe38-4f0c-ea0a-b053a9ea4ea9"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-08-06 11:54:05.898964'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}