{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm_No_Dup_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3709022f287a438ca843c83dc99eec6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40ef56d77399465ab16dd8c655f38e99",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f734a46eb3494d828b008796cd2c3015",
              "IPY_MODEL_3409e1a2b798425b88863064c58e15a1"
            ]
          }
        },
        "40ef56d77399465ab16dd8c655f38e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f734a46eb3494d828b008796cd2c3015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9f773c825caf422fb37235499fc6e2e2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_334139f50c084e4bad6840824952ccb8"
          }
        },
        "3409e1a2b798425b88863064c58e15a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_149d91e7662d4507ac1ebb15e9652578",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:06&lt;00:00, 35.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8cb14ad89264e05bbd2af0f13c9f697"
          }
        },
        "9f773c825caf422fb37235499fc6e2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "334139f50c084e4bad6840824952ccb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "149d91e7662d4507ac1ebb15e9652578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8cb14ad89264e05bbd2af0f13c9f697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5fc8b47e2774011bda25f858876a5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_df99cac366464cd2b6b6c03b65dc0110",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8c24e4bb3c74bfc9b55409712005738",
              "IPY_MODEL_39371fd329a34ab9a1415a0484520277"
            ]
          }
        },
        "df99cac366464cd2b6b6c03b65dc0110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8c24e4bb3c74bfc9b55409712005738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e347c1cbbb74ec4aa1fc2e6f37698ed",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e6255de859949c8b70c3eb560e9913f"
          }
        },
        "39371fd329a34ab9a1415a0484520277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_832ed0d659594c6abb155f4e457cac2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [1:25:10&lt;00:00,  3.20s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11ee824bbaa449a0a2f5317928c88309"
          }
        },
        "3e347c1cbbb74ec4aa1fc2e6f37698ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e6255de859949c8b70c3eb560e9913f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "832ed0d659594c6abb155f4e457cac2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11ee824bbaa449a0a2f5317928c88309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d587d2e3d3d6449f8326b02b468fec30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_260ebc8ec4794ba6b09a4d523aa19c19",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_572fc659c17a4c6bbb6b53f54fbf3803",
              "IPY_MODEL_79f743816f5142ed96d5789f05cf3260"
            ]
          }
        },
        "260ebc8ec4794ba6b09a4d523aa19c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "572fc659c17a4c6bbb6b53f54fbf3803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3b74116c62f949b6b38f6d3aeb9e63c4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53f9edc511274920bd4d21e8a1e25ff1"
          }
        },
        "79f743816f5142ed96d5789f05cf3260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ff1be38540544f88ba96ba2c603fbc0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [27:58&lt;00:00,  1.05s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c4f4729f7f440c88cbc4afbbac52d3d"
          }
        },
        "3b74116c62f949b6b38f6d3aeb9e63c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53f9edc511274920bd4d21e8a1e25ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ff1be38540544f88ba96ba2c603fbc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c4f4729f7f440c88cbc4afbbac52d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e74fc10376d4b07979482aba983ebae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_664ec5ffe28e46b2b50bea537fdbc16f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa747c1d84dd4b908f3afe971247162d",
              "IPY_MODEL_d70b23e93bf3431c9554bbdc14e9c1f2"
            ]
          }
        },
        "664ec5ffe28e46b2b50bea537fdbc16f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa747c1d84dd4b908f3afe971247162d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe12a5d31eb744aa875f7c3f6e58dfa3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8f39ebb0b58404aae5e4db2aff5888f"
          }
        },
        "d70b23e93bf3431c9554bbdc14e9c1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7978192de14a4e70a47a397af706aca5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [27:55&lt;00:00,  1.05s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5fa18bdb34d41c5be95c52bfb87bef0"
          }
        },
        "fe12a5d31eb744aa875f7c3f6e58dfa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8f39ebb0b58404aae5e4db2aff5888f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7978192de14a4e70a47a397af706aca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5fa18bdb34d41c5be95c52bfb87bef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2201862f-375a-4f12-d337-8c1f8b92dde3"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 15.26 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6467ecf6-2f1c-410e-972f-6baf0202ca58"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86a37900-dbfa-4198-cd8a-0e2bcdfff94e"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "db4b726a-08a3-4b48-944e-2d83daf4e7d3"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0ab101a3-174b-4fb2-fba1-4a2aff2f1416"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "ed8b512b-b647-4f02-ef55-7736c223c20d"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 17.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1d261382-54e6-48c8-8856-dab7567c7689"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e26acea3-dd41-4615-d796-1b25e597204b"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "8e5ac200-57a2-43e1-c308-30e60a7b4a21"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "436a7acb-46e1-4329-dc6c-e1d37293c25a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    #CornerstoneCaroline is really out here tryna ...\n",
              "1    Time to empower one another! 💪🏻💪🏼💪🏽💪🏾💪🏿 #Metoo...\n",
              "2    Poll suggests backlash to #MeToo movement coul...\n",
              "3    #MeToo Merch - Man Equals Woman - 3\" Sew / Iro...\n",
              "4    Ghazala Wahab is the latest to speak out again...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7181493-0484-40a0-e26c-5847d64e934d"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:34<00:00, 11791628.36B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce4d5bfe-1244-4634-8916-69ee0e2e112e"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 310308.52B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "1d46a65e-0c97-4d94-dbba-54762863a082"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e21f40f-23e0-46cf-f9a9-0d2619a142b0"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        \n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        \n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bd2365b-fda6-4855-8a21-b01f96edbf57"
      },
      "source": [
        "col_name = \"Sarcasm\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760,
          "referenced_widgets": [
            "3709022f287a438ca843c83dc99eec6c",
            "40ef56d77399465ab16dd8c655f38e99",
            "f734a46eb3494d828b008796cd2c3015",
            "3409e1a2b798425b88863064c58e15a1",
            "9f773c825caf422fb37235499fc6e2e2",
            "334139f50c084e4bad6840824952ccb8",
            "149d91e7662d4507ac1ebb15e9652578",
            "a8cb14ad89264e05bbd2af0f13c9f697",
            "e5fc8b47e2774011bda25f858876a5c6",
            "df99cac366464cd2b6b6c03b65dc0110",
            "c8c24e4bb3c74bfc9b55409712005738",
            "39371fd329a34ab9a1415a0484520277",
            "3e347c1cbbb74ec4aa1fc2e6f37698ed",
            "4e6255de859949c8b70c3eb560e9913f",
            "832ed0d659594c6abb155f4e457cac2e",
            "11ee824bbaa449a0a2f5317928c88309",
            "d587d2e3d3d6449f8326b02b468fec30",
            "260ebc8ec4794ba6b09a4d523aa19c19",
            "572fc659c17a4c6bbb6b53f54fbf3803",
            "79f743816f5142ed96d5789f05cf3260",
            "3b74116c62f949b6b38f6d3aeb9e63c4",
            "53f9edc511274920bd4d21e8a1e25ff1",
            "7ff1be38540544f88ba96ba2c603fbc0",
            "4c4f4729f7f440c88cbc4afbbac52d3d",
            "8e74fc10376d4b07979482aba983ebae",
            "664ec5ffe28e46b2b50bea537fdbc16f",
            "fa747c1d84dd4b908f3afe971247162d",
            "d70b23e93bf3431c9554bbdc14e9c1f2",
            "fe12a5d31eb744aa875f7c3f6e58dfa3",
            "a8f39ebb0b58404aae5e4db2aff5888f",
            "7978192de14a4e70a47a397af706aca5",
            "a5fa18bdb34d41c5be95c52bfb87bef0"
          ]
        },
        "outputId": "1130dc1e-11f5-4079-8918-a9a1ec046096"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6382\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3709022f287a438ca843c83dc99eec6c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5fc8b47e2774011bda25f858876a5c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0209\n",
            "Train Losses : [0.1686479151248932, 0.2148076444864273, 0.328422874212265, 0.2657708525657654, 0.6548516750335693, 1.1633843183517456, 2.042356014251709, 1.0008596181869507, 0.5202145576477051, 0.08172910660505295, 0.10187235474586487, 0.0904683917760849, 0.13741132616996765, 0.10147765278816223, 0.5440549850463867, 0.31692758202552795, 0.13468977808952332, 0.1551719754934311, 0.10028086602687836, 0.08553800731897354, 0.5781309604644775, 0.06016547605395317, 0.027544882148504257, 0.04060864821076393, 0.018915636464953423, 0.011498693376779556, 0.00986927468329668, 0.008546224795281887, 0.01835126057267189, 0.057149965316057205, 0.0019503284711390734, 0.11353261023759842, 0.0036236450541764498, 0.001806096755899489, 0.0019006162183359265, 0.0010523112723603845, 0.001970812678337097, 0.0009480630396865308, 0.002769853686913848, 0.0004538052889984101, 0.0008726335363462567, 0.0005767046241089702, 0.19942831993103027, 0.0004000135522801429, 0.0008909419411793351, 0.0011342683574184775, 0.0015276552876457572, 0.0024643326178193092, 0.946394681930542, 0.000997356022708118, 0.000741773284971714, 0.0005869426531717181, 0.001652129809372127, 0.0022300879936665297, 0.0019752755761146545, 0.0037490003742277622, 0.0021491358056664467, 0.004357251804322004, 0.001692121266387403, 0.008370998315513134, 0.002129851607605815, 0.0019566321279853582, 0.516868531703949, 0.002127588028088212, 0.0005633631953969598, 0.0006651622825302184, 0.0007953488384373486, 0.000782887393143028, 0.0007212669588625431, 0.0005482961423695087, 0.0006462550372816622, 0.00046755222138017416, 0.0006433785310946405, 0.0006504902266897261, 0.000669048517011106, 0.0005330103449523449, 0.0008724575163796544, 0.0007309133070521057, 0.3798007667064667, 0.00047576005454175174, 0.0004217613604851067, 0.0005569690838456154, 0.00047849389375187457, 0.0004463719669729471, 0.0004380884347483516, 0.0004669697373174131, 0.0005154608516022563, 0.00046060653403401375, 0.0009218882187269628, 0.2974368929862976, 0.13453617691993713, 0.0006424738094210625, 0.000660548685118556, 0.0007863175706006587, 0.09730526804924011, 0.0011206896742805839, 0.2318734973669052, 0.0014750678092241287, 0.0015631909482181072, 0.0018465298926457763, 0.0019933111034333706, 0.0031186130363494158, 0.004098114091902971, 0.003389447694644332, 0.004620801191776991, 0.006916204933077097, 0.0030112415552139282, 0.00372284185141325, 0.003427912713959813, 0.0035748512018471956, 0.24739892780780792, 0.003784523345530033, 0.0035036089830100536, 0.0034592857118695974, 0.0044922358356416225, 0.003397831227630377, 0.0033332337625324726, 0.002619662322103977, 0.003012657631188631, 0.002950608031824231, 0.002987000159919262, 0.0024874184746295214, 0.002371198032051325, 0.002522513037547469, 0.0027612026315182447, 0.002388221910223365, 0.0021642849314957857, 0.002169358544051647, 0.0025400505401194096, 0.0018367294687777758, 0.0021542327012866735, 0.0016663995338603854, 0.10559435933828354, 0.0018025506287813187, 0.001972705591470003, 0.0017859451472759247, 0.0020209222566336393, 0.001592801185324788, 0.001697634463198483, 0.0024557330179959536, 0.0024297048803418875, 0.0022988400887697935, 0.0018326916033402085, 0.002585383364930749, 0.1144467294216156, 0.0028692390769720078, 0.001826565945520997, 0.001803537248633802, 0.0020065419375896454, 0.06971419602632523, 0.05204707011580467, 0.002306900452822447, 0.002088383538648486, 0.002972436137497425, 0.09840058535337448, 0.004617478232830763, 0.214335635304451, 0.10692425817251205, 0.003914874978363514, 0.006904499605298042, 0.008000622503459454, 0.01122483890503645, 0.017957298085093498, 0.005251388065516949, 0.00823974795639515, 0.01708047278225422, 0.009614156559109688, 0.02730388380587101, 0.004756556823849678, 0.0038792137056589127, 0.0029137914534658194, 0.009817108511924744, 0.007380648050457239, 0.003593267872929573, 0.004053869750350714, 0.0036554543767124414, 0.0015984710771590471, 0.002531669568270445, 0.0027622689958661795, 0.32783037424087524, 0.001383660128340125, 0.0019658522214740515, 0.0015733768232166767, 0.0017667255597189069, 0.0020092225167900324, 0.001218272722326219, 0.0011153056984767318, 0.0011359008494764566, 0.0008991214563138783, 0.0012361262924969196, 0.0009275504271499813, 0.0007648399332538247, 0.0009008152992464602, 0.0007460942724719644, 0.0009022678132168949, 0.0008935979567468166, 0.0007065990939736366, 0.0008790874271653593, 0.0006985070067457855, 0.0008674669079482555, 0.0007665319135412574, 0.0007376990397460759, 0.0005566940526477993, 0.0007584855775348842, 0.0005394324543885887, 0.0007760821026749909, 0.0005520668346434832, 0.000668434367980808, 0.0005167417693883181, 0.0005121593712829053, 0.0005253441049717367, 0.0006231812876649201, 0.0006216681795194745, 0.0005702617345377803, 0.0004777524445671588, 0.0005264629144221544, 0.0005629657534882426, 0.0004380758327897638, 0.0004822412447538227, 0.00047539404476992786, 0.0005261583137325943, 0.00045953402877785265, 0.0004648151807487011, 0.0004632552445400506, 0.00045894485083408654, 0.0005235372809693217, 0.00039420556277036667, 0.09873181581497192, 0.0005775384488515556, 0.0004815888241864741, 0.000525082868989557, 0.0005927868187427521, 0.0008745131781324744, 0.3277127742767334, 0.00084250996587798, 0.0007537314668297768, 0.0008756470051594079, 0.0008291230187751353, 0.0009228923008777201, 0.0009647214901633561, 0.0010688937036320567, 0.0009512127726338804, 0.0009060485754162073, 0.0009620626806281507, 0.0009874249808490276, 0.0010513953166082501, 0.0011514949146658182, 0.001025709556415677, 0.1716311126947403, 0.001637580106034875, 0.0013745402684435248, 0.0016341742593795061, 0.0015361399855464697, 0.001449986477382481, 0.0012916986597701907, 0.13227540254592896, 0.001819184748455882, 0.0015903684543445706, 0.0015745616983622313, 0.0016851469408720732, 0.0023665677290409803, 0.002044426277279854, 0.0032924164552241564, 0.0021773630287498236, 0.08916081488132477, 0.0025138980709016323, 0.0027083391323685646, 0.002319874009117484, 0.002726019825786352, 0.003221556544303894, 0.11678127944469452, 0.002492898376658559, 0.0031354567036032677, 0.003170374780893326, 0.0053685805760324, 0.0030183119233697653, 0.005160169210284948, 0.0028311896603554487, 0.15895697474479675, 0.004449266940355301, 0.0031972150318324566, 0.004444397985935211, 0.006024203263223171, 0.003002521814778447, 0.2622285783290863, 0.002553728176280856, 0.0032264920882880688, 0.003244071500375867, 0.0025518888141959906, 0.0027154271956533194, 0.004007258452475071, 0.0031004142947494984, 0.06492377817630768, 0.003067054320126772, 0.00320988311432302, 0.002975242445245385, 0.13504432141780853, 0.00258709117770195, 0.005899243522435427, 0.00311311986297369, 0.003472572425380349, 0.17744262516498566, 0.1434912085533142, 0.00455414317548275, 0.003710539545863867, 0.005944747943431139, 0.0040883468464016914, 0.005528446286916733, 0.004427626263350248, 0.06386856734752655, 0.003919631242752075, 0.004930560477077961, 0.004032898228615522, 0.005107356235384941, 0.004018495790660381, 0.0036095657851547003, 0.004101757425814867, 0.003942311275750399, 0.003819648642092943, 0.004980691708624363, 0.004210537765175104, 0.003089791163802147, 0.0046228328719735146, 0.0033182823099195957, 0.0033013855572789907, 0.0024751925375312567, 0.002534210681915283, 0.002292368561029434, 0.0025151909794658422, 0.12954938411712646, 0.2409793585538864, 0.0026741770561784506, 0.0026214122772216797, 0.0022469395771622658, 0.0029667243361473083, 0.0025359513238072395, 0.0027093319222331047, 0.002045857021585107, 0.0023566880263388157, 0.002016735728830099, 0.003495625453069806, 0.0021858958061784506, 0.0031298520043492317, 0.07872609049081802, 0.0022069180849939585, 0.001964190509170294, 0.0023966985754668713, 0.002073093084618449, 0.002523726550862193, 0.0019114220049232244, 0.17282302677631378, 0.002524064853787422, 0.0019252707716077566, 0.0027641847264021635, 0.002816951833665371, 0.0021631638519465923, 0.14274439215660095, 0.0023562356363981962, 0.002550158416852355, 0.002838380401954055, 0.0025050798431038857, 0.002414484741166234, 0.0026373127475380898, 0.0026628265623003244, 0.003029203275218606, 0.0027043151203542948, 0.0031193646136671305, 0.0023791270796209574, 0.0026775796432048082, 0.002932759001851082, 0.002439849777147174, 0.520058274269104, 0.0027481340803205967, 0.003269943641498685, 0.003506571054458618, 0.0033510434441268444, 0.004254858009517193, 0.11352413147687912, 0.004519806243479252, 0.004967971239238977, 0.004875521175563335, 0.004289872013032436, 0.004913005977869034, 0.0046472093090415, 0.004178000148385763, 0.005083282943814993, 0.0044167363084852695, 0.004308863077312708, 0.005659190006554127, 0.004169843625277281, 0.00402464484795928, 0.0041392482817173, 0.0036428947933018208, 0.0038033248856663704, 0.00395778426900506, 0.003112928243353963, 0.09370658546686172, 0.0038803815841674805, 0.0036445907317101955, 0.0029389613773673773, 0.003061919240280986, 0.003693275386467576, 0.002789451740682125, 0.003906474448740482, 0.003096258733421564, 0.0028555572498589754, 0.002340449020266533, 0.0025278583634644747, 0.002753030275925994, 0.002767397090792656, 0.002739210380241275, 0.00232216389849782, 0.0026306903455406427, 0.11009087413549423, 0.0023534554056823254, 0.0025010877288877964, 0.0018856448587030172, 0.002328810514882207, 0.00188916502520442, 0.1047021672129631, 0.002017779741436243, 0.0023388792760670185, 0.00217408942990005, 0.0020440835505723953, 0.0022781856823712587, 0.002817535772919655, 0.001918830443173647, 0.0018213631119579077, 0.001674270024523139, 0.0020660797599703074, 0.001966005191206932, 0.001989517593756318, 0.0018725843401625752, 0.0019175789784640074, 0.0017504424322396517, 0.001961511792615056, 0.0017839160282164812, 0.0023583173751831055, 0.0013915892923250794, 0.0014815895119681954, 0.11258842051029205, 0.001877240021713078, 0.0013993592001497746, 0.0017484751297160983, 0.002059475053101778, 0.001499687903560698, 0.0014307878445833921, 0.0014907170552760363, 0.0017232979880645871, 0.0014422924723476171, 0.0020203161984682083, 0.00135476840659976, 0.0014665498165413737, 0.001293920329771936, 0.0019857301376760006, 0.0013169980375096202, 0.001879725488834083, 0.0020561108831316233, 0.0012932393001392484, 0.11705648899078369, 0.001344159827567637, 0.0014745271764695644, 0.001417644671164453, 0.001251728506758809, 0.0015121769392862916, 0.0019312117947265506, 0.0019393089460209012, 0.0018895480316132307, 0.0019809852819889784, 0.0017392312875017524, 0.0013542308006435633, 0.0014927071752026677, 0.0015243592206388712, 0.14702127873897552, 0.0014423668617382646, 0.0016513721784576774, 0.001299916417337954, 0.0014331318670883775, 0.0018834430957213044, 0.0014356875326484442, 0.0012825136072933674, 0.002104587620124221, 0.0018200475024059415, 0.0018174166325479746, 0.0013177170185372233, 0.0016110764117911458, 0.0016387501964345574, 0.09117992222309113, 0.0013317994307726622, 0.0015134154818952084, 0.0020359621848911047, 0.0014718184247612953, 0.001724173896946013, 0.0013947106199339032, 0.0025103080552071333, 0.0022452829871326685, 0.24099642038345337, 0.0022069718688726425, 0.0014866120181977749, 0.0017774003790691495, 0.002066871151328087, 0.0016015018336474895, 0.0019102768274024129, 0.0016979399370029569, 0.0017993627116084099, 0.0018965925555676222, 0.0019393861293792725, 0.001687276060692966, 0.0021071620285511017, 0.0022475498262792826, 0.0016021850751712918, 0.0017230581725016236, 0.0016026573721319437, 0.001920746872201562, 0.0015951659297570586, 0.0014204286271706223, 0.001524379593320191, 0.0020705382339656353, 0.001325364806689322, 0.0014480474637821317, 0.0013759871944785118, 0.0017169845523312688, 0.001213358948007226, 0.001401327783241868, 0.00122921506408602, 0.0011691602412611246, 0.0013589367736130953, 0.0011999063426628709, 0.0012587049277499318, 0.0010421342449262738, 0.0010830244282260537, 0.0009621455683372915, 0.0010539916111156344, 0.0010822885669767857, 0.0011063899146392941, 0.0015127352671697736, 0.0010445433435961604, 0.000834048492833972, 0.0009961500763893127, 0.0009527006186544895, 0.0008471562177874148, 0.0010492517612874508, 0.0008438353543169796, 0.000831248180475086, 0.0007868871907703578, 0.0007372174877673388, 0.000805933028459549, 0.0010090863797813654, 0.23194102942943573, 0.0010947888949885964, 0.0006907442584633827, 0.0008605406619608402, 0.0010992626193910837, 0.0008800787618383765, 0.0008844613330438733, 0.0008418818470090628, 0.0008111357456073165, 0.0008130865753628314, 0.0009616583702154458, 0.0011724865762516856, 0.0008205751655623317, 0.0008343547233380377, 0.0007721000001765788, 0.0012364083668217063, 0.0008769208798184991, 0.0008695694850757718, 0.0008601292502135038, 0.000806870695669204, 0.0008580813882872462, 0.0008617700659669936, 0.0009198244661092758, 0.0008302926435135305, 0.0006976713193580508, 0.0008941470296122134, 0.0007291845977306366, 0.0007481668144464493, 0.0011557001853361726, 0.0007390991086140275, 0.0008146596373990178, 0.0008260305621661246, 0.0006273984326981008, 0.0006860252469778061, 0.000818094122223556, 0.0006742916884832084, 0.0008512591011822224, 0.0006079361191950738, 0.0007401512702926993, 0.0006884172325953841, 0.0005899503012187779, 0.0006391780916601419, 0.0006473067915067077, 0.0006651569274254143, 0.0005625633057206869, 0.0007783137261867523, 0.0005902286502532661, 0.0006149864057078958, 0.0007317323470488191, 0.000664055987726897, 0.0005391327431425452, 0.0006229875725694001, 0.0005478315870277584, 0.0005589938373304904, 0.0005531256319954991, 0.00047132206964306533, 0.16034968197345734, 0.0005474795470945537, 0.0005532458308152854, 0.3113306760787964, 0.000665437662974, 0.0007551672752015293, 0.0009043962345458567, 0.0008589228964410722, 0.0009589007240720093, 0.0009348696912638843, 0.0011260354658588767, 0.001064702053554356, 0.0010805074125528336, 0.001035616034641862, 0.0011016079224646091, 0.001418201718479395, 0.0010952478041872382, 0.0013682026183232665, 0.001670490368269384, 0.0012045173207297921, 0.00115151924546808, 0.001449738396331668, 0.001291000167839229, 0.19180920720100403, 0.001293097622692585, 0.0015054893447086215, 0.0014638592256233096, 0.0013697544345632195, 0.0016334473621100187, 0.0014636721462011337, 0.0015989961102604866, 0.0015673867892473936, 0.0014743244973942637, 0.0015719018410891294, 0.0017391423461958766, 0.0017793773440644145, 0.0022776222322136164, 0.0015395553782582283, 0.0016467490931972861, 0.17772769927978516, 0.0015250721480697393, 0.0015267160488292575, 0.15717121958732605, 0.001614684471860528, 0.001862902194261551, 0.0019825692288577557, 0.0019850016105920076, 0.001999947242438793, 0.002046023029834032, 0.0020803329534828663, 0.0023844349198043346, 0.0021863561123609543, 0.00226554274559021, 0.00214281864464283, 0.0022310575004667044, 0.0022277587559074163, 0.002312424825504422, 0.1489226520061493, 0.0026316915173083544, 0.1547051966190338, 0.0024236447643488646, 0.0026398205664008856, 0.0031971116550266743, 0.12360966205596924, 0.002887108363211155, 0.0032046539708971977, 0.003555986797437072, 0.003295811591669917, 0.12075679749250412, 0.004135475028306246, 0.003930258564651012, 0.0038337172009050846, 0.0038666168693453074, 0.004289574921131134, 0.004310907796025276, 0.0041697071865201, 0.004217608366161585, 0.004289019387215376, 0.004048201721161604, 0.0043607125990092754, 0.0036332979798316956, 0.0036077434197068214, 0.14141365885734558, 0.003756121965125203, 0.0035169553011655807, 0.003437835955992341, 0.08473552763462067, 0.003473978955298662, 0.00357188587076962, 0.0038777857553213835, 0.0037037215661257505, 0.003571542212739587, 0.003568036248907447, 0.0035607211757451296, 0.003310504602268338, 0.003346713026985526, 0.0033721639774739742, 0.0033472233917564154, 0.003156284336000681, 0.0031655272468924522, 0.002884359797462821, 0.15331614017486572, 0.0027480311691761017, 0.002690490335226059, 0.0034293110948055983, 0.00273947324603796, 0.0026464881375432014, 0.002761838724836707, 0.08302491903305054, 0.002677049720659852, 0.0026590698398649693, 0.002657212782651186, 0.0026356030721217394, 0.0026791945565491915, 0.0026139800902456045, 0.0025586728006601334, 0.0025872124824672937, 0.002641537459567189, 0.0023655372206121683, 0.0025077625177800655, 0.002350124530494213, 0.0022461875341832638, 0.002152354223653674, 0.002133155707269907, 0.002180777955800295, 0.0022234271746128798, 0.0021286120172590017, 0.0020656906999647617, 0.14409662783145905, 0.001940779504366219, 0.0019470513798296452, 0.0018941554008051753, 0.001893693464808166, 0.0019373665563762188, 0.0019382723839953542, 0.0019106650725007057, 0.0019006194779649377, 0.001908368431031704, 0.0017941823462024331, 0.001862452831119299, 0.0018455126555636525, 0.001983186462894082, 0.001662351773120463, 0.16693387925624847, 0.0018331222236156464, 0.0018140565371140838, 0.0018221541540697217, 0.0019052033312618732, 0.0018679549684748054, 0.0018861726857721806, 0.0019161916570737958, 0.10611241310834885, 0.0021553162951022387, 0.0019447689410299063, 0.1344626098871231, 0.002135331742465496, 0.002316690981388092, 0.0023770700208842754, 0.0026361006312072277, 0.0026512229815125465, 0.18867316842079163, 0.0029930779710412025, 0.0027944569010287523, 0.002931332914158702, 0.002934124320745468, 0.0829869955778122, 0.0037701865658164024, 0.0032828846015036106, 0.0037626964040100574, 0.0036883968859910965, 0.004016266204416752, 0.11455440521240234, 0.003683626651763916, 0.08859919011592865, 0.004170228261500597, 0.003983577247709036, 0.004208393860608339, 0.004524715710431337, 0.004275810904800892, 0.004252167418599129, 0.004257851280272007, 0.004400161560624838, 0.004125574138015509, 0.0046552387066185474, 0.004087940324097872, 0.00398776913061738, 0.0038399493787437677, 0.0034138367045670748, 0.003467406379058957, 0.0032945084385573864, 0.0036398328375071287, 0.0028616099152714014, 0.00288832513615489, 0.0028920683544129133, 0.0025409627705812454, 0.0028955682646483183, 0.0028242014814168215, 0.002452235436066985, 0.0022453335113823414, 0.0025473451241850853, 0.0020410248544067144, 0.0020212302915751934, 0.002346843248233199, 0.0017986772581934929, 0.001955572050064802, 0.001651476020924747, 0.0016765790060162544, 0.0015300370287150145, 0.0016974973259493709, 0.0015054255491122603, 0.0013510171556845307, 0.0013160244561731815, 0.07267095893621445, 0.0014439867809414864, 0.0014347709948197007, 0.0012929944787174463, 0.11907686293125153, 0.0013503353111445904, 0.001457584323361516, 0.0014651556266471744, 0.0015288025606423616, 0.0016457873862236738, 0.12358205020427704, 0.0015590599505230784, 0.0017338519683107734, 0.0017937468364834785, 0.0017896228237077594, 0.0020378290209919214, 0.0019069232512265444, 0.002342265797778964, 0.002456370973959565, 0.00213118689134717, 0.0018513218965381384, 0.002347704954445362, 0.002499612048268318, 0.11694151908159256, 0.001868369523435831, 0.002237159525975585, 0.0023196120746433735, 0.0021711590234190226, 0.0021500522270798683, 0.002485183998942375, 0.0022468497045338154, 0.0025138105265796185, 0.002163295168429613, 0.002267810981720686, 0.002094511641189456, 0.0023541629780083895, 0.002036355435848236, 0.0018981872126460075, 0.0022180795203894377, 0.0025166706182062626, 0.001919096102938056, 0.0018255641916766763, 0.002080365549772978, 0.11055269092321396, 0.001995140453800559, 0.0016261079581454396, 0.0018573974957689643, 0.0018938329303637147, 0.0016399648739024997, 0.00182826176751405, 0.001617178786545992, 0.001903480850160122, 0.0017699429299682379, 0.0021872324869036674, 0.1759670227766037, 0.0017973637441173196, 0.0017714881105348468, 0.07354054600000381, 0.00205886154435575, 0.001985116396099329, 0.0023606927134096622, 0.19801321625709534, 0.002938780002295971, 0.0031920718029141426, 0.0024017898831516504, 0.002919185208156705, 0.002928132424131036, 0.0028390081133693457, 0.0030700608622282743, 0.002958837430924177, 0.0028276697266846895, 0.0032153406646102667, 0.0030963432509452105, 0.0031028720550239086, 0.0028670900501310825, 0.002935627242550254, 0.0028407054487615824, 0.0023501934483647346, 0.0027571371756494045, 0.002307297894731164, 0.002370275557041168, 0.002463405719026923, 0.002218936337158084, 0.0020698958542197943, 0.0020608745981007814, 0.0020063475240021944, 0.002180830342695117, 0.0019516326719895005, 0.0020260310266166925, 0.001763066160492599, 0.17747952044010162, 0.0016968677518889308, 0.0020932492334395647, 0.0022114089224487543, 0.196012943983078, 0.0019679469987750053, 0.0021179772447794676, 0.001968915807083249, 0.001999499974772334, 0.00213653058744967, 0.002700444543734193, 0.0026160154957324266, 0.002139393473044038, 0.0021407646127045155, 0.0022034072317183018, 0.0027496544644236565, 0.002496023429557681, 0.002559325657784939, 0.0024872904177755117, 0.15035982429981232, 0.0024352918844670057, 0.0023282868787646294, 0.0023607653565704823, 0.0023782814387232065, 0.0023425102699548006, 0.002259625121951103, 0.0025438719894737005, 0.14636538922786713, 0.002297726459801197, 0.0030046487227082253, 0.0025461073964834213, 0.002519152360036969, 0.002595038153231144, 0.0028672306798398495, 0.0023672981187701225, 0.0030513980891555548, 0.0029847214464098215, 0.17152023315429688, 0.0024755026679486036, 0.1286647915840149, 0.002669201698154211, 0.003060314105823636, 0.0027680369094014168, 0.0031731417402625084, 0.0033753335010260344, 0.0030932482331991196, 0.003324280260130763, 0.10481129586696625, 0.14354702830314636, 0.0035426628310233355, 0.004082784056663513, 0.0038714127149432898, 0.003947425168007612, 0.0036411022301763296, 0.003741469932720065, 0.1442464292049408, 0.004091987852007151, 0.004243583884090185, 0.004294536076486111, 0.004819018766283989, 0.005162612535059452, 0.004614441189914942, 0.004548598546534777, 0.004005737137049437, 0.00423944229260087, 0.003622211515903473, 0.09857825934886932, 0.00400449987500906, 0.003662424860522151, 0.003656687680631876, 0.003467783099040389, 0.0033847761806100607, 0.003430555807426572, 0.003595757996663451, 0.003575844457373023, 0.003563852747902274, 0.0031318075489252806, 0.0031127945985645056, 0.0028939400799572468, 0.003183175576850772, 0.0027848032768815756, 0.002499878406524658, 0.0025100628845393658, 0.0022706021554768085, 0.0021942774765193462, 0.0021124191116541624, 0.0020141652785241604, 0.002104436280205846, 0.002045984147116542, 0.0018913716776296496, 0.0017949871253222227, 0.0019469961989670992, 0.001827017404139042, 0.0017523937858641148, 0.0016031088307499886, 0.0016392790712416172, 0.0014716462465003133, 0.0015130708925426006, 0.001362817594781518, 0.15077462792396545, 0.0016173607436940074, 0.0013497908366844058, 0.001604794175364077, 0.0014800108037889004, 0.001663649338297546, 0.0014963563298806548, 0.0013983069220557809, 0.001568766892887652, 0.0013849118258804083, 0.0013696036767214537, 0.0016581305535510182, 0.0014657005667686462, 0.001344225718639791, 0.0013033043360337615, 0.0013901619240641594, 0.0013482472859323025, 0.0013627137523144484, 0.0015157499583438039, 0.001258568256162107, 0.001273066969588399, 0.22600528597831726, 0.001327509293332696, 0.0013365447521209717, 0.0014412242453545332, 0.0015231369761750102, 0.0015295809134840965, 0.001430580043233931, 0.0015245885588228703, 0.001623112941160798, 0.0016323989257216454, 0.001664254697971046, 0.0014319524634629488, 0.0014146593166515231, 0.00145849515683949, 0.0014403389068320394, 0.0013771215453743935, 0.0013852509437128901, 0.001537421834655106, 0.0013743587769567966, 0.001400217181071639, 0.0013308906927704811, 0.0016066974494606256, 0.0012484146282076836, 0.0012733085313811898, 0.0013299839338287711, 0.0013362739700824022, 0.0012501440942287445, 0.0012690266594290733, 0.0011750963749364018, 0.001148468116298318, 0.0011214024852961302, 0.0012528473744168878, 0.001053279498592019, 0.18544445931911469, 0.0011860053054988384, 0.0012659075437113643, 0.0011942296987399459, 0.0012401328422129154, 0.0012832421343773603, 0.0012399035040289164, 0.0013336841948330402, 0.0012335830833762884, 0.1527240127325058, 0.0014101952547207475, 0.0013262443244457245, 0.001486254739575088, 0.0014664630871266127, 0.001461392268538475, 0.0015345833962783217, 0.0016714382218196988, 0.0016359202563762665, 0.001662744558416307, 0.001736995531246066, 0.0016771791270002723, 0.0015732261817902327, 0.0016839541494846344, 0.001777460565790534, 0.0016234481008723378, 0.0017325134249404073, 0.001516740769147873, 0.0019220835529267788, 0.0014695811551064253, 0.001593609806150198, 0.0015942170284688473, 0.0014265762874856591, 0.0014652564423158765, 0.001346878008916974, 0.0013832516269758344, 0.0013097563060000539, 0.0014288158854469657, 0.0012987174559384584, 0.00129508797544986, 0.0012422248255461454, 0.0012619653716683388, 0.0012019855203107, 0.0011246835347265005, 0.0011018230579793453, 0.001125104958191514, 0.0010500358184799552, 0.001048943609930575, 0.0010447875829413533, 0.001014502253383398, 0.0009790784679353237, 0.001044806675054133, 0.0009460060973651707, 0.000994770904071629, 0.0009854136733338237, 0.0009339854004792869, 0.000945023784879595, 0.0009322591940872371, 0.0008634579717181623, 0.000813133257906884, 0.0009104973287321627, 0.0008442773832939565, 0.14955931901931763, 0.0009156111627817154, 0.0008752458961680532, 0.0008996754768304527, 0.000884065986610949, 0.0009413082152605057, 0.0009477217681705952, 0.0009453120292164385, 0.0010201147524639964, 0.0010291771031916142, 0.0009819299448281527, 0.17881304025650024, 0.001053902436979115, 0.0010792689863592386, 0.0011835376499220729, 0.0011608387576416135, 0.0012105987407267094, 0.0013406133512035012, 0.001268454478122294, 0.0012824420118704438, 0.0012971851974725723, 0.0015079277800396085, 0.001338590169325471, 0.0014338205801323056, 0.001347832614555955, 0.0014877849025651813, 0.0013982146047055721, 0.0013070604763925076, 0.0012877919944003224, 0.0013464470393955708, 0.0012580693000927567, 0.001270385691896081, 0.001346878008916974, 0.0012563512427732348, 0.0012555583380162716, 0.001249448163434863, 0.0013226409209892154, 0.0011316061718389392, 0.0011406763223931193, 0.0012510708766058087, 0.0010983800748363137, 0.0011517450911924243, 0.0010893186554312706, 0.0010384813649579883, 0.2299416959285736, 0.0011303253704681993, 0.11632076650857925, 0.19111187756061554, 0.0013911956921219826, 0.1607203483581543, 0.0017640714067965746, 0.0019370527006685734, 0.0021898832637816668, 0.0024142349138855934, 0.002543514594435692, 0.0027270170394331217, 0.0029490250162780285, 0.003073286497965455, 0.11894851177930832, 0.003526765387505293, 0.0038077796343714, 0.0038740988820791245, 0.09942769259214401, 0.12683483958244324, 0.004536336753517389, 0.004887586459517479, 0.0048224227502942085, 0.004926087334752083, 0.005375973880290985, 0.005212151445448399, 0.005201232619583607, 0.005200049839913845, 0.0055221328511834145, 0.005204908549785614, 0.005248657893389463, 0.00484725134447217, 0.005148962140083313, 0.004705921746790409, 0.0044679539278149605, 0.004278837703168392, 0.00402133259922266, 0.004085164051502943, 0.003962344955652952, 0.003565866267308593, 0.0034552670549601316, 0.003351676743477583, 0.003119938774034381, 0.0033104943577200174, 0.00299660861492157, 0.003007831983268261, 0.002606277819722891, 0.0024937856942415237, 0.0026005159597843885, 0.0023111875634640455, 0.1527508646249771, 0.0021843768190592527, 0.002218493027612567, 0.002300720661878586, 0.002250035759061575, 0.0022399108856916428, 0.0022981835063546896, 0.002032156568020582, 0.0020010070875287056, 0.0020316969603300095, 0.0020927591249346733, 0.0020216079428792, 0.0018632415449246764, 0.1280621886253357, 0.0019912892021238804, 0.15960225462913513, 0.00196613697335124, 0.10270988941192627, 0.002270942786708474, 0.002415142022073269, 0.002555425511673093, 0.002629362978041172, 0.002946580993011594, 0.0027207478415220976, 0.0028553938027471304, 0.0028950716368854046, 0.002924899570643902, 0.002914727432653308, 0.0028675671201199293, 0.00314747984521091, 0.1900031417608261, 0.002915448509156704, 0.0032508079893887043, 0.0031569001730531454, 0.003058204660192132, 0.0031121207866817713, 0.003212607465684414, 0.003004229860380292, 0.0029650304932147264, 0.0032277374994009733, 0.002907700836658478, 0.0030117749702185392, 0.16497968137264252, 0.1322563737630844, 0.002912061521783471, 0.0032496496569365263, 0.0031331637874245644, 0.0032129683531820774, 0.003577099647372961, 0.11596323549747467, 0.0033734957687556744, 0.0035768249072134495, 0.0036362314131110907, 0.0034778935369104147, 0.0034945067018270493, 0.0035918275825679302, 0.0037112953141331673, 0.11978976428508759, 0.003499135607853532, 0.00378351379185915, 0.0037338859401643276, 0.003866038052365184, 0.003687115851789713, 0.0034897124860435724, 0.0035812032874673605, 0.003522466868162155, 0.003444463713094592, 0.003424194874241948, 0.0031852310057729483, 0.0030875031370669603, 0.0030222400091588497, 0.0028752959333360195, 0.13228943943977356, 0.14022985100746155, 0.0029328404925763607, 0.00295345694757998, 0.0030566256027668715, 0.003158239182084799, 0.003152090823277831, 0.003167916089296341, 0.003146146656945348, 0.0032189462799578905, 0.0032847882248461246, 0.0031730704940855503, 0.0031372804660350084, 0.003089811187237501, 0.0028806650079786777, 0.0028914017602801323, 0.003158384235575795, 0.0026843794621527195, 0.0027025945018976927, 0.0026191486977040768, 0.002440539887174964, 0.0027677922043949366, 0.0022719751577824354, 0.002225105185061693, 0.002240424742922187, 0.002176291774958372, 0.0020734076388180256, 0.13086342811584473, 0.20924851298332214, 0.20095835626125336, 0.00224728649482131, 0.002478832146152854, 0.1812606304883957, 0.002759070135653019, 0.0030559662263840437, 0.0033608651719987392, 0.003424812341108918, 0.15611469745635986, 0.0037486529909074306, 0.003996316809207201, 0.004115954972803593, 0.0043074581772089005, 0.0044568427838385105, 0.004607522860169411, 0.004573069512844086, 0.004460265394300222, 0.004482925403863192, 0.004501067567616701, 0.004375029355287552, 0.004445239901542664, 0.004328982438892126, 0.004122953396290541, 0.003974890802055597, 0.0038828663527965546, 0.003892341861501336, 0.0036019477993249893, 0.0036425823345780373, 0.0034106909297406673, 0.0032494687475264072, 0.0031191310845315456, 0.002997591160237789, 0.0028968092519789934, 0.0027746926061809063, 0.10327556729316711, 0.0027190856635570526, 0.00260901334695518, 0.002691329689696431, 0.0025813509710133076, 0.0025298953987658024, 0.0024727415293455124, 0.0023923232220113277, 0.0023968066088855267, 0.0023258726578205824, 0.0022612246684730053, 0.002197117544710636, 0.0021951196249574423, 0.0020677032880485058, 0.001991609111428261, 0.0020432211458683014, 0.0019158474169671535, 0.001922314753755927, 0.001843077945522964, 0.001739703118801117, 0.0016955204773694277, 0.001726967515423894, 0.0016237231902778149, 0.001612653722986579, 0.0015205622185021639, 0.0015284833498299122, 0.001489250804297626, 0.0014468141598626971, 0.0013658906100317836, 0.001387890661135316, 0.1409495770931244, 0.0013442202471196651, 0.0014085171278566122, 0.0014133924851194024, 0.0014522542478516698, 0.0014230767264962196, 0.0014167164918035269, 0.15725554525852203, 0.0014857292408123612, 0.0015764175914227962, 0.0016661034896969795, 0.0016609409358352423, 0.0016698624240234494, 0.0017102170968428254, 0.0017369764391332865, 0.0017388915875926614, 0.001754301250912249, 0.0017650367226451635, 0.00175864074844867, 0.0017621980514377356, 0.0017560028936713934, 0.0017768669640645385, 0.0016991362208500504, 0.0016910834237933159, 0.001691845478489995, 0.15214844048023224, 0.0017212312668561935, 0.0017298388993367553, 0.0018118981970474124, 0.0018148262752220035, 0.0018245783867314458, 0.001833712449297309, 0.0018062181770801544, 0.0018536337884142995, 0.001811559428460896, 0.001869318773970008, 0.0017937615048140287, 0.001745483255945146, 0.0018083008471876383, 0.0017029682639986277, 0.0017116472590714693, 0.001656210282817483, 0.0016755189280956984, 0.0016576508060097694, 0.0016037158202379942, 0.001619158429093659, 0.001579391653649509, 0.0015005337772890925, 0.0014777283649891615, 0.0014711429830640554, 0.0014411177253350616, 0.0014198316494002938, 0.0013328735949471593, 0.0013275539968162775, 0.0013602252583950758, 0.1233600527048111, 0.001292456523515284, 0.0013270315248519182, 0.0013482448412105441, 0.00136150314938277, 0.0013648911844938993, 0.0014641660964116454, 0.0013657878153026104, 0.0013791563687846065, 0.0013671749038621783, 0.001359238289296627, 0.0013565459521487355, 0.0013523618690669537, 0.0014066849835217, 0.0013207474257797003, 0.001346748904325068, 0.0012945865746587515, 0.0012892065569758415, 0.0012789967004209757, 0.0013025865191593766, 0.001289175357669592, 0.0012049190700054169, 0.001285410369746387, 0.001207684283144772, 0.0011580564314499497, 0.0011582038132473826, 0.001137872925028205, 0.0010956847108900547, 0.0010719618294388056, 0.0010587901342660189, 0.0010614536004140973, 0.0010178814409300685, 0.0010014391737058759, 0.0010048417607322335, 0.0009641636279411614, 0.0009973784908652306, 0.0009453252423554659, 0.000940020545385778, 0.0009233379387296736, 0.0009213185403496027, 0.0008782970253378153, 0.0008783853845670819, 0.0009094429551623762, 0.0008339815540239215, 0.1566050499677658, 0.0008600674336776137, 0.000967059750109911, 0.000922149047255516, 0.0009491420933045447, 0.0009716461645439267, 0.0009652129956521094, 0.0009754984057508409, 0.0010055903112515807, 0.0010161760728806257, 0.0010213612113147974, 0.001006471924483776, 0.0010385685600340366, 0.0010155609343200922, 0.1449919044971466, 0.0011130340863019228, 0.0010989622678607702, 0.001200406113639474, 0.0012185561936348677, 0.0012103787157684565, 0.001289350911974907, 0.0012952927500009537, 0.001243521342985332, 0.0012672098819166422, 0.0012498036958277225, 0.0012876249384135008, 0.0012883024755865335, 0.0013153336476534605, 0.1396847814321518, 0.0013248074101284146, 0.16966582834720612, 0.001484747976064682, 0.15554936230182648, 0.0017655896954238415, 0.0019071812275797129, 0.002112135523930192, 0.002270977245643735, 0.0023554526269435883, 0.002438182011246681, 0.002517836634069681, 0.0025620011147111654, 0.0026363118086010218, 0.002785550896078348, 0.0027153841219842434, 0.002740690251812339, 0.0027814593631774187, 0.0027872032951563597, 0.0027509070932865143, 0.002794025233015418, 0.00280191982164979, 0.00269333622418344, 0.0026253405958414078, 0.002597745042294264, 0.0025414982810616493, 0.002490815706551075, 0.0024466051254421473, 0.14871305227279663, 0.00244934787042439, 0.0024493313394486904, 0.1266118884086609, 0.0025743008591234684, 0.0025534662418067455, 0.002600395120680332, 0.0026434529572725296, 0.0027197885792702436, 0.002735178219154477, 0.002742557320743799, 0.0027994588017463684, 0.002691970206797123, 0.002707058098167181, 0.002663184190168977, 0.00264664925634861, 0.0026671839877963066, 0.002573390258476138, 0.002498654881492257, 0.0025190587621182203, 0.0023534984793514013, 0.002279895357787609, 0.002234453335404396, 0.002193256514146924, 0.002149366308003664, 0.002078411402180791, 0.0021127937361598015, 0.0019694436341524124, 0.1228368952870369, 0.001964046387001872, 0.0020125105511397123, 0.0019599900115281343, 0.001974516548216343, 0.002041060011833906, 0.0019655099604278803, 0.12416204065084457, 0.002017001388594508, 0.0021033762022852898, 0.1166360005736351, 0.0022109129931777716, 0.002234399551525712, 0.11246122419834137, 0.0024528398644179106, 0.0026098669040948153, 0.0027639230247586966, 0.0028861169703304768, 0.002932863775640726, 0.002966978121548891, 0.0031021239701658487, 0.002992695663124323, 0.003031318774446845, 0.003016516100615263, 0.0031311577185988426, 0.003101951675489545, 0.003035406582057476, 0.0028881505131721497, 0.0028408528305590153, 0.0029558795504271984, 0.0028072246350347996, 0.0027084199246019125, 0.10011505335569382]\n",
            "Val loss 0.012736976271574585\n",
            "Val auc roc 0.46189868028948494\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d587d2e3d3d6449f8326b02b468fec30",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0151\n",
            "Train Losses : [0.0026800581254065037, 0.0027747107669711113, 0.002628215355798602, 0.002592118689790368, 0.0027117650024592876, 0.0026239906437695026, 0.002490344224497676, 0.002509400947019458, 0.002490684622898698, 0.002401197561994195, 0.0023503329139202833, 0.0022946710232645273, 0.0023203894961625338, 0.002206480363383889, 0.0022837654687464237, 0.10027474164962769, 0.0022032291162759066, 0.0021042521111667156, 0.0022603513207286596, 0.0022187770809978247, 0.0021055147517472506, 0.002082530176267028, 0.0021125853527337313, 0.0020769175607711077, 0.0020933321211487055, 0.0020471324678510427, 0.0019235162762925029, 0.0018906162586063147, 0.001885120407678187, 0.0018385755829513073, 0.0018235157476738095, 0.0017168993363156915, 0.0018889053026214242, 0.00168343645054847, 0.0016864113276824355, 0.0016839092131704092, 0.15927739441394806, 0.0016901441849768162, 0.0016683334251865745, 0.001681031077168882, 0.0017845011316239834, 0.0018139132298529148, 0.0016573488246649504, 0.001627935329452157, 0.0016346012707799673, 0.1350298672914505, 0.001750902272760868, 0.0017662658356130123, 0.002075064228847623, 0.001890254789032042, 0.0018931978847831488, 0.0018934295512735844, 0.0019219276728108525, 0.00196227733977139, 0.002070493996143341, 0.0018707267008721828, 0.001892843167297542, 0.0019609741866588593, 0.001885613426566124, 0.0018172074342146516, 0.0018318763468414545, 0.001738591818138957, 0.0017426094273105264, 0.00181972433347255, 0.001655289437621832, 0.0016149414004758, 0.0015953306574374437, 0.0016011446714401245, 0.001545360661111772, 0.0016304259188473225, 0.0014891023747622967, 0.0014398932689800858, 0.16222047805786133, 0.15912432968616486, 0.0015683156671002507, 0.0017033161129802465, 0.001701630768366158, 0.0018232684815302491, 0.0018750871531665325, 0.10869497060775757, 0.0020334278233349323, 0.002166587160900235, 0.002142079407349229, 0.0022434808779507875, 0.002333973767235875, 0.002347041852772236, 0.002464582212269306, 0.002422863617539406, 0.0024123825132846832, 0.0023574840743094683, 0.002376181073486805, 0.002421706449240446, 0.0024424907751381397, 0.002314869314432144, 0.002498347545042634, 0.0022919715847820044, 0.0022199146915227175, 0.0022488264366984367, 0.002290532225742936, 0.002133117988705635, 0.002220882335677743, 0.0020273549016565084, 0.002058243378996849, 0.0019398817094042897, 0.0019610528834164143, 0.0018792569171637297, 0.002026767237111926, 0.0018502550665289164, 0.0017294514691457152, 0.0017961588455364108, 0.0016878778114914894, 0.0016676231753081083, 0.001559554599225521, 0.001548700500279665, 0.001472414587624371, 0.0014770310372114182, 0.0015064283506944776, 0.0013830643147230148, 0.0013799791922792792, 0.0013945529935881495, 0.0013178198132663965, 0.0012511200038716197, 0.001268974388949573, 0.13654020428657532, 0.0012281998060643673, 0.0012851246865466237, 0.0012972757685929537, 0.0013790689408779144, 0.12450774759054184, 0.0013813618570566177, 0.0014348117401823401, 0.0015228575794026256, 0.0015630722045898438, 0.0015417964896187186, 0.0016714056255295873, 0.0016424490604549646, 0.0016293489607051015, 0.0017329715192317963, 0.001654663821682334, 0.0016711128409951925, 0.0016291221836581826, 0.001615802408196032, 0.0016286965692415833, 0.0015925420448184013, 0.001574259833432734, 0.001541903242468834, 0.0015534082194790244, 0.13908067345619202, 0.0015904351603239775, 0.0015985585050657392, 0.0016684775473549962, 0.0016810824163258076, 0.10672824084758759, 0.0018124568741768599, 0.1179720088839531, 0.0019110095454379916, 0.002036395249888301, 0.0021554280538111925, 0.002232267986983061, 0.002264738315716386, 0.002440783893689513, 0.0024681915529072285, 0.14792346954345703, 0.002621755702421069, 0.002630364615470171, 0.0027098623104393482, 0.0028730302583426237, 0.00286359922029078, 0.0032269805669784546, 0.0029654179234057665, 0.09663309156894684, 0.0030729598365724087, 0.15009495615959167, 0.0033186492510139942, 0.0035520954988896847, 0.14667284488677979, 0.003593401750549674, 0.00398168433457613, 0.003951163962483406, 0.00402327673509717, 0.004120242781937122, 0.004083174280822277, 0.004202465992420912, 0.004256068728864193, 0.003997417166829109, 0.00434087123721838, 0.003978903871029615, 0.0039058367256075144, 0.0038940072990953922, 0.0037751528434455395, 0.003903997829183936, 0.0035772675182670355, 0.003507646732032299, 0.0032773457933217287, 0.0034338445402681828, 0.0031694190111011267, 0.00324833020567894, 0.003072936786338687, 0.002946356078609824, 0.002905644243583083, 0.002648241352289915, 0.0025202911347150803, 0.0024342492688447237, 0.0023275394923985004, 0.0022374503314495087, 0.002303764224052429, 0.002131630666553974, 0.0021821882110089064, 0.002023298991844058, 0.0019413009285926819, 0.0018606893718242645, 0.0018376701045781374, 0.0017867585411295295, 0.0017422563396394253, 0.001650080899707973, 0.001568054547533393, 0.0015810367185622454, 0.0015923823229968548, 0.001497135846875608, 0.0014266170328482985, 0.0014605297474190593, 0.00141427805647254, 0.0013412369880825281, 0.11904650181531906, 0.001343690906651318, 0.0014397179475054145, 0.001368873636238277, 0.1553797721862793, 0.0014739728067070246, 0.0014910884201526642, 0.0015229223063215613, 0.0016090163262560964, 0.0015859821578487754, 0.0016707972390577197, 0.0016788163920864463, 0.0016098275082185864, 0.0016245113220065832, 0.0016689467011019588, 0.0016957058105617762, 0.9660221934318542, 0.001974884420633316, 0.0023642019368708134, 0.002704489976167679, 0.0030509347561746836, 0.0034486958757042885, 0.003756911726668477, 0.003910524770617485, 0.004500934388488531, 0.004628908820450306, 0.005124375689774752, 0.004682338796555996, 0.004776393063366413, 0.004911830648779869, 0.004903004504740238, 0.004868983756750822, 0.005135283339768648, 0.005009267944842577, 0.00529442960396409, 0.004833189770579338, 0.0050924187526106834, 0.004647952504456043, 0.004896744154393673, 0.004491712898015976, 0.004460157826542854, 0.004480594303458929, 0.004093664698302746, 0.09558244049549103, 0.11813878268003464, 0.003895622445270419, 0.00404910184442997, 0.004153120331466198, 0.003953213337808847, 0.0038137203082442284, 0.0038211806677281857, 0.004185162950307131, 0.0038759729359298944, 0.0037271648179739714, 0.0037594609893858433, 0.0034752339124679565, 0.003598856972530484, 0.0035235248506069183, 0.0034880666062235832, 0.0031771338544785976, 0.1595691591501236, 0.0030910468194633722, 0.0034583669621497393, 0.0033817673102021217, 0.003232672344893217, 0.003118982072919607, 0.0030500588472932577, 0.0029381781350821257, 0.003015352413058281, 0.002925123320892453, 0.0027362173423171043, 0.0026622088626027107, 0.002782292664051056, 0.0025843086186796427, 0.0025962262880057096, 0.002548878313973546, 0.09672242403030396, 0.0024759613443166018, 0.0023811175487935543, 0.12045277655124664, 0.002692657522857189, 0.0027312810998409986, 0.0025243605487048626, 0.002590091899037361, 0.0024523348547518253, 0.002493118168786168, 0.002476991154253483, 0.0025987548287957907, 0.002516721608117223, 0.002559967804700136, 0.0025928260292857885, 0.00237591122277081, 0.0023842884693294764, 0.0026540039107203484, 0.0023263192269951105, 0.002489270642399788, 0.0023803000804036856, 0.002348462352529168, 0.0021013785153627396, 0.002186447847634554, 0.002160858130082488, 0.002208191202953458, 0.002051585353910923, 0.0018615501467138529, 0.0018670432036742568, 0.001955267507582903, 0.0018906299956142902, 0.0018282702658325434, 0.0017066859873011708, 0.0017074111383408308, 0.001612157211638987, 0.0015589125687256455, 0.001567420782521367, 0.0015712894964963198, 0.0015091109089553356, 0.001439581741578877, 0.00144980289041996, 0.00138664070982486, 0.0014560373965650797, 0.0014759671175852418, 0.00155580323189497, 0.0014270824613049626, 0.0014196858974173665, 0.001355753163807094, 0.0013228349853307009, 0.001292007160373032, 0.0012157885357737541, 0.0012292894534766674, 0.0011252450058236718, 0.0012658464256674051, 0.0012089579831808805, 0.0011226854985579848, 0.0010970094008371234, 0.001080446527339518, 0.0011450217571109533, 0.0011592849623411894, 0.0010870869737118483, 0.0009847877081483603, 0.0010180383687838912, 0.0010596986394375563, 0.20606757700443268, 0.0010961557272821665, 0.0010611166944727302, 0.0012126662768423557, 0.0011927285231649876, 0.00114086561370641, 0.0010999194346368313, 0.0011570726055651903, 0.0011847729329019785, 0.0011760384077206254, 0.0011647898936644197, 0.001226911903358996, 0.0011787030380219221, 0.0011226997012272477, 0.0011761359637603164, 0.0012258205097168684, 0.0012465837644413114, 0.001128433272242546, 0.001087016542442143, 0.0010987884597852826, 0.0011339191114529967, 0.0010641437256708741, 0.00107048568315804, 0.001063276780769229, 0.0010087927803397179, 0.0010543265379965305, 0.0010942888911813498, 0.001003976329229772, 0.001073429244570434, 0.14707836508750916, 0.12294385582208633, 0.0010568836005404592, 0.0011909535387530923, 0.0013182753464207053, 0.001299345400184393, 0.001347875688225031, 0.0013353945687413216, 0.0013297895202413201, 0.001522214850410819, 0.0013989402214065194, 0.0013757981359958649, 0.0015070718945935369, 0.0015763799892738461, 0.0014299916801974177, 0.0014213152462616563, 0.0015200955094769597, 0.0015978902811184525, 0.001594164059497416, 0.001415133010596037, 0.0014271116815507412, 0.0017676856368780136, 0.001553593436256051, 0.001552306697703898, 0.0015078848227858543, 0.001505748019553721, 0.0013959459029138088, 0.0014590817736461759, 0.001329591847024858, 0.0014233519323170185, 0.0013776710256934166, 0.0012934248661622405, 0.0014719634782522917, 0.0014054585481062531, 0.0013657578965649009, 0.0012734327465295792, 0.0013175982749089599, 0.0011729508405551314, 0.0011704500066116452, 0.0011408299906179309, 0.0010977508500218391, 0.17476920783519745, 0.0011766321258619428, 0.0012339529348537326, 0.0011846983106806874, 0.001298797084018588, 0.0012434277450665832, 0.0012545597273856401, 0.0012401369167491794, 0.0014344381634145975, 0.0012604785151779652, 0.12591597437858582, 0.0014429460279643536, 0.1685025691986084, 0.0014657620340585709, 0.0014962105778977275, 0.0016022970667108893, 0.13357947766780853, 0.0017148882616311312, 0.0018211491405963898, 0.0019366373308002949, 0.001948612742125988, 0.0020293586421757936, 0.002152610570192337, 0.0022804723121225834, 0.0023571611382067204, 0.0023586093448102474, 0.0024470144417136908, 0.17857150733470917, 0.0024135808926075697, 0.0025512564461678267, 0.0024700178764760494, 0.002629385096952319, 0.002750420942902565, 0.002635036129504442, 0.00283925817348063, 0.002807612530887127, 0.0025238306261599064, 0.09578384459018707, 0.002588209928944707, 0.002883227774873376, 0.08131396770477295, 0.002781426766887307, 0.003141568973660469, 0.0028970877174288034, 0.0028129101265221834, 0.0029765614308416843, 0.19424809515476227, 0.0029935985803604126, 0.003183086635544896, 0.0030789391603320837, 0.0031142127700150013, 0.003122988622635603, 0.003274663118645549, 0.003181761596351862, 0.003259390825405717, 0.003091285238042474, 0.003229851368814707, 0.003110081423074007, 0.003237298456951976, 0.0031769757624715567, 0.0029580844566226006, 0.002860093954950571, 0.0028217860963195562, 0.0028681426774710417, 0.0026608644984662533, 0.002674815710633993, 0.0025438331067562103, 0.0027622394263744354, 0.002581881359219551, 0.002624219749122858, 0.002584952861070633, 0.002406809013336897, 0.0023923537228256464, 0.0023367709945887327, 0.0023566994350403547, 0.002062944695353508, 0.0020480428356677294, 0.0020645817276090384, 1.0596766471862793, 0.0022772070951759815, 0.0025228639133274555, 0.002847617492079735, 0.0031353801023215055, 0.00332829263061285, 0.003741879714652896, 0.003934318199753761, 0.003944992087781429, 0.0044586616568267345, 0.0043326690793037415, 0.004364331252872944, 0.004542849026620388, 0.0048084016889333725, 0.004955753218382597, 0.005078508984297514, 0.005225833505392075, 0.004722378216683865, 0.004488492850214243, 0.004534849431365728, 0.0045313360169529915, 0.004331009928137064, 0.004481681622564793, 0.004314592573791742, 0.0041752103716135025, 0.004155420232564211, 0.004191549029201269, 0.0037806101609021425, 0.003979802131652832, 0.0036992747336626053, 0.0035293118562549353, 0.0035482991952449083, 0.0036823111586272717, 0.0032557412050664425, 0.003514939220622182, 0.003146218368783593, 0.0030984755139797926, 0.003068954683840275, 0.002863220637664199, 0.0028706362936645746, 0.0028026860672980547, 0.0026553869247436523, 0.0026234190445393324, 0.18090519309043884, 0.002582866232842207, 0.002644437598064542, 0.002432383829727769, 0.0024252627044916153, 0.0024735049810260534, 0.002400575904175639, 0.0023981023114174604, 0.002391287125647068, 0.00237264228053391, 0.0022518045734614134, 0.0022327834740281105, 0.0022390808444470167, 0.0022175698541104794, 0.0021783437114208937, 0.002125364262610674, 0.0021381909027695656, 0.0020534726791083813, 0.0020127452444285154, 0.0019450187683105469, 0.0019313161028549075, 0.10582967847585678, 0.0019025892252102494, 0.0019124526297673583, 0.0019555650651454926, 0.0019208246376365423, 0.002025668742135167, 0.0018971473909914494, 0.0019399956800043583, 0.001915371511131525, 0.0019866430666297674, 0.0019177348585799336, 0.0018794413190335035, 0.17499856650829315, 0.0018248569685965776, 0.001965791918337345, 0.0019294918747618794, 0.0019110471475869417, 0.002005013171583414, 0.0019335512770339847, 0.0019561033695936203, 0.0019069170812144876, 0.0019912782590836287, 0.002047400688752532, 0.0018840867560356855, 0.001862486358731985, 0.0019050879636779428, 0.0018972137477248907, 0.0018902092706412077, 0.00183727010153234, 0.0017777319299057126, 0.0017957885283976793, 0.001757713733240962, 0.0017701336182653904, 0.15064284205436707, 0.0017167194746434689, 0.0017656323034316301, 0.001790531212463975, 0.0017651473172008991, 0.0018126139184460044, 0.0019181182142347097, 0.001757710357196629, 0.0018159953178837895, 0.0018006954342126846, 0.0018199763726443052, 0.0017823516391217709, 0.0017835760954767466, 0.001837625284679234, 0.0016890468541532755, 0.0016640817048028111, 0.15037544071674347, 0.0017350178677588701, 0.001774907810613513, 0.0018001492135226727, 0.11424367129802704, 0.12671200931072235, 0.001984973670914769, 0.001982071902602911, 0.002107334788888693, 0.002114581409841776, 0.0023419877979904413, 0.0022145919501781464, 0.0024287127889692783, 0.002317743143066764, 0.0024885537568479776, 0.0024164123460650444, 0.0024577826261520386, 0.002381882630288601, 0.12288904190063477, 0.0023871613666415215, 0.08537529408931732, 0.0025449353270232677, 0.002676033414900303, 0.002753166714683175, 0.002713956870138645, 0.002705818973481655, 0.00283224368467927, 0.002743912162259221, 0.002797596389427781, 0.0028538499027490616, 0.002953141462057829, 0.002825102536007762, 0.0029873866587877274, 0.0027661968488246202, 0.11645618081092834, 0.0026655560359358788, 0.0027499746065586805, 0.0027532039675861597, 0.0030417845118790865, 0.0027045821771025658, 0.0028146798722445965, 0.0028179059736430645, 0.0028643584810197353, 0.0028337903786450624, 0.0026972154155373573, 0.002811550861224532, 0.0026787715032696724, 0.0026734969578683376, 0.002510884078219533, 0.0025092344731092453, 0.0025593675673007965, 0.002599806059151888, 0.002444640966132283, 0.002384720603004098, 0.0023006144911050797, 0.0022496480960398912, 0.0023252079263329506, 0.002184209879487753, 0.0022198061924427748, 0.002172298962250352, 0.002033391734585166, 0.001959919696673751, 0.0019258720567449927, 0.0020171739161014557, 0.0019687043968588114, 0.0017915487987920642, 0.0018330971943214536, 0.0017470362363383174, 0.0018493495881557465, 0.0017454444896429777, 0.0017024079570546746, 0.0015971401007845998, 0.0016793847316876054, 0.0016072905855253339, 0.0016501799691468477, 0.001563777681440115, 0.0014959133695811033, 0.0015962212346494198, 0.0014930200995877385, 0.001399474567733705, 0.001531538786366582, 0.0014096649829298258, 0.0013216986553743482, 0.001358390087261796, 0.11304446309804916, 0.0013368887593969703, 0.0013863210333511233, 0.0013664944563061, 0.0014315699227154255, 0.1299511343240738, 0.0013874679571017623, 0.001468309317715466, 0.001438757753930986, 0.0016123870154842734, 0.00154358078725636, 0.001486761961132288, 0.0016165677225217223, 0.0015445984899997711, 0.0015305717242881656, 0.0016281470889225602, 0.0016667976742610335, 0.0016084049129858613, 0.001687222975306213, 0.12826089560985565, 0.001592140644788742, 0.00167793408036232, 0.17724646627902985, 0.11790825426578522, 0.0018107675714418292, 0.0019203537376597524, 0.002114608883857727, 0.002117834985256195, 0.0021754633635282516, 0.0022330100182443857, 0.002475954592227936, 0.002358566038310528, 0.0023090364411473274, 0.0024218892212957144, 0.0024248023983091116, 0.0023269704543054104, 0.002747186226770282, 0.0025409776717424393, 0.0023307926021516323, 0.002410067478194833, 0.002283989218994975, 0.0024004580918699503, 0.002262584399431944, 0.002465456025674939, 0.002484437543898821, 0.002428990788757801, 0.136097252368927, 0.002455442911013961, 0.0024281295482069254, 0.0022494408767670393, 0.002319352002814412, 0.002374752424657345, 0.0023899544030427933, 0.00219471356831491, 0.0022026882506906986, 0.0022852018009871244, 0.002435858827084303, 0.0021289691794663668, 0.002269868040457368, 0.0021428032778203487, 0.002045941073447466, 0.00220912485383451, 0.0021685524843633175, 0.0020213585812598467, 0.001982283079996705, 0.002049521543085575, 0.0019210384925827384, 0.001897720037959516, 0.0018951367819681764, 0.0018772953189909458, 0.0017561597051098943, 0.4958661198616028, 0.0020743890199810266, 0.0021171991247683764, 0.0021794901695102453, 0.002241092035546899, 0.0024624671787023544, 0.002419019117951393, 0.002652740105986595, 0.0024934003595262766, 0.0025741667486727238, 0.08715498447418213, 0.002726587699726224, 0.0028372681699693203, 0.0029553486965596676, 0.002821306698024273, 0.002798020141199231, 0.002890213392674923, 0.0031334594823420048, 0.003088947618380189, 0.0031802458688616753, 0.0030863159336149693, 0.002873847493901849, 0.0031122376676648855, 0.002990187145769596, 0.0026977898087352514, 0.002732811961323023, 0.0027545911725610495, 0.0026440501678735018, 0.0025559524074196815, 0.0027963980101048946, 0.0026136983651667833, 0.0024442884605377913, 0.0025559694040566683, 0.0023688056971877813, 0.0025508692488074303, 0.0025266283191740513, 0.0025469008833169937, 0.0022177263163030148, 0.00227278470993042, 0.0024328045547008514, 0.0021052355878055096, 0.002034509088844061, 0.002290574833750725, 0.0021605067886412144, 0.0020975032821297646, 0.001902956049889326, 0.0021001046989113092, 0.0018396449740976095, 0.0017572621582075953, 0.001824070350266993, 0.0017965832957997918, 0.0018583146156743169, 0.0016330546932294965, 0.0016879778122529387, 0.001591272302903235, 0.0015938638243824244, 0.0017503068083897233, 0.0016114813042804599, 0.001736904145218432, 0.0015079602599143982, 0.0016124466201290488, 0.0015121056931093335, 0.0014501631958410144, 0.10788344591856003, 0.001483636791817844, 0.0014630034565925598, 0.0014579643029719591, 0.001484361127950251, 0.001551235793158412, 0.0014441409148275852, 0.0014869922306388617, 0.0017155586974695325, 0.0014963687863200903, 0.0014990370254963636, 0.0015056480187922716, 0.0016011325642466545, 0.0015451557701453567, 0.0014239093288779259, 0.001401327783241868, 0.0013683491852134466, 0.0013500649947673082, 0.0013696154346689582, 0.0015210917918011546, 0.0013168301666155457, 0.0013336619595065713, 0.0014538962859660387, 0.001369111007079482, 0.001290800399146974, 0.2565132975578308, 0.0013446575030684471, 0.0012777347583323717, 0.001338165602646768, 0.0013898562174290419, 0.001391549943946302, 0.0013189079472795129, 0.15288092195987701, 0.0013971846783533692, 0.001408687443472445, 0.001518851611763239, 0.0014711354160681367, 0.0015447733458131552, 0.0015102988108992577, 0.0818314403295517, 0.0016315074171870947, 0.10531090945005417, 0.0016486013773828745, 0.0020113959908485413, 0.0017319116741418839, 0.001885488978587091, 0.0019745873287320137, 0.0021135001443326473, 0.001862101606093347, 0.002078473335132003, 0.0020218074787408113, 0.001986119197681546, 0.0019463901408016682, 0.09251715987920761, 0.1271059662103653, 0.0020065237767994404, 0.00239887204952538, 0.0023556912783533335, 0.0023043369874358177, 0.002314579440280795, 0.002518307650461793, 0.1298106461763382, 0.0027488465420901775, 0.002521411282941699, 0.002588626928627491, 0.0025908115785568953, 0.0030463230796158314, 0.0025358085986226797, 0.0026165994349867105, 0.002759617054834962, 0.002710482804104686, 0.0029040391091257334, 0.002698772819712758, 0.0026613909285515547, 0.0027323421090841293, 0.0025512573774904013, 0.0024590559769421816, 0.002499121706932783, 0.0024864948354661465, 0.0024918944109231234, 0.002589777112007141, 0.0025581486988812685, 0.0026890006847679615, 0.002397461561486125, 0.0023340387269854546, 0.15638281404972076, 0.14040781557559967, 0.0022927464451640844, 0.0023813920561224222, 0.00233644712716341, 0.002467334968969226, 0.0026831647846847773, 0.0024509027134627104, 0.0024308343417942524, 0.0024506396148353815, 0.0025223959237337112, 0.0023758304305374622, 0.0026185191236436367, 0.0025004178751260042, 0.0024438719265162945, 0.0023769992403686047, 0.00242729764431715, 0.002477002562955022, 0.002296299673616886, 0.0022889049723744392, 0.002280015265569091, 0.0021210077684372663, 0.0022764611057937145, 0.0020861104130744934, 0.002289330819621682, 0.002297029597684741, 0.12190522253513336, 0.0021230224519968033, 0.08730650693178177, 0.0021574373822659254, 0.002083988394588232, 0.002078043995425105, 0.00221772282384336, 0.0023184488527476788, 0.0023211475927382708, 0.18566399812698364, 0.002166702877730131, 0.0022165824193507433, 0.16791145503520966, 0.0024723384995013475, 0.002561439061537385, 0.00264696660451591, 0.0026268635410815477, 0.0025998097844421864, 0.002576715312898159, 0.002684554783627391, 0.0028799613937735558, 0.0027706248220056295, 0.0027384385466575623, 0.002691794652491808, 0.002722464967519045, 0.0025315883103758097, 0.002667914843186736, 0.0026530795730650425, 0.00249133980832994, 0.0028164852410554886, 0.15355700254440308, 0.002436424605548382, 0.0024341035168617964, 0.002489048056304455, 0.07618018984794617, 0.0028657088987529278, 0.002662614919245243, 0.002535414882004261, 0.002604817971587181, 0.002738810144364834, 0.0025847069919109344, 0.0025467812083661556, 0.002875496866181493, 0.002662874525412917, 0.0026758783496916294, 0.0025143097154796124, 0.002591575961560011, 0.0024748044088482857, 0.002645274391397834, 0.002345541724935174, 0.0023788923863321543, 0.0024475674144923687, 0.0025261391419917345, 0.0025135474279522896, 0.002368399640545249, 0.0022533030714839697, 0.0021368693560361862, 0.09761621057987213, 0.0025546762626618147, 0.0022610228043049574, 0.0022899077739566565, 0.002083469880744815, 0.0020610475912690163, 0.002177291316911578, 0.0023408872075378895, 0.22671358287334442, 0.002127748914062977, 0.002277176594361663, 0.002097838092595339, 0.0022445982322096825, 0.14449679851531982, 0.0021192850545048714, 0.0022105476818978786, 0.0025475728325545788, 0.0023225510958582163, 0.09129562228918076, 0.002362789586186409, 0.11032557487487793, 0.0027308734133839607, 0.0026639308780431747, 0.002945796586573124, 0.0027846393641084433, 0.0028169516008347273, 0.0028774000238627195, 0.0028580864891409874, 0.002897681202739477, 0.15871867537498474, 0.0028984693344682455, 0.0029537377413362265, 0.0029394442681223154, 0.002916512545198202, 0.0028975666500627995, 0.003142395056784153, 0.1342078298330307, 0.0032020919024944305, 0.0030685148667544127, 0.0031876673456281424, 0.17864418029785156, 0.0031873774714767933, 0.003316757967695594, 0.003372384700924158, 0.0034217191860079765, 0.003341234987601638, 0.0037568749394267797, 0.0034318857360631227, 0.0032613512594252825, 0.003374934196472168, 0.0034864768385887146, 0.13529272377490997, 0.0032674807589501143, 0.0034094005823135376, 0.003254017559811473, 0.003247050102800131, 0.003321537747979164, 0.003385258372873068, 0.003161337459459901, 0.003141718916594982, 0.0033303056843578815, 0.18874356150627136, 0.1800539493560791, 0.003216132987290621, 0.003392220241948962, 0.0034050303511321545, 0.0035606524907052517, 0.003410305827856064, 0.0034160884097218513, 0.0033976645208895206, 0.0034686161670833826, 0.003313635941594839, 0.0033328887075185776, 0.0034613374155014753, 0.003353752661496401, 0.0031909209210425615, 0.003305399790406227, 0.003205597400665283, 0.0033310374710708857, 0.003056328045204282, 0.003010553540661931, 0.0030522418674081564, 0.0029356239829212427, 0.0029079990927129984, 0.002808998804539442, 0.002732114400714636, 0.0027019635308533907, 0.0028931114356964827, 0.0027931155636906624, 0.0026236327830702066, 0.0024915256071835756, 0.00251679215580225, 0.0023757878225296736, 0.0023430718574672937, 0.002336269710212946, 0.002369875553995371, 0.002206118544563651, 0.0021965233609080315, 0.17142291367053986, 0.002261221641674638, 0.14206774532794952, 0.13788928091526031, 0.0024386479053646326, 0.0023492465261369944, 0.1674092561006546, 0.0025876788422465324, 0.002630762755870819, 0.0027741778176277876, 0.0028734677471220493, 0.002839147113263607, 0.0028476319275796413, 0.1197727844119072, 0.0030275401659309864, 0.003040025243535638, 0.10944679379463196, 0.003239360637962818, 0.0033046863973140717, 0.0033497188705950975, 0.0036121888551861048, 0.003498096251860261, 0.00351904658600688, 0.0034256279468536377, 0.0035587463062256575, 0.003487905953079462, 0.0034868158400058746, 0.003414599224925041, 0.00357636995613575, 0.0034042915794998407, 0.003457589540630579, 0.10977894812822342, 0.0033499160781502724, 0.13211816549301147, 0.003486286848783493, 0.003504646010696888, 0.0034654231276363134, 0.003494777949526906, 0.003520907135680318, 0.003550355089828372, 0.003415693761780858, 0.15098868310451508, 0.11712484061717987, 0.003606806742027402, 0.0035222135484218597, 0.0035733450204133987, 0.003607402089983225, 0.0036618595477193594, 0.0036640274338424206, 0.003635541768744588, 0.0036476245149970055, 0.003576582530513406, 0.0037391704972833395, 0.0035331202670931816, 0.003749995492398739, 0.0035186447203159332, 0.0034605935215950012, 0.0034014908596873283, 0.003431143471971154, 0.0034055891446769238, 0.003266941523179412, 0.00327042443677783, 0.003117596497759223, 0.117063008248806, 0.003040318377315998, 0.003166693262755871, 0.0031025726348161697, 0.0029786587692797184, 0.003043270669877529, 0.002968418877571821, 0.002863593166694045, 0.002977786585688591, 0.002967396518215537, 0.0028354560490697622, 0.0028452295809984207, 0.002692766021937132, 0.002703276462852955, 0.0025903298519551754, 0.002532246755436063, 0.00271458737552166, 0.002451772103086114, 0.0024702949449419975, 0.002439233474433422, 0.0023382892832159996, 0.0023893131874501705, 0.0023508602753281593, 0.0022333075758069754, 0.0021687806583940983, 0.0021909133065491915, 0.0021147544030100107, 0.002096851821988821, 0.002115292940288782, 0.0020167825277894735, 0.0019905087538063526, 0.0019371132366359234, 0.0019404864870011806, 0.0018728857394307852, 0.001849548309110105, 0.0018178075551986694, 0.0018583579221740365, 0.0017744512297213078, 0.0018287169514223933, 0.0017383869271725416, 0.0016614828491583467, 0.0016741483705118299, 0.001629937905818224, 0.0016118705971166492, 0.0015940233133733273, 0.0016149276634678245, 0.0015823496505618095, 0.0015562851913273335, 0.0015511967940256, 0.001480830367654562, 0.0014430247247219086, 0.0014342204667627811, 0.001415360951796174, 0.0014240439049899578, 0.0014232035027816892, 0.0014433680335059762, 0.0013443937059491873, 0.001396043924614787, 0.001301297452300787, 0.001295673195272684, 0.0012807352468371391, 0.0012832512147724628, 0.001259466866031289, 0.18102814257144928, 0.0012464761966839433, 0.0013480657944455743, 0.0012895914260298014, 0.0012833148939535022, 0.0013007442466914654, 0.001312946085818112, 0.001294566784054041, 0.0013261657441034913, 0.0013575957855209708, 0.0013315881369635463, 0.001297563430853188, 0.0012946655042469501, 0.0013570240698754787, 0.0013353655813261867, 0.0013135612243786454, 0.001305107376538217, 0.16301719844341278, 0.0013594359625130892, 0.0013639783719554543, 0.0013687759637832642, 0.0013501534704118967, 0.0013586815912276506, 0.0013712752843275666, 0.0013742555165663362, 0.001418565632775426, 0.0014914384810253978, 0.17213492095470428, 0.0014617163687944412, 0.5751253962516785, 0.0016070776619017124, 0.0017533780774101615, 0.14357005059719086, 0.002036008285358548, 0.002210689475759864, 0.0024075836408883333, 0.0025337301194667816, 0.0026591122150421143, 0.14531631767749786, 0.00287412921898067, 0.003132330719381571, 0.0030389626044780016, 0.0034154928289353848, 0.0032850049901753664, 0.00331692211329937, 0.0034360955469310284, 0.003441641805693507, 0.15993016958236694, 0.0035281223244965076, 0.003654347499832511, 0.0038013379089534283, 0.003756874240934849, 0.0037630300503224134, 0.0037535903975367546, 0.0037371318321675062, 0.003738283645361662, 0.003739357693120837, 0.003765555564314127, 0.0036659203469753265, 0.003690900979563594, 0.0036511493381112814, 0.003613834735006094, 0.003536676988005638, 0.0035240536089986563, 0.0034969656262546778, 0.003384161042049527, 0.003362994408234954, 0.00332063902169466, 0.003313259221613407, 0.003379418747499585, 0.0031268703751266003, 0.003119360888376832, 0.003028517821803689, 0.0029559459071606398, 0.0028962360229343176, 0.002849181182682514, 0.0027796244248747826, 0.11748342961072922, 0.002733389614149928, 0.0027299262583255768, 0.002719100099056959, 0.1371667981147766, 0.0028031517285853624, 0.002741304924711585, 0.0027219082694500685, 0.0027194588910788298, 0.0028448442462831736, 0.002742861397564411, 0.1386748105287552, 0.002898601582273841, 0.002809026511386037, 0.002878571627661586, 0.0028493194840848446, 0.0027791340835392475, 0.0027805306017398834, 0.0028468987438827753, 0.0027555779088288546, 0.0027575658168643713, 0.0027360408566892147, 0.002781527116894722, 0.0028210144955664873, 0.00280614267103374, 0.0026631117798388004, 0.002619817154482007, 0.002568932017311454, 0.0025274574290961027, 0.0025241682305932045, 0.0024697883054614067, 0.0024452470242977142, 0.13734644651412964, 0.0024032124783843756, 0.0024060853756964207, 0.002428872510790825, 0.0024296308401972055, 0.0023922701366245747, 0.12185673415660858, 0.0024008715990930796, 0.0024333333130925894, 0.1222338080406189, 0.002474880311638117, 0.0025270746555179358, 0.00254538981243968, 0.0025833146646618843, 0.002604379551485181, 0.0026476953644305468, 0.13903288543224335, 0.10893084853887558, 0.0028356295078992844, 0.002807093784213066, 0.0029105644207447767, 0.0029625706374645233, 0.0030632056295871735, 0.0029796650633215904, 0.003059204900637269, 0.0030038875993341208, 0.0030436257366091013, 0.0030024624429643154, 0.11645360291004181, 0.0030162925831973553, 0.11315549910068512, 0.12941785156726837, 0.0032198294065892696, 0.0033049543853849173, 0.003322141943499446, 0.0033652347046881914, 0.0034847173374146223, 0.0034793997183442116, 0.0036295622121542692, 0.003627103753387928, 0.0034927180968225002, 0.003470701165497303, 0.0034716716036200523, 0.09007352590560913, 0.0036333638709038496, 0.003541755024343729, 0.1329791247844696, 0.0035750276874750853, 0.003586790058761835, 0.003588329767808318, 0.003770924638956785, 0.003755563870072365, 0.0037983013316988945, 0.003687652526423335, 0.0037304996512830257, 0.10956406593322754, 0.0037333292420953512, 0.003790844464674592, 0.1327543705701828, 0.49876368045806885, 0.003806023858487606, 0.004044665489345789, 0.0043549006804823875, 0.00432656379416585, 0.004645171575248241, 0.004629800096154213, 0.004859327804297209, 0.11683367937803268, 0.004885319620370865, 0.004946340806782246, 0.005156234372407198, 0.005082706455141306, 0.13151073455810547, 0.005448039621114731, 0.10197076946496964, 0.005619925446808338, 0.005374483298510313, 0.005300592165440321, 0.005378322675824165, 0.005534084513783455, 0.005433844868093729, 0.005308466497808695, 0.00555946072563529, 0.005330621264874935, 0.005148631986230612, 0.005088851787149906, 0.005218023434281349, 0.005191856995224953, 0.004837547428905964, 0.00476415641605854, 0.004793787840753794, 0.0047342656180262566, 0.004486215766519308, 0.00451394310221076, 0.004322283901274204, 0.004292909521609545, 0.004208259750157595, 0.0040922267362475395, 0.0039044152945280075, 0.003924500197172165, 0.003978821914643049, 0.0036438971292227507, 0.0036410794127732515, 0.003566964063793421, 0.0034430688247084618, 0.0034235704224556684, 0.0033115071710199118, 0.0033103341702371836, 0.0033357294742017984, 0.14678290486335754, 0.0031014224514365196, 0.0030816560611128807, 0.0031349805649369955, 0.002988598309457302, 0.003017533104866743, 0.0029045604169368744, 0.0029123714193701744, 0.002879031002521515, 0.0028958418406546116, 0.002836804836988449, 0.0027877872344106436, 0.002816602122038603, 0.002681455807760358, 0.0026233794633299112, 0.0026609464548528194, 0.00258607673458755, 0.0025513404980301857, 0.002498845336958766, 0.14813540875911713, 0.13543042540550232, 0.00267446949146688, 0.002580290427431464, 0.002585440641269088, 0.002593244891613722, 0.002666292479261756, 0.0025891405530273914, 0.1171826496720314, 0.002654425799846649, 0.002630955772474408, 0.002718976465985179, 0.17219768464565277, 0.0028531767893582582, 0.002762993797659874, 0.0028528603725135326, 0.0030050647910684347, 0.002844455884769559, 0.10994591563940048, 0.002911182353273034, 0.002895906800404191, 0.0030093577224761248, 0.0031993165612220764, 0.0031712744385004044, 0.0030964685138314962, 0.003051256062462926, 0.00302200042642653, 0.003071335842832923, 0.0029758368618786335, 0.0859609916806221, 0.003038059687241912, 0.17650066316127777, 0.0030949872452765703, 0.0030737766064703465, 0.0031486214138567448, 0.0032024518586695194, 0.0031852065585553646, 0.0031149443238973618, 0.003250391222536564, 0.0032635105308145285, 0.003168761497363448, 0.0030947462655603886, 0.003094207961112261, 0.0030854621436446905, 0.003008923027664423, 0.003141731722280383, 0.002987067447975278, 0.002957297954708338, 0.002894391305744648, 0.0028595069888979197, 0.00288111693225801, 0.0028214494232088327, 0.00285880989395082, 0.002785956487059593, 0.002726849867030978, 0.0026359534822404385, 0.0025973054580390453, 0.0025585535913705826, 0.0025103329680860043, 0.002582152606919408, 0.002476585330441594, 0.002528887940570712, 0.002379755023866892, 0.0024811970070004463, 0.0023456558119505644, 0.1212427094578743, 0.002435525180771947, 0.13705229759216309, 0.0022936814930289984, 0.002407418331131339, 0.002427276922389865, 0.0024373349733650684, 0.002394711831584573, 0.002465300029143691, 0.002432356821373105, 0.002430942142382264, 0.0024136912543326616, 0.0023990964982658625, 0.1142757311463356, 0.0023623278830200434, 0.0024512968957424164, 0.0024561865720897913, 0.002434616442769766, 0.0024243041407316923, 0.002404803177341819, 0.0025371594820171595, 0.0023974739015102386, 0.002485100645571947, 0.0024010930210351944, 0.002411613939329982, 0.002431447384878993, 0.0024217679165303707, 0.002314070239663124, 0.0023751305416226387, 0.0024531325325369835, 0.002223657676950097, 0.002280451124534011, 0.002162040676921606, 0.0021370984613895416, 0.0021605449728667736, 0.0021180855110287666, 0.0021457213442772627, 0.0020961954724043608, 0.0021000977139919996, 0.002085011685267091, 0.001986465882509947, 0.002088053384795785, 0.001994711346924305, 0.0019957544282078743, 0.0020227963104844093, 0.0019215024076402187, 0.001969717675819993, 0.0018602210329845548, 0.001825895393267274, 0.0018520706798881292, 0.0017465001437813044, 0.0017807704862207174, 0.0018058604327961802, 0.0017617926932871342, 0.15411096811294556, 0.13938257098197937, 0.0017390870489180088, 0.0018377795349806547, 0.0018138524610549212]\n",
            "Val loss 0.013261562213593427\n",
            "Val auc roc 0.4127288207747978\n",
            "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     2: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e74fc10376d4b07979482aba983ebae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0139\n",
            "Train Losses : [0.0018551584798842669, 0.0019696359522640705, 0.0019276596140116453, 0.0018004777375608683, 0.001837997231632471, 0.17602066695690155, 0.0019025319488719106, 0.0019624268170446157, 0.0018382107373327017, 0.0018377486849203706, 0.0019004298374056816, 0.0018644626252353191, 0.0018390198238193989, 0.001872934284619987, 0.0018217588076367974, 0.0019321241416037083, 0.0018209926784038544, 0.0018874898087233305, 0.0018520766170695424, 0.0018627492245286703, 0.0018153818091377616, 0.0018967038486152887, 0.0018616784363985062, 0.0018507532076910138, 0.0018308705184608698, 0.0018195986049249768, 0.001895877649076283, 0.0018213524017482996, 0.133719339966774, 0.0018519532168284059, 0.0018662592628970742, 0.0018653940642252564, 0.0018709602300077677, 0.0019131533335894346, 0.0018461360596120358, 0.0018834543880075216, 0.16430842876434326, 0.001899951952509582, 0.001898968475870788, 0.001888853614218533, 0.0018239283235743642, 0.0018918344285339117, 0.001872260239906609, 0.0019264620495960116, 0.0018856488168239594, 0.0018273914465680718, 0.12306921184062958, 0.001839998411014676, 0.0019108516862615943, 0.0019048666581511497, 0.0018899334827437997, 0.0018777380464598536, 0.11879951506853104, 0.15242259204387665, 0.001890258165076375, 0.0018851974746212363, 0.0019379185978323221, 0.13290919363498688, 0.0018819140968844295, 0.0018789380555972457, 0.001901831477880478, 0.0019509405829012394, 0.0019478739704936743, 0.0018997564911842346, 0.0019751370418816805, 0.12068618834018707, 0.0020240379963070154, 0.0019829028751701117, 0.0019818085711449385, 0.0019144726684316993, 0.0019285195739939809, 0.0020132679492235184, 0.0019778539426624775, 0.0019424790516495705, 0.0019483112264424562, 0.0019342810846865177, 0.0019402861362323165, 0.0019932754803448915, 0.0019325473112985492, 0.0019309923518449068, 0.0019321981817483902, 0.0019993153400719166, 0.001996394246816635, 0.0019511425634846091, 0.0019854502752423286, 0.001957983709871769, 0.001926965662278235, 0.0019121263176202774, 0.001959636341780424, 0.0019043419742956758, 0.001946721924468875, 0.0019051744602620602, 0.00196078117005527, 0.001995653845369816, 0.0018786366563290358, 0.0019485319498926401, 0.001897579524666071, 0.0018902132287621498, 0.0018792676273733377, 0.001978878863155842, 0.15247772634029388, 0.0019026435911655426, 0.0018744636327028275, 0.00192934088408947, 0.0019212205661460757, 0.09793773293495178, 0.0018934976542368531, 0.001888206577859819, 0.0019294958328828216, 0.0019075175514444709, 0.001981519628316164, 0.0019229755271226168, 0.0019215756328776479, 0.0020128327887505293, 0.001986938063055277, 0.0019329646602272987, 0.0019113982561975718, 0.0019158268114551902, 0.001903755939565599, 0.0020032364409416914, 0.001880823285318911, 0.0018972173565998673, 0.0019362373277544975, 0.0019239154644310474, 0.0020023598335683346, 0.001966940937563777, 0.0019138792995363474, 0.001982085406780243, 0.0019040006445720792, 0.0018720794469118118, 0.0019626484718173742, 0.00187755620572716, 0.0019465909572318196, 0.0018640978960320354, 0.0019175015622749925, 0.0020130460616201162, 0.0018501761369407177, 0.0018595348810777068, 0.001877891249023378, 0.001925152144394815, 0.0019285025773569942, 0.0018975975690409541, 0.0019514716695994139, 0.0018663976807147264, 0.0018838352989405394, 0.0018719659419730306, 0.0018452148651704192, 0.001867164857685566, 0.001908071106299758, 0.0018841830315068364, 0.0018624839140102267, 0.1646886020898819, 0.0018915210384875536, 0.0019382927566766739, 0.001836166251450777, 0.001901533454656601, 0.0019160372903570533, 0.001837233197875321, 0.14939215779304504, 0.0018876494141295552, 0.0018975866260007024, 0.001943802461028099, 0.0019976866897195578, 0.001964814495295286, 0.001858639414422214, 0.0018534933915361762, 0.0020019307266920805, 0.11902490258216858, 0.001939687062986195, 0.1547481268644333, 0.001871186075732112, 0.0019640345126390457, 0.0018959944136440754, 0.0018690546276047826, 0.0018835882656276226, 0.001892580185085535, 0.001939507550559938, 0.0018928898498415947, 0.0018790211761370301, 0.16643396019935608, 0.001970440149307251, 0.001909212558530271, 0.0019338811980560422, 0.0018878577975556254, 0.0019023333443328738, 0.0018931578379124403, 0.002009694930166006, 0.0019887995440512896, 0.001984100788831711, 0.1697782278060913, 0.0018995966529473662, 0.0018974171252921224, 0.0019813256803900003, 0.0019087125547230244, 0.001921667717397213, 0.0019643513951450586, 0.0019477505702525377, 0.001970042707398534, 0.0019104945240542293, 0.0018999603344127536, 0.0019630587194114923, 0.001905290875583887, 0.002010443015024066, 0.0019088563276454806, 0.0019999437499791384, 0.0019428356317803264, 0.001981575507670641, 0.0019845792558044195, 0.001888790400698781, 0.0019300563726574183, 0.001958731561899185, 0.002055079909041524, 0.09188481420278549, 0.0018801243277266622, 0.0018828394822776318, 0.10069315135478973, 0.001904557109810412, 0.001969253644347191, 0.001941262511536479, 0.0019173974869772792, 0.0018941216403618455, 0.002033581491559744, 0.001954023027792573, 0.001974525861442089, 0.00191349012311548, 0.0019179820083081722, 0.0020027582067996264, 0.0019346059998497367, 0.0019541014917194843, 0.0019382552709430456, 0.001975076273083687, 0.0019274662481620908, 0.0019079389749094844, 0.001988741336390376, 0.0019036264857277274, 0.001892775297164917, 0.002005536574870348, 0.0020061915274709463, 0.0018978064181283116, 0.0019086170941591263, 0.001986761810258031, 0.0018875451060011983, 0.1669607162475586, 0.001902344054542482, 0.1709454208612442, 0.001883260440081358, 0.0019057475728914142, 0.0018993347184732556, 0.0019502058858051896, 0.0019498853944242, 0.001981086563318968, 0.0019143318058922887, 0.0020201844163239002, 0.00194695929531008, 0.0019135682377964258, 0.0019514014711603522, 0.001912972191348672, 0.0018867402104660869, 0.0019359729485586286, 0.0019022675696760416, 0.001962210051715374, 0.001987024210393429, 0.0018814869690686464, 0.0018899651477113366, 0.0019182800315320492, 0.0019079389749094844, 0.0018835263326764107, 0.0019259501714259386, 0.18042972683906555, 0.0019225457217544317, 0.002001736778765917, 0.001958003733307123, 0.0019090367713943124, 0.0019364638719707727, 0.0018945508636534214, 0.001974566141143441, 0.0020058604422956705, 0.0019926095847040415, 0.0019554547034204006, 0.0019006021320819855, 0.0019279926782473922, 0.001964565832167864, 0.0018927713390439749, 0.0019045170629397035, 0.0018883137963712215, 0.0018804480787366629, 0.0018882694421336055, 0.0019375168485566974, 0.001935332315042615, 0.0018785118591040373, 0.0018796721706166863, 0.0019285223679617047, 0.0018710396252572536, 0.0018832659116014838, 0.0018778296653181314, 0.0019089768175035715, 0.0019293379737064242, 0.0019200820242986083, 0.002032920718193054, 0.11443393677473068, 0.0018572123954072595, 0.0018758262740448117, 0.001904588076286018, 0.0018898050766438246, 0.0018875182140618563, 0.0019031227566301823, 0.0018896840047091246, 0.0019338008714839816, 0.09766675531864166, 0.0018777562072500587, 0.0019350765505805612, 0.001865455531515181, 0.0018644373631104827, 0.0018478739075362682, 0.0018775591161102057, 0.001885822624899447, 0.0019635313656181097, 0.0018666052492335439, 0.12826761603355408, 0.0019225889118388295, 0.0018600033363327384, 0.0019351023947820067, 0.001928513403981924, 0.001972361234948039, 0.0019232106860727072, 0.19221757352352142, 0.17414326965808868, 0.0020117058884352446, 0.0018752147443592548, 0.0019037448801100254, 0.0020297213923186064, 0.0018994640558958054, 0.0019239290850237012, 0.0018981753382831812, 0.0019285693997517228, 0.0019140663789585233, 0.0019883622881025076, 0.0019477690802887082, 0.0019794944673776627, 0.0019304817542433739, 0.0019380179001018405, 0.0019579799845814705, 0.0019329789793118834, 0.0019458369351923466, 0.0019316031830385327, 0.0018947324715554714, 0.0018861349672079086, 0.001948330900631845, 0.0019025626825168729, 0.0018974262056872249, 0.0019284181762486696, 0.001893723732791841, 0.1465742439031601, 0.001880740630440414, 0.0018893333617597818, 0.0019029470859095454, 0.0019054928561672568, 0.16907596588134766, 0.0018906897166743875, 0.0019041748018935323, 0.0019103257218375802, 0.0019168555736541748, 0.0020545395091176033, 0.0019055099692195654, 0.0018977863946929574, 0.002081712707877159, 0.0018979321466758847, 0.0019738427363336086, 0.001896787085570395, 0.001939481357112527, 0.0019179184455424547, 0.0019675365183502436, 0.001954434672370553, 0.0019162329845130444, 0.002002440858632326, 0.0019509752746671438, 0.0019055668963119388, 0.001948108896613121, 0.0019951798021793365, 0.0018970646196976304, 0.0019917062018066645, 0.002015673089772463, 0.0019045739900320768, 0.0018998862942680717, 0.001882343553006649, 0.0018743663094937801, 0.0019514686428010464, 0.001933843595907092, 0.001987679861485958, 0.0018670944264158607, 0.0019402605248615146, 0.0019156888592988253, 0.0018790204776450992, 0.0018972826655954123, 0.001956148073077202, 0.0019134156173095107, 0.0019433245761319995, 0.0019473930587992072, 0.0019078077748417854, 0.13496017456054688, 0.00185714743565768, 0.0018614120781421661, 0.0018848809413611889, 0.001868190593086183, 0.0019074762240052223, 0.0018494334071874619, 0.001955472631379962, 0.001919776783324778, 0.0018831276101991534, 0.0018723850371316075, 0.0019442273769527674, 0.0018920638831332326, 0.0018633116269484162, 0.001887492835521698, 0.0019683409482240677, 0.0019109636778011918, 0.11185804009437561, 0.0018432213691994548, 0.0019242448033764958, 0.0018738131038844585, 0.0018929000943899155, 0.0018937806598842144, 0.001851898618042469, 0.14040698111057281, 0.001942734234035015, 0.0019026376539841294, 0.0019047317327931523, 0.0019026061054319143, 0.0019183120457455516, 0.0019200424430891871, 0.14043454825878143, 0.0018540254095569253, 0.0019680187106132507, 0.0019066118402406573, 0.0019287163158878684, 0.0019585315603762865, 0.0019070951966568828, 0.0019520614296197891, 0.0019296969985589385, 0.0018945407355204225, 0.0018889055354520679, 0.15895578265190125, 0.0018987712683156133, 0.0018673330778256059, 0.0019041263731196523, 0.0018946129130199552, 0.0019311854848638177, 0.001987656345590949, 0.0019437740556895733, 0.13928663730621338, 0.0019325421890243888, 0.0020048257429152727, 0.0019239528337493539, 0.0018967881333082914, 0.13313819468021393, 0.0018897223053500056, 0.0019716233946383, 0.001951629645191133, 0.0019003666238859296, 0.0019220642279833555, 0.001926687778905034, 0.001998042920604348, 0.001900640083476901, 0.00199076347053051, 0.0019468538230285048, 0.002023129491135478, 0.0019097962649539113, 0.001953231170773506, 0.0018986198119819164, 0.001966934883967042, 0.0019211226608604193, 0.001991825643926859, 0.0019921278581023216, 0.001948531367816031, 0.0019192895852029324, 0.0019185369601473212, 0.0020080965477973223, 0.0019261466804891825, 0.0020275397691875696, 0.0019028264796361327, 0.00209803762845695, 0.0019677740056067705, 0.0019132232991978526, 0.00193421496078372, 0.158192977309227, 0.0019141011871397495, 0.0018996393773704767, 0.0019041787600144744, 0.15786030888557434, 0.0019173914333805442, 0.002016756683588028, 0.602810800075531, 0.0019785314798355103, 0.001966102048754692, 0.0019564246758818626, 0.0019849271047860384, 0.0019397251307964325, 0.0019701258279383183, 0.001968957483768463, 0.0019853406120091677, 0.002004980808123946, 0.0020027935970574617, 0.0020084185525774956, 0.0019808299839496613, 0.001983452122658491, 0.002000098815187812, 0.0019720946438610554, 0.0020745480433106422, 0.0019802048336714506, 0.002000418957322836, 0.0019876977894455194, 0.002026623347774148, 0.001955209532752633, 0.0019613720942288637, 0.002011273754760623, 0.001995971193537116, 0.0019949995912611485, 0.0020520503167062998, 0.0020426830742508173, 0.0020735329017043114, 0.1447286456823349, 0.001942525035701692, 0.002135475166141987, 0.002028157003223896, 0.0020384981762617826, 0.002020095009356737, 0.0019743687007576227, 0.001986489165574312, 0.001955835148692131, 0.0019552416633814573, 0.0019656068179756403, 0.00199555023573339, 0.0019671551417559385, 0.0019996657501906157, 0.001999330474063754, 0.0019479029579088092, 0.0019743822049349546, 0.001993678044527769, 0.002109777182340622, 0.002004508161917329, 0.0019485496450215578, 0.0019558200147002935, 0.001981996465474367, 0.0019609027076512575, 0.0019483421929180622, 0.002003002678975463, 0.0020376108586788177, 0.0019690359476953745, 0.0019705931190401316, 0.0020265576895326376, 0.001995042897760868, 0.0019505671225488186, 0.001967750024050474, 0.0019506426760926843, 0.002080557867884636, 0.0019683430436998606, 0.0019939627964049578, 0.0019154053879901767, 0.09367304295301437, 0.001986755058169365, 0.001953176688402891, 0.001981407403945923, 0.0019206978613510728, 0.0019624591805040836, 0.001959186280146241, 0.0019777100533246994, 0.001935805194079876, 0.0019348245114088058, 0.001976390602067113, 0.002091130008921027, 0.0019132629968225956, 0.0020511052571237087, 0.0019677826203405857, 0.0019128251587972045, 0.0019865715876221657, 0.001925490447320044, 0.001999370753765106, 0.0019225955475121737, 0.0019901960622519255, 0.0019246955635026097, 0.0019004478817805648, 0.00189589976798743, 0.0019506779499351978, 0.0019099891651421785, 0.001952079008333385, 0.0019561208318918943, 0.00188286486081779, 0.001899317605420947, 0.16132064163684845, 0.0019241317640990019, 0.001989133656024933, 0.0018972625257447362, 0.001942309783771634, 0.001943951123394072, 0.0019014354329556227, 0.12210538238286972, 0.0018850092310458422, 0.0019555394537746906, 0.0019287877948954701, 0.0019601224921643734, 0.0019065203377977014, 0.0019892577547580004, 0.0019998792558908463, 0.0018859844421967864, 0.0018876332323998213, 0.0019489284604787827, 0.0019285519374534488, 0.001928010256960988, 0.0018907752819359303, 0.0019307424081489444, 0.002046731999143958, 0.0019507053075358272, 0.0019040432525798678, 0.0019252653000876307, 0.0019752015359699726, 0.0019082528306171298, 0.0019114614697173238, 0.0019217057852074504, 0.0019602333195507526, 0.0018899274291470647, 0.001890974584966898, 0.001923826290294528, 0.0020460740197449923, 0.0020098004024475813, 0.0019178035436198115, 0.0018731376621872187, 0.001868420047685504, 0.0018838252872228622, 0.001908865524455905, 0.0018765843706205487, 0.001879956224001944, 0.0018796604126691818, 0.1315007358789444, 0.0019061751663684845, 0.0019003875786438584, 0.0018578728195279837, 0.0019177001668140292, 0.13146905601024628, 0.0019005282083526254, 0.00199984572827816, 0.0019091357244178653, 0.0019249269971624017, 0.0018742952961474657, 0.1125001534819603, 0.002001505810767412, 0.0019471585983410478, 0.0019359905272722244, 0.0019564018584787846, 0.0019459426403045654, 0.0019241494592279196, 0.0018820958212018013, 0.0019428477389737964, 0.001920604845508933, 0.001997784711420536, 0.0019530593417584896, 0.0019699318800121546, 0.0019020544132217765, 0.001877286471426487, 0.12242919951677322, 0.0018742949469015002, 0.0019004875794053078, 0.0018968223594129086, 0.0018716828199103475, 0.0019476431189104915, 0.001902855234220624, 0.001978181069716811, 0.0019318958511576056, 0.001888863043859601, 0.0020206423941999674, 0.001901530660688877, 0.0019251115154474974, 0.002001115819439292, 0.0019406236242502928, 0.14240369200706482, 0.0019295563688501716, 0.00197427487000823, 0.0018972508842125535, 0.0019044126383960247, 0.0018916807603091002, 0.002041440224274993, 0.0018767071887850761, 0.001887427642941475, 0.0019211969338357449, 0.0019125062972307205, 0.0018954856786876917, 0.001954849809408188, 0.0019272661302238703, 0.0019097930053249002, 0.0019093221053481102, 0.10440246015787125, 0.0019771598745137453, 0.0018971192184835672, 0.0019141361117362976, 0.0018666358664631844, 0.0019209685269743204, 0.0019394578412175179, 0.001912263804115355, 0.1630917489528656, 0.0019202824914827943, 0.0019226265139877796, 0.001879714080132544, 0.0018850755877792835, 0.0019327703630551696, 0.0019065208034589887, 0.11156244575977325, 0.001908165868371725, 0.0019051331328228116, 0.0019034978467971087, 0.001908075180836022, 0.0019014048157259822, 0.001970543060451746, 0.10387089848518372, 0.0019174489425495267, 0.001991997705772519, 0.001925082877278328, 0.001899146824143827, 0.0019006076036021113, 0.0018971400568261743, 0.001888682134449482, 0.0018979430897161365, 0.0019016198348253965, 0.0019543853122740984, 0.001896091504022479, 0.0019993153400719166, 0.0019374977564439178, 0.1505441963672638, 0.001970425248146057, 0.09078013151884079, 0.0020341752097010612, 0.0018989117816090584, 0.0020388769917190075, 0.001952673657797277, 0.0019732953514903784, 0.0019324809545651078, 0.0019741214346140623, 0.0019220958929508924, 0.0019362346502020955, 0.0020195094402879477, 0.001932861632667482, 0.002033293480053544, 0.001961318776011467, 0.0019957039039582014, 0.001941873342730105, 0.0019627574365586042, 0.0019412827678024769, 0.0019635481294244528, 0.001906160730868578, 0.0018905666656792164, 0.0019185193814337254, 0.0019509114790707827, 0.001922433846630156, 0.0019156448543071747, 0.0019862204790115356, 0.0019886870868504047, 0.0019156619673594832, 0.0019137851195409894, 0.001952259917743504, 0.0019266781164333224, 0.0019531172001734376, 0.0019226904259994626, 0.0019067272078245878, 0.0018837419338524342, 0.0018987520597875118, 0.0020206496119499207, 0.0019204841228201985, 0.0019703509751707315, 0.0018750564195215702, 0.0019271279452368617, 0.0019386415369808674, 0.0019189540762454271, 0.0018735125195235014, 0.0019338992424309254, 0.0019174263579770923, 0.1586655080318451, 0.0019102802034467459, 0.0018726128619164228, 0.0019184417324140668, 0.0018825939623638988, 0.0019309256458655, 0.0019109002314507961, 0.001888240105472505, 0.001936243032105267, 0.0018684903625398874, 0.0019123650854453444, 0.0019064137013629079, 0.001988888019695878, 0.0019586270209401846, 0.001992541830986738, 0.0018742564134299755, 0.0019090367713943124, 0.001973284175619483, 0.0019660929683595896, 0.0018925208132714033, 0.13839241862297058, 0.0018903178861364722, 0.0019162989920005202, 0.001928273937664926, 0.13179883360862732, 0.00186529743950814, 0.0018861526623368263, 0.12317278236150742, 0.0018787853186950088, 0.0019294285448268056, 0.0019190069288015366, 0.001969949109479785, 0.13592557609081268, 0.0018874555826187134, 0.1298329085111618, 0.0019366813357919455, 0.0019153308821842074, 0.0019061012426391244, 0.13343626260757446, 0.0020286706276237965, 0.0019459390314295888, 0.0019281106069684029, 0.001997070387005806, 0.0019270145567134023, 0.001939878216944635, 0.0019503781804814935, 0.14149735867977142, 0.0019341863226145506, 0.0020417110063135624, 0.0019686517771333456, 0.0020012918394058943, 0.0019863357301801443, 0.0019319802522659302, 0.001937145134434104, 0.0019989656284451485, 0.001948228687979281, 0.0019532206933945417, 0.1090339720249176, 0.1551683098077774, 0.1329527497291565, 0.001971200108528137, 0.0019378518918529153, 0.0019715551752597094, 0.002033700468018651, 0.001982731046155095, 0.0019702960271388292, 0.001982239307835698, 0.001986005110666156, 0.0020265751518309116, 0.0020103033166378736, 0.0020195634569972754, 0.0019691074267029762, 0.0019905478693544865, 0.0019790618680417538, 0.0019863592460751534, 0.15315133333206177, 0.0020749142859131098, 0.00199312437325716, 0.0020115717779845, 0.0019909050315618515, 0.10523983836174011, 0.002004060195758939, 0.001972752157598734, 0.001963934628292918, 0.0020571670029312372, 0.0020220549777150154, 0.0020041903480887413, 0.0019873310811817646, 0.001965806121006608, 0.1566053032875061, 0.0021007126197218895, 0.00200448976829648, 0.002103548962622881, 0.002071268390864134, 0.0020553069189190865, 0.0020036487840116024, 0.0020623018499463797, 0.13552796840667725, 0.002090966561809182, 0.0020269611850380898, 0.0020830819848924875, 0.0020095102954655886, 0.002026015892624855, 0.13107959926128387, 0.002014647936448455, 0.0020278727170079947, 0.002010375028476119, 0.1453259289264679, 0.002102897735312581, 0.002038032514974475, 0.0021114819683134556, 0.002011232078075409, 0.0020559607073664665, 0.14545215666294098, 0.0020725324284285307, 0.0020521492697298527, 0.0020101694390177727, 0.0020645896438509226, 0.002018748316913843, 0.00203125667758286, 0.0020946974400430918, 0.0021203081123530865, 0.11071237176656723, 0.002036773832514882, 0.0020565250888466835, 0.1342940330505371, 0.002036202233284712, 0.0020355205051600933, 0.0021075927652418613, 0.0020492461044341326, 0.002073487499728799, 0.002052512252703309, 0.002073971088975668, 0.10803517699241638, 0.0021097990684211254, 0.002102096099406481, 0.0020607016049325466, 0.0021090656518936157, 0.002136750379577279, 0.002107894280925393, 0.002090682042762637, 0.002081072423607111, 0.0021595475263893604, 0.002056177705526352, 0.13822875916957855, 0.0020372115541249514, 0.0020344543736428022, 0.0020518384408205748, 0.14152589440345764, 0.0021233600564301014, 0.0020569730550050735, 0.0020734115969389677, 0.0020685282070189714, 0.0020559020340442657, 0.002186230616644025, 0.14140930771827698, 0.002063603838905692, 0.0021094046533107758, 0.0021231251303106546, 0.002093080896884203, 0.0021440202835947275, 0.13288043439388275, 0.0020868738647550344, 0.0021127890795469284, 0.00208052946254611, 0.12255772203207016, 0.0021197176538407803, 0.002119458746165037, 0.002076264936476946, 0.002086751628667116, 0.0021190952975302935, 0.002119813347235322, 0.0021288383286446333, 0.0021298325154930353, 0.002067417372018099, 0.0021148277446627617, 0.0021653471048921347, 0.0021394093055278063, 0.0021379957906901836, 0.0021624970249831676, 0.0021366511937230825, 0.0020966525189578533, 0.0020782994106411934, 0.0021191404666751623, 0.0021309913136065006, 0.002074525458738208, 0.0020691598765552044, 0.0021029901690781116, 0.002127290703356266, 0.002067818306386471, 0.12292423099279404, 0.002181312069296837, 0.002090941881760955, 0.0021381231490522623, 0.002106280066072941, 0.002118085278198123, 0.00208570365794003, 0.0021705166436731815, 0.12137513607740402, 0.0020662008319050074, 0.0021724931430071592, 0.0021833127830177546, 0.002069412963464856, 0.12395546585321426, 0.0021787623409181833, 0.1200779378414154, 0.0020708038937300444, 0.002086391905322671, 0.002109296852722764, 0.0022108436096459627, 0.0021556655410677195, 0.002123251324519515, 0.0021024425514042377, 0.0021207642275840044, 0.0021198356989771128, 0.10952290147542953, 0.0021465723402798176, 0.14293642342090607, 0.134902223944664, 0.0020893276669085026, 0.0021393648348748684, 0.0021950462833046913, 0.13659004867076874, 0.0021388749592006207, 0.0021613361313939095, 0.1822313368320465, 0.0021460377611219883, 0.1266363561153412, 0.0022794120013713837, 0.002133170375600457, 0.0022435870487242937, 0.0021512992680072784, 0.0021757003851234913, 0.00212608790025115, 0.0021938919089734554, 0.002144732279703021, 0.0021875263191759586, 0.4592526853084564, 0.12526202201843262, 0.0021786834113299847, 0.0021888765040785074, 0.002258613472804427, 0.002227845136076212, 0.002183282747864723, 0.002189258113503456, 0.002190025756135583, 0.0022115164902061224, 0.002248738892376423, 0.002257448388263583, 0.0022948547266423702, 0.0022108471021056175, 0.002217741683125496, 0.002257110085338354, 0.002219201298430562, 0.0022231945767998695, 0.0022324733436107635, 0.0022250483743846416, 0.0022241545375436544, 0.002288403455168009, 0.0022133123129606247, 0.002214711857959628, 0.0022426594514399767, 0.002308071358129382, 0.002261532237753272, 0.002210474107414484, 0.0022248048335313797, 0.002221612958237529, 0.12462934106588364, 0.0022165742702782154, 0.002216891385614872, 0.0022024877835065126, 0.00219297269359231, 0.002291688695549965, 0.002185697667300701, 0.0022073278669267893, 0.002184628276154399, 0.0022016961593180895, 0.0022461428306996822, 0.002199759939685464, 0.0021895840764045715, 0.0022308523766696453, 0.00227800733409822, 0.002317446516826749, 0.002244714880362153, 0.002231830731034279, 0.0022335636895149946, 0.00224358681589365, 0.002169674262404442, 0.0022076896857470274, 0.0022466606460511684, 0.0022955951280891895, 0.002287207404151559, 0.002205147873610258, 0.11954634636640549, 0.002179737901315093, 0.0021863661240786314, 0.09843932092189789, 0.0022561310324817896, 0.0021876716054975986, 0.002220325404778123, 0.0021828331518918276, 0.0022245889995247126, 0.12318067252635956, 0.0022503596264868975, 0.0021942516323179007, 0.002206864533945918, 0.00224299356341362, 0.11139146238565445, 0.0021807169541716576, 0.0022218995727598667, 0.0021805851720273495, 0.0022290623746812344, 0.0022732731886208057, 0.002243740949779749, 0.0023353323340415955, 0.0022571722511202097, 0.0022177197970449924, 0.0022577005438506603, 0.002197500318288803, 0.0021862774156033993, 0.0021822655107825994, 0.002202865667641163, 0.0022892404813319445, 0.0022048817481845617, 0.0022342607844620943, 0.002255973406136036, 0.0022756021935492754, 0.0022374310065060854, 0.002183186588808894, 0.002251141704618931, 0.002183991950005293, 0.00232446426525712, 0.002184987301006913, 0.002279389649629593, 0.002208273857831955, 0.10633642226457596, 0.002206286648288369, 0.0022147726267576218, 0.0022117996122688055, 0.002244704170152545, 0.002410966670140624, 0.002177392365410924, 0.0022218262311071157, 0.0021700887009501457, 0.002254185499623418, 0.002208229387179017, 0.0021863840520381927, 0.12553836405277252, 0.0022264872677624226, 0.0022840837482362986, 0.0021993552800267935, 0.0021827947348356247, 0.002225044649094343, 0.002229257021099329, 0.0021908869966864586, 0.002160737756639719, 0.0022167207207530737, 0.0022378384601324797, 0.002224955940619111, 0.0021589621901512146, 0.002222898416221142, 0.0022360440343618393, 0.002161820651963353, 0.1277909278869629, 0.0021733061876147985, 0.002213068073615432, 0.0022515144664794207, 0.0021976011339575052, 0.13954000174999237, 0.002168860286474228, 0.002208107616752386, 0.002165108220651746, 0.0022158734500408173, 0.0021702370140701532, 0.002191172679886222, 0.0021880092099308968, 0.0022438575979322195, 0.10194248706102371, 0.002201550407335162, 0.002205043099820614, 0.0022142960224300623, 0.002163894008845091, 0.002238101325929165, 0.0021957203280180693, 0.002181135816499591, 0.0022142769303172827, 0.0022516297176480293, 0.0022139044012874365, 0.0021629133261740208, 0.002193872816860676, 0.0022153197787702084, 0.0022027913946658373, 0.002241803565993905, 0.0021966358181089163, 0.002172094536945224, 0.0022336600814014673, 0.0021920904982835054, 0.002220525871962309, 0.002182048512622714, 0.002227727323770523, 0.0022275096271187067, 0.0021669589914381504, 0.12368945777416229, 0.0021709995344281197, 0.002157609211280942, 0.0022159204818308353, 0.0022039313334971666, 0.0021896495018154383, 0.0021753525361418724, 0.0021614383440464735, 0.0022068258840590715, 0.0022426985669881105, 0.00219355127774179, 0.002250355901196599, 0.002219140063971281, 0.0022490806877613068, 0.0021549996454268694, 0.002181761199608445, 0.0021466966718435287, 0.0021690509747713804, 0.002171250293031335, 0.0021942462772130966, 0.0021493101958185434, 0.002197668654844165, 0.002237828681245446, 0.0022255871444940567, 0.002225677017122507, 0.00219219783321023, 0.002217255299910903, 0.002175352070480585, 0.002241360256448388, 0.0022315741516649723, 0.002157114678993821, 0.0021728763822466135, 0.002155544236302376, 0.002162052085623145, 0.0021811011247336864, 0.0021537558641284704, 0.002157424343749881, 0.0022124226670712233, 0.0021999285090714693, 0.002130338456481695, 0.0021813774947077036, 0.0021823784336447716, 0.0021861509885638952, 0.0022109707351773977, 0.0021803583949804306, 0.002186946338042617, 0.1230517029762268, 0.002173067769035697, 0.0021486154291778803, 0.0021324267145246267, 0.0021503858733922243, 0.12143976986408234, 0.0021393788047134876, 0.002232991624623537, 0.0021490869112312794, 0.0021578033920377493, 0.13445265591144562, 0.0021354667842388153, 0.002271889476105571, 0.0022093974985182285, 0.0022950731217861176, 0.0022327036131173372, 0.0022377129644155502, 0.0021833048667758703, 0.0021308916620910168, 0.002212807536125183, 0.002242049900814891, 0.002151066204532981, 0.002144578145816922, 0.0021788664162158966, 0.002138458425179124, 0.0021442316938191652, 0.0021400763653218746, 0.0022273401264101267, 0.002158908173441887, 0.0021823700517416, 0.0021442563738673925, 0.002207615878432989, 0.002196516375988722, 0.0021308050490915775, 0.002232988364994526, 0.002244614763185382, 0.002188056241720915, 0.002264551119878888, 0.0022197708021849394, 0.0021746885031461716, 0.002190003637224436, 0.002165922662243247, 0.0022374882828444242, 0.002266101073473692, 0.0022265492007136345, 0.0021283153910189867, 0.140526682138443, 0.1652953177690506, 0.00228202436119318, 0.002191275591030717, 0.002205911325290799, 0.002151208696886897, 0.002181765390560031, 0.0021478640846908092, 0.0022126352414488792, 0.0021445900201797485, 0.002259403932839632, 0.0021377280354499817, 0.0021678560879081488, 0.002137746661901474, 0.002177778398618102, 0.11556318402290344, 0.002208759542554617, 0.0021423213183879852, 0.0021762060932815075, 0.0021645883098244667, 0.002160110045224428, 0.0022090799175202847, 0.002220770576968789, 0.002194103319197893, 0.0021435972303152084, 0.002153342589735985, 0.0021723865065723658, 0.15766450762748718, 0.002151103923097253, 0.0021578336600214243, 0.0021639897022396326, 0.0021492233499884605, 0.002201781142503023, 0.002150476211681962, 0.002159237628802657, 0.002122696256265044, 0.0021951438393443823, 0.0021556916180998087, 0.002240158384665847, 0.002132395515218377, 0.0021826191805303097, 0.0021718693897128105, 0.002168301958590746, 0.002131986664608121, 0.0021347266156226397, 0.0021374188363552094, 0.113129623234272, 0.002132745459675789, 0.002129009459167719, 0.002157618524506688, 0.002173846121877432, 0.0021738430950790644, 0.002245095791295171, 0.1698232889175415, 0.0021325284615159035, 0.002133516827598214, 0.00213036872446537, 0.002167630707845092, 0.0022135574836283922, 0.00217545498162508, 0.0022037900052964687, 0.0021756659261882305, 0.00227946019731462, 0.0022023578640073538, 0.002244156552478671, 0.002142308745533228, 0.0021628853864967823, 0.0021798983216285706, 0.0021492489613592625, 0.0021650895942002535, 0.0021227486431598663, 0.0021959953010082245, 0.0021761469542980194, 0.002216694876551628, 0.13335062563419342, 0.00221227016299963, 0.002143699675798416, 0.0022485279478132725, 0.12256146967411041, 0.002139353659003973, 0.002144393278285861, 0.16041739284992218, 0.0021887128241360188, 0.002159665571525693, 0.19044369459152222, 0.0022216951474547386, 0.0021438952535390854, 0.002217653440311551, 0.0022193242330104113, 0.0022174366749823093, 0.002200561109930277, 0.0021380484104156494, 0.0021724714897572994, 0.0021843616850674152, 0.002250439953058958, 0.0021984349004924297, 0.0021492226514965296, 0.0021461057476699352, 0.002158942399546504, 0.0021579612512141466, 0.0021978223230689764, 0.002261489164084196, 0.0022800900042057037, 0.0021372258197516203, 0.13803371787071228, 0.0021595903672277927, 0.002133325906470418, 0.0022200196981430054, 0.002235660096630454, 0.12374641001224518, 0.0021703492384403944, 0.002179037081077695, 0.0021425201557576656, 0.0021909470669925213, 0.0021406831219792366, 0.0021323864348232746, 0.0021638174075633287, 0.002151128137484193, 0.002257784130051732, 0.002272949554026127, 0.0021380058024078608, 0.002202504314482212, 0.002315161982551217, 0.002173972548916936, 0.00213722325861454, 0.0022413444239646196, 0.0022061371710151434, 0.002140903612598777, 0.002171199768781662, 0.0022140888031572104, 0.0022147048730403185, 0.0022285000886768103, 0.002377951517701149, 0.0021391045302152634, 0.0022032451815903187, 0.002162290271371603, 0.0021851363126188517, 0.0021638337057083845, 0.0022232146002352238, 0.11492838710546494, 0.0021404684521257877, 0.0022293366491794586, 0.0021914781536906958, 0.002134369919076562, 0.002273661782965064, 0.0022387446369975805, 0.002142813289538026, 0.002128832507878542, 0.0023030161391943693, 0.0021492333617061377, 0.0022305131424218416, 0.0021679128985852003, 0.0021899405401200056, 0.002190588042140007, 0.0021715923212468624, 0.0021815632935613394, 0.0021532713435590267, 0.0021471211221069098, 0.0021520669106394053, 0.0021530557423830032, 0.002174336463212967, 0.002192129148170352, 0.002126365900039673, 0.18359820544719696, 0.0021354469936341047, 0.0021457995753735304, 0.0021854955703020096, 0.002306085778400302, 0.002251852536574006, 0.0022073935251682997, 0.002170547842979431, 0.0021632639691233635, 0.002140764845535159, 0.0021765436977148056, 0.00219497038051486, 0.002148896921426058, 0.0021385892760008574, 0.0021350274328142405, 0.0022457861341536045, 0.0021456608083099127, 0.002137403702363372, 0.0022146543487906456, 0.002182889496907592, 0.0021189579274505377, 0.002187949139624834, 0.0021544769406318665, 0.12365972250699997, 0.0021865637972950935, 0.0021663489751517773, 0.0023281590547412634, 0.0022826706990599632, 0.0022134152241051197, 0.002175816334784031, 0.0022247701417654753, 0.0021899498533457518, 0.002242522779852152, 0.002140102442353964, 0.002134632086381316, 0.002118122298270464, 0.1384027749300003, 0.0022039772011339664, 0.002231197664514184, 0.00215943087823689, 0.0021835158113390207, 0.002120131393894553, 0.0021386302541941404, 0.10924167931079865, 0.002147241961210966, 0.0022172899916768074, 0.13890841603279114, 0.0021729804575443268, 0.002150449203327298, 0.002124315593391657, 0.0021922520827502012, 0.002149580977857113, 0.002155821770429611, 0.0021922362502664328, 0.002183635951951146, 0.002147875027731061, 0.0021708898711949587, 0.0021961615420877934, 0.002247374504804611, 0.002199101261794567, 0.0022192050237208605, 0.0021751883905380964, 0.002154909772798419, 0.0021513905376195908, 0.0022363353054970503, 0.0023008540738373995, 0.0022221622057259083, 0.00228700484149158, 0.002139850752428174, 0.0021555935963988304, 0.00218909396789968, 0.0021564143244177103, 0.002179924864321947, 0.0021555935963988304, 0.12964680790901184, 0.0021347564179450274, 0.0021223004441708326, 0.002239895286038518, 0.002145539503544569, 0.002146313898265362, 0.0021360612008720636, 0.00218151044100523, 0.0021962635219097137, 0.0021402083802968264, 0.0021553596016019583, 0.002142931567505002, 0.15388141572475433, 0.0021662081126123667, 0.002122127218171954, 0.0023012415040284395, 0.0021629759576171637, 0.0021487874910235405, 0.0022238860838115215, 0.002208783756941557, 0.0022060261107981205, 0.09863196313381195, 0.14741022884845734, 0.0021454039961099625, 0.002149157924577594, 0.0022271331399679184, 0.00214002444408834, 0.002194290515035391, 0.0021619645413011312, 0.0022130655124783516, 0.4846613109111786, 0.0021735262125730515, 0.0021549949888139963, 0.0021405403967946768, 0.0021380477119237185, 0.002169472398236394, 0.0022581417579203844, 0.0021243332885205746, 0.0021510948427021503, 0.002152310451492667, 0.002152154454961419, 0.002239107619971037, 0.0021855831146240234, 0.002120637334883213, 0.0021284553222358227, 0.002171341562643647, 0.0022179195657372475, 0.002168527338653803, 0.0022035553120076656, 0.0021878296975046396, 0.002293030498549342, 0.002190729370340705, 0.0021566255018115044, 0.0022524897940456867, 0.0021964656189084053, 0.002140599302947521, 0.0021422409918159246, 0.0021458121482282877, 0.0022362421732395887, 0.002206454984843731, 0.0021597687155008316, 0.0021356213837862015, 0.002146297600120306, 0.00216541881673038, 0.0021618674509227276, 0.0021647592075169086, 0.002202363219112158, 0.002183698583394289, 0.0021754703484475613, 0.0021497132256627083, 0.002165233949199319, 0.12140394002199173, 0.16543234884738922, 0.002175420755520463, 0.0021457006223499775, 0.0021303570829331875, 0.002182737924158573, 0.002165851416066289, 0.0022030428517609835, 0.11296918243169785, 0.13715510070323944, 0.1357850730419159, 0.0021634851582348347, 0.002225587610155344, 0.002250887220725417, 0.002178206807002425, 0.1013357862830162, 0.0021953564137220383, 0.0021932944655418396, 0.002170309191569686, 0.002148705767467618]\n",
            "Val loss 0.013053579300287225\n",
            "Val auc roc 0.4866326096211154\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cb145ee-fe46-4221-a837-d640715d4a3d"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c003fe2b-9c6f-4dc6-aed5-cbea0ac4441a"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c784e4aa-635c-48ea-e95e-558119a1bf2d"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "50dd762d-52e3-4921-cafe-d3ae5098e788"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Sarcasm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Sarcasm]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88fd9a91-7d3a-457b-dd45-4a991fe201ad"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-08-06 12:33:09.597443'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}