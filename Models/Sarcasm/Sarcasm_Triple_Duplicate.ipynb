{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3d53224da414ed984afc5939f90e102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8efaf4456fea474f9a0aae0c5714f3ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d5315e4096a4a80b5e00752c6ad030c",
              "IPY_MODEL_3bddf2b48731432bac4fa377016d32d4"
            ]
          }
        },
        "8efaf4456fea474f9a0aae0c5714f3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d5315e4096a4a80b5e00752c6ad030c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_410f4542f1a44d81ad3314f070c7f515",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6e155f9077f4c80ad26d223fdfc5c3b"
          }
        },
        "3bddf2b48731432bac4fa377016d32d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e263573792c04e5a8088fe80c6b4fa76",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:39&lt;00:00, 6.15MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6ac733e2be6411095086f3ae070ecbd"
          }
        },
        "410f4542f1a44d81ad3314f070c7f515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6e155f9077f4c80ad26d223fdfc5c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e263573792c04e5a8088fe80c6b4fa76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6ac733e2be6411095086f3ae070ecbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10c57fd8e2d241f0a0ad3486940aca0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c415e2df75ba46e09ad27572cd85fb93",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2725cb06a56848f599c424c80c611cf4",
              "IPY_MODEL_86dbd209d2e74d778103bda00e8da9ff"
            ]
          }
        },
        "c415e2df75ba46e09ad27572cd85fb93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2725cb06a56848f599c424c80c611cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9881576aa2354b63bc15d5aedb565780",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1728,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1728,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f328210958f45d6b33912965b683408"
          }
        },
        "86dbd209d2e74d778103bda00e8da9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_59ce69631b064fdcbbd68a90c475b9f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1728/1728 [15:51&lt;00:00,  1.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcc570628765455eb0f16ea0943fcdee"
          }
        },
        "9881576aa2354b63bc15d5aedb565780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f328210958f45d6b33912965b683408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59ce69631b064fdcbbd68a90c475b9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcc570628765455eb0f16ea0943fcdee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbf35343d0914ba8951ca6e22e84bee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12751d7b670549c1a698352e33e239b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9591a16f76c349609dfdfffbcb961111",
              "IPY_MODEL_a553943878344ba4942fa6bfb40c73ec"
            ]
          }
        },
        "12751d7b670549c1a698352e33e239b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9591a16f76c349609dfdfffbcb961111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3207f21694ed4fdfb1d1e344eb06eb67",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1728,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1728,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72ea60d8f56040d79017d6cf5900b081"
          }
        },
        "a553943878344ba4942fa6bfb40c73ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f956d43b486746e8affb689301a7bcca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1728/1728 [16:05&lt;00:00,  1.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56b606ea84954967889b4310bcaa80a1"
          }
        },
        "3207f21694ed4fdfb1d1e344eb06eb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72ea60d8f56040d79017d6cf5900b081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f956d43b486746e8affb689301a7bcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56b606ea84954967889b4310bcaa80a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65d30ce1994740b2b83be835eb7a657c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e6bdb3e1424649f9a28a4a1d52c18d01",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8ae72eb11614bc3a063ea7c57ad1631",
              "IPY_MODEL_b5d4ac488bb848408724c4bd970bfa21"
            ]
          }
        },
        "e6bdb3e1424649f9a28a4a1d52c18d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8ae72eb11614bc3a063ea7c57ad1631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bee90bf0986b46178bdfe460d56a22a2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1728,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1728,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_021287038fb24b608ea2e47132dcd3e6"
          }
        },
        "b5d4ac488bb848408724c4bd970bfa21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e7d7c4a8b5f4ebe9c3f280dbee624f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1728/1728 [16:11&lt;00:00,  1.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e04ef415106b4d14a94abbe593d6f52e"
          }
        },
        "bee90bf0986b46178bdfe460d56a22a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "021287038fb24b608ea2e47132dcd3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e7d7c4a8b5f4ebe9c3f280dbee624f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e04ef415106b4d14a94abbe593d6f52e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "78af6258-5f2c-4e55-e1c3-099324debca7"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 42.24 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1708dab7-8116-49dd-c792-73d2b7170ad8"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4cb760c-86a4-411c-9984-630fd2f34f80"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8e5b6f2b-11dd-4a94-bd66-361339acc4a2"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "bbbb0a21-3a7d-42aa-a782-8d00afe4f9e9"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "3dbc1121-3cc4-42b5-f4f8-1436d281093f"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 15.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f58b4ab3-b500-48b4-dd01-34670c0334c5"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6649c3eb-c815-40a0-927d-97097411c595"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "660fafd3-1aee-4676-9be5-c02c2fbd5e8a"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "82b92827-29a4-4c9c-ae44-63ba9289433b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    One Year of #MeToo: How the Movement Eludes Go...\n",
              "1     We will provide you the best services in enti...\n",
              "2    Is it harmless banter and leg pulling @suhelse...\n",
              "3    @Alyssa_Milano I guess @Alyssa_Milano thought ...\n",
              "4                                        ption - no:2 \n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f409c7b2-915b-4a85-b352-4c1558145ada"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:10<00:00, 37108971.06B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa21d278-6578-4831-903e-a50c15fad83e"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 880536.30B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "3c793d96-e28d-4632-b8de-6cab490a2665"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1001fa61-3a40-4ed7-82c9-c350c833b756"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        df4 = df2.copy().reset_index(drop=True)\n",
        "        # df5 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            random.shuffle(text)\n",
        "            text3 = ' '.join(text)\n",
        "            df3['text'][i]=text3\n",
        "            random.shuffle(text)\n",
        "            text4 = ' '.join(text)\n",
        "            df4['text'][i]=text4\n",
        "            random.shuffle(text)\n",
        "            # text5 = ' '.join(text)\n",
        "            # df5['text'][i]=text5\n",
        "        self.data = self.data.append(df2, ignore_index=True)\n",
        "        self.data = self.data.append(df3, ignore_index=True)\n",
        "        self.data = self.data.append(df4, ignore_index=True)\n",
        "        # self.data = self.data.append(df5, ignore_index=True)\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18d50c73-099b-4182-a397-899b2209fe90"
      },
      "source": [
        "col_name = \"Sarcasm\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3d53224da414ed984afc5939f90e102",
            "8efaf4456fea474f9a0aae0c5714f3ed",
            "2d5315e4096a4a80b5e00752c6ad030c",
            "3bddf2b48731432bac4fa377016d32d4",
            "410f4542f1a44d81ad3314f070c7f515",
            "f6e155f9077f4c80ad26d223fdfc5c3b",
            "e263573792c04e5a8088fe80c6b4fa76",
            "a6ac733e2be6411095086f3ae070ecbd",
            "10c57fd8e2d241f0a0ad3486940aca0e",
            "c415e2df75ba46e09ad27572cd85fb93",
            "2725cb06a56848f599c424c80c611cf4",
            "86dbd209d2e74d778103bda00e8da9ff",
            "9881576aa2354b63bc15d5aedb565780",
            "9f328210958f45d6b33912965b683408",
            "59ce69631b064fdcbbd68a90c475b9f4",
            "fcc570628765455eb0f16ea0943fcdee",
            "fbf35343d0914ba8951ca6e22e84bee3",
            "12751d7b670549c1a698352e33e239b6",
            "9591a16f76c349609dfdfffbcb961111",
            "a553943878344ba4942fa6bfb40c73ec",
            "3207f21694ed4fdfb1d1e344eb06eb67",
            "72ea60d8f56040d79017d6cf5900b081",
            "f956d43b486746e8affb689301a7bcca",
            "56b606ea84954967889b4310bcaa80a1",
            "65d30ce1994740b2b83be835eb7a657c",
            "e6bdb3e1424649f9a28a4a1d52c18d01",
            "b8ae72eb11614bc3a063ea7c57ad1631",
            "b5d4ac488bb848408724c4bd970bfa21",
            "bee90bf0986b46178bdfe460d56a22a2",
            "021287038fb24b608ea2e47132dcd3e6",
            "7e7d7c4a8b5f4ebe9c3f280dbee624f1",
            "e04ef415106b4d14a94abbe593d6f52e"
          ]
        },
        "outputId": "2da26170-647f-4529-da47-d11699944307"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6913\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3d53224da414ed984afc5939f90e102",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10c57fd8e2d241f0a0ad3486940aca0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1728.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0668\n",
            "Train Losses : [0.1378786563873291, 0.3543471097946167, 1.4890379905700684, 2.2543938159942627, 1.7386232614517212, 1.2391912937164307, 0.19131430983543396, 0.21013428270816803, 0.35940486192703247, 0.12458676844835281, 0.7032493352890015, 1.8036695718765259, 0.35466596484184265, 0.27178293466567993, 0.986802339553833, 0.20721931755542755, 0.18949683010578156, 0.3025212585926056, 0.05373397096991539, 0.077674500644207, 0.02868703007698059, 0.06945042312145233, 0.1661403328180313, 0.08927667886018753, 0.01806540973484516, 0.05010281503200531, 0.011942056939005852, 0.013533158227801323, 0.007603724021464586, 0.010023854672908783, 0.014903758652508259, 0.005938712973147631, 0.12701153755187988, 0.005920083727687597, 0.006853498984128237, 0.0052047185599803925, 0.007260709535330534, 0.0019734634552150965, 0.0033829878084361553, 0.0040549905970692635, 0.0017272192053496838, 0.0013557743513956666, 0.14868766069412231, 0.0040240054950118065, 0.0031185843981802464, 0.0030155382119119167, 0.0025953014846891165, 0.023761054500937462, 0.007276900578290224, 0.0020615688990801573, 0.0023265699855983257, 1.1364694833755493, 0.10943984985351562, 1.039966344833374, 0.0036747069098055363, 0.0019249414326623082, 0.12078224867582321, 0.0029940458480268717, 0.0031646208371967077, 0.004422706551849842, 0.005227250978350639, 0.002885064808651805, 0.18833592534065247, 0.005404735449701548, 0.10003110021352768, 0.03818148747086525, 0.3291165232658386, 0.008761147037148476, 0.08997450023889542, 0.12633544206619263, 0.00750803854316473, 0.00909697450697422, 0.025927403941750526, 0.008028003387153149, 0.011797795072197914, 0.013410619460046291, 0.013065709732472897, 0.18705323338508606, 0.17412197589874268, 0.26670873165130615, 0.009883660823106766, 0.023961061611771584, 0.12653203308582306, 0.007253254298120737, 0.006497533526271582, 0.00612050062045455, 0.009590054862201214, 0.006269961129873991, 0.7430379986763, 0.013808738440275192, 0.15299978852272034, 0.2318258136510849, 0.010590427555143833, 0.0763300433754921, 0.010284453630447388, 0.07983562350273132, 0.016305522993206978, 0.017520897090435028, 0.19336360692977905, 0.015691692009568214, 0.28931379318237305, 0.015278269536793232, 0.019087983295321465, 0.020801670849323273, 0.022831261157989502, 0.1582639217376709, 0.01929893158376217, 0.019365306943655014, 0.01436708401888609, 0.24365593492984772, 0.013717436231672764, 0.015936031937599182, 0.01314830407500267, 0.10708674788475037, 0.07689681649208069, 0.010157916694879532, 0.008992080576717854, 0.4042190909385681, 0.12890854477882385, 0.06008957698941231, 0.008477432653307915, 0.010534857399761677, 0.18703995645046234, 0.010952225886285305, 0.010444482788443565, 0.008505606092512608, 0.10733874887228012, 0.008820846676826477, 0.00942620262503624, 0.23412874341011047, 0.009136684238910675, 0.007872577756643295, 0.007490773219615221, 0.007025217171758413, 0.006996584590524435, 0.05376414954662323, 0.14473751187324524, 0.00635102391242981, 0.00759127689525485, 0.005827078130096197, 0.006127479951828718, 0.005368851125240326, 0.005772989708930254, 0.16129480302333832, 0.005048357415944338, 0.005037261173129082, 0.13475078344345093, 0.0048766955733299255, 0.004565179347991943, 0.00467034662142396, 0.004443163517862558, 0.09631327539682388, 0.0056940834037959576, 0.004784337244927883, 0.004317835438996553, 0.004844834562391043, 0.004767712205648422, 0.0045740422792732716, 0.12915000319480896, 0.0039488570764660835, 0.00397910363972187, 0.004113746806979179, 0.13966073095798492, 0.005273476243019104, 0.08633991330862045, 0.05994930490851402, 0.1955442577600479, 0.005094232503324747, 0.0055257161147892475, 0.005805653054267168, 0.005701081827282906, 0.11701252311468124, 0.1618087887763977, 0.005466654896736145, 0.28003060817718506, 0.007206382695585489, 0.31087493896484375, 0.13188135623931885, 0.00846595037728548, 0.008782409131526947, 0.14329227805137634, 0.01163175143301487, 0.010506466031074524, 0.34049728512763977, 0.15398532152175903, 0.013860124163329601, 0.015266386792063713, 0.014264678582549095, 0.13975703716278076, 0.015449745580554008, 0.014216727577149868, 0.01539432443678379, 0.06410259008407593, 0.01423561666160822, 0.01427584420889616, 0.09793782234191895, 0.012704982422292233, 0.43217238783836365, 0.012358526699244976, 0.012748030945658684, 0.10024566948413849, 0.012568013742566109, 0.012262606993317604, 0.011859877035021782, 0.013461996801197529, 0.15022769570350647, 0.011966491118073463, 0.011492042802274227, 0.01052605826407671, 0.010576633736491203, 0.009454324841499329, 0.009139618836343288, 0.008491773158311844, 0.45529288053512573, 0.00790176261216402, 0.0892348363995552, 0.008521542884409428, 0.31988441944122314, 0.009931378997862339, 0.010898415930569172, 0.09135473519563675, 0.011530069634318352, 0.011282557621598244, 0.01150481216609478, 0.01290986966341734, 0.011651445180177689, 0.050678543746471405, 0.012483788654208183, 0.012828966602683067, 0.010667880065739155, 0.40958380699157715, 0.011416025459766388, 0.05182372406125069, 0.012560524046421051, 0.29257798194885254, 0.013786506839096546, 0.2757347524166107, 0.01451844535768032, 0.06366360932588577, 0.01951572671532631, 0.020064914599061012, 0.16801156103610992, 0.017257994040846825, 0.019342074170708656, 0.02167014218866825, 0.01849304884672165, 0.022675542160868645, 0.017934037372469902, 0.019821081310510635, 0.5944802165031433, 0.014221597462892532, 0.20094965398311615, 0.05727793276309967, 0.013441860675811768, 0.014503358863294125, 0.01391863077878952, 0.14372257888317108, 0.05930563062429428, 0.01136473286896944, 0.0128617063164711, 0.011646063067018986, 0.19156643748283386, 0.01043261680752039, 0.17457087337970734, 0.00967138260602951, 0.009232095442712307, 0.008912498131394386, 0.09196648746728897, 0.11245353519916534, 0.008327237330377102, 0.008090763352811337, 0.008234735578298569, 0.00766632379963994, 0.007513805758208036, 0.12105776369571686, 0.1037597730755806, 0.006887347437441349, 0.12646378576755524, 0.4322773516178131, 0.0995655283331871, 0.11200863122940063, 0.00864944513887167, 0.31225404143333435, 0.12430327385663986, 0.011387532576918602, 0.09899333864450455, 0.013750848360359669, 0.1477467566728592, 0.015319745056331158, 0.01593768782913685, 0.29681843519210815, 0.017699619755148888, 0.49380573630332947, 0.2262895107269287, 0.025127828121185303, 0.07889700680971146, 0.2468530386686325, 0.036203961819410324, 0.04046378284692764, 0.1151445209980011, 0.043878357857465744, 0.04543928802013397, 0.0431242398917675, 0.04202638939023018, 0.2817372977733612, 0.1327509731054306, 0.038853079080581665, 0.037226900458335876, 0.10581158101558685, 0.09392399340867996, 0.11133106052875519, 0.029911331832408905, 0.027496082708239555, 0.025882109999656677, 0.023125335574150085, 0.022834831848740578, 0.01945408061146736, 0.10495959967374802, 0.016487738117575645, 0.08820214867591858, 0.11320001631975174, 0.012643318623304367, 0.011893241666257381, 0.011212390847504139, 0.010510017164051533, 0.1306809037923813, 0.08988244831562042, 0.00814077164977789, 0.1060006245970726, 0.09921898692846298, 0.12279292196035385, 0.15395487844944, 0.1048380583524704, 0.007409167941659689, 0.007242260500788689, 0.00720249256119132, 0.0070662484504282475, 0.07883697003126144, 0.006950925569981337, 0.10328220576047897, 0.007262773811817169, 0.1233273595571518, 0.07690242677927017, 0.007232236675918102, 0.007480025291442871, 0.007575716357678175, 0.007035371381789446, 0.006980093661695719, 0.00693982420489192, 0.09600143134593964, 0.007222031708806753, 0.006476245820522308, 0.09770495444536209, 0.00649965088814497, 0.0068125552497804165, 0.11258158087730408, 0.006495945621281862, 0.007147163152694702, 0.1290663629770279, 0.00708709517493844, 0.00679754139855504, 0.14093808829784393, 0.1905510574579239, 0.006169825326651335, 0.10390231758356094, 0.006220611277967691, 0.3833846151828766, 0.007479983381927013, 0.007905629463493824, 0.00797612126916647, 0.13079582154750824, 0.009128552861511707, 0.008922163397073746, 0.11246666312217712, 0.010683192871510983, 0.1381487101316452, 0.009928777813911438, 0.010631765238940716, 0.10126286000013351, 0.10967837274074554, 0.09398539364337921, 0.010691605508327484, 0.12805768847465515, 0.010789787396788597, 0.01085391640663147, 0.01090673916041851, 0.011214825324714184, 0.08161971718072891, 0.08162497729063034, 0.01071223709732294, 0.010370058938860893, 0.010664255358278751, 0.010714434087276459, 0.11360388994216919, 0.010336684063076973, 0.009451895952224731, 0.009465868584811687, 0.008999551646411419, 0.09191815555095673, 0.008456127718091011, 0.007988209836184978, 0.007843932136893272, 0.00752245495095849, 0.10706031322479248, 0.1091630682349205, 0.08845439553260803, 0.007029421627521515, 0.0766473188996315, 0.007265495136380196, 0.08312290161848068, 0.007335216738283634, 0.008008524775505066, 0.007284531369805336, 0.006845786701887846, 0.11074312031269073, 0.006816280540078878, 0.1637643575668335, 0.006846030708402395, 0.1291298270225525, 0.006534154061228037, 0.006686330772936344, 0.07487967610359192, 0.0812174454331398, 0.00741550512611866, 0.006639110390096903, 0.06146905943751335, 0.0067281476221978664, 0.00705626979470253, 0.12549667060375214, 0.006922253407537937, 0.00715364096686244, 0.006563202012330294, 0.15540127456188202, 0.006932990159839392, 0.08649853616952896, 0.007461902219802141, 0.006942983716726303, 0.0067834011279046535, 0.006485274527221918, 0.06625308096408844, 0.00674982275813818, 0.007015095558017492, 0.07162769883871078, 0.006423002574592829, 0.006080342456698418, 0.006784518249332905, 0.006848723627626896, 0.006592083722352982, 0.005952011793851852, 0.13447800278663635, 0.005447978153824806, 0.005331900902092457, 0.0052072214893996716, 0.00527241500094533, 0.0058280243538320065, 0.34287673234939575, 0.005066508427262306, 0.12159822136163712, 0.006108391098678112, 0.005833734292536974, 0.00640885578468442, 0.00627553416416049, 0.006873659789562225, 0.0068204402923583984, 0.006772253662347794, 0.006450209300965071, 0.006241584196686745, 0.006757527124136686, 0.10188315808773041, 0.007030435837805271, 0.007079781033098698, 0.1358776092529297, 0.006117837969213724, 0.006792621687054634, 0.006410987116396427, 0.006077237892895937, 0.20096507668495178, 0.006132564973086119, 0.0068179527297616005, 0.00710567319765687, 0.005660221911966801, 0.06715050339698792, 0.005546100903302431, 0.005538006778806448, 0.0052536544390022755, 0.11759556829929352, 0.005942513234913349, 0.005472819320857525, 0.0972495824098587, 0.005573251284658909, 0.00556455971673131, 0.005408473778516054, 0.43895360827445984, 0.1122109666466713, 0.006295057944953442, 0.0062629459425807, 0.007243271917104721, 0.008020518347620964, 0.151391863822937, 0.007458026055246592, 0.1450270563364029, 0.1638866364955902, 0.0080751096829772, 0.008257973939180374, 0.008481492288410664, 0.14703373610973358, 0.009383083321154118, 0.11201915144920349, 0.009476949460804462, 0.08112401515245438, 0.009214451536536217, 0.10195717960596085, 0.40350407361984253, 0.11061932891607285, 0.010456196032464504, 0.13920800387859344, 0.011259112507104874, 0.012126115150749683, 0.5480676293373108, 0.01326387096196413, 0.21127040684223175, 0.01725662685930729, 0.018699217587709427, 0.02008698880672455, 0.021751169115304947, 0.145171657204628, 0.023462317883968353, 0.0887729823589325, 0.08075471222400665, 0.023811127990484238, 0.15417663753032684, 0.023672079667448997, 0.02377053163945675, 0.024389946833252907, 0.14572027325630188, 0.16394904255867004, 0.022100530564785004, 0.020061347633600235, 0.01928890310227871, 0.018161632120609283, 0.017485400661826134, 0.016059260815382004, 0.10679147392511368, 0.014648081734776497, 0.013427810743451118, 0.013478386215865612, 0.011809592135250568, 0.011207489296793938, 0.3249255418777466, 0.010080991312861443, 0.01008190680295229, 0.00982521753758192, 0.00939322728663683, 0.31009960174560547, 0.009403087198734283, 0.009716725908219814, 0.09963866323232651, 0.009935243055224419, 0.009756023995578289, 0.009982683695852757, 0.08584447205066681, 0.2523183524608612, 0.06575775891542435, 0.10242142528295517, 0.13327762484550476, 0.36212432384490967, 0.09946154803037643, 0.01370090339332819, 0.140601247549057, 0.015367850661277771, 0.01612005941569805, 0.016651151701807976, 0.11953248083591461, 0.017226912081241608, 0.016847189515829086, 0.017049705609679222, 0.016759468242526054, 0.2546464204788208, 0.01681273803114891, 0.01836973987519741, 0.016618577763438225, 0.016171270981431007, 0.054186880588531494, 0.016145719215273857, 0.015623806044459343, 0.0157326590269804, 0.014645162038505077, 0.014256365597248077, 0.01337425597012043, 0.1287257969379425, 0.06852449476718903, 0.013818633742630482, 0.011597746051847935, 0.012404187582433224, 0.09037745743989944, 0.11253367364406586, 0.009521683678030968, 0.009795582853257656, 0.00939202681183815, 0.06953047960996628, 0.008759481832385063, 0.008627668023109436, 0.008097151294350624, 0.007494720164686441, 0.007364608347415924, 0.007265689317137003, 0.23143421113491058, 0.006759279407560825, 0.006576343905180693, 0.1205192282795906, 0.006526933517307043, 0.005962645635008812, 0.005679139867424965, 0.15861934423446655, 0.005445991177111864, 0.13056707382202148, 0.005515281111001968, 0.09741338342428207, 0.005916697438806295, 0.1219969093799591, 0.005709528457373381, 0.005816796328872442, 0.12270892411470413, 0.3281930088996887, 0.006264245603233576, 0.13725198805332184, 0.006941249128431082, 0.0073327673599123955, 0.007817131467163563, 0.007936343550682068, 0.008201979100704193, 0.00851634331047535, 0.00824454054236412, 0.008910817094147205, 0.008317616768181324, 0.00835126731544733, 0.008788264356553555, 0.00873495452105999, 0.06799418479204178, 0.15986180305480957, 0.007912873290479183, 0.008945545181632042, 0.12542714178562164, 0.007608781103044748, 0.007492612116038799, 0.33619973063468933, 0.12537437677383423, 0.008486869744956493, 0.008581786416471004, 0.00864680577069521, 0.00886722281575203, 0.009079772979021072, 0.009174997918307781, 0.13822096586227417, 0.11240352690219879, 0.00924001820385456, 0.009715122170746326, 0.11333012580871582, 0.009137165732681751, 0.07140076160430908, 0.14838846027851105, 0.009244933724403381, 0.009628420695662498, 0.10814063996076584, 0.009444107301533222, 0.14454352855682373, 0.00931756291538477, 0.009386273100972176, 0.009408723562955856, 0.008946193382143974, 0.008845509961247444, 0.008653894998133183, 0.008328037336468697, 0.008182470686733723, 0.0950731486082077, 0.007918866351246834, 0.2950064241886139, 0.007950590923428535, 0.13722772896289825, 0.00816375482827425, 0.008410955779254436, 0.00846430379897356, 0.09889155626296997, 0.10289054363965988, 0.11772871017456055, 0.11546263098716736, 0.10836797207593918, 0.009463121183216572, 0.12089316546916962, 0.10931526869535446, 0.010125227272510529, 0.010508195497095585, 0.010469933040440083, 0.010635373182594776, 0.01053403690457344, 0.010457086376845837, 0.09131608158349991, 0.08326680958271027, 0.10546290874481201, 0.14057256281375885, 0.010226448066532612, 0.1247817650437355, 0.13194166123867035, 0.08593443036079407, 0.08844179660081863, 0.010596736334264278, 0.09034895151853561, 0.08480586856603622, 0.011490387842059135, 0.09892339259386063, 0.011173470877110958, 0.011211556382477283, 0.010798580013215542, 0.01113117765635252, 0.010977241210639477, 0.010489610023796558, 0.010027940385043621, 0.009998021647334099, 0.09759216010570526, 0.00926772877573967, 0.10461228340864182, 0.1445857435464859, 0.008636457845568657, 0.008818772621452808, 0.008668586611747742, 0.12255138158798218, 0.007903961464762688, 0.00804160162806511, 0.0939071774482727, 0.00821063295006752, 0.007739735767245293, 0.007311591878533363, 0.007080866489559412, 0.10899840295314789, 0.0808827355504036, 0.006933512166142464, 0.0069335331209003925, 0.006628795526921749, 0.006633996497839689, 0.006537881679832935, 0.15163731575012207, 0.30145063996315, 0.3232722282409668, 0.0080008739605546, 0.007809243630617857, 0.008706188760697842, 0.009197980165481567, 0.009796966798603535, 0.12130209058523178, 0.01056336797773838, 0.10352245718240738, 0.010932328179478645, 0.13195499777793884, 0.011161092668771744, 0.11434074491262436, 0.01218271255493164, 0.011923566460609436, 0.012387244030833244, 0.1672830730676651, 0.011693816632032394, 0.2782328128814697, 0.01185271330177784, 0.012820246629416943, 0.012408718466758728, 0.012381257489323616, 0.013322010636329651, 0.012657323852181435, 0.012111921794712543, 0.12730573117733002, 0.012441396713256836, 0.011824291199445724, 0.011543682776391506, 0.010907354764640331, 0.01072738878428936, 0.3706558048725128, 0.1200881376862526, 0.08834699541330338, 0.011372042819857597, 0.011827594600617886, 0.01140972413122654, 0.011279486119747162, 0.01116421539336443, 0.09813705086708069, 0.01110535766929388, 0.011209034360945225, 0.3862086534500122, 0.07072684168815613, 0.17108087241649628, 0.011820279993116856, 0.012679516337811947, 0.012888486497104168, 0.012216703034937382, 0.11474189907312393, 0.1313103437423706, 0.09067530930042267, 0.012638079933822155, 0.012011565268039703, 0.01195268239825964, 0.012616440653800964, 0.011573120951652527, 0.011313206516206264, 0.011395418085157871, 0.09750340133905411, 0.010708053596317768, 0.13273410499095917, 0.010010131634771824, 0.009691452607512474, 0.009601149708032608, 0.11272834241390228, 0.00889777485281229, 0.008768956176936626, 0.00853985920548439, 0.11467421054840088, 0.37521132826805115, 0.00847607757896185, 0.008555387146770954, 0.11351729184389114, 0.00878987368196249, 0.009038285352289677, 0.11128938943147659, 0.1040269210934639, 0.00921644363552332, 0.009381664916872978, 0.009553050622344017, 0.1269110143184662, 0.009289764799177647, 0.35580018162727356, 0.009843897074460983, 0.2863701283931732, 0.11568330228328705, 0.011844546534121037, 0.01245113741606474, 0.012927887961268425, 0.013604442588984966, 0.013768020085990429, 0.01399734802544117, 0.014024276286363602, 0.01416344940662384, 0.014010121114552021, 0.01350666955113411, 0.013313595205545425, 0.08284524828195572, 0.013075885362923145, 0.01231362670660019, 0.012394722551107407, 0.10446389764547348, 0.011297875083982944, 0.07844556868076324, 0.01075768657028675, 0.11694372445344925, 0.010394343174993992, 0.010018925182521343, 0.009706647135317326, 0.11467427015304565, 0.10327061265707016, 0.00935773178935051, 0.11148319393396378, 0.009013715200126171, 0.008946898393332958, 0.00847598910331726, 0.13469482958316803, 0.12366196513175964, 0.08554954081773758, 0.008279982022941113, 0.00829586572945118, 0.008061456494033337, 0.11125533282756805, 0.008024967275559902, 0.007810967043042183, 0.007723152171820402, 0.007767695467919111, 0.0821421667933464, 0.00737726641818881, 0.35755032300949097, 0.007806779351085424, 0.007918729446828365, 0.08936288952827454, 0.008172745816409588, 0.008521364070475101, 0.09876684844493866, 0.008732957765460014, 0.008646699599921703, 0.10995686054229736, 0.09808836132287979, 0.008937140926718712, 0.009034669026732445, 0.09109817445278168, 0.11250494420528412, 0.009462402202188969, 0.009245408698916435, 0.009233924560248852, 0.009391887113451958, 0.009077672846615314, 0.0965966060757637, 0.009075237438082695, 0.008697695098817348, 0.008594552986323833, 0.008573937229812145, 0.008842509239912033, 0.09665273874998093, 0.007899046875536442, 0.007868888787925243, 0.007755642756819725, 0.007454185746610165, 0.007374167442321777, 0.07534217089414597, 0.14063455164432526, 0.007228097412735224, 0.006846202537417412, 0.29837796092033386, 0.006996202748268843, 0.1355983018875122, 0.007525634486228228, 0.008072820492088795, 0.11815289407968521, 0.11601793020963669, 0.008882272988557816, 0.008479305543005466, 0.10207326710224152, 0.10733672976493835, 0.0093482481315732, 0.0890570878982544, 0.3279310464859009, 0.11514066159725189, 0.01022295467555523, 0.012050682678818703, 0.011717675253748894, 0.08072998374700546, 0.012263976037502289, 0.012528100982308388, 0.012473632581532001, 0.012383968569338322, 0.01250565517693758, 0.011925100348889828, 0.012062485329806805, 0.10658276081085205, 0.15255646407604218, 0.011239809915423393, 0.1367180049419403, 0.010795443318784237, 0.010563255287706852, 0.01054837554693222, 0.08503326773643494, 0.010610667988657951, 0.009702416136860847, 0.0097415242344141, 0.009378667920827866, 0.009150417521595955, 0.009549437090754509, 0.008666268549859524, 0.0798192098736763, 0.007988392375409603, 0.007720550522208214, 0.007381790783256292, 0.12231608480215073, 0.0070574344135820866, 0.006662448402494192, 0.006488478742539883, 0.006357439327985048, 0.006250173319131136, 0.006034420803189278, 0.006029701326042414, 0.1309354305267334, 0.14008861780166626, 0.14532768726348877, 0.0055994754657149315, 0.005505140405148268, 0.005673100706189871, 0.005525311455130577, 0.08805578947067261, 0.14292459189891815, 0.005394603591412306, 0.005601607263088226, 0.005538505036383867, 0.00554420193657279, 0.005390353500843048, 0.005371303763240576, 0.005317668430507183, 0.005174558609724045, 0.005032435525208712, 0.005074624437838793, 0.12433028221130371, 0.005016155540943146, 0.004852902609854937, 0.12041160464286804, 0.004805913195014, 0.11825533211231232, 0.004802570212632418, 0.004904544912278652, 0.1288907676935196, 0.004979953169822693, 0.005129318684339523, 0.004966570530086756, 0.004897932521998882, 0.004888045135885477, 0.004943288862705231, 0.0048387558199465275, 0.004732775967568159, 0.15240836143493652, 0.12971869111061096, 0.09202434867620468, 0.004885965492576361, 0.004956610966473818, 0.005075104534626007, 0.00521691981703043, 0.005061567761003971, 0.005280994810163975, 0.11307292431592941, 0.0050728777423501015, 0.005088478792458773, 0.005170479882508516, 0.12491359561681747, 0.37714362144470215, 0.139537051320076, 0.00584509689360857, 0.00622593704611063, 0.006575573235750198, 0.006809726823121309, 0.0070976801216602325, 0.007252152543514967, 0.007412073202431202, 0.007593946531414986, 0.09973399341106415, 0.007478468120098114, 0.007627948187291622, 0.3511364459991455, 0.008012497797608376, 0.12914463877677917, 0.3025728762149811, 0.009651492349803448, 0.1451534479856491, 0.09698700904846191, 0.11517790704965591, 0.012572143226861954, 0.012911306694149971, 0.0855042114853859, 0.014132036827504635, 0.014192812144756317, 0.014533531852066517, 0.12442029267549515, 0.014478901401162148, 0.014639935456216335, 0.014670711942017078, 0.014200921170413494, 0.014060180634260178, 0.1390444040298462, 0.013432612642645836, 0.08944149315357208, 0.012898881919682026, 0.012744969688355923, 0.01221366599202156, 0.09058210998773575, 0.011363726109266281, 0.011103227734565735, 0.010707149282097816, 0.010496855713427067, 0.010421499609947205, 0.009791597723960876, 0.08805260062217712, 0.009102285839617252, 0.07545684278011322, 0.008542079478502274, 0.008175970986485481, 0.007891079410910606, 0.0076272557489573956, 0.00749196344986558, 0.007222828455269337, 0.08233752101659775, 0.006900380365550518, 0.006720914971083403, 0.006331823766231537, 0.00617931829765439, 0.006166862323880196, 0.005803287960588932, 0.005571510177105665, 0.13659651577472687, 0.0053487373515963554, 0.09164577722549438, 0.005099732428789139, 0.005154085345566273, 0.11748206615447998, 0.004907938651740551, 0.4350734353065491, 0.10023252665996552, 0.7719036340713501, 0.10216636955738068, 0.007668847683817148, 0.008766810409724712, 0.009472604840993881, 0.010748925618827343, 0.011341833509504795, 0.012742672115564346, 0.1213248148560524, 0.0770207941532135, 0.09583240747451782, 0.014276283793151379, 0.014935998246073723, 0.10098757594823837, 0.01591484807431698, 0.0928320661187172, 0.016377460211515427, 0.015751363709568977, 0.12401112169027328, 0.01581108383834362, 0.16544078290462494, 0.11788461357355118, 0.14817826449871063, 0.0919281616806984, 0.015464895404875278, 0.0965612456202507, 0.015102704986929893, 0.07533742487430573, 0.10156811028718948, 0.014508530497550964, 0.014512413181364536, 0.014135375618934631, 0.23465147614479065, 0.013920450583100319, 0.09470848739147186, 0.09746008366346359, 0.2877327799797058, 0.0985286682844162, 0.016535572707653046, 0.11589077860116959, 0.016304876655340195, 0.01716587506234646, 0.13448461890220642, 0.3181590437889099, 0.017776964232325554, 0.01810738630592823, 0.018237082287669182, 0.01814805530011654, 0.018621787428855896, 0.017919793725013733, 0.01808442547917366, 0.017253218218684196, 0.10686691105365753, 0.016713164746761322, 0.11095639318227768, 0.01659253053367138, 0.015226396732032299, 0.13007597625255585, 0.014742330648005009, 0.013935770839452744, 0.07719888538122177, 0.09062477946281433, 0.012768769636750221, 0.14878831803798676, 0.012272553518414497, 0.6601437926292419, 0.08870632201433182, 0.013314628042280674, 0.01353543996810913, 0.014151975512504578, 0.014426928013563156, 0.12733714282512665, 0.014787576161324978, 0.014852062799036503, 0.015321755781769753, 0.12392033636569977, 0.014825480058789253, 0.08648165315389633, 0.01476987823843956, 0.014377583749592304, 0.013972796499729156, 0.013525856658816338, 0.013194972649216652, 0.013066370971500874, 0.01278526708483696, 0.32270798087120056, 0.012041536159813404, 0.012119078077375889, 0.10358704626560211, 0.011975961737334728, 0.011895177885890007, 0.011778452433645725, 0.01173761859536171, 0.011271927505731583, 0.13043993711471558, 0.010970763862133026, 0.010725246742367744, 0.01071498729288578, 0.01014489121735096, 0.009982801973819733, 0.11959322541952133, 0.12388671934604645, 0.12464164942502975, 0.11941670626401901, 0.009028040803968906, 0.09599781036376953, 0.14496737718582153, 0.00903131254017353, 0.008910027332603931, 0.009291870519518852, 0.008860493078827858, 0.008757058531045914, 0.6584180593490601, 0.11725149303674698, 0.107701376080513, 0.09830795973539352, 0.10054940730333328, 0.011887285858392715, 0.10402850806713104, 0.013184959068894386, 0.11259496957063675, 0.013854378834366798, 0.11642257124185562, 0.28557562828063965, 0.015237892977893353, 0.08534112572669983, 0.016390513628721237, 0.09732671082019806, 0.017286017537117004, 0.018055498600006104, 0.25394710898399353, 0.46600016951560974, 0.020056230947375298, 0.02130209654569626, 0.11173392832279205, 0.02371946908533573, 0.12077400833368301, 0.025228552520275116, 0.09476876258850098, 0.10583809018135071, 0.026758110150694847, 0.026386946439743042, 0.026341000571846962, 0.025921370834112167, 0.02588677406311035, 0.02519192174077034, 0.024048803374171257, 0.260781854391098, 0.022971654310822487, 0.2805570363998413, 0.022792598232626915, 0.022763319313526154, 0.022577837109565735, 0.022242864593863487, 0.021674735471606255, 0.12434475868940353, 0.08063283562660217, 0.08844512701034546, 0.01998763531446457, 0.2060990333557129, 0.019265349954366684, 0.01946086622774601, 0.018993960693478584, 0.10356111824512482, 0.0184481218457222, 0.01809999905526638, 0.0178940761834383, 0.017076553776860237, 0.01646776683628559, 0.098463274538517, 0.015508736483752728, 0.015029823407530785, 0.014868351630866528, 0.10522890090942383, 0.013399187475442886, 0.012912177480757236, 0.012716534547507763, 0.012265993282198906, 0.011645520105957985, 0.010946559719741344, 0.11648738384246826, 0.010506708174943924, 0.1456967145204544, 0.009577620774507523, 0.08065781742334366, 0.009375358000397682, 0.008976883254945278, 0.008913146331906319, 0.09707571566104889, 0.00812701229006052, 0.007994836196303368, 0.007989039644598961, 0.007946417666971684, 0.0074254185892641544, 0.0071869660168886185, 0.11753889173269272, 0.13206706941127777, 0.10664907842874527, 0.006953848991543055, 0.09932242333889008, 0.12433309108018875, 0.006702578626573086, 0.006713182665407658, 0.006809721235185862, 0.1255027800798416, 0.006989413872361183, 0.00677642272785306, 0.006660781800746918, 0.0066294120624661446, 0.006660158280283213, 0.006499915849417448, 0.32859912514686584, 0.006596304941922426, 0.09848611801862717, 0.007060311734676361, 0.11561606079339981, 0.007239053491503, 0.12358710169792175, 0.32822245359420776, 0.008164630271494389, 0.008595324121415615, 0.10032631456851959, 0.009234636090695858, 0.08273288607597351, 0.010136039927601814, 0.010256532579660416, 0.010909590870141983, 0.11037537455558777, 0.13277286291122437, 0.11367669701576233, 0.011274144984781742, 0.10202474147081375, 0.01126647274941206, 0.011493041180074215, 0.011423486284911633, 0.12064104527235031, 0.28871145844459534, 0.011895015835762024, 0.0121115418151021, 0.012494359165430069, 0.01240527629852295, 0.013067590072751045, 0.012981115840375423, 0.012916934676468372, 0.012386170215904713, 0.09067648649215698, 0.012251471169292927, 0.0981222540140152, 0.26124459505081177, 0.01195333618670702, 0.09449022263288498, 0.11198035627603531, 0.012854564934968948, 0.01285524107515812, 0.012838616035878658, 0.2968151569366455, 0.013295143842697144, 0.0937521830201149, 0.10941005498170853, 0.1376921683549881, 0.014459008350968361, 0.014620451256632805, 0.014393812976777554, 0.07845846563577652, 0.13444611430168152, 0.0148412324488163, 0.0880826786160469, 0.01491493172943592, 0.014301013201475143, 0.08911021798849106, 0.1175464540719986, 0.013761283829808235, 0.12579300999641418, 0.15857075154781342, 0.013901330530643463, 0.01377070602029562, 0.09070800989866257, 0.07136870920658112, 0.13406798243522644, 0.12359704077243805, 0.01287965476512909, 0.01262731198221445, 0.12990151345729828, 0.12319844216108322, 0.012400828301906586, 0.012680976651608944, 0.08039302378892899, 0.1123344674706459, 0.012089595198631287, 0.011803085915744305, 0.011505485512316227, 0.011426612734794617, 0.010992836207151413, 0.09567518532276154, 0.010541022755205631, 0.10325352102518082, 0.11099953949451447, 0.010015192441642284, 0.0891413763165474, 0.009734062477946281, 0.009566204622387886, 0.11479492485523224, 0.009538760408759117, 0.009275980293750763, 0.009275048971176147, 0.009074605070054531, 0.15759272873401642, 0.008533901534974575, 0.008393908850848675, 0.008203105069696903, 0.0895165279507637, 0.09326171875, 0.12004212290048599, 0.007795897778123617, 0.007886684499680996, 0.09295662492513657, 0.34939053654670715, 0.007962793111801147, 0.008417617529630661, 0.08545660972595215, 0.09370003640651703, 0.009155656211078167, 0.2970370948314667, 0.3117951452732086, 0.010451720096170902, 0.011261854320764542, 0.012207772582769394, 0.012474333867430687, 0.11243414133787155, 0.1350385546684265, 0.013969643972814083, 0.01454231422394514, 0.0951709970831871, 0.014827488921582699, 0.014853120781481266, 0.10470890998840332, 0.015259521082043648, 0.09190893173217773, 0.266670286655426, 0.01522678229957819, 0.015942934900522232, 0.11374115198850632, 0.08555836230516434, 0.01627829298377037, 0.11678028106689453, 0.016275957226753235, 0.10724085569381714, 0.016806799918413162, 0.525261402130127, 0.017009949311614037, 0.018059929832816124, 0.1396210938692093, 0.11287513375282288, 0.019844209775328636, 0.1275504231452942, 0.0200789924710989, 0.020077254623174667, 0.02021932043135166, 0.09935002028942108, 0.019830651581287384, 0.019875463098287582, 0.019343944266438484, 0.077363021671772, 0.12637320160865784, 0.11160843819379807, 0.01805569790303707, 0.1026609018445015, 0.017081553116440773, 0.32846951484680176, 0.09770055115222931, 0.01689309813082218, 0.11194080114364624, 0.017111875116825104, 0.01716282218694687, 0.01691959984600544, 0.14343619346618652, 0.016171494498848915, 0.10788336396217346, 0.09703505039215088, 0.015681495890021324, 0.10563498735427856, 0.01491248607635498, 0.01467812992632389, 0.014898990280926228, 0.11981960386037827, 0.01375821977853775, 0.013451743870973587, 0.013125619851052761, 0.2559886872768402, 0.012985936366021633, 0.0128459008410573, 0.012522948905825615, 0.12000197917222977, 0.14717218279838562, 0.10711059719324112, 0.1161850318312645, 0.012262874282896519, 0.0121205048635602, 0.10156041383743286, 0.012173563241958618, 0.09368480741977692, 0.11466928571462631, 0.012188849970698357, 0.10216663777828217, 0.09798979014158249, 0.011655651032924652, 0.11483912914991379, 0.011633390560746193, 0.011544588021934032, 0.011633110232651234, 0.011257058009505272, 0.011097675189375877, 0.010809424333274364, 0.10859286785125732, 0.12700343132019043, 0.010259823873639107, 0.010160730220377445, 0.009930843487381935, 0.009808924980461597, 0.6667263507843018, 0.010127317160367966, 0.10731246322393417, 0.33788710832595825, 0.118052177131176, 0.10154949128627777, 0.0931330993771553, 0.1025811955332756, 0.014956573024392128, 0.11197876930236816, 0.016202203929424286, 0.016428619623184204, 0.017064761370420456, 0.017055798321962357, 0.01699090749025345, 0.016998786479234695, 0.01696167327463627, 0.016808029264211655, 0.10990245640277863, 0.08868908137083054, 0.016006935387849808, 0.015819204971194267, 0.01543369796127081, 0.10104797035455704, 0.11404391378164291, 0.014475087635219097, 0.10959814488887787, 0.3050016164779663, 0.01421810407191515, 0.11055223643779755, 0.01454583927989006, 0.014384710229933262, 0.1206367239356041, 0.014239751733839512, 0.09416880458593369, 0.09984929114580154, 0.014059904031455517, 0.013852511532604694, 0.013765068724751472, 0.013641965575516224, 0.09690067172050476, 0.013215407729148865, 0.0900329053401947, 0.01266624964773655, 0.012706904672086239, 0.01228718739002943, 0.10614127665758133, 0.01166774146258831, 0.011374911293387413, 0.09849105775356293, 0.13191579282283783, 0.10091578960418701, 0.010557095520198345, 0.12319966405630112, 0.010374031960964203, 0.01028449647128582, 0.010072173550724983, 0.009893346577882767, 0.10816862434148788, 0.09634151309728622, 0.12209778279066086, 0.009469603188335896, 0.009360384196043015, 0.009353356435894966, 0.11390098929405212, 0.009068520739674568, 0.008975847624242306, 0.3034681975841522, 0.009062966331839561, 0.1170588955283165, 0.10126571357250214, 0.00957302562892437, 0.009705126285552979, 0.009934348054230213, 0.009984409436583519, 0.009930701926350594, 0.009903783909976482, 0.0963764637708664, 0.009738302789628506, 0.009651046246290207, 0.009698308072984219, 0.11134042590856552, 0.009453058242797852, 0.009328420273959637, 0.009196268394589424, 0.008993007242679596, 0.00883499812334776, 0.008746439591050148, 0.008470568805932999, 0.10688318312168121, 0.008165089413523674, 0.1168702244758606, 0.007929055020213127, 0.0077768960036337376, 0.007705481257289648, 0.0075425342656672, 0.0075278449803590775, 0.007241262588649988, 0.007134307641535997, 0.09119130671024323, 0.0068312049843370914, 0.12561455368995667, 0.006733430549502373, 0.006562704686075449, 0.006457363720983267, 0.006410632748156786, 0.006237417925149202, 0.08871356397867203, 0.00613529235124588, 0.11010964959859848, 0.00612664595246315, 0.1041269302368164, 0.005913588218390942, 0.1191307082772255, 0.005938371177762747, 0.0059279934503138065, 0.0059557450003921986, 0.005968800280243158, 0.005882853176444769, 0.10429852455854416, 0.005793618969619274, 0.11102720350027084, 0.005844724830240011, 0.10157514363527298, 0.005829643923789263, 0.005862955003976822, 0.005880798678845167, 0.10936753451824188, 0.005845671519637108, 0.005862649995833635, 0.006005560047924519, 0.005942018236964941, 0.005977073218673468, 0.10907875746488571, 0.10105451941490173, 0.005750490352511406, 0.005742358043789864, 0.005791323259472847, 0.3848652243614197, 0.005998098757117987, 0.10251417011022568, 0.00649491511285305, 0.006859983317553997, 0.0070677450858056545, 0.006965320557355881, 0.007066925521939993, 0.007103787735104561, 0.007251447532325983, 0.12246975302696228, 0.0072519429959356785, 0.007266797125339508, 0.13067574799060822, 0.00744663504883647, 0.1097571849822998, 0.007313072681427002, 0.10032869875431061, 0.10469990968704224, 0.09283843636512756, 0.007657424546778202, 0.007716578431427479, 0.0077411578968167305, 0.09527502954006195, 0.007909232750535011, 0.11630455404520035, 0.007856038399040699, 0.007872440852224827, 0.007902403362095356, 0.007825660519301891, 0.007784200832247734, 0.007816880010068417, 0.007678298279643059, 0.007573359180241823, 0.0075200083665549755, 0.0072546908631920815, 0.10952460765838623, 0.007204381749033928, 0.007002606522291899, 0.007221407722681761, 0.006706498563289642, 0.1379767805337906, 0.006631603930145502, 0.11417700350284576, 0.13010786473751068, 0.12000397592782974, 0.08558322489261627, 0.006574572529643774, 0.09772298485040665, 0.006753775756806135, 0.10142860561609268, 0.37715789675712585, 0.11266504228115082, 0.10671389847993851, 0.007956261746585369, 0.10951575636863708, 0.008648691698908806, 0.10389954596757889, 0.10101926326751709, 0.009677175432443619, 0.08247336745262146, 0.010192383080720901, 0.010538695380091667, 0.010502812452614307, 0.28205400705337524, 0.011345765553414822, 0.2685231864452362, 0.12119031697511673, 0.013001049868762493, 0.013837223872542381, 0.08593997359275818, 0.014522470533847809, 0.014650250785052776, 0.11110995709896088, 0.015379698947072029, 0.015519252046942711, 0.015364671126008034, 0.09765435010194778, 0.01537786703556776, 0.10583140701055527, 0.015137302689254284, 0.014911654405295849, 0.014931163750588894, 0.01468014344573021, 0.014395272359251976, 0.013962010852992535, 0.013481087051331997]\n",
            "Val loss 0.0525681179490088\n",
            "Val auc roc 0.5102345758354756\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbf35343d0914ba8951ca6e22e84bee3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1728.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0578\n",
            "Train Losses : [0.10741108655929565, 0.012996133416891098, 0.012515679001808167, 0.10869994014501572, 0.011915627866983414, 0.011881256476044655, 0.011455575004220009, 0.6098138093948364, 0.09212782979011536, 0.2802286148071289, 0.012737755663692951, 0.12130192667245865, 0.3005461096763611, 0.1152568981051445, 0.016029097139835358, 0.01690131612122059, 0.2627638876438141, 0.11210823059082031, 0.019944848492741585, 0.020657140761613846, 0.021028224378824234, 0.021639637649059296, 0.1269012838602066, 0.02244710549712181, 0.022109195590019226, 0.09997790306806564, 0.11584510654211044, 0.022540532052516937, 0.0990305170416832, 0.10038226842880249, 0.12528565526008606, 0.11185000091791153, 0.02070409618318081, 0.10690954327583313, 0.02021046169102192, 0.10514747351408005, 0.08131679892539978, 0.01949773170053959, 0.29835620522499084, 0.08716912567615509, 0.019005894660949707, 0.019057875499129295, 0.018806012347340584, 0.0184918325394392, 0.018126433715224266, 0.09238667041063309, 0.01762273535132408, 0.09175916761159897, 0.0172938983887434, 0.10498473048210144, 0.1060798391699791, 0.015806028619408607, 0.09080415964126587, 0.015484735369682312, 0.10821686685085297, 0.014727065339684486, 0.01441954169422388, 0.014004223048686981, 0.013758770190179348, 0.013335093855857849, 0.012793348170816898, 0.01243195217102766, 0.12610004842281342, 0.10109902918338776, 0.10721486806869507, 0.011523978784680367, 0.09673040360212326, 0.12621809542179108, 0.010861828923225403, 0.1104544922709465, 0.010572447441518307, 0.010380158200860023, 0.1380278766155243, 0.010110474191606045, 0.009892134927213192, 0.09138070791959763, 0.009854302741587162, 0.10800142586231232, 0.00944586843252182, 0.08650478720664978, 0.3087107837200165, 0.11230397969484329, 0.009714453481137753, 0.3104245364665985, 0.01043391227722168, 0.011308702640235424, 0.011449668556451797, 0.14183975756168365, 0.08426044881343842, 0.012756812386214733, 0.012526556849479675, 0.012824657373130322, 0.012694881297647953, 0.012727510184049606, 0.012518147937953472, 0.10640723258256912, 0.01286407932639122, 0.3643489480018616, 0.08888912200927734, 0.01298533845692873, 0.013023723848164082, 0.13574345409870148, 0.09201353788375854, 0.013251514174044132, 0.013446102850139141, 0.013375694863498211, 0.013391283340752125, 0.013340111821889877, 0.013114050030708313, 0.012745998799800873, 0.1425113081932068, 0.08746309578418732, 0.012113787233829498, 0.012402515858411789, 0.01172140333801508, 0.08773732930421829, 0.011473054066300392, 0.011280727572739124, 0.010923129506409168, 0.010747036896646023, 0.010346668772399426, 0.010249519720673561, 0.13007859885692596, 0.009917092509567738, 0.11224576085805893, 0.009280474856495857, 0.009182708337903023, 0.008922104723751545, 0.008971137925982475, 0.12318316102027893, 0.008508381433784962, 0.00834196899086237, 0.008230810984969139, 0.00791588332504034, 0.007716769818216562, 0.007522211875766516, 0.007359441369771957, 0.0071185799315571785, 0.007010930683463812, 0.006931512150913477, 0.006702734623104334, 0.006443675607442856, 0.0062607042491436005, 0.006122572347521782, 0.005957524757832289, 0.0892118513584137, 0.14161282777786255, 0.12331809848546982, 0.005636356305330992, 0.005821895785629749, 0.1158134937286377, 0.1233375295996666, 0.005725119728595018, 0.005742483772337437, 0.12892641127109528, 0.005735619459301233, 0.10790547728538513, 0.005921761970967054, 0.0058359988033771515, 0.005882603581994772, 0.0059267934411764145, 0.005905210506170988, 0.0058846683241426945, 0.11700835824012756, 0.005877294111996889, 0.005833055358380079, 0.12152598053216934, 0.005866493098437786, 0.00587474787607789, 0.005888564046472311, 0.005854115821421146, 0.005739591550081968, 0.005779407452791929, 0.005665935110300779, 0.11702023446559906, 0.1054263561964035, 0.7710655331611633, 0.0060371155850589275, 0.006532582454383373, 0.007047529332339764, 0.007444221060723066, 0.3168199062347412, 0.008424296043813229, 0.009009706787765026, 0.0901801735162735, 0.009950986132025719, 0.10568779706954956, 0.010756393894553185, 0.011237172409892082, 0.011618363671004772, 0.011675632558763027, 0.11044889688491821, 0.012077010236680508, 0.08167686313390732, 0.012266314588487148, 0.08888646215200424, 0.10076116770505905, 0.012335647828876972, 0.012405343353748322, 0.09562056511640549, 0.0127090560272336, 0.11204957216978073, 0.0126890167593956, 0.10514360666275024, 0.012284446507692337, 0.12543539702892303, 0.012214298360049725, 0.01215249765664339, 0.11926954239606857, 0.011752256192266941, 0.09444817155599594, 0.011703255586326122, 0.011375333182513714, 0.01122249010950327, 0.12759599089622498, 0.10132147371768951, 0.011350374668836594, 0.11758401989936829, 0.010609285905957222, 0.36384159326553345, 0.09127994626760483, 0.010938076302409172, 0.011203300207853317, 0.14710336923599243, 0.011323806829750538, 0.011427843011915684, 0.09628939628601074, 0.011467191390693188, 0.09140651673078537, 0.01152362022548914, 0.011386588215827942, 0.011356960982084274, 0.011230292730033398, 0.10205179452896118, 0.011086474172770977, 0.01094070728868246, 0.01065863948315382, 0.010460080578923225, 0.010449867695569992, 0.010116266086697578, 0.009926248341798782, 0.11396046727895737, 0.00946554634720087, 0.009255059994757175, 0.009064063429832458, 0.008939444087445736, 0.008664421737194061, 0.008475677110254765, 0.008250802755355835, 0.008153002709150314, 0.00783970020711422, 0.11903350055217743, 0.007651837542653084, 0.09406297653913498, 0.00737680122256279, 0.1027107834815979, 0.1262703835964203, 0.007014954928308725, 0.0972534790635109, 0.006959002930670977, 0.007041820790618658, 0.09948252886533737, 0.1033545657992363, 0.1242314875125885, 0.006994302850216627, 0.007146005518734455, 0.007069418206810951, 0.0070460340939462185, 0.39061468839645386, 0.0071893008425831795, 0.007579070515930653, 0.0076078008860349655, 0.3656589984893799, 0.008168741129338741, 0.008629348129034042, 0.008814269676804543, 0.11597676575183868, 0.09479393810033798, 0.009604014456272125, 0.3287886679172516, 0.11100175231695175, 0.10110276192426682, 0.011470974422991276, 0.12015616148710251, 0.012229534797370434, 0.012615658342838287, 0.012979898601770401, 0.013211490586400032, 0.10553725808858871, 0.013584441505372524, 0.10904835909605026, 0.013599221594631672, 0.013624212704598904, 0.28815004229545593, 0.013946855440735817, 0.014008788391947746, 0.01420180406421423, 0.014050224795937538, 0.014251378364861012, 0.11980675905942917, 0.014223790727555752, 0.13414427638053894, 0.01374056376516819, 0.01367721613496542, 0.013436084613204002, 0.10054691880941391, 0.11113809049129486, 0.012939013540744781, 0.09358666092157364, 0.012667051516473293, 0.01262690406292677, 0.012336364015936852, 0.012266948819160461, 0.011852574534714222, 0.11254727840423584, 0.09690386801958084, 0.011303500272333622, 0.12468048185110092, 0.010966556146740913, 0.010908903554081917, 0.010714699514210224, 0.12235621362924576, 0.10564245283603668, 0.010235395282506943, 0.09050954878330231, 0.11911720037460327, 0.10660417377948761, 0.09789597243070602, 0.009821871295571327, 0.009789006784558296, 0.00981624610722065, 0.2989361584186554, 0.1289081573486328, 0.09887789934873581, 0.3404662609100342, 0.11852288991212845, 0.11390355229377747, 0.10431678593158722, 0.012232781387865543, 0.012732206843793392, 0.013095649890601635, 0.013208855874836445, 0.013368292711675167, 0.013442383147776127, 0.013663831166923046, 0.013541698455810547, 0.11679288744926453, 0.25790998339653015, 0.3009604811668396, 0.014207448810338974, 0.01515034306794405, 0.2760407030582428, 0.015854107216000557, 0.01648322306573391, 0.017016831785440445, 0.017496591433882713, 0.017584698274731636, 0.017609665170311928, 0.017671912908554077, 0.01763814128935337, 0.017489366233348846, 0.017317980527877808, 0.2673700749874115, 0.017348239198327065, 0.0172523632645607, 0.017225047573447227, 0.12431075423955917, 0.11974421888589859, 0.10264203697443008, 0.08015894889831543, 0.01679336093366146, 0.0165280532091856, 0.016300326213240623, 0.016348643228411674, 0.015816569328308105, 0.10479728877544403, 0.01521390862762928, 0.014925875701010227, 0.014622218906879425, 0.09919418394565582, 0.10336074978113174, 0.01408494170755148, 0.07805241644382477, 0.08972635120153427, 0.013007116504013538, 0.012939822860062122, 0.11339877545833588, 0.0122709134593606, 0.012200060300529003, 0.01198335736989975, 0.01151843462139368, 0.10742120444774628, 0.1051102727651596, 0.010941908694803715, 0.010770208202302456, 0.12165237963199615, 0.010375670157372952, 0.010269008576869965, 0.10908136516809464, 0.009883229620754719, 0.009941511787474155, 0.009668366052210331, 0.3223295509815216, 0.31933918595314026, 0.010028606280684471, 0.010292304679751396, 0.010584949515759945, 0.09667425602674484, 0.1165628507733345, 0.31099990010261536, 0.011845779605209827, 0.012564841657876968, 0.012600013986229897, 0.1088186725974083, 0.013163923285901546, 0.013458427041769028, 0.013600175268948078, 0.013776978477835655, 0.013621630147099495, 0.10988178104162216, 0.10788329690694809, 0.0135691212490201, 0.013384849764406681, 0.013352292589843273, 0.09992880374193192, 0.12164364755153656, 0.013216172344982624, 0.012980028986930847, 0.07603336125612259, 0.012569488026201725, 0.01242135651409626, 0.012164071202278137, 0.11200318485498428, 0.1294056624174118, 0.29962342977523804, 0.012062111869454384, 0.011994251981377602, 0.012002167291939259, 0.0121097257360816, 0.011958400718867779, 0.012031815014779568, 0.09477154910564423, 0.011827928014099598, 0.01159537211060524, 0.011454368010163307, 0.011407466605305672, 0.09663977473974228, 0.011092858389019966, 0.010853201150894165, 0.09570589661598206, 0.10598448663949966, 0.1002456322312355, 0.09984929114580154, 0.010457170195877552, 0.1263018548488617, 0.010249919258058071, 0.010174482129514217, 0.010128949768841267, 0.010011470876634121, 0.10365258157253265, 0.00971316173672676, 0.009893790818750858, 0.00973333977162838, 0.009395059198141098, 0.009485664777457714, 0.09617386013269424, 0.10838959366083145, 0.008768212050199509, 0.008735462091863155, 0.12624551355838776, 0.12044892460107803, 0.10804787278175354, 0.008707566186785698, 0.08839007467031479, 0.10236213356256485, 0.008512954227626324, 0.008610364980995655, 0.008648186922073364, 0.3128693103790283, 0.00877344235777855, 0.00906235259026289, 0.11144548654556274, 0.009229130111634731, 0.009312286972999573, 0.009387234225869179, 0.10168630629777908, 0.009823217056691647, 0.009692207910120487, 0.010043056681752205, 0.00952188204973936, 0.1359984576702118, 0.09932456910610199, 0.2734498083591461, 0.1252012401819229, 0.010034846141934395, 0.010308260098099709, 0.010530039668083191, 0.010505378246307373, 0.010710823349654675, 0.12339533120393753, 0.12112582474946976, 0.010764693841338158, 0.010752839036285877, 0.01094850990921259, 0.1267099827528, 0.010779466480016708, 0.01072582509368658, 0.01056363619863987, 0.010455920360982418, 0.10704831033945084, 0.010276131331920624, 0.010334973223507404, 0.35978439450263977, 0.10592572391033173, 0.010291473008692265, 0.08480203151702881, 0.10417178273200989, 0.09278985857963562, 0.011114594526588917, 0.0110396109521389, 0.011213988065719604, 0.10724224895238876, 0.011214728467166424, 0.09669017791748047, 0.1106601133942604, 0.011022201739251614, 0.011054929345846176, 0.010985162109136581, 0.010906622745096684, 0.1001954972743988, 0.010856997221708298, 0.1045604795217514, 0.1328393965959549, 0.010572944767773151, 0.010524698533117771, 0.010409146547317505, 0.010267876088619232, 0.35211077332496643, 0.29379576444625854, 0.08840885758399963, 0.01110267173498869, 0.011526001617312431, 0.25082674622535706, 0.012279678136110306, 0.11592203378677368, 0.0944213792681694, 0.013635192066431046, 0.30490195751190186, 0.26138558983802795, 0.09679771214723587, 0.016576603055000305, 0.01701824925839901, 0.01799185387790203, 0.12261845916509628, 0.2750093638896942, 0.01943400502204895, 0.019851716235280037, 0.020314624533057213, 0.07786257565021515, 0.02080317586660385, 0.020965369418263435, 0.02107119932770729, 0.10441503673791885, 0.02085237205028534, 0.020818093791604042, 0.020581843331456184, 0.02028091996908188, 0.02037625201046467, 0.01946870982646942, 0.018885595723986626, 0.018721692264080048, 0.1005740538239479, 0.017448026686906815, 0.017136145383119583, 0.016521576792001724, 0.015997469425201416, 0.015540954656898975, 0.014760135672986507, 0.13968275487422943, 0.013998417183756828, 0.01389920525252819, 0.013299498707056046, 0.10544304549694061, 0.012576517648994923, 0.11567644774913788, 0.01210527028888464, 0.011338882148265839, 0.011417802423238754, 0.010892080143094063, 0.311651349067688, 0.010669232346117496, 0.09986463189125061, 0.01049263495951891, 0.010637907311320305, 0.010356920771300793, 0.14280913770198822, 0.11566455662250519, 0.010221240110695362, 0.13216595351696014, 0.010346557945013046, 0.01039823330938816, 0.010141614824533463, 0.08811184018850327, 0.33324089646339417, 0.010197782889008522, 0.010448535904288292, 0.01051335409283638, 0.010509791783988476, 0.01047242060303688, 0.010471036657691002, 0.11168011277914047, 0.010837349109351635, 0.11703447252511978, 0.1232781633734703, 0.010300536639988422, 0.0765945166349411, 0.010348000563681126, 0.010525024496018887, 0.010269824415445328, 0.09903298318386078, 0.010084977373480797, 0.010036583989858627, 0.010091595351696014, 0.00971973780542612, 0.1270786076784134, 0.009443207643926144, 0.009374311193823814, 0.129021555185318, 0.009126530028879642, 0.08929476141929626, 0.11778724193572998, 0.009005753323435783, 0.008901815861463547, 0.0963250994682312, 0.00889557134360075, 0.08152521401643753, 0.008844602853059769, 0.008752751164138317, 0.008681006729602814, 0.008997505530714989, 0.11958659440279007, 0.3655029833316803, 0.10549629479646683, 0.008808324113488197, 0.009245678782463074, 0.009152282029390335, 0.009649291634559631, 0.009244448505342007, 0.009537066332995892, 0.009372861124575138, 0.08601540327072144, 0.009367325343191624, 0.11570840328931808, 0.0969739556312561, 0.009227371774613857, 0.009278613142669201, 0.009145382791757584, 0.12181157618761063, 0.009130178950726986, 0.009016157127916813, 0.009183835238218307, 0.09217268228530884, 0.12068814784288406, 0.009073053486645222, 0.008749032393097878, 0.10523759573698044, 0.10737921297550201, 0.008709150366485119, 0.008666438981890678, 0.008700993843376637, 0.12113502621650696, 0.12662501633167267, 0.00872243382036686, 0.11741206794977188, 0.008484745398163795, 0.008459527045488358, 0.008417910896241665, 0.00854228064417839, 0.008290471509099007, 0.09852507710456848, 0.11936400830745697, 0.008166172541677952, 0.11082281917333603, 0.008205209858715534, 0.008180865086615086, 0.12673062086105347, 0.08912251889705658, 0.00807398185133934, 0.08591353893280029, 0.12315002828836441, 0.09294689446687698, 0.008380240760743618, 0.008317910134792328, 0.08938427269458771, 0.00855599157512188, 0.008436959236860275, 0.0083353566005826, 0.12222469598054886, 0.11415978521108627, 0.11725017428398132, 0.008434274233877659, 0.3473607301712036, 0.008624128997325897, 0.009140345267951488, 0.009154422208666801, 0.009110929444432259, 0.009598265402019024, 0.009501087479293346, 0.11727011948823929, 0.08955129235982895, 0.12047294527292252, 0.009616482071578503, 0.11410244554281235, 0.009818632155656815, 0.009803108870983124, 0.009668600745499134, 0.1292872130870819, 0.009784720838069916, 0.009705405682325363, 0.009892613627016544, 0.009530095383524895, 0.09579120576381683, 0.00947659369558096, 0.09718168526887894, 0.009253093041479588, 0.009261350147426128, 0.009219345636665821, 0.09612635523080826, 0.008882766589522362, 0.008797725662589073, 0.008813218213617802, 0.008558068424463272, 0.3211105167865753, 0.008555709384381771, 0.008682730607688427, 0.11373181641101837, 0.008979149162769318, 0.11181265860795975, 0.009135417640209198, 0.009142887778580189, 0.009219779632985592, 0.009303595870733261, 0.009007558226585388, 0.09111183881759644, 0.3262757658958435, 0.009164520539343357, 0.009650276042521, 0.009532853029668331, 0.11770933866500854, 0.10941632837057114, 0.009790933690965176, 0.08420795947313309, 0.30093204975128174, 0.010388080962002277, 0.12096557766199112, 0.11439885944128036, 0.011378075927495956, 0.01142621599137783, 0.10099630802869797, 0.011880138888955116, 0.012090591713786125, 0.012278391979634762, 0.11935774981975555, 0.012298408895730972, 0.012168456800282001, 0.012247907929122448, 0.10067632049322128, 0.012249687686562538, 0.12356647849082947, 0.08750637620687485, 0.11996252834796906, 0.011816775426268578, 0.011768168769776821, 0.01203432958573103, 0.011879160068929195, 0.011616201139986515, 0.01140524446964264, 0.12467285990715027, 0.326518714427948, 0.10431678593158722, 0.011340467259287834, 0.011405340395867825, 0.01151293609291315, 0.0115637993440032, 0.011526446789503098, 0.08924534171819687, 0.01145985908806324, 0.011332020163536072, 0.011230191215872765, 0.011548271402716637, 0.13066938519477844, 0.010870327241718769, 0.01091484073549509, 0.010554291307926178, 0.30498000979423523, 0.010617720894515514, 0.010764000937342644, 0.010733767412602901, 0.010683607310056686, 0.01074698381125927, 0.010558359324932098, 0.12305880337953568, 0.010449572466313839, 0.010387109592556953, 0.09448708593845367, 0.010283206589519978, 0.010123973712325096, 0.10855832695960999, 0.010239973664283752, 0.009965742938220501, 0.1411028951406479, 0.00965161807835102, 0.009528064168989658, 0.6868462562561035, 0.009801321662962437, 0.3136879503726959, 0.01085398904979229, 0.011338292621076107, 0.011873353272676468, 0.12057284265756607, 0.012798157520592213, 0.012874365784227848, 0.013148590922355652, 0.013277167454361916, 0.013512752018868923, 0.013783327303826809, 0.0940224677324295, 0.01361046638339758, 0.28621405363082886, 0.10896381735801697, 0.10148221999406815, 0.014120558276772499, 0.014261054806411266, 0.01450617890805006, 0.014627546072006226, 0.10486480593681335, 0.014367649331688881, 0.014341399073600769, 0.27918434143066406, 0.014468271285295486, 0.014662886038422585, 0.014947629533708096, 0.014849435538053513, 0.014696081168949604, 0.1121792122721672, 0.01442493312060833, 0.014338326640427113, 0.01420887466520071, 0.013924640603363514, 0.013741491362452507, 0.1246480718255043, 0.013217087835073471, 0.013129160739481449, 0.01274149026721716, 0.08662252128124237, 0.012347918003797531, 0.091647669672966, 0.01197205949574709, 0.011685480363667011, 0.25551220774650574, 0.10097820311784744, 0.011739594861865044, 0.0116369454190135, 0.011795908212661743, 0.011693393811583519, 0.12442990392446518, 0.11276504397392273, 0.011415266431868076, 0.11951664835214615, 0.011227536015212536, 0.09134109318256378, 0.0909726694226265, 0.11530285328626633, 0.011284872889518738, 0.011163543909788132, 0.10730776935815811, 0.011080531403422356, 0.011158077046275139, 0.010870841331779957, 0.010887607000768185, 0.010659564286470413, 0.010490369983017445, 0.010368105955421925, 0.32593417167663574, 0.010314987041056156, 0.010463111102581024, 0.010411462746560574, 0.010314482264220715, 0.14438053965568542, 0.010326526127755642, 0.11273566633462906, 0.010325169190764427, 0.10448838025331497, 0.010288511402904987, 0.010194730944931507, 0.01012094970792532, 0.010167592205107212, 0.01004867535084486, 0.009935753419995308, 0.13182169198989868, 0.009869758039712906, 0.10888341814279556, 0.009489172138273716, 0.009397098794579506, 0.009411515668034554, 0.009202923625707626, 0.10089337080717087, 0.009023357182741165, 0.008856586180627346, 0.00875556655228138, 0.00869640801101923, 0.008531956002116203, 0.008466128259897232, 0.10604910552501678, 0.00805572234094143, 0.11584384739398956, 0.007985859178006649, 0.007937001995742321, 0.10377856343984604, 0.007669871672987938, 0.007603300269693136, 0.007582898251712322, 0.007436414714902639, 0.007332173176109791, 0.10543832927942276, 0.007170728873461485, 0.007097279652953148, 0.0071065085940063, 0.006904860958456993, 0.33729827404022217, 0.006944575812667608, 0.10283225774765015, 0.0946420356631279, 0.007242104038596153, 0.0074424841441214085, 0.00758912181481719, 0.007474981714040041, 0.1127060279250145, 0.12076222151517868, 0.1236027404665947, 0.10268273949623108, 0.007826415821909904, 0.007890052162110806, 0.00806555338203907, 0.007986320182681084, 0.008127376437187195, 0.008094663731753826, 0.344474196434021, 0.00812544021755457, 0.008300325833261013, 0.008494622074067593, 0.008532912470400333, 0.008592138066887856, 0.008642877452075481, 0.008653326891362667, 0.10922257602214813, 0.11391305178403854, 0.008726526983082294, 0.11678274720907211, 0.10179208219051361, 0.3588796854019165, 0.009119084104895592, 0.009353512898087502, 0.08709470927715302, 0.08851130306720734, 0.009999223984777927, 0.2985166609287262, 0.010506706312298775, 0.10139666497707367, 0.10000104457139969, 0.011472625657916069, 0.011767384596168995, 0.09964123368263245, 0.012475003488361835, 0.3279015123844147, 0.012720081023871899, 0.08760176599025726, 0.09102228283882141, 0.013645398430526257, 0.01389392465353012, 0.11667953431606293, 0.014245444908738136, 0.014186365529894829, 0.01419905200600624, 0.10500908643007278, 0.014254090376198292, 0.014250097796320915, 0.014034127816557884, 0.10020042210817337, 0.11945436894893646, 0.014101436361670494, 0.30200377106666565, 0.1211826354265213, 0.013917339034378529, 0.014025506563484669, 0.014613247476518154, 0.2532184422016144, 0.014333625324070454, 0.3075335919857025, 0.015102488920092583, 0.015516649931669235, 0.09975846111774445, 0.01602335274219513, 0.1067858561873436, 0.016336044296622276, 0.12099872529506683, 0.016531718894839287, 0.016421189531683922, 0.08467373996973038, 0.1227417141199112, 0.09048274904489517, 0.10392925143241882, 0.016321897506713867, 0.016303613781929016, 0.016418496146798134, 0.11376920342445374, 0.016221441328525543, 0.11837369948625565, 0.01550128124654293, 0.015289177186787128, 0.09983286261558533, 0.01487666741013527, 0.01478621643036604, 0.014595229178667068, 0.08831123262643814, 0.1030762642621994, 0.013770801946520805, 0.013479483313858509, 0.013371486216783524, 0.013096965849399567, 0.012782515026628971, 0.12310246378183365, 0.09685275703668594, 0.012152962386608124, 0.012204901315271854, 0.31305885314941406, 0.10664014518260956, 0.09920430183410645, 0.11966614425182343, 0.012023020535707474, 0.08335147798061371, 0.012425326742231846, 0.10809299349784851, 0.11334176361560822, 0.2919209897518158, 0.012597840279340744, 0.012997901067137718, 0.013120092451572418, 0.013017108663916588, 0.013125204481184483, 0.013069281354546547, 0.01326353196054697, 0.013094653375446796, 0.012989083305001259, 0.012813176959753036, 0.012703060172498226, 0.012668382376432419, 0.01218695379793644, 0.1042400449514389, 0.0965832993388176, 0.011786923743784428, 0.1060834676027298, 0.01156328059732914, 0.011382412165403366, 0.3466176986694336, 0.109589584171772, 0.01139355544000864, 0.01148574985563755, 0.01160583645105362, 0.07915353029966354, 0.09068066626787186, 0.011789974756538868, 0.011686393059790134, 0.011482586152851582, 0.09630637615919113, 0.011400291696190834, 0.011284051463007927, 0.011219484731554985, 0.011109723709523678, 0.010988998226821423, 0.010832540690898895, 0.09878237545490265, 0.1086193397641182, 0.3041645288467407, 0.010623895563185215, 0.010774681344628334, 0.010817134752869606, 0.011014657095074654, 0.11756953597068787, 0.011116491630673409, 0.010978400707244873, 0.0944451317191124, 0.10674428939819336, 0.010791662149131298, 0.09419304132461548, 0.010860849171876907, 0.0884893536567688, 0.01076432317495346, 0.010690473951399326, 0.11562665551900864, 0.010640976950526237, 0.01053092535585165, 0.01046711765229702, 0.010502263903617859, 0.010340604931116104, 0.010020013898611069, 0.010034250095486641, 0.13462990522384644, 0.009817850776016712, 0.009575116448104382, 0.009417761117219925, 0.009317364543676376, 0.009165315888822079, 0.11851520091295242, 0.008759121410548687, 0.3482159972190857, 0.32179519534111023, 0.009122664108872414, 0.1105823963880539, 0.009670908562839031, 0.010242888703942299, 0.00997297465801239, 0.010422402992844582, 0.010395442135632038, 0.010252582840621471, 0.010449026711285114, 0.010391613468527794, 0.010259570553898811, 0.010213562287390232, 0.10454046726226807, 0.01007079891860485, 0.010082647204399109, 0.00996011309325695, 0.08691214770078659, 0.009739100001752377, 0.009633395820856094, 0.11299590766429901, 0.10984277725219727, 0.009685722179710865, 0.12097810953855515, 0.009600784629583359, 0.009290087968111038, 0.09891165792942047, 0.12087982147932053, 0.009498468600213528, 0.009167714044451714, 0.009096624329686165, 0.009104548022150993, 0.14362098276615143, 0.10140110552310944, 0.09189833700656891, 0.10454414039850235, 0.008925779722630978, 0.11082054674625397, 0.10613495856523514, 0.009294766932725906, 0.009139805100858212, 0.009029385633766651, 0.00903748907148838, 0.008880944922566414, 0.008919632993638515, 0.11263373494148254, 0.32295265793800354, 0.009092971682548523, 0.08393789827823639, 0.08527514338493347, 0.08892203122377396, 0.009528093039989471, 0.009863662533462048, 0.009644114412367344, 0.009783572517335415, 0.10224143415689468, 0.009809349663555622, 0.01010170392692089, 0.009974146261811256, 0.009815145283937454, 0.010036592371761799, 0.009805948473513126, 0.009693123400211334, 0.009724615141749382, 0.009428940713405609, 0.11668715626001358, 0.009270079433918, 0.009107576683163643, 0.009022579528391361, 0.3147824704647064, 0.00908864289522171, 0.11473017930984497, 0.10416845977306366, 0.08824785053730011, 0.009198606014251709, 0.0995037779211998, 0.009396633133292198, 0.009425116702914238, 0.00945950672030449, 0.00963236577808857, 0.1257546991109848, 0.08913913369178772, 0.13171012699604034, 0.009930260479450226, 0.11503727734088898, 0.08151228725910187, 0.009670662693679333, 0.009722334332764149, 0.009704670868813992, 0.009821157902479172, 0.09704593569040298, 0.1365271955728531, 0.00967724435031414, 0.00981209147721529, 0.009811555966734886, 0.35451874136924744, 0.010036231018602848, 0.009862684644758701, 0.1284921020269394, 0.009936666116118431, 0.009933157823979855, 0.010175663977861404, 0.06483650952577591, 0.010225025936961174, 0.010149112902581692, 0.010051053948700428, 0.10667624324560165, 0.010091885924339294, 0.009968779981136322, 0.12580247223377228, 0.14169920980930328, 0.009932112880051136, 0.00965835526585579, 0.1397107094526291, 0.009908493608236313, 0.08493125438690186, 0.009601217694580555, 0.009832981042563915, 0.00964618381112814, 0.009312947280704975, 0.009317057207226753, 0.00922235008329153, 0.009181557223200798, 0.008960975334048271, 0.0976635068655014, 0.009078232571482658, 0.008578065782785416, 0.008468973450362682, 0.00833197683095932, 0.008324637077748775, 0.00820531789213419, 0.13336607813835144, 0.007823089137673378, 0.007823989726603031, 0.00783512368798256, 0.4213954210281372, 0.007724144961684942, 0.007937130518257618, 0.25493231415748596, 0.007936854846775532, 0.008371034637093544, 0.008303547278046608, 0.008540898561477661, 0.008754553273320198, 0.008684555068612099, 0.008574852719902992, 0.13145911693572998, 0.13999482989311218, 0.28933045268058777, 0.10740304738283157, 0.009375464171171188, 0.009884290397167206, 0.1073715090751648, 0.009914620779454708, 0.10730141401290894, 0.01040598750114441, 0.010265229269862175, 0.11005768924951553, 0.010522847063839436, 0.01049429178237915, 0.10201746225357056, 0.0930095985531807, 0.010430173017084599, 0.010719005018472672, 0.11749828606843948, 0.1402682512998581, 0.011003880761563778, 0.30537569522857666, 0.010974000208079815, 0.10988704115152359, 0.011348356492817402, 0.01138589158654213, 0.011456540785729885, 0.011361914686858654, 0.11703947186470032, 0.011420833878219128, 0.12359368801116943, 0.011481705121695995, 0.011484337039291859, 0.01141540426760912, 0.011245599947869778, 0.12810058891773224, 0.011309514753520489, 0.09486163407564163, 0.011099481955170631, 0.010875822976231575, 0.1107596829533577, 0.1253325194120407, 0.011035075411200523, 0.09691711515188217, 0.31237003207206726, 0.010851973667740822, 0.08970728516578674, 0.011039300821721554, 0.10678144544363022, 0.0114009790122509, 0.01122298650443554, 0.011289308778941631, 0.011642596684396267, 0.30413132905960083, 0.011462111957371235, 0.011817035265266895, 0.01190707366913557, 0.01179340947419405, 0.1130576878786087, 0.011744861491024494, 0.09529899060726166, 0.012030234560370445, 0.012056510895490646, 0.08438809216022491, 0.011787604540586472, 0.011866972781717777, 0.09380697458982468, 0.01163324061781168, 0.011549146845936775, 0.011511570774018764, 0.011427733115851879, 0.011599929071962833, 0.011447499506175518, 0.2961004376411438, 0.011039619334042072, 0.29564329981803894, 0.09216775000095367, 0.011457785964012146, 0.012070896103978157, 0.01182552706450224, 0.07148174941539764, 0.09262175112962723, 0.012047589756548405, 0.10798151046037674, 0.1320948749780655, 0.12878000736236572, 0.012571875937283039, 0.11376222968101501, 0.012739989906549454, 0.012781193479895592, 0.12384162843227386, 0.012449346482753754, 0.012362866662442684, 0.012399218045175076, 0.012403332628309727, 0.10289741307497025, 0.012192377820611, 0.011868156492710114, 0.012241321615874767, 0.08295226097106934, 0.09074914455413818, 0.011473733931779861, 0.011352240107953548, 0.13887238502502441, 0.01131591759622097, 0.12481685727834702, 0.010883625596761703, 0.2731146812438965, 0.011171957477927208, 0.011248200200498104, 0.011007068678736687, 0.010985936038196087, 0.011461463756859303, 0.010924345813691616, 0.010793974623084068, 0.010782139375805855, 0.0855625718832016, 0.010491385124623775, 0.137323796749115, 0.12292056530714035, 0.010885241441428661, 0.010506363585591316, 0.010212238878011703, 0.010418087244033813, 0.010244498960673809, 0.009933392517268658, 0.06511934101581573, 0.009839646518230438, 0.009592194110155106, 0.11139891296625137, 0.3016943633556366, 0.009400995448231697, 0.009825775399804115, 0.009763073176145554, 0.1113487184047699, 0.14546245336532593, 0.009966680780053139, 0.010192221030592918, 0.009883381426334381, 0.01006484217941761, 0.009815017692744732, 0.009834480471909046, 0.009820070117712021, 0.009708809666335583, 0.009450816549360752, 0.009528551250696182, 0.08575350046157837, 0.00928264670073986, 0.009224560111761093, 0.009100493043661118, 0.09665041416883469, 0.11746495962142944, 0.12958799302577972, 0.3641079366207123, 0.6134307980537415, 0.009924793615937233, 0.1259458065032959, 0.010632817633450031, 0.010882575996220112, 0.11650829017162323, 0.011938448995351791, 0.011951399967074394, 0.06725192815065384, 0.012465416453778744, 0.012717203237116337, 0.09920938313007355, 0.013734613545238972, 0.0915442407131195, 0.08719028532505035, 0.013963833451271057, 0.10663735121488571, 0.01382592786103487, 0.013502828776836395, 0.01351070124655962, 0.10245057195425034, 0.013968880288302898, 0.11969787627458572, 0.01343892514705658, 0.10349809378385544, 0.013570757582783699, 0.012895907275378704, 0.013091964647173882, 0.012964263558387756, 0.012749221175909042, 0.09566061198711395, 0.11762090772390366, 0.012190382927656174, 0.012160247191786766, 0.012151161208748817, 0.01191853079944849, 0.01164387445896864, 0.011368743143975735, 0.11100640892982483, 0.011062250472605228, 0.010957286693155766, 0.09519528597593307, 0.0997118279337883, 0.01045199390500784, 0.1094905436038971, 0.1462874412536621, 0.010210216976702213, 0.010043212212622166, 0.010383284650743008, 0.010105286724865437, 0.01000410970300436, 0.009979591704905033, 0.009581114165484905, 0.009722616523504257, 0.34433093667030334, 0.00933813489973545, 0.009545019827783108, 0.009486161172389984, 0.11074608564376831, 0.00931514985859394, 0.11386503279209137, 0.009712210856378078, 0.11896903812885284, 0.11688348650932312, 0.009480256587266922, 0.009500444866716862, 0.0946391299366951, 0.11022156476974487, 0.13534045219421387, 0.29313406348228455, 0.009722588583827019, 0.01013401709496975, 0.010454156436026096, 0.1293932944536209, 0.010272742249071598, 0.01055741123855114, 0.010353338904678822, 0.11949369311332703, 0.010478287003934383, 0.010494457557797432, 0.3698763847351074, 0.1200910359621048, 0.3743405342102051, 0.011261947453022003, 0.01186488289386034, 0.012293190695345402, 0.32941657304763794, 0.012654749676585197, 0.012718466110527515, 0.01320523303002119, 0.013215955346822739, 0.013485499657690525, 0.013905320316553116, 0.013666331768035889, 0.013683609664440155, 0.013647130690515041, 0.013679329305887222, 0.013811477459967136, 0.013371788896620274, 0.10573426634073257, 0.013430876657366753, 0.3653525710105896, 0.0135421771556139, 0.01318777073174715, 0.01332816481590271, 0.013228952884674072, 0.013146820478141308, 0.013194829225540161, 0.012968344613909721, 0.012982720509171486, 0.012904828414320946, 0.012630589306354523, 0.08359958231449127, 0.1151631623506546, 0.012420780956745148, 0.012068981304764748, 0.012171559035778046, 0.011924258433282375, 0.01172122173011303, 0.011464138515293598, 0.011334783397614956, 0.011190405115485191, 0.11826205998659134, 0.010682386346161366, 0.01054324209690094, 0.08741816133260727, 0.010218504816293716, 0.010052656754851341, 0.010265779681503773, 0.08384881913661957, 0.009874271228909492, 0.009690754115581512, 0.00953394640237093, 0.009293417446315289, 0.13436125218868256, 0.009096099995076656, 0.09170592576265335, 0.009065939113497734, 0.009000285528600216, 0.10462599247694016, 0.008690803311765194, 0.40368273854255676, 0.008843639865517616, 0.1273288130760193, 0.00872646365314722, 0.008897068910300732, 0.00883177388459444, 0.0089413458481431, 0.009022572077810764, 0.3436196446418762, 0.1140071228146553, 0.009364061988890171, 0.35636085271835327, 0.09196695685386658, 0.010096999816596508, 0.010266521945595741, 0.01045770850032568, 0.010620520450174809, 0.010950522497296333, 0.10883206874132156, 0.01112149003893137, 0.01113822590559721, 0.011325993575155735, 0.01127014122903347, 0.011231557466089725, 0.35968318581581116, 0.011204336769878864, 0.011335311457514763, 0.011656302958726883, 0.011391360312700272, 0.11211317032575607, 0.10203773528337479, 0.011577548459172249, 0.10828765481710434, 0.011542757973074913, 0.10643987357616425, 0.011729995720088482, 0.10570830851793289, 0.011640205979347229, 0.011759505607187748, 0.01175443921238184, 0.011492633260786533, 0.10860530287027359, 0.011297629214823246, 0.08910120278596878, 0.10319281369447708, 0.09659670293331146, 0.01110142096877098, 0.01112871803343296, 0.11831589043140411, 0.08995645493268967, 0.3478802442550659, 0.01110855583101511, 0.12239788472652435, 0.10469195246696472, 0.011592648923397064, 0.011568130925297737, 0.011962216347455978, 0.011777589097619057, 0.011836592108011246, 0.011663459241390228, 0.09305781126022339, 0.011704916134476662, 0.011569643393158913, 0.011511807329952717, 0.01140762772411108, 0.08970854431390762, 0.09848075360059738, 0.011280379258096218, 0.011173373088240623, 0.011158496141433716, 0.01108964066952467, 0.010802369564771652, 0.28745076060295105, 0.010788044892251492, 0.08529359102249146, 0.010801953263580799, 0.09193158149719238, 0.09459436684846878, 0.010905918665230274, 0.011079112067818642, 0.010868004523217678, 0.010974755510687828, 0.010850462131202221, 0.010992668569087982, 0.010725699365139008, 0.010653275065124035, 0.010578603483736515, 0.10613388568162918, 0.010299078188836575, 0.14460180699825287, 0.10658817738294601, 0.010005851276218891, 0.010199205949902534, 0.11746035516262054, 0.009754867292940617, 0.29044124484062195, 0.11100873351097107, 0.09587118774652481, 0.10806956887245178, 0.1345725655555725, 0.010494355112314224, 0.10863665491342545, 0.010545256547629833, 0.010649803094565868, 0.01062862854450941, 0.010692374780774117, 0.12071216106414795, 0.01066369004547596, 0.1038123369216919, 0.3445957899093628, 0.010896550491452217, 0.0875917598605156, 0.011238072998821735, 0.011307521723210812, 0.011574586853384972, 0.011437572538852692, 0.10301550477743149, 0.011441587470471859, 0.011419098824262619, 0.011598494835197926, 0.011335832066833973, 0.011378460563719273, 0.011186177842319012, 0.011194268241524696, 0.011015060357749462, 0.32201144099235535, 0.010939560830593109, 0.010900840163230896, 0.09700538963079453, 0.10765291005373001, 0.011284385807812214, 0.011301012709736824, 0.010995021089911461, 0.011166960000991821, 0.11162742227315903, 0.011184467934072018, 0.010946874506771564, 0.010847784578800201, 0.010748946107923985, 0.11728096753358841, 0.010799127630889416, 0.09848176687955856, 0.01057085394859314, 0.010451464913785458, 0.272748738527298, 0.09356604516506195, 0.010500033386051655, 0.12092817574739456, 0.010584736242890358, 0.010664129629731178, 0.010919785127043724, 0.010787704959511757, 0.010697995312511921, 0.010567841120064259, 0.01060628890991211, 0.010495062917470932, 0.1363588273525238, 0.010290214791893959, 0.12620098888874054, 0.5808238983154297, 0.010484068654477596, 0.010881174355745316, 0.011202801018953323, 0.011362124234437943, 0.011741625145077705, 0.08602724224328995, 0.10823845863342285, 0.35171154141426086, 0.012191344052553177, 0.012567642144858837, 0.11314799636602402]\n",
            "Val loss 0.0532175402454424\n",
            "Val auc roc 0.4933342705655527\n",
            "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     2: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65d30ce1994740b2b83be835eb7a657c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1728.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0558\n",
            "Train Losses : [0.012835548259317875, 0.09022711217403412, 0.012754322029650211, 0.09469306468963623, 0.012989038601517677, 0.012996725738048553, 0.013041120953857899, 0.012885801494121552, 0.0127964336425066, 0.013126800768077374, 0.11690090596675873, 0.10307735204696655, 0.012930918484926224, 0.10924971848726273, 0.08174552023410797, 0.1009286642074585, 0.013008734211325645, 0.012833494693040848, 0.012923280708491802, 0.01322890818119049, 0.013069272972643375, 0.01270083338022232, 0.012903781607747078, 0.11745688319206238, 0.01266828365623951, 0.1223997101187706, 0.08081728965044022, 0.13551993668079376, 0.012856246903538704, 0.13177284598350525, 0.012617099098861217, 0.106434665620327, 0.3101854920387268, 0.012757259421050549, 0.012599024921655655, 0.012614688836038113, 0.012758537195622921, 0.012913894839584827, 0.10569282621145248, 0.012652244418859482, 0.0126720005646348, 0.012807231396436691, 0.012832779437303543, 0.012781781144440174, 0.01276646088808775, 0.01265721581876278, 0.012533511966466904, 0.12238550186157227, 0.01266828365623951, 0.012749296613037586, 0.0923805981874466, 0.1332888901233673, 0.012578516267240047, 0.0909002497792244, 0.01275599468499422, 0.09439636766910553, 0.01245231181383133, 0.012431848794221878, 0.1205587387084961, 0.01248844526708126, 0.26458457112312317, 0.012567644938826561, 0.11615768820047379, 0.10277194529771805, 0.012464559637010098, 0.01253244373947382, 0.11650602519512177, 0.11860973387956619, 0.1070847362279892, 0.1327821910381317, 0.08259645104408264, 0.012445789761841297, 0.012559442780911922, 0.012608721852302551, 0.26816123723983765, 0.12802720069885254, 0.0125972805544734, 0.2888174057006836, 0.01265647541731596, 0.012646472081542015, 0.08959919959306717, 0.012484719045460224, 0.08675418049097061, 0.012794747948646545, 0.012770893052220345, 0.01251963060349226, 0.012518652714788914, 0.2886362671852112, 0.012786886654794216, 0.3428293466567993, 0.012841290794312954, 0.012759302742779255, 0.01276925764977932, 0.09030672907829285, 0.11157117038965225, 0.012724514119327068, 0.013100910000503063, 0.07937415689229965, 0.012708516791462898, 0.27973443269729614, 0.012932930141687393, 0.10674522072076797, 0.28743547201156616, 0.012778260745108128, 0.012853449210524559, 0.11224514991044998, 0.1049547865986824, 0.013185068033635616, 0.013049113564193249, 0.012837536633014679, 0.10753881186246872, 0.012887299992144108, 0.013123903423547745, 0.013021048158407211, 0.11355381458997726, 0.012894557788968086, 0.08909451216459274, 0.012950754724442959, 0.013058622367680073, 0.01286428514868021, 0.013028338551521301, 0.012935745529830456, 0.013011084869503975, 0.09330692142248154, 0.012912357226014137, 0.012888362631201744, 0.012768191285431385, 0.012869155034422874, 0.012733226642012596, 0.11002501845359802, 0.012888832949101925, 0.012644443660974503, 0.08515271544456482, 0.012823034077882767, 0.012725243344902992, 0.012770121917128563, 0.012743359431624413, 0.14150428771972656, 0.012758033350110054, 0.0900384783744812, 0.14222419261932373, 0.012600489892065525, 0.012810376472771168, 0.012563640251755714, 0.012530696578323841, 0.13402025401592255, 0.012603751383721828, 0.012586141005158424, 0.10570796579122543, 0.12979952991008759, 0.012595811858773232, 0.012419496662914753, 0.012723321095108986, 0.012481567449867725, 0.012352284975349903, 0.01243631448596716, 0.012330408208072186, 0.012525778263807297, 0.012400505132973194, 0.012273171916604042, 0.012198558077216148, 0.012196501716971397, 0.012377277947962284, 0.012422170490026474, 0.07648000866174698, 0.01249249279499054, 0.01222984679043293, 0.012163782492280006, 0.2691401541233063, 0.10195097327232361, 0.012232368811964989, 0.09171886742115021, 0.25523537397384644, 0.012252990156412125, 0.012059333734214306, 0.01234598457813263, 0.012314893305301666, 0.012209836393594742, 0.09056135267019272, 0.09657224267721176, 0.09099001437425613, 0.012227918952703476, 0.012142273597419262, 0.012079275213181973, 0.012312195263803005, 0.012163428589701653, 0.10136447101831436, 0.012129456736147404, 0.09170005470514297, 0.012072504498064518, 0.012339119799435139, 0.012053186073899269, 0.10061978548765182, 0.012090080417692661, 0.012017954140901566, 0.012369337491691113, 0.08924852311611176, 0.012108820490539074, 0.012436595745384693, 0.012070323340594769, 0.2706339657306671, 0.012202216312289238, 0.0120459059253335, 0.12972722947597504, 0.011997722089290619, 0.012031407095491886, 0.012079809792339802, 0.09321191161870956, 0.012173408642411232, 0.012080945074558258, 0.12537232041358948, 0.011985200457274914, 0.11147216707468033, 0.011946335434913635, 0.011973017826676369, 0.011915098875761032, 0.012067640200257301, 0.012001595459878445, 0.011819264851510525, 0.012251106090843678, 0.012121235020458698, 0.011937922798097134, 0.011803125962615013, 0.011794771067798138, 0.011734774336218834, 0.011893190443515778, 0.011778967455029488, 0.011740457266569138, 0.09779338538646698, 0.011898106895387173, 0.011800362728536129, 0.011836745776236057, 0.011740641668438911, 0.2942216992378235, 0.01165800355374813, 0.09516121447086334, 0.3035009801387787, 0.09653916209936142, 0.10038972645998001, 0.011787145398557186, 0.09587922692298889, 0.14174947142601013, 0.011905289255082607, 0.01188136637210846, 0.09141901135444641, 0.10472159087657928, 0.012107045389711857, 0.011867130175232887, 0.09778948873281479, 0.011643323116004467, 0.011848850175738335, 0.011896952986717224, 0.11074116080999374, 0.01170433685183525, 0.0890648141503334, 0.01165398396551609, 0.01181184221059084, 0.011811481788754463, 0.011876950040459633, 0.011772263795137405, 0.10730499774217606, 0.08583073318004608, 0.011615640483796597, 0.3603568375110626, 0.011869650334119797, 0.09872482717037201, 0.10685659199953079, 0.011731382459402084, 0.011674595065414906, 0.09747660160064697, 0.01169404573738575, 0.011729556135833263, 0.011967185884714127, 0.011835412122309208, 0.09882700443267822, 0.01161276176571846, 0.011789429001510143, 0.011692763306200504, 0.011746356263756752, 0.011864278465509415, 0.01161642000079155, 0.011638796888291836, 0.11930239945650101, 0.011528662405908108, 0.011504069902002811, 0.11059769243001938, 0.011824695393443108, 0.011570905335247517, 0.01181691326200962, 0.011580046266317368, 0.08896538615226746, 0.011435265652835369, 0.011462783440947533, 0.1009959802031517, 0.011437919922173023, 0.09056713432073593, 0.10697650164365768, 0.08526677638292313, 0.12471407651901245, 0.08018728345632553, 0.0115926843136549, 0.01136864721775055, 0.01144181564450264, 0.011385594494640827, 0.011493307538330555, 0.10938563197851181, 0.11604779213666916, 0.011290648952126503, 0.011407893151044846, 0.011586344800889492, 0.12416565418243408, 0.01142343319952488, 0.10962499678134918, 0.11265724897384644, 0.09286890178918839, 0.011217014864087105, 0.011379282921552658, 0.011363067664206028, 0.011206505820155144, 0.011436115019023418, 0.01130219642072916, 0.11265010386705399, 0.01146878395229578, 0.011410271748900414, 0.12879891693592072, 0.0982615202665329, 0.10274042934179306, 0.01123215164989233, 0.08196389675140381, 0.1209016814827919, 0.10148478299379349, 0.01117089856415987, 0.10333202034235, 0.011120523326098919, 0.2769167423248291, 0.011171063408255577, 0.01117549929767847, 0.011177119798958302, 0.011206292547285557, 0.011295885778963566, 0.01141976285725832, 0.01119150035083294, 0.011179101653397083, 0.1116788312792778, 0.11755388230085373, 0.13234826922416687, 0.011158698238432407, 0.011237818747758865, 0.01137237437069416, 0.1258157193660736, 0.011385947465896606, 0.11648042500019073, 0.01125334296375513, 0.011427128687500954, 0.3009551465511322, 0.011155704036355019, 0.10516554862260818, 0.011397653259336948, 0.011162991635501385, 0.011158413253724575, 0.11300569027662277, 0.10962561517953873, 0.011321622878313065, 0.011243680492043495, 0.08448866754770279, 0.011348776519298553, 0.12648127973079681, 0.09437339007854462, 0.011216146871447563, 0.09050832688808441, 0.011582564562559128, 0.011139562353491783, 0.09219341725111008, 0.011196116916835308, 0.011045307852327824, 0.011088347993791103, 0.011208607815206051, 0.11976608633995056, 0.011217024177312851, 0.13609786331653595, 0.01118722464889288, 0.011066787876188755, 0.011184120550751686, 0.011181751266121864, 0.01109043974429369, 0.08797814697027206, 0.011096978560090065, 0.011056351475417614, 0.13213388621807098, 0.09871964156627655, 0.011173393577337265, 0.6510143876075745, 0.011132588610053062, 0.011027593165636063, 0.011157792061567307, 0.011242569424211979, 0.011252004653215408, 0.11844580620527267, 0.011147621087729931, 0.011127769947052002, 0.0807100310921669, 0.11005675792694092, 0.011102923192083836, 0.0933738723397255, 0.011429095640778542, 0.01104204636067152, 0.011201141402125359, 0.011336997151374817, 0.01121825072914362, 0.011243588291108608, 0.011140081100165844, 0.011036037467420101, 0.011025220155715942, 0.11966131627559662, 0.0112966513261199, 0.011375739239156246, 0.011099161580204964, 0.011207024566829205, 0.010938542895019054, 0.10553103685379028, 0.010919260792434216, 0.010936673730611801, 0.11350945383310318, 0.3357783257961273, 0.011000734753906727, 0.09335862845182419, 0.011039947159588337, 0.12671580910682678, 0.11784519255161285, 0.011193640530109406, 0.13010163605213165, 0.14050815999507904, 0.0930783748626709, 0.01114401500672102, 0.010996855795383453, 0.11074022948741913, 0.11098536849021912, 0.12584051489830017, 0.010969500988721848, 0.10782965272665024, 0.011084150522947311, 0.010953104123473167, 0.13022156059741974, 0.09460869431495667, 0.011055996641516685, 0.010990568436682224, 0.011092104017734528, 0.10938374698162079, 0.011175179854035378, 0.10686495155096054, 0.12246079742908478, 0.0979875698685646, 0.01102509442716837, 0.011171409860253334, 0.1123863235116005, 0.12480105459690094, 0.011130962520837784, 0.010980968363583088, 0.13722606003284454, 0.010991950519382954, 0.3270205855369568, 0.010976290330290794, 0.2857711613178253, 0.010980452410876751, 0.09663862735033035, 0.010975820012390614, 0.01127326488494873, 0.011051335372030735, 0.011198624037206173, 0.011084729805588722, 0.011132211424410343, 0.011039887554943562, 0.08633206784725189, 0.011041496880352497, 0.011157097294926643, 0.01115430612117052, 0.011009125970304012, 0.32261940836906433, 0.011048995889723301, 0.011088907718658447, 0.011211888864636421, 0.0869385227560997, 0.11765090376138687, 0.01111310813575983, 0.011178429238498211, 0.011289502494037151, 0.09982800483703613, 0.011110140010714531, 0.011037483811378479, 0.011186285875737667, 0.011165051721036434, 0.1254025548696518, 0.011234555393457413, 0.10357099771499634, 0.011027871631085873, 0.1106390655040741, 0.011078360490500927, 0.011201722547411919, 0.011165893636643887, 0.09008852392435074, 0.011293647810816765, 0.011018306948244572, 0.10883959382772446, 0.11799712479114532, 0.01097046583890915, 0.011173343285918236, 0.01099632028490305, 0.01089105848222971, 0.08066950738430023, 0.11834407597780228, 0.011207625269889832, 0.010942474938929081, 0.1171349585056305, 0.011183219030499458, 0.01110945176333189, 0.01089846808463335, 0.011019538156688213, 0.1324191391468048, 0.273733913898468, 0.010859904810786247, 0.12699951231479645, 0.11451539397239685, 0.01111160684376955, 0.11536610871553421, 0.010971746407449245, 0.09514137357473373, 0.011063599959015846, 0.14082463085651398, 0.0910872295498848, 0.2817290723323822, 0.12211591750383377, 0.11248353868722916, 0.010982953943312168, 0.011192318983376026, 0.01107731182128191, 0.09232711791992188, 0.34598875045776367, 0.12011799216270447, 0.011341214179992676, 0.011343666352331638, 0.26288625597953796, 0.11338697373867035, 0.011036050505936146, 0.11626111716032028, 0.011223920620977879, 0.10883566737174988, 0.011324945837259293, 0.011273598298430443, 0.011251847259700298, 0.10921583324670792, 0.1060446947813034, 0.011289848014712334, 0.011211003176867962, 0.1049528419971466, 0.011149022728204727, 0.011418339796364307, 0.2719782888889313, 0.011385802179574966, 0.011165021918714046, 0.011189035139977932, 0.011365600861608982, 0.1260012537240982, 0.011329473927617073, 0.011275200173258781, 0.09615904837846756, 0.011176478117704391, 0.01148483157157898, 0.011287958361208439, 0.011353905312716961, 0.011291920207440853, 0.114158034324646, 0.011246425099670887, 0.011188948526978493, 0.10897029936313629, 0.011251190677285194, 0.11825543642044067, 0.01127357967197895, 0.011263368651270866, 0.011355587281286716, 0.3310772180557251, 0.31202590465545654, 0.011242185719311237, 0.1192357987165451, 0.011361731216311455, 0.01116553321480751, 0.011432810686528683, 0.011393098160624504, 0.01140619721263647, 0.011190676130354404, 0.011355213820934296, 0.01125094760209322, 0.3177342712879181, 0.011385435238480568, 0.10028356313705444, 0.011435908265411854, 0.115865059196949, 0.011266364715993404, 0.37700170278549194, 0.12574253976345062, 0.11489010602235794, 0.08966502547264099, 0.09175538271665573, 0.11344610154628754, 0.09915406256914139, 0.011528152041137218, 0.1379312127828598, 0.011408708058297634, 0.011460864916443825, 0.011450976133346558, 0.07659327238798141, 0.11054688692092896, 0.011355869472026825, 0.011388633400201797, 0.011449157260358334, 0.011379462666809559, 0.011435531079769135, 0.011333784088492393, 0.011348443105816841, 0.28706255555152893, 0.011391045525670052, 0.12044341117143631, 0.01155425701290369, 0.011527043767273426, 0.01150988694280386, 0.11367660015821457, 0.31934893131256104, 0.01144076231867075, 0.30935388803482056, 0.01153327152132988, 0.011536435224115849, 0.011883017607033253, 0.01171877607703209, 0.011975412257015705, 0.2960796356201172, 0.10625411570072174, 0.11388391256332397, 0.011517071165144444, 0.011669081635773182, 0.011756682768464088, 0.011498532257974148, 0.1259395182132721, 0.011597536504268646, 0.011915263719856739, 0.11059824377298355, 0.011551009491086006, 0.011506467126309872, 0.011559433303773403, 0.011822294443845749, 0.011653495021164417, 0.10989312082529068, 0.011694337241351604, 0.011660889722406864, 0.01158637460321188, 0.011827426962554455, 0.011628588661551476, 0.01182947400957346, 0.09980907291173935, 0.011618684977293015, 0.011707155033946037, 0.10207570344209671, 0.011547504924237728, 0.07742158323526382, 0.01141320075839758, 0.13344720005989075, 0.011626534163951874, 0.011506764218211174, 0.08039151132106781, 0.011560370214283466, 0.011372661218047142, 0.011514701880514622, 0.01143384538590908, 0.011779583059251308, 0.11677711457014084, 0.011605378240346909, 0.11625797301530838, 0.08585816621780396, 0.11151318997144699, 0.01144107524305582, 0.011593841947615147, 0.11273474991321564, 0.01135049108415842, 0.011412489227950573, 0.01133775431662798, 0.08144589513540268, 0.011265809647738934, 0.09815967082977295, 0.011512759141623974, 0.12290695309638977, 0.0113363703712821, 0.011392096988856792, 0.30479902029037476, 0.011319590732455254, 0.10035435855388641, 0.011359346099197865, 0.011499674059450626, 0.011482415720820427, 0.011580473743379116, 0.08548019826412201, 0.09770757704973221, 0.08703439682722092, 0.011294727213680744, 0.28674349188804626, 0.08202748745679855, 0.011399011127650738, 0.1236940249800682, 0.011442248709499836, 0.011359011754393578, 0.011280668899416924, 0.2902965545654297, 0.0113381864503026, 0.09333544224500656, 0.01132307481020689, 0.11428844183683395, 0.12915931642055511, 0.01164666935801506, 0.011403361335396767, 0.011500132270157337, 0.09260838478803635, 0.01138819195330143, 0.011352378875017166, 0.011456780135631561, 0.011695869266986847, 0.011552281677722931, 0.09804056584835052, 0.011550354771316051, 0.1135738417506218, 0.011403863318264484, 0.12536035478115082, 0.011435621418058872, 0.01143915206193924, 0.011415485292673111, 0.011311225593090057, 0.011521104723215103, 0.08495192229747772, 0.3087482452392578, 0.11936821788549423, 0.32074764370918274, 0.08981926739215851, 0.011404742486774921, 0.0116670997813344, 0.01150259468704462, 0.01136044505983591, 0.011388268321752548, 0.01159561239182949, 0.011922954581677914, 0.011556313373148441, 0.10458424687385559, 0.011436006985604763, 0.011560704559087753, 0.0944623351097107, 0.1058606281876564, 0.011353632435202599, 0.011587399989366531, 0.011535026133060455, 0.10702615976333618, 0.011509518139064312, 0.011512521654367447, 0.01147510576993227, 0.08438273519277573, 0.10320226848125458, 0.10074127465486526, 0.12396256625652313, 0.011423197574913502, 0.011329647153615952, 0.011277172714471817, 0.10896286368370056, 0.011332087218761444, 0.07854585349559784, 0.011483901180326939, 0.01141420379281044, 0.011299630627036095, 0.011395814828574657, 0.011264667846262455, 0.011320079676806927, 0.09825357049703598, 0.011365334503352642, 0.09432090818881989, 0.011361167766153812, 0.01121106743812561, 0.011298224329948425, 0.01118851825594902, 0.011644394136965275, 0.011400862596929073, 0.011183875612914562, 0.011284967884421349, 0.1035582423210144, 0.011290540918707848, 0.011287705041468143, 0.09800084680318832, 0.011187002994120121, 0.08138853311538696, 0.011113268323242664, 0.011164030991494656, 0.07514605671167374, 0.2689177989959717, 0.01106041669845581, 0.09207607060670853, 0.14014534652233124, 0.011212947778403759, 0.01119849644601345, 0.011170615442097187, 0.1299242526292801, 0.11475850641727448, 0.011131648905575275, 0.011177663691341877, 0.10732676833868027, 0.07680550962686539, 0.09790923446416855, 0.011072728782892227, 0.011155935935676098, 0.10425712168216705, 0.011086455546319485, 0.011092521250247955, 0.011325924657285213, 0.01106900442391634, 0.011190122924745083, 0.011110614985227585, 0.011336132884025574, 0.011293238028883934, 0.09830578416585922, 0.1129879504442215, 0.11343225836753845, 0.316423237323761, 0.08721400797367096, 0.011293874122202396, 0.011180291883647442, 0.011102358810603619, 0.011246278882026672, 0.011263553984463215, 0.011317460797727108, 0.09070117026567459, 0.011252179741859436, 0.12323758751153946, 0.011065306141972542, 0.01105597522109747, 0.13088417053222656, 0.011288360692560673, 0.011056052520871162, 0.01113735232502222, 0.011168773286044598, 0.12543843686580658, 0.01102394424378872, 0.01117901410907507, 0.011103403754532337, 0.011199149303138256, 0.08828061819076538, 0.07991156727075577, 0.08935880661010742, 0.12025115638971329, 0.01094665378332138, 0.13805896043777466, 0.01103154756128788, 0.011122558265924454, 0.09407470375299454, 0.011040774174034595, 0.10343964397907257, 0.011096527799963951, 0.011007021181285381, 0.011053270660340786, 0.011002209037542343, 0.010919574648141861, 0.32125988602638245, 0.011053542606532574, 0.011054947972297668, 0.011084312573075294, 0.011112525127828121, 0.011340195313096046, 0.010991652496159077, 0.011103314347565174, 0.0998525321483612, 0.0110822394490242, 0.010945708490908146, 0.12386171519756317, 0.011003340594470501, 0.011061662808060646, 0.12312012910842896, 0.010905762203037739, 0.010982980951666832, 0.10285975784063339, 0.30148160457611084, 0.010897310450673103, 0.11519456654787064, 0.010973222553730011, 0.12007428705692291, 0.010889961384236813, 0.0992145836353302, 0.011229736730456352, 0.12068071216344833, 0.010963778011500835, 0.09626311808824539, 0.09230667352676392, 0.010964917950332165, 0.11615633219480515, 0.08479895442724228, 0.011092565022408962, 0.1082916334271431, 0.011310120113193989, 0.11919606477022171, 0.011066315695643425, 0.01088010799139738, 0.10581597685813904, 0.011111482046544552, 0.010913294740021229, 0.011068553663790226, 0.01106061227619648, 0.010945028625428677, 0.01110103726387024, 0.011181538924574852, 0.010888875462114811, 0.010873680002987385, 0.011197068728506565, 0.10631668567657471, 0.010977462865412235, 0.010865094140172005, 0.011137295514345169, 0.010918261483311653, 0.010979216545820236, 0.01111659687012434, 0.07324739545583725, 0.01081650797277689, 0.010790988802909851, 0.010923665016889572, 0.0107814846560359, 0.13593938946723938, 0.1061578094959259, 0.011005829088389874, 0.08148673176765442, 0.29831019043922424, 0.13972637057304382, 0.010831743478775024, 0.010928698815405369, 0.08469231426715851, 0.01083329226821661, 0.010788226500153542, 0.12846025824546814, 0.3311099410057068, 0.010756248608231544, 0.010768098756670952, 0.011037329211831093, 0.10138975828886032, 0.27360987663269043, 0.010931317694485188, 0.09726474434137344, 0.26508820056915283, 0.011085386388003826, 0.3008553683757782, 0.011139309033751488, 0.010980280116200447, 0.10323027521371841, 0.086189866065979, 0.010995233431458473, 0.01100245863199234, 0.010973856784403324, 0.010939491912722588, 0.010988687165081501, 0.01104249618947506, 0.010990693233907223, 0.011234375648200512, 0.011030460707843304, 0.1249619871377945, 0.0112738823518157, 0.010979500599205494, 0.01135754119604826, 0.011106004007160664, 0.10276897996664047, 0.011011816561222076, 0.011022815480828285, 0.011068660765886307, 0.010961252264678478, 0.011146399192512035, 0.11147166788578033, 0.010987038724124432, 0.10536439716815948, 0.010959976352751255, 0.2881803512573242, 0.010967067442834377, 0.010881831869482994, 0.011139997281134129, 0.12994278967380524, 0.11990936845541, 0.1289438009262085, 0.011165264062583447, 0.010941077955067158, 0.010930746793746948, 0.12833625078201294, 0.011156925931572914, 0.010940637439489365, 0.011071322485804558, 0.01096342597156763, 0.34122103452682495, 0.010891382582485676, 0.010948865674436092, 0.01091749407351017, 0.3131744861602783, 0.010974288918077946, 0.10351142287254333, 0.011129645630717278, 0.1348252296447754, 0.10415446758270264, 0.11958042532205582, 0.3183084726333618, 0.011024038307368755, 0.011082598008215427, 0.01101196650415659, 0.01099594309926033, 0.1082577109336853, 0.011127622798085213, 0.011101027019321918, 0.011119041591882706, 0.01116203237324953, 0.13200141489505768, 0.011137214489281178, 0.011034288443624973, 0.011125504970550537, 0.011059703305363655, 0.1194440945982933, 0.09745259582996368, 0.011102408170700073, 0.01111084595322609, 0.011152598075568676, 0.10407746583223343, 0.011014129035174847, 0.011288518086075783, 0.011134738102555275, 0.011005716398358345, 0.010953247547149658, 0.09676513075828552, 0.011040953919291496, 0.011176352389156818, 0.11901937425136566, 0.01101289875805378, 0.01094523910433054, 0.10111236572265625, 0.01098533347249031, 0.11066722869873047, 0.011011830531060696, 0.010995758697390556, 0.011072320863604546, 0.010977844707667828, 0.01101332250982523, 0.011119247414171696, 0.10426837205886841, 0.01100422814488411, 0.1005069687962532, 0.1364927589893341, 0.09547138214111328, 0.2650858163833618, 0.11539102345705032, 0.010850376449525356, 0.01107877492904663, 0.10125280916690826, 0.010916369967162609, 0.011171293444931507, 0.01089329645037651, 0.0855945274233818, 0.011117091402411461, 0.0109909912571311, 0.011136570945382118, 0.010997861623764038, 0.010907615534961224, 0.1003425270318985, 0.10825394093990326, 0.01090482622385025, 0.10497061163187027, 0.12320015579462051, 0.10988710820674896, 0.13160361349582672, 0.10767437517642975, 0.10203338414430618, 0.010906146839261055, 0.010907778516411781, 0.010957804508507252, 0.010989513248205185, 0.12660451233386993, 0.010914000682532787, 0.1108923926949501, 0.010984191671013832, 0.01088618766516447, 0.011143009178340435, 0.11173886060714722, 0.1326560378074646, 0.010849549435079098, 0.10336777567863464, 0.011012515053153038, 0.0957682654261589, 0.08836649358272552, 0.11628826707601547, 0.011052743531763554, 0.011101152747869492, 0.2925685942173004, 0.12372510135173798, 0.011073299683630466, 0.09760883450508118, 0.08866652101278305, 0.11674721539020538, 0.010869613848626614, 0.010863744653761387, 0.011148454621434212, 0.1308063119649887, 0.010911506600677967, 0.01085615810006857, 0.011061285622417927, 0.01103687658905983, 0.011073172092437744, 0.11563021689653397, 0.10815811902284622, 0.011036875657737255, 0.11198387295007706, 0.011073296889662743, 0.11429326236248016, 0.010953967459499836, 0.010944285430014133, 0.010850397869944572, 0.011106565594673157, 0.010874981060624123, 0.010992053896188736, 0.11585008352994919, 0.08891855180263519, 0.010806639678776264, 0.011058577336370945, 0.0855962336063385, 0.010947562754154205, 0.011026346124708652, 0.010864989832043648, 0.09238249063491821, 0.010827622376382351, 0.01083953958004713, 0.010935629718005657, 0.11541431397199631, 0.09297174960374832, 0.010793603956699371, 0.010817665606737137, 0.010834535583853722, 0.1271982342004776, 0.10496886074542999, 0.010877212509512901, 0.010803761892020702, 0.010899160988628864, 0.11397714167833328, 0.010750421322882175, 0.011133062653243542, 0.13357189297676086, 0.01082528941333294, 0.010775765404105186, 0.011119848117232323, 0.010859241709113121, 0.10293135792016983, 0.010725680738687515, 0.010742252692580223, 0.010792176239192486, 0.010829909704625607, 0.010694172233343124, 0.010715130716562271, 0.010752243921160698, 0.010832739993929863, 0.2904026508331299, 0.13417001068592072, 0.09875614941120148, 0.010945421643555164, 0.010665745474398136, 0.335333913564682, 0.010833586566150188, 0.596723735332489, 0.010758736170828342, 0.010827254503965378, 0.010903188958764076, 0.010900118388235569, 0.10556547343730927, 0.011092583648860455, 0.08030557632446289, 0.09989865869283676, 0.08755610138177872, 0.010831628926098347, 0.010977729223668575, 0.01086509507149458, 0.011011851951479912, 0.1102290078997612, 0.3124760091304779, 0.010808799415826797, 0.011389953084290028, 0.010855566710233688, 0.010987690649926662, 0.010962839238345623, 0.011026711203157902, 0.2639676034450531, 0.01102789118885994, 0.011042976751923561, 0.11769192665815353, 0.35140419006347656, 0.11702325195074081, 0.011158416047692299, 0.010909093543887138, 0.01094899047166109, 0.11509430408477783, 0.010897122323513031, 0.2970145642757416, 0.09235723316669464, 0.011304319836199284, 0.1398746222257614, 0.011152057908475399, 0.010977213270962238, 0.011002055369317532, 0.010989139787852764, 0.08575104922056198, 0.09952753037214279, 0.1000571921467781, 0.0111212944611907, 0.11532529443502426, 0.011260471306741238, 0.0896504819393158, 0.011016340926289558, 0.010982628911733627, 0.010951305739581585, 0.010970312170684338, 0.12002115696668625, 0.011028441600501537, 0.0792553499341011, 0.011255932040512562, 0.011096758767962456, 0.10600017011165619, 0.011120482347905636, 0.011035545729100704, 0.011304140090942383, 0.010998757556080818, 0.011010758578777313, 0.010949707590043545, 0.010985800996422768, 0.10818198323249817, 0.011286270804703236, 0.10204610228538513, 0.011059367097914219, 0.011024681851267815, 0.1091482862830162, 0.011174207553267479, 0.09387674182653427, 0.12943142652511597, 0.01124617364257574, 0.09393579512834549, 0.01113503985106945, 0.01105768233537674, 0.011012464761734009, 0.011069477535784245, 0.010979062877595425, 0.13104785978794098, 0.11840356141328812, 0.011059839278459549, 0.011089745908975601, 0.010957565158605576, 0.011110101826488972, 0.011041015386581421, 0.010858130641281605, 0.011086889542639256, 0.011090006679296494, 0.011118218302726746, 0.010929255746304989, 0.12719139456748962, 0.010970281437039375, 0.010987155139446259, 0.10022637248039246, 0.11252651363611221, 0.01080973632633686, 0.010862954892218113, 0.11721621453762054, 0.010892612859606743, 0.010975927114486694, 0.08692774921655655, 0.11842288076877594, 0.010913236998021603, 0.11326312273740768, 0.01098914910107851, 0.010779195465147495, 0.011028870940208435, 0.01084183156490326, 0.0108127910643816, 0.010866919532418251, 0.13759443163871765, 0.010819632560014725, 0.092735655605793, 0.010769043117761612, 0.010848211124539375, 0.08431034535169601, 0.011087681166827679, 0.010869842953979969, 0.13009457290172577, 0.09467902779579163, 0.010733001865446568, 0.011058750562369823, 0.10566432029008865, 0.01100924052298069, 0.08267485350370407, 0.010917178355157375, 0.31593090295791626, 0.01087639294564724, 0.088613361120224, 0.011118745431303978, 0.10728533565998077, 0.010766356252133846, 0.010818671435117722, 0.010941051878035069, 0.010815263725817204, 0.010824089869856834, 0.011082095094025135, 0.12470059841871262, 0.01079629547894001, 0.010847450233995914, 0.11083339899778366, 0.11199671775102615, 0.010803574696183205, 0.10324518382549286, 0.08739671856164932, 0.0845862403512001, 0.010733550414443016, 0.010781737975776196, 0.1210295706987381, 0.010721107944846153, 0.010810504667460918, 0.01103304885327816, 0.01073363609611988, 0.010741496458649635, 0.010694080963730812, 0.010805081576108932, 0.01074214931577444, 0.09622929990291595, 0.010972811840474606, 0.09597085416316986, 0.2862072288990021, 0.2745662033557892, 0.010849039070308208, 0.010844133794307709, 0.3208262324333191, 0.010808257386088371, 0.09309469908475876, 0.010903597809374332, 0.11188317090272903, 0.11063426733016968, 0.010873079299926758, 0.10766611993312836, 0.010903188027441502, 0.010829455219209194, 0.010879595763981342, 0.01098744384944439, 0.010990485548973083, 0.01076782401651144, 0.01084141619503498, 0.10759875923395157, 0.010794893838465214, 0.1148669645190239, 0.010876240208745003, 0.09722527861595154, 0.09497370570898056, 0.10730264335870743, 0.09010276943445206, 0.010739513672888279, 0.010906906798481941, 0.10631278157234192, 0.010982236824929714, 0.1084815114736557, 0.010800827294588089, 0.010752282105386257, 0.010851813480257988, 0.010990183800458908, 0.0944855660200119, 0.010906487703323364, 0.3593062460422516, 0.010726473294198513, 0.011003182269632816, 0.11537455767393112, 0.5912539958953857, 0.12601977586746216, 0.12172862887382507, 0.01086278073489666, 0.3459220230579376, 0.10348569601774216, 0.011066998355090618, 0.01103836577385664, 0.13306523859500885, 0.010955523699522018, 0.01087723858654499, 0.010885205119848251, 0.12845678627490997, 0.14918655157089233, 0.09900202602148056, 0.2977116107940674, 0.09360520541667938, 0.011154653504490852, 0.011152212508022785, 0.011022605933248997, 0.01105109415948391, 0.011191684752702713, 0.011297207325696945, 0.010960320942103863, 0.010924980975687504, 0.011007118970155716, 0.010940689593553543, 0.010941384360194206, 0.011209308169782162, 0.011010529473423958, 0.09253226220607758, 0.09909602254629135, 0.010899659246206284, 0.01115789357572794, 0.10240150988101959, 0.011004314757883549, 0.011162519454956055, 0.010942439548671246, 0.010915948078036308, 0.01102767325937748, 0.10893340408802032, 0.011084687896072865, 0.011060726828873158, 0.010982072912156582, 0.10807647556066513, 0.011231516487896442, 0.011251925490796566, 0.010858937166631222, 0.10537579655647278, 0.010995724238455296, 0.09714409708976746, 0.010968729853630066, 0.011027257889509201, 0.01085466518998146, 0.32124659419059753, 0.010851478204131126, 0.010880222544074059, 0.28544652462005615, 0.11332821846008301, 0.10512994229793549, 0.09899718314409256, 0.09301481395959854, 0.010846728459000587, 0.11285681277513504, 0.33016154170036316, 0.011140983551740646, 0.29283761978149414, 0.11204947531223297, 0.11454189568758011, 0.011035463772714138, 0.010959738865494728, 0.09509626775979996, 0.011000147089362144, 0.010991689749062061, 0.12487093359231949, 0.010898789390921593, 0.011194699443876743, 0.010900557041168213, 0.011304651387035847, 0.010969574563205242, 0.010962736792862415, 0.08258979022502899, 0.01106829009950161, 0.11273699253797531, 0.01093111652880907, 0.010887890122830868, 0.011095637455582619, 0.010977995581924915, 0.11632323265075684, 0.07940775901079178, 0.09750279784202576, 0.11351794749498367, 0.1301683932542801, 0.010959852486848831, 0.011068196035921574, 0.011037993244826794, 0.11496485769748688, 0.011014167219400406, 0.0849326103925705, 0.110867440700531, 0.09006629884243011, 0.011050140485167503, 0.09486007690429688, 0.10528267920017242, 0.010886093601584435, 0.011012187227606773, 0.12607455253601074, 0.010985082946717739, 0.12445400655269623, 0.011202212423086166, 0.01128503866493702, 0.01105019822716713, 0.01088990643620491, 0.011013003066182137, 0.010870140977203846, 0.01090515311807394, 0.010880852118134499, 0.27183112502098083, 0.010896560736000538, 0.011365639045834541, 0.0924273282289505, 0.011370816268026829, 0.09666092693805695, 0.010892985388636589, 0.12887731194496155, 0.010995578020811081, 0.011071678251028061, 0.10618862509727478, 0.10688501596450806, 0.011042620055377483, 0.11221831291913986, 0.01104278676211834, 0.010850274935364723, 0.010931931436061859, 0.010904217138886452, 0.01085843238979578, 0.011111742816865444, 0.010893451981246471, 0.11558545380830765, 0.010905190370976925, 0.01099505927413702, 0.11701198667287827, 0.27940237522125244, 0.10694855451583862, 0.010936268605291843, 0.011054965667426586, 0.01089527364820242, 0.09764929860830307, 0.0845184326171875, 0.011060614138841629, 0.011208618059754372, 0.011171885766088963, 0.09932985156774521, 0.08928163349628448, 0.010881955735385418, 0.0109828757122159, 0.010863952338695526, 0.011009479872882366, 0.010956511832773685, 0.011034086346626282, 0.010851754806935787, 0.09901956468820572, 0.010892516002058983, 0.010935245081782341, 0.011119073256850243, 0.11922842264175415, 0.010903016664087772, 0.11078311502933502, 0.09919250756502151, 0.277331680059433, 0.010920942761003971, 0.011000712402164936, 0.010888181626796722, 0.010950480587780476, 0.30283501744270325, 0.011154617182910442, 0.11395556479692459, 0.0111235985532403, 0.09919267892837524, 0.011149626225233078, 0.011038994416594505, 0.011049073189496994, 0.011121691204607487, 0.010879004374146461, 0.09571940451860428, 0.01099963579326868, 0.010909399949014187, 0.10355505347251892, 0.010962514206767082, 0.010894251987338066, 0.10954981297254562, 0.010958299040794373, 0.1132388785481453, 0.12096774578094482, 0.11608918011188507, 0.09312845021486282, 0.11681770533323288, 0.09978605806827545, 0.011018297635018826, 0.010835827328264713, 0.010843932628631592, 0.10700155794620514, 0.13182879984378815, 0.324509859085083, 0.011084228754043579, 0.09694824367761612, 0.010994656011462212, 0.01095102820545435, 0.011081862263381481, 0.08911184221506119, 0.010861688293516636, 0.01107488851994276, 0.011158172972500324, 0.12300802767276764, 0.010904273949563503, 0.011276334524154663, 0.011183924973011017, 0.09493827074766159, 0.01085076853632927, 0.011057788506150246, 0.10972276329994202, 0.011030806228518486, 0.0973421037197113, 0.011003216728568077, 0.011105839163064957, 0.010968156158924103, 0.011001959443092346, 0.010884854011237621, 0.010993534699082375, 0.011262589134275913, 0.010884682647883892, 0.010921836830675602, 0.3121716380119324, 0.01089904922991991, 0.324859082698822, 0.011189479380846024, 0.11550124734640121, 0.010892297141253948, 0.1074884906411171, 0.010904924012720585, 0.10765212029218674, 0.011155292391777039, 0.010867741890251637, 0.010857139714062214, 0.011076729744672775, 0.010915297083556652, 0.011051835492253304, 0.01093319058418274, 0.011188101023435593, 0.010906756855547428, 0.010861307382583618, 0.010966680012643337, 0.010882215574383736, 0.09391038119792938, 0.010977440513670444, 0.010977624915540218, 0.010899602435529232, 0.01093650609254837, 0.010888426564633846, 0.010996844619512558, 0.10850849747657776, 0.010917617939412594, 0.11354351788759232, 0.10597316920757294, 0.011041061021387577, 0.01108495146036148, 0.11872407048940659, 0.010873707011342049, 0.010957391932606697, 0.010974401608109474, 0.010925143957138062, 0.011155447922647, 0.01083606481552124, 0.010998964309692383, 0.26491492986679077, 0.33966025710105896, 0.010853971354663372, 0.010963110253214836, 0.010837662033736706, 0.011083071120083332, 0.11075588315725327, 0.07260875403881073, 0.10627761483192444, 0.27768823504447937, 0.010977296158671379, 0.010953698307275772, 0.010853420943021774, 0.12247409671545029, 0.09004782885313034, 0.11866435408592224, 0.010925334878265858, 0.010820473544299603, 0.1081213429570198, 0.010916451923549175, 0.10555853694677353, 0.010913534089922905, 0.01090104877948761, 0.010948779992759228, 0.28213247656822205, 0.010910900309681892, 0.010868802666664124, 0.010932653211057186, 0.010860703885555267, 0.011048831045627594, 0.011129549704492092, 0.08348461240530014, 0.011031962931156158, 0.01089441031217575, 0.01103734876960516, 0.010992095805704594, 0.010863524861633778, 0.011027642525732517, 0.010938404127955437, 0.09111572057008743, 0.011021401733160019, 0.12284108251333237, 0.01084696501493454, 0.11224163323640823, 0.010965608060359955, 0.01106505561619997, 0.09361453354358673, 0.01081607211381197, 0.12772265076637268, 0.010939127765595913, 0.010990244336426258, 0.010905181057751179, 0.08447035402059555, 0.01103257667273283, 0.0896233394742012, 0.10021837800741196, 0.01081087440252304, 0.010936479084193707, 0.12167193740606308, 0.09462103247642517, 0.01100446842610836, 0.10078469663858414, 0.12898671627044678, 0.011049764230847359, 0.0109043437987566, 0.13053858280181885, 0.01098504476249218, 0.010891735553741455, 0.01094154454767704, 0.01088104210793972, 0.010894718579947948, 0.010885386727750301, 0.010977305471897125, 0.011138729751110077, 0.011001905426383018, 0.01090230792760849, 0.011042538098990917, 0.1412384808063507, 0.010870681144297123, 0.010934828780591488, 0.10092011839151382, 0.010921447537839413, 0.011102426797151566, 0.32176485657691956, 0.010987107641994953, 0.12244745343923569, 0.01111890934407711]\n",
            "Val loss 0.05315261756858\n",
            "Val auc roc 0.48977345758354757\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-05.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "221a078a-0e2f-4728-d86d-908f17ac2ff5"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5a386c2-0f2c-4db2-b0f4-fc8c463f4164"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b016551d-77da-4069-f9ff-9237355dfc10"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "787bd736-58b5-4f70-ddb7-11dbf8091cf3"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Generalized_Hate]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8597b24e-73be-4fca-e8bf-7c7588e39d03"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-08-05 05:02:17.197769'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}