{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm_Double_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c90e1793a154881b18235622f2cfb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0666729eaa83452fb44183f30a4d6f56",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34479291330d42069e3589c926298a4e",
              "IPY_MODEL_16226e3f65874f1fa18c80bee8ee8bec"
            ]
          }
        },
        "0666729eaa83452fb44183f30a4d6f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34479291330d42069e3589c926298a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9fcdaa860481446c94b1dfcfe55a88ea",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbb08fe30b804708b1deb51fae75713c"
          }
        },
        "16226e3f65874f1fa18c80bee8ee8bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be5ee1026dcf43849e7dac9911025588",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:12&lt;00:00, 19.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39654b20d8f44cc1b130e5b122f3dbff"
          }
        },
        "9fcdaa860481446c94b1dfcfe55a88ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbb08fe30b804708b1deb51fae75713c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be5ee1026dcf43849e7dac9911025588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39654b20d8f44cc1b130e5b122f3dbff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3fcf86b71fc426f9df9aa81bf86b1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd38e8e263e44f898ca97d30ceaede4e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26e891fdb845455490e0e358ba73fd79",
              "IPY_MODEL_8cfa7338e8ae4715adea93745d62b0f4"
            ]
          }
        },
        "cd38e8e263e44f898ca97d30ceaede4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26e891fdb845455490e0e358ba73fd79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01b2495c9ec146cc80a338e2c9294987",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1663,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1663,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4dd8de8f752242719e2333b0a2522310"
          }
        },
        "8cfa7338e8ae4715adea93745d62b0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c11809544634736a435372eebe21317",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1663/1663 [29:50&lt;00:00,  1.08s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80d5354abbae47168a883dcb664c2de5"
          }
        },
        "01b2495c9ec146cc80a338e2c9294987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4dd8de8f752242719e2333b0a2522310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c11809544634736a435372eebe21317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80d5354abbae47168a883dcb664c2de5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c417712c23d8422eb57ce2197e617b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_719d9311914e45f2a4c0508bb68dfe75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9c110deb4f648ca91abb8bf2ede59a7",
              "IPY_MODEL_8d739ca6a2a34126a6474f25d6894e0e"
            ]
          }
        },
        "719d9311914e45f2a4c0508bb68dfe75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9c110deb4f648ca91abb8bf2ede59a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b22a2a6a3cf94f07b30dfc0f246ab434",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1663,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1663,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25a7d4114df54757861e1e35d450a6aa"
          }
        },
        "8d739ca6a2a34126a6474f25d6894e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4094927e095f450a83e4b016b04169e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1663/1663 [30:29&lt;00:00,  1.10s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64b75a6a67184e43a48f44ef59a69249"
          }
        },
        "b22a2a6a3cf94f07b30dfc0f246ab434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25a7d4114df54757861e1e35d450a6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4094927e095f450a83e4b016b04169e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64b75a6a67184e43a48f44ef59a69249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c4f1ace329041e58778cd62937693e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82b5fe1a59ea48309a694cacd9be93cb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f12b74ebebb49b49b9387cd56fb5f73",
              "IPY_MODEL_c53b4c578e414045a50ef32bad2ae6b9"
            ]
          }
        },
        "82b5fe1a59ea48309a694cacd9be93cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f12b74ebebb49b49b9387cd56fb5f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5dde08524994a019b4a9290d2388d21",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1663,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1663,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fbec007d0d743eb8839afde7398f56e"
          }
        },
        "c53b4c578e414045a50ef32bad2ae6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d6fbb7e9ef5438cbf6af483f65c3266",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1663/1663 [30:32&lt;00:00,  1.10s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4aeb7b7845e544a29a3b4d792cd678f6"
          }
        },
        "b5dde08524994a019b4a9290d2388d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fbec007d0d743eb8839afde7398f56e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d6fbb7e9ef5438cbf6af483f65c3266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4aeb7b7845e544a29a3b4d792cd678f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d73a70e5-d204-453d-f031-35193fd7ca67"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 33.08 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae51da11-a23b-4f9d-bf54-bf8f1b5f5525"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e319c61-c9a1-48f2-e7a2-70777c064522"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "22a1296a-55e8-42c3-f731-9aa4e4e9a346"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "45c1bceb-f83f-40fb-ed4e-0ec3a80eb7d5"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "bc62f671-b6ee-4a90-eefa-eb62b05a766d"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 16.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b49fdee9-fb19-4d98-9c88-66b87a7dfbab"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "23bd18b3-313b-4ce6-b255-9573612c5cfd"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "951befa0-7ccc-4662-d22e-f46bfc5a2e39"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "21ba399a-6669-4421-c22f-71638c0e98df"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    At last all of us respect law, So lets file th...\n",
              "1    @TheRestlessQuil Got this from another ex-empl...\n",
              "2    Tanushree Dutta, Who Triggered India's #MeToo,...\n",
              "3    Nothing better than an inspiring, intellectual...\n",
              "4                                        ption - no:2 \n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee2cc59a-6581-4dd5-d8bb-1c8bdcdb1575"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:08<00:00, 49574815.88B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcee686c-a67f-4faf-cf12-26c53ceff838"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 1902820.34B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9d105edb-de04-408a-d81f-8e6a224adacf"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cf1c32f-29b7-4ff3-f1f7-f44c4d7c08cc"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            random.shuffle(text)\n",
        "            text3 = ' '.join(text)\n",
        "            df3['text'][i]=text3\n",
        "        self.data = self.data.append(df2, ignore_index=True)\n",
        "        self.data = self.data.append(df3, ignore_index=True)\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6979fa5d-d7d4-477a-b88e-ac1215bdd2ea"
      },
      "source": [
        "col_name = \"Sarcasm\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862,
          "referenced_widgets": [
            "6c90e1793a154881b18235622f2cfb36",
            "0666729eaa83452fb44183f30a4d6f56",
            "34479291330d42069e3589c926298a4e",
            "16226e3f65874f1fa18c80bee8ee8bec",
            "9fcdaa860481446c94b1dfcfe55a88ea",
            "fbb08fe30b804708b1deb51fae75713c",
            "be5ee1026dcf43849e7dac9911025588",
            "39654b20d8f44cc1b130e5b122f3dbff",
            "e3fcf86b71fc426f9df9aa81bf86b1dd",
            "cd38e8e263e44f898ca97d30ceaede4e",
            "26e891fdb845455490e0e358ba73fd79",
            "8cfa7338e8ae4715adea93745d62b0f4",
            "01b2495c9ec146cc80a338e2c9294987",
            "4dd8de8f752242719e2333b0a2522310",
            "1c11809544634736a435372eebe21317",
            "80d5354abbae47168a883dcb664c2de5",
            "c417712c23d8422eb57ce2197e617b29",
            "719d9311914e45f2a4c0508bb68dfe75",
            "b9c110deb4f648ca91abb8bf2ede59a7",
            "8d739ca6a2a34126a6474f25d6894e0e",
            "b22a2a6a3cf94f07b30dfc0f246ab434",
            "25a7d4114df54757861e1e35d450a6aa",
            "4094927e095f450a83e4b016b04169e5",
            "64b75a6a67184e43a48f44ef59a69249",
            "6c4f1ace329041e58778cd62937693e7",
            "82b5fe1a59ea48309a694cacd9be93cb",
            "8f12b74ebebb49b49b9387cd56fb5f73",
            "c53b4c578e414045a50ef32bad2ae6b9",
            "b5dde08524994a019b4a9290d2388d21",
            "9fbec007d0d743eb8839afde7398f56e",
            "3d6fbb7e9ef5438cbf6af483f65c3266",
            "4aeb7b7845e544a29a3b4d792cd678f6"
          ]
        },
        "outputId": "ccecd22a-c75a-4917-bb7a-414f776837c7"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6654\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c90e1793a154881b18235622f2cfb36",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3fcf86b71fc426f9df9aa81bf86b1dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1663.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0457\n",
            "Train Losses : [0.18383705615997314, 0.20690378546714783, 0.3798971474170685, 0.39837467670440674, 1.1926060914993286, 2.1802420616149902, 2.11582612991333, 0.43669000267982483, 0.3602844774723053, 0.031019937247037888, 0.11035104840993881, 0.7965489029884338, 0.15784431993961334, 0.4832354485988617, 0.36534586548805237, 0.1659339964389801, 0.21869343519210815, 0.09442366659641266, 0.11001679301261902, 0.3119807243347168, 0.03936852887272835, 0.040591176599264145, 0.057058244943618774, 0.022236566990613937, 0.02934928424656391, 0.02424597181379795, 0.2372661978006363, 0.011130730621516705, 0.011068901047110558, 0.009248226881027222, 0.00662017660215497, 0.004568539559841156, 0.05376806482672691, 0.002887180307880044, 0.003756102407351136, 0.0024508920032531023, 0.0019082846119999886, 0.004235582891851664, 0.003108167089521885, 0.31677037477493286, 0.000669893401209265, 0.0008455562638118863, 0.3079604208469391, 0.0013249453622847795, 0.0011272786650806665, 0.0005190643132664263, 0.0015804001595824957, 0.0005489522591233253, 0.04506068304181099, 0.0011942900018766522, 0.0009387132013216615, 0.0013470958219841123, 0.0011408987920731306, 0.002310545416548848, 0.0007314403192140162, 0.004084551706910133, 0.0006533445557579398, 0.0005773973534815013, 0.004538234788924456, 0.00046442620805464685, 1.0676347017288208, 0.0008871721802279353, 0.004318879917263985, 0.0026630645152181387, 0.0013935099123045802, 0.002212642692029476, 0.003137002233415842, 0.9914888143539429, 0.0017160193528980017, 0.004301044158637524, 0.0031249658204615116, 0.0016808625077828765, 0.14967389404773712, 0.0023183219600468874, 0.047750458121299744, 0.15882658958435059, 0.0029542511329054832, 0.010484615340828896, 0.004363750107586384, 0.33918336033821106, 0.0036719448398798704, 0.634710967540741, 0.2198667973279953, 0.012827381491661072, 0.29926884174346924, 0.07767871767282486, 0.013325060717761517, 0.052643828094005585, 0.015725813806056976, 0.01607668586075306, 0.12370353192090988, 0.014632271602749825, 0.023144520819187164, 0.032943446189165115, 0.020222464576363564, 0.024464242160320282, 0.015014653094112873, 0.019016683101654053, 0.011257817037403584, 0.010653800331056118, 0.01212900411337614, 0.1992749720811844, 0.006436584517359734, 0.009967406280338764, 0.012095678597688675, 0.005051889922469854, 0.004082797095179558, 0.0038964878767728806, 0.0981321632862091, 0.004723179619759321, 0.004111654125154018, 0.003333727130666375, 0.0026535429060459137, 0.002183381235226989, 0.003183885244652629, 0.16247914731502533, 0.0020339046604931355, 0.15176276862621307, 0.0021421401761472225, 0.003216551383957267, 0.0035088055301457644, 0.07977330684661865, 0.004591301083564758, 0.001993912272155285, 0.002027256181463599, 0.0019602328538894653, 0.004657123237848282, 0.0029967715963721275, 0.002547250362113118, 0.14160983264446259, 0.001714845304377377, 0.0018816154915839434, 0.0029014681931585073, 0.00278297602199018, 0.0027550815138965845, 0.3971405029296875, 0.002510503400117159, 0.002784443786367774, 0.00334160216152668, 0.09785215556621552, 0.002365075284615159, 0.003439165186136961, 0.45740705728530884, 0.0037510348483920097, 0.0024356269277632236, 0.004615724086761475, 0.004221122246235609, 0.002742085140198469, 0.13998660445213318, 0.004315357189625502, 0.0034182292874902487, 0.004443490877747536, 0.1077246367931366, 0.0033795887138694525, 0.00418854970484972, 0.003291204571723938, 0.003342196810990572, 0.004449877887964249, 0.0030318552162498236, 0.24263344705104828, 0.32587796449661255, 0.006985616870224476, 0.00376595719717443, 0.004184978548437357, 0.006592736579477787, 0.10701403766870499, 0.3692259192466736, 0.005614106543362141, 0.004992044996470213, 0.005485616158694029, 0.0052003865130245686, 0.0065907989628612995, 0.008213458582758904, 0.006768650375306606, 0.004873385187238455, 0.11928605288267136, 0.00624737236648798, 0.013037057593464851, 0.011520606465637684, 0.15700504183769226, 0.005034651141613722, 0.006932062096893787, 0.006008904427289963, 0.006431008223444223, 0.22673574090003967, 0.008936931379139423, 0.007069834973663092, 0.07272759824991226, 0.004613910801708698, 0.10412611067295074, 0.7366482615470886, 0.006057053338736296, 0.3985201418399811, 0.008801721967756748, 0.008938892744481564, 0.01065625250339508, 0.014355390332639217, 0.0108497878536582, 0.010727575048804283, 0.009932594373822212, 0.057079434394836426, 0.011118046939373016, 0.008853806182742119, 0.008682039566338062, 0.01099486742168665, 0.009579179808497429, 0.008243999443948269, 0.008351555094122887, 0.008943101391196251, 0.008206486701965332, 0.07074429094791412, 0.2070966511964798, 0.009123291820287704, 0.00611003628000617, 0.009033268317580223, 0.008546017110347748, 0.008500221185386181, 0.005892827641218901, 0.005832659546285868, 0.1966734528541565, 0.005776380188763142, 0.133240208029747, 0.005943890195339918, 0.0045175920240581036, 0.004220043774694204, 0.005064454860985279, 0.004598754923790693, 0.005001031793653965, 0.24541720747947693, 0.004223824944347143, 0.1319032609462738, 0.0049565378576517105, 0.004393063019961119, 0.004188878461718559, 0.004330245312303305, 0.07611063122749329, 0.0044700587168335915, 0.004950787406414747, 0.004015985410660505, 0.004153697285801172, 0.005259486380964518, 0.004942659288644791, 0.12837430834770203, 0.0799221321940422, 0.004856465384364128, 0.005196910351514816, 0.004569075535982847, 0.31150367856025696, 0.005524030886590481, 0.006268311757594347, 0.00472157122567296, 0.005301355849951506, 0.004401146434247494, 0.006141077261418104, 0.004064611159265041, 0.00441126199439168, 0.15626877546310425, 0.004205459728837013, 0.13765546679496765, 0.04221901670098305, 0.004266577307134867, 0.0038178798276931047, 0.005129521246999502, 0.004475254099816084, 0.005927107762545347, 0.045467618852853775, 0.004925909452140331, 0.0043103983625769615, 0.005217080470174551, 0.12544094026088715, 0.00534914480522275, 0.005448662675917149, 0.005810893140733242, 0.005520310252904892, 0.004250809084624052, 0.004033668898046017, 0.008437739685177803, 0.00350617035292089, 0.004434200003743172, 0.005356975831091404, 0.003685120027512312, 0.002924752188846469, 0.006543989293277264, 0.2490355372428894, 0.003480705199763179, 0.0039890240877866745, 0.0026080450043082237, 0.0037058263551443815, 0.1340712010860443, 0.0038309493102133274, 0.002651035785675049, 0.0024437163956463337, 0.0035920082591474056, 0.0027920634020119905, 0.23303039371967316, 0.0029716803692281246, 0.0023771189153194427, 0.0027612289413809776, 0.2742557227611542, 0.003022134769707918, 0.002548311837017536, 0.0033177994191646576, 0.0023179310373961926, 0.0027460227720439434, 0.0023881213273853064, 0.0027851008344441652, 0.13122901320457458, 0.08154590427875519, 0.002414967166259885, 0.003046529833227396, 0.18259677290916443, 0.0027461627032607794, 0.003982394002377987, 0.003235156647861004, 0.0032535719219595194, 0.11335265636444092, 0.004328136797994375, 0.12085679173469543, 0.004504506941884756, 0.004236897453665733, 0.10271738469600677, 0.004780136048793793, 0.22691978514194489, 0.0936855748295784, 0.005144538823515177, 0.0071637630462646484, 0.0064954012632369995, 0.004889205563813448, 0.007174602244049311, 0.005883411504328251, 0.005031987093389034, 0.0056855520233511925, 0.004997267387807369, 0.006021087523549795, 0.0821428969502449, 0.0046655465848743916, 0.005162568762898445, 0.004589397925883532, 0.00478093046694994, 0.14094285666942596, 0.00565182464197278, 0.09797609597444534, 0.005216335877776146, 0.004433400928974152, 0.007356818299740553, 0.004594304133206606, 0.0039770943112671375, 0.004080679267644882, 0.13798171281814575, 0.004157701972872019, 0.10868018120527267, 0.0043764784932136536, 0.005513408221304417, 0.004221399314701557, 0.005234153475612402, 0.11007224023342133, 0.006243800278753042, 0.0044270777143538, 0.003969627432525158, 0.004347518086433411, 0.004917270969599485, 0.0037718401290476322, 0.004338559694588184, 0.008258294314146042, 0.0035252035595476627, 0.0037421027664095163, 0.0032188217155635357, 0.12311635166406631, 0.003253604518249631, 0.004355274606496096, 0.08165260404348373, 0.0039028190076351166, 0.004082551226019859, 0.0034698587842285633, 0.003934647887945175, 0.0032948844600468874, 0.0033154888078570366, 0.002930199494585395, 0.003163286717608571, 0.0035587891470640898, 0.0029142634011805058, 0.004872051067650318, 0.00324842962436378, 0.0026038114447146654, 0.003098467132076621, 0.17380960285663605, 0.002430280903354287, 0.0025734545197337866, 0.14602045714855194, 0.0024853856302797794, 0.0029571556951850653, 0.0027780896052718163, 0.0026918607763946056, 0.052367351949214935, 0.21486049890518188, 0.0029691685922443867, 0.0029608081094920635, 0.0036061927676200867, 0.004399209748953581, 0.00342034874483943, 0.0034675798378884792, 0.002908210502937436, 0.16232578456401825, 0.0033298649359494448, 0.003131870413199067, 0.0034855231642723083, 0.00400635227560997, 0.0046800244599580765, 0.0036854029167443514, 0.003835728857666254, 0.0032830634154379368, 0.0034319974947720766, 0.0034567047841846943, 0.002921806648373604, 0.002852892968803644, 0.0028247046284377575, 0.0028416444547474384, 0.003816261189058423, 0.18878722190856934, 0.0029327082447707653, 0.0028472915291786194, 0.0024345149286091328, 0.0024240033235400915, 0.003230634145438671, 0.0029373059514909983, 0.002671611960977316, 0.0029528781305998564, 0.0024242030922323465, 0.0030517461709678173, 0.0021889719646424055, 0.002679688623175025, 0.0024653172586113214, 0.002149825682863593, 0.0032307233195751905, 0.1282726228237152, 0.001948328921571374, 0.0019136056071147323, 0.0019294189987704158, 0.16707384586334229, 0.003202713094651699, 0.001983474474400282, 0.0028965850360691547, 0.0024178263265639544, 0.002971310168504715, 0.0025276450905948877, 0.0021633547730743885, 0.0025354940444231033, 0.002274176338687539, 0.002154681598767638, 0.002034148434177041, 0.13957321643829346, 0.0033665813971310854, 0.4919743239879608, 0.24940036237239838, 0.003771898802369833, 0.0054811155423521996, 0.31651297211647034, 0.1202026754617691, 0.004094270523637533, 0.038055889308452606, 0.005510750692337751, 0.005801019258797169, 0.08647314459085464, 0.356469064950943, 0.008330504409968853, 0.008715435862541199, 0.01092473417520523, 0.00984603725373745, 0.06687479466199875, 0.011168723925948143, 0.011983866803348064, 0.01392432488501072, 0.013326440006494522, 0.11205492913722992, 0.013485890813171864, 0.013881102204322815, 0.011576096527278423, 0.011585934087634087, 0.014329928904771805, 0.012980925850570202, 0.06427925825119019, 0.09775330126285553, 0.011652225628495216, 0.012442778795957565, 0.00998105388134718, 0.00806809775531292, 0.011022528633475304, 0.01106844749301672, 0.006697902921587229, 0.007147002499550581, 0.007364880759268999, 0.00622536288574338, 0.00532902916893363, 0.005430296529084444, 0.1862621307373047, 0.004703395534306765, 0.005717366933822632, 0.0048806690610945225, 0.004242386668920517, 0.08886498957872391, 0.00491428142413497, 0.005046086385846138, 0.12967678904533386, 0.0038592787459492683, 0.09693554043769836, 0.22054041922092438, 0.0036775688640773296, 0.0039035603404045105, 0.004591464530676603, 0.004258521366864443, 0.0048975758254528046, 0.0038070371374487877, 0.003486799309030175, 0.004391038324683905, 0.0033715355675667524, 0.0034394608810544014, 0.003934030421078205, 0.0037098911125212908, 0.0032457769848406315, 0.0032944539561867714, 0.0033860397525131702, 0.004413256421685219, 0.16375307738780975, 0.0036299952771514654, 0.11374975740909576, 0.003187829628586769, 0.0037341006100177765, 0.0029696831479668617, 0.0036807889118790627, 0.002895127283409238, 0.003405405906960368, 0.0030906773172318935, 0.0031706562731415033, 0.0028858655132353306, 0.004010416567325592, 0.0026796080637723207, 0.0030971956439316273, 0.002634942065924406, 0.08138484507799149, 0.0028890473768115044, 0.1515733152627945, 0.0028439322486519814, 0.0027342115063220263, 0.002960734535008669, 0.0034589795395731926, 0.0034121789503842592, 0.0032122049015015364, 0.002561780624091625, 0.0024986425414681435, 0.10865457355976105, 0.0025596728082746267, 0.003085633972659707, 0.0027926017064601183, 0.0024991801474243402, 0.11275935918092728, 0.00269879843108356, 0.21188220381736755, 0.0030142797622829676, 0.003453456796705723, 0.003081756178289652, 0.004234977997839451, 0.0032371862325817347, 0.0031256205402314663, 0.003443379420787096, 0.003469581250101328, 0.004025267902761698, 0.003329632803797722, 0.07025178521871567, 0.0815226137638092, 0.0034873676486313343, 0.0036687306128442287, 0.003579335752874613, 0.0037206837441772223, 0.0035443208180367947, 0.004275298211723566, 0.0037419209256768227, 0.0038000273052603006, 0.13085202872753143, 0.06336428970098495, 0.1591787487268448, 0.1872679442167282, 0.005033512599766254, 0.004918924067169428, 0.072880819439888, 0.006583029869943857, 0.005105036776512861, 0.15814745426177979, 0.006450435146689415, 0.04987555742263794, 0.08566238731145859, 0.005235616583377123, 0.01004060823470354, 0.006258205510675907, 0.00806642696261406, 0.00552280992269516, 0.007126741576939821, 0.007072002626955509, 0.007064349949359894, 0.006631916854530573, 0.0051374309696257114, 0.1347230225801468, 0.008858081884682178, 0.2747431993484497, 0.00923056062310934, 0.12500250339508057, 0.004800428636372089, 0.005425787530839443, 0.006366545334458351, 0.006846084259450436, 0.006340197287499905, 0.004915979690849781, 0.08328276127576828, 0.006176311988383532, 0.006222112569957972, 0.005235728342086077, 0.005360826384276152, 0.005211224779486656, 0.005898139905184507, 0.004732743836939335, 0.0050523667596280575, 0.2646641135215759, 0.004096966236829758, 0.0038621388375759125, 0.004844703245908022, 0.05784640088677406, 0.0037466874346137047, 0.00412960397079587, 0.0037045555654913187, 0.005350326653569937, 0.051175326108932495, 0.0060660261660814285, 0.005402065347880125, 0.1428118348121643, 0.004576030187308788, 0.08506116271018982, 0.005854328162968159, 0.006036704406142235, 0.004977935925126076, 0.004872473888099194, 0.0049592433497309685, 0.13652624189853668, 0.2805980443954468, 0.21179181337356567, 0.003661541035398841, 0.00380978942848742, 0.005357576999813318, 0.003961184527724981, 0.005030915606766939, 0.14521144330501556, 0.004544327966868877, 0.0701410248875618, 0.08905602246522903, 0.004589397460222244, 0.15367141366004944, 0.006380473263561726, 0.007651807274669409, 0.005680873990058899, 0.005749247502535582, 0.00649851793423295, 0.006559279281646013, 0.005870265420526266, 0.005295715294778347, 0.007150725461542606, 0.005240187980234623, 0.005376170855015516, 0.1518360823392868, 0.004950280301272869, 0.08389534056186676, 0.006613678764551878, 0.0051599591970443726, 0.0052233911119401455, 0.005374019034206867, 0.004675598815083504, 0.07658936083316803, 0.3578326106071472, 0.09728091955184937, 0.0054378267377614975, 0.006329761818051338, 0.0059429495595395565, 0.05160036310553551, 0.007738872431218624, 0.007801974657922983, 0.006972584407776594, 0.011234979145228863, 0.007585157174617052, 0.009159202687442303, 0.00943775288760662, 0.008930536918342113, 0.007089698687195778, 0.13314379751682281, 0.009345093742012978, 0.006324179004877806, 0.0062440019100904465, 0.08790545910596848, 0.00589811010286212, 0.00727460253983736, 0.006084613036364317, 0.008254260756075382, 0.005378006026148796, 0.006050317082554102, 0.160897895693779, 0.005945599637925625, 0.00482949847355485, 0.005652690306305885, 0.004672307521104813, 0.004942907486110926, 0.0064336215145885944, 0.006936751771718264, 0.003962482791393995, 0.004271835088729858, 0.003534717718139291, 0.004364370368421078, 0.004115571733564138, 0.0055148103274405, 0.1330725997686386, 0.0036160668823868036, 0.003480337094515562, 0.004124462138861418, 0.004238560330122709, 0.0635216161608696, 0.0031022035982459784, 0.002829316770657897, 0.0037878677248954773, 0.0035452949814498425, 0.00419986667111516, 0.0025847326032817364, 0.002523789880797267, 0.002499847672879696, 0.18429696559906006, 0.00253019155934453, 0.002339209895581007, 0.0025469190441071987, 0.0035875693429261446, 0.0027474567759782076, 0.0025032951962202787, 0.002826361684128642, 0.002433008048683405, 0.44940418004989624, 0.003321818308904767, 0.005089031532406807, 0.0028875998686999083, 0.06533744931221008, 0.003597929608076811, 0.00548743549734354, 0.12963613867759705, 0.08958162367343903, 0.005624518729746342, 0.005798310041427612, 0.6368414163589478, 0.2150043398141861, 0.006194062996655703, 0.49978819489479065, 0.009251568466424942, 0.179276242852211, 0.010283993557095528, 0.06502704322338104, 0.06872320175170898, 0.020584408193826675, 0.08480364829301834, 0.15326140820980072, 0.01685980148613453, 0.018562156707048416, 0.01758984662592411, 0.11336731165647507, 0.018971409648656845, 0.016765758395195007, 0.01805155724287033, 0.016320623457431793, 0.016535652801394463, 0.08627976477146149, 0.12543152272701263, 0.014776034280657768, 0.013502494432032108, 0.07399747520685196, 0.09524320811033249, 0.44863396883010864, 0.012042111717164516, 0.012516994029283524, 0.29122841358184814, 0.013897350989282131, 0.01390156615525484, 0.014184726402163506, 0.01467512734234333, 0.0152245769277215, 0.0158726554363966, 0.013425140641629696, 0.013322887010872364, 0.013543177396059036, 0.012253686785697937, 0.011879239231348038, 0.01124590914696455, 0.08743416517972946, 0.011596789583563805, 0.010424058884382248, 0.009840191341936588, 0.00905115157365799, 0.09378328919410706, 0.10582339763641357, 0.4101789593696594, 0.00839068554341793, 0.008987050503492355, 0.009065213613212109, 0.00914275087416172, 0.009807913564145565, 0.008387335576117039, 0.1451484113931656, 0.13602806627750397, 0.09556172788143158, 0.008354520425200462, 0.00822175107896328, 0.008396483026444912, 0.008574259467422962, 0.007994376122951508, 0.007997310720384121, 0.19092348217964172, 0.007573803421109915, 0.008048543706536293, 0.11158706992864609, 0.1062144786119461, 0.00813235528767109, 0.11518123745918274, 0.1433762162923813, 0.12199626117944717, 0.007838613353669643, 0.008898800238966942, 0.008042965084314346, 0.00815864372998476, 0.007710510399192572, 0.0078099253587424755, 0.1033095046877861, 0.007866100408136845, 0.008250890299677849, 0.007623446639627218, 0.007552699651569128, 0.006945333909243345, 0.006809005048125982, 0.006812605541199446, 0.1639649122953415, 0.0787365734577179, 0.0060052876360714436, 0.006855946034193039, 0.12031624466180801, 0.0058640833012759686, 0.005795754957944155, 0.005866281222552061, 0.005844490136951208, 0.005426742602139711, 0.005574923474341631, 0.15499679744243622, 0.00524965301156044, 0.0051252711564302444, 0.3321426212787628, 0.0053674387745559216, 0.005811058450490236, 0.006102513521909714, 0.006152039859443903, 0.006333957426249981, 0.006547578144818544, 0.09554897248744965, 0.006413801573216915, 0.14263150095939636, 0.006751110311597586, 0.006674373988062143, 0.00717016588896513, 0.007052963133901358, 0.006908772047609091, 0.0066861556842923164, 0.00689435750246048, 0.006468466017395258, 0.006544667761772871, 0.42644110321998596, 0.006518505979329348, 0.007140371482819319, 0.007253756280988455, 0.006996331736445427, 0.00740024633705616, 0.006991718430072069, 0.006976647302508354, 0.007236668840050697, 0.11500371247529984, 0.007320694159716368, 0.09544236958026886, 0.006957437843084335, 0.11107026040554047, 0.007596030831336975, 0.13937842845916748, 0.007496603298932314, 0.007487129420042038, 0.34297338128089905, 0.09512537717819214, 0.008520407602190971, 0.008493729867041111, 0.0988398939371109, 0.19076117873191833, 0.15664787590503693, 0.010397253558039665, 0.01047246903181076, 0.010823173448443413, 0.010997207835316658, 0.011842991225421429, 0.010941003449261189, 0.011442691087722778, 0.010672532021999359, 0.011283662170171738, 0.012818536721169949, 0.010096130892634392, 0.01039911713451147, 0.009363272227346897, 0.009305895306169987, 0.008189785294234753, 0.09422297775745392, 0.11238085478544235, 0.00791111495345831, 0.007892102003097534, 0.09095214307308197, 0.006965025793761015, 0.006611951626837254, 0.00640442268922925, 0.11707186698913574, 0.006258115172386169, 0.006588983349502087, 0.006655118428170681, 0.005963193252682686, 0.14431248605251312, 0.005812552757561207, 0.07260290533304214, 0.005655521992594004, 0.005949417594820261, 0.005245387554168701, 0.005125341471284628, 0.005683213472366333, 0.08069387823343277, 0.11699697375297546, 0.004851791076362133, 0.005378229543566704, 0.004856525454670191, 0.005268633831292391, 0.005230202339589596, 0.1411263793706894, 0.004600061569362879, 0.004757744260132313, 0.004541258327662945, 0.005459961947053671, 0.004768257029354572, 0.004382005892693996, 0.0042717899195849895, 0.004465175326913595, 0.004415180534124374, 0.0042327772825956345, 0.0043762256391346455, 0.004461771808564663, 0.003711412660777569, 0.003673398867249489, 0.05749101564288139, 0.003391078906133771, 0.0036345350090414286, 0.003527569118887186, 0.13057515025138855, 0.0045662191696465015, 0.003468712791800499, 0.17556248605251312, 0.4846043884754181, 0.12859074771404266, 0.004042233340442181, 0.11078877002000809, 0.0053128888830542564, 0.0051989867351949215, 0.007085714023560286, 0.006325905676931143, 0.006821733433753252, 0.13985079526901245, 0.08496765792369843, 0.0644894391298294, 0.008128347806632519, 0.4275103211402893, 0.008641457185149193, 0.008935222402215004, 0.012523695826530457, 0.009812082163989544, 0.013179655186831951, 0.010587545111775398, 0.10514600574970245, 0.011179311200976372, 0.15022334456443787, 0.014872190542519093, 0.013044463470578194, 0.011160395108163357, 0.010806124657392502, 0.010889980010688305, 0.011007548309862614, 0.3342122733592987, 0.04535694792866707, 0.012907734140753746, 0.010818266309797764, 0.1340656727552414, 0.0106718260794878, 0.01187526062130928, 0.013363135978579521, 0.0120261674746871, 0.010707328096032143, 0.01155848428606987, 0.011417483910918236, 0.11575403064489365, 0.1615297794342041, 0.009574026800692081, 0.08130542188882828, 0.15239040553569794, 0.16410836577415466, 0.05437565967440605, 0.13116642832756042, 0.010913913138210773, 0.009738684631884098, 0.009313296526670456, 0.008695831522345543, 0.008729648776352406, 0.008381442166864872, 0.008868413977324963, 0.0087279062718153, 0.03598848730325699, 0.007639945950359106, 0.007706951349973679, 0.0072673000395298, 0.007174024358391762, 0.0068684048019349575, 0.007371986750513315, 0.006073358003050089, 0.005859116092324257, 0.006553573068231344, 0.005789042916148901, 0.0055652339942753315, 0.005428454373031855, 0.19175219535827637, 0.004985546227544546, 0.13867159187793732, 0.004445952363312244, 0.005246617365628481, 0.005162329412996769, 0.17288357019424438, 0.005341225769370794, 0.08635151386260986, 0.005151839926838875, 0.10556672513484955, 0.004512181039899588, 0.004518961999565363, 0.13985104858875275, 0.005737361963838339, 0.005166348069906235, 0.08877302706241608, 0.005307244136929512, 0.005303260870277882, 0.005187835544347763, 0.09045998007059097, 0.005262347403913736, 0.0646544024348259, 0.005386839155107737, 0.005802046973258257, 0.14721956849098206, 0.06657979637384415, 0.005934949964284897, 0.005784731823951006, 0.005628934595733881, 0.18831337988376617, 0.006180544383823872, 0.005745147820562124, 0.007656790316104889, 0.006264667492359877, 0.006053753662854433, 0.005984860472381115, 0.005458081141114235, 0.00593935139477253, 0.09292999655008316, 0.005544742103666067, 0.005496439058333635, 0.005288762506097555, 0.005523340310901403, 0.10088246315717697, 0.005003240425139666, 0.12337024509906769, 0.00503151398152113, 0.005439017433673143, 0.004988620523363352, 0.005700374487787485, 0.004635423421859741, 0.005008548032492399, 0.005345086567103863, 0.004577604588121176, 0.004198876209557056, 0.0043096658773720264, 0.09242045879364014, 0.00474825594574213, 0.18368230760097504, 0.003993409685790539, 0.005015304312109947, 0.16388657689094543, 0.00417851097881794, 0.0041641308926045895, 0.0041583385318517685, 0.004749869927763939, 0.0043595475144684315, 0.004076746292412281, 0.004853697959333658, 0.004600160289555788, 0.003843114012852311, 0.09308743476867676, 0.00446439441293478, 0.12107141315937042, 0.004150409251451492, 0.0041656033135950565, 0.004106422886252403, 0.1849454939365387, 0.08557906746864319, 0.004552051424980164, 0.004097755532711744, 0.004331293515861034, 0.004396897740662098, 0.1773015558719635, 0.00543932756409049, 0.004954832140356302, 0.004784989636391401, 0.005385476164519787, 0.004704349674284458, 0.11415316164493561, 0.00451623322442174, 0.005107869394123554, 0.004746259190142155, 0.004679725039750338, 0.004542183130979538, 0.11728445440530777, 0.1704232096672058, 0.004884869325906038, 0.006595340557396412, 0.004981757141649723, 0.055704694241285324, 0.0046438840217888355, 0.004717273637652397, 0.0058586494997143745, 0.005285267718136311, 0.004771916661411524, 0.11668930947780609, 0.004970873240381479, 0.07021773606538773, 0.004895932041108608, 0.0057030715979635715, 0.004701226484030485, 0.004633946809917688, 0.004982737358659506, 0.005085074342787266, 0.005267962347716093, 0.004449686035513878, 0.004169152583926916, 0.005304441787302494, 0.004484719131141901, 0.004960371181368828, 0.004469986539334059, 0.003918050788342953, 0.0037992943543940783, 0.003981545567512512, 0.10731314867734909, 0.003415968269109726, 0.0036117425188422203, 0.003189924405887723, 0.14984919130802155, 0.0033187640365213156, 0.0032586483284831047, 0.0035601488780230284, 0.003147201146930456, 0.003742012195289135, 0.0031190961599349976, 0.0038239387795329094, 0.1848183423280716, 0.003526685293763876, 0.1751699298620224, 0.09085169434547424, 0.0035011405125260353, 0.003609729465097189, 0.004360989201813936, 0.003987425472587347, 0.003693103091791272, 0.004295643884688616, 0.004160611424595118, 0.003710231278091669, 0.0036841947585344315, 0.12029329687356949, 0.0038817119784653187, 0.004051963798701763, 0.005749248433858156, 0.003796316683292389, 0.004095400217920542, 0.13450495898723602, 0.004067008383572102, 0.0038150560576468706, 0.003913854248821735, 0.003920853603631258, 0.003993005026131868, 0.4192204475402832, 0.004074199125170708, 0.09956063330173492, 0.004722191486507654, 0.005195064935833216, 0.19928213953971863, 0.11333885788917542, 0.006392671726644039, 0.06874977797269821, 0.007505933754146099, 0.007988079451024532, 0.13248635828495026, 0.20118646323680878, 0.28443440794944763, 0.009858048520982265, 0.009183123707771301, 0.009385609067976475, 0.07122249156236649, 0.011522670276463032, 0.043810438364744186, 0.012543730437755585, 0.011497050523757935, 0.011799336411058903, 0.012972899712622166, 0.012070178054273129, 0.3047123849391937, 0.05294949188828468, 0.2010398656129837, 0.014868787489831448, 0.11339915543794632, 0.016077803447842598, 0.01737167499959469, 0.017563244327902794, 0.07429439574480057, 0.018632441759109497, 0.14948724210262299, 0.019077841192483902, 0.09370984882116318, 0.01600707694888115, 0.11406080424785614, 0.0200833510607481, 0.01652856543660164, 0.017322024330496788, 0.18185395002365112, 0.013990693725645542, 0.013278892263770103, 0.27986428141593933, 0.1278609037399292, 0.013484572991728783, 0.10519499331712723, 0.08194085955619812, 0.013953429646790028, 0.1274082362651825, 0.012856381945312023, 0.016659019514918327, 0.12749360501766205, 0.08775918185710907, 0.012767904438078403, 0.015790589153766632, 0.013209464959800243, 0.015019429847598076, 0.013267388567328453, 0.011266693472862244, 0.009786922484636307, 0.010602761059999466, 0.012305633164942265, 0.008655862882733345, 0.009554868564009666, 0.008475139737129211, 0.008323433808982372, 0.010031855665147305, 0.006828887388110161, 0.007887987419962883, 0.17416445910930634, 0.006325329188257456, 0.005387670360505581, 0.0768141970038414, 0.006552790757268667, 0.004936670884490013, 0.005002229008823633, 0.00505124730989337, 0.004864861257374287, 0.0046079689636826515, 0.004131571855396032, 0.004172930493950844, 0.15672332048416138, 0.00376594765111804, 0.004403752740472555, 0.003613236593082547, 0.003768333001062274, 0.004206562414765358, 0.005404969677329063, 0.003615560242906213, 0.003543978789821267, 0.0036995415575802326, 0.0030316661577671766, 0.003570496803149581, 0.0030116343405097723, 0.0031162535306066275, 0.003217281773686409, 0.0030071064829826355, 0.002780322218313813, 0.002594232792034745, 0.5029470920562744, 0.12050409615039825, 0.002878426108509302, 0.00329882581718266, 0.0032622755970805883, 0.004941466264426708, 0.0038218486588448286, 0.003984613809734583, 0.14405374228954315, 0.23166784644126892, 0.004297837149351835, 0.004757586866617203, 0.004782072734087706, 0.0053406283259391785, 0.004913647193461657, 0.09445938467979431, 0.0058846743777394295, 0.005353344604372978, 0.005533677991479635, 0.08734654635190964, 0.006221788935363293, 0.005631203763186932, 0.005521966144442558, 0.0057597896084189415, 0.006259372923523188, 0.006099785678088665, 0.005980652756989002, 0.006600214168429375, 0.40434518456459045, 0.0056471144780516624, 0.0056798430159688, 0.006041714455932379, 0.006205271929502487, 0.00688794394955039, 0.13356219232082367, 0.00668140035122633, 0.0066928500309586525, 0.006755099631845951, 0.007899665273725986, 0.00693640997633338, 0.30810821056365967, 0.00712180882692337, 0.007202641572803259, 0.008344440720975399, 0.00829657819122076, 0.007514983881264925, 0.00791641604155302, 0.12898658215999603, 0.00824366882443428, 0.00800667516887188, 0.009416270069777966, 0.008050234988331795, 0.007712700869888067, 0.00780835235491395, 0.007599135860800743, 0.00809666607528925, 0.1855533868074417, 0.09697292745113373, 0.007412643171846867, 0.09935057908296585, 0.006848217453807592, 0.007370473351329565, 0.006918175611644983, 0.007710217032581568, 0.006745488848537207, 0.006425175815820694, 0.006877726409584284, 0.0067934682592749596, 0.0063399747014045715, 0.006327825132757425, 0.005628843791782856, 0.005437295418232679, 0.4714300334453583, 0.006429426372051239, 0.006341612432152033, 0.006053670775145292, 0.005959559231996536, 0.005987058859318495, 0.0061827152967453, 0.006419155281037092, 0.006314003374427557, 0.006424541585147381, 0.006073524709790945, 0.1743726134300232, 0.006388932000845671, 0.005875851958990097, 0.006196422502398491, 0.0060237376019358635, 0.13687337934970856, 0.005832290276885033, 0.4381616413593292, 0.006249360740184784, 0.1324819028377533, 0.008249899372458458, 0.007074907887727022, 0.007346624042838812, 0.007507086265832186, 0.008581714704632759, 0.13645537197589874, 0.00801954697817564, 0.008093026466667652, 0.008671393617987633, 0.008400429971516132, 0.008490139618515968, 0.007933971472084522, 0.008159652352333069, 0.008005230687558651, 0.007619895506650209, 0.007602596189826727, 0.007834474556148052, 0.00704160425812006, 0.08726762235164642, 0.006711034569889307, 0.08381173014640808, 0.1620984822511673, 0.006714558694511652, 0.006552896462380886, 0.06141239404678345, 0.00638956855982542, 0.006313415709882975, 0.006175681948661804, 0.31355172395706177, 0.11339949816465378, 0.007198987063020468, 0.007078326307237148, 0.007182623725384474, 0.007372735999524593, 0.008044734597206116, 0.007655843161046505, 0.007868586108088493, 0.07900164276361465, 0.10271532833576202, 0.0075903343968093395, 0.007651898544281721, 0.008018544875085354, 0.007723312359303236, 0.007697169203311205, 0.00775919621810317, 0.007896775379776955, 0.007347262930124998, 0.115080825984478, 0.07965230941772461, 0.0069262683391571045, 0.008293303661048412, 0.0069360556080937386, 0.006635876838117838, 0.00653797434642911, 0.006517970003187656, 0.006380395032465458, 0.10510815680027008, 0.0064022121950984, 0.0057707070372998714, 0.09819195419549942, 0.0058351620100438595, 0.005683400668203831, 0.00568782351911068, 0.005586062092334032, 0.005227391608059406, 0.0056174155324697495, 0.005360632669180632, 0.005486304871737957, 0.005950257182121277, 0.0048164003528654575, 0.004851854871958494, 0.004411250818520784, 0.004253585822880268, 0.1194014847278595, 0.004311635624617338, 0.004721052944660187, 0.004174921195954084, 0.0038742388132959604, 0.004194911103695631, 0.0038537494838237762, 0.11190016567707062, 0.1606755256652832, 0.0035811199340969324, 0.003906106809154153, 0.003956658765673637, 0.003921755589544773, 0.0038577928207814693, 0.06576084345579147, 0.004012499935925007, 0.14141032099723816, 0.004393280483782291, 0.004016759805381298, 0.003943695221096277, 0.11113614588975906, 0.004088957328349352, 0.00420790072530508, 0.003926623612642288, 0.004062201362103224, 0.004217631183564663, 0.00415039574727416, 0.003947535529732704, 0.003945763222873211, 0.10524828732013702, 0.0038537157233804464, 0.00387210794724524, 0.004236834589391947, 0.004093330353498459, 0.0037707355804741383, 0.10140889137983322, 0.004082313738763332, 0.003998016472905874, 0.004712398629635572, 0.10254939645528793, 0.003849287983030081, 0.004366856999695301, 0.003947349265217781, 0.004159430041909218, 0.0041020880453288555, 0.004015706479549408, 0.0035893081221729517, 0.14166191220283508, 0.0036465278826653957, 0.0038099794182926416, 0.0038045209366828203, 0.003718307474628091, 0.1433371901512146, 0.003940477501600981, 0.004029039293527603, 0.003904466051608324, 0.004048922564834356, 0.004109436646103859, 0.003807124448940158, 0.0036923347506672144, 0.00349250016734004, 0.1879083812236786, 0.003688681172206998, 0.003569897497072816, 0.0036066637840121984, 0.0036674404982477427, 0.003507399233058095, 0.0036386155989021063, 0.11439118534326553, 0.003989644348621368, 0.0035487983841449022, 0.08576693385839462, 0.003978928551077843, 0.1401013880968094, 0.003729354590177536, 0.12995457649230957, 0.12918458878993988, 0.0044105579145252705, 0.0041763195767998695, 0.1370239406824112, 0.004540877882391214, 0.004882575012743473, 0.11290723085403442, 0.005709801334887743, 0.10453519970178604, 0.11354197561740875, 0.005497531965374947, 0.0057694618590176105, 0.00607975572347641, 0.005978857632726431, 0.12875652313232422, 0.0069683329202234745, 0.006077161058783531, 0.0063340552151203156, 0.006672785617411137, 0.1813735067844391, 0.006389280315488577, 0.006405525840818882, 0.08864837139844894, 0.07864280790090561, 0.006904504727572203, 0.07895030081272125, 0.006490127183496952, 0.007224548142403364, 0.006641872692853212, 0.0069463616237044334, 0.0068011716939508915, 0.006380064878612757, 0.006835490930825472, 0.006108105648308992, 0.14924997091293335, 0.00627265265211463, 0.006139236502349377, 0.006257855799049139, 0.006395905278623104, 0.006139934528619051, 0.08181051909923553, 0.006058359984308481, 0.005907428916543722, 0.006225620396435261, 0.005466029513627291, 0.005212301854044199, 0.0048676347360014915, 0.16836141049861908, 0.005675301421433687, 0.12962113320827484, 0.005000942852348089, 0.10168261080980301, 0.005254961084574461, 0.00474891671910882, 0.00472980597987771, 0.00510472571477294, 0.16661399602890015, 0.004946834873408079, 0.004709027707576752, 0.005087499972432852, 0.004965365398675203, 0.005557189229875803, 0.21033601462841034, 0.005101190879940987, 0.004880370572209358, 0.09804825484752655, 0.12131346017122269, 0.005093726795166731, 0.005178950261324644, 0.15951262414455414, 0.005347082391381264, 0.005111858248710632, 0.00524152722209692, 0.005207994021475315, 0.005313890986144543, 0.0052749463357031345, 0.005119630601257086, 0.005092041566967964, 0.005040721967816353, 0.005357781890779734, 0.004845313262194395, 0.004816166125237942, 0.004805955570191145, 0.004743986297398806, 0.004561127163469791, 0.004736445378512144, 0.004391568247228861, 0.004371292889118195, 0.0042211925610899925, 0.004127820022404194, 0.11727126687765121, 0.0038951400201767683, 0.0037383560556918383, 0.12257760763168335, 0.0036693657748401165, 0.10125814378261566, 0.00382613530382514, 0.08095893263816833, 0.004168249666690826, 0.003953543026000261, 0.0038351856637746096, 0.11336404085159302, 0.004216700326651335, 0.003997430671006441, 0.1292165219783783, 0.1318286806344986, 0.00447376724332571, 0.004505958408117294, 0.004507742822170258, 0.004922663327306509, 0.004896463360637426, 0.0047281221486628056, 0.004544150084257126, 0.004705413244664669, 0.14331580698490143, 0.004619461949914694, 0.004769342485815287, 0.004678367171436548, 0.004673571325838566, 0.004666553810238838, 0.004721799865365028, 0.004743552766740322, 0.11984946578741074, 0.004474456887692213]\n",
            "Val loss 0.030443110444767465\n",
            "Val auc roc 0.48681669767931757\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c417712c23d8422eb57ce2197e617b29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1663.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0373\n",
            "Train Losses : [0.10357870161533356, 0.004744705744087696, 0.004590493626892567, 0.004507661797106266, 0.0045118872076272964, 0.004465088713914156, 0.004673338029533625, 0.363067626953125, 0.09248076379299164, 0.3996044099330902, 0.005476690828800201, 0.09834250807762146, 0.007281316909939051, 0.007383362390100956, 0.007878080941736698, 0.008357546292245388, 0.10616768896579742, 0.009249355643987656, 0.13916370272636414, 0.010518696159124374, 0.01081076916307211, 0.011449090205132961, 0.12861891090869904, 0.0963033139705658, 0.01117877010256052, 0.011843770742416382, 0.0971311703324318, 0.011248542927205563, 0.01109720952808857, 0.011794782243669033, 0.061487216502428055, 0.010876602493226528, 0.011747324839234352, 0.010401925072073936, 0.010840018279850483, 0.09363081306219101, 0.010906850919127464, 0.011035030707716942, 0.009609325788915157, 0.00952637754380703, 0.00898632500320673, 0.008935713209211826, 0.008511354215443134, 0.07653245329856873, 0.36390766501426697, 0.11008148640394211, 0.007918929681181908, 0.15030398964881897, 0.008554540574550629, 0.07434527575969696, 0.00974713359028101, 0.009365029633045197, 0.12057895958423615, 0.13087907433509827, 0.009211167693138123, 0.010319539345800877, 0.009892296977341175, 0.009151682257652283, 0.2184663861989975, 0.009816022589802742, 0.008975589647889137, 0.010547072626650333, 0.009133849292993546, 0.008747740648686886, 0.009213006123900414, 0.008418794721364975, 0.008590739220380783, 0.008384295739233494, 0.0075874789617955685, 0.007672032807022333, 0.006984565407037735, 0.007234380580484867, 0.0065149893052875996, 0.006930803880095482, 0.006669841706752777, 0.005884805228561163, 0.006867981981486082, 0.006121397018432617, 0.005152191035449505, 0.0051970286294817924, 0.00479927146807313, 0.00463895034044981, 0.11920082569122314, 0.00431692972779274, 0.004169462248682976, 0.08507779240608215, 0.004022850655019283, 0.003997146151959896, 0.004053536336869001, 0.0041112108156085014, 0.004328236915171146, 0.003733827965334058, 0.0037213193718343973, 0.0036676793824881315, 0.003472684882581234, 0.0034980308264493942, 0.0033581028692424297, 0.0036449662875384092, 0.14911752939224243, 0.22028563916683197, 0.0035025279503315687, 0.003302579512819648, 0.003273840993642807, 0.17947351932525635, 0.0035730423405766487, 0.003571929642930627, 0.0035479252692312002, 0.11320411413908005, 0.0037121467757970095, 0.0036119427531957626, 0.0036624609492719173, 0.003848243271932006, 0.12603266537189484, 0.10876663029193878, 0.46352890133857727, 0.09779909253120422, 0.004757968243211508, 0.005157231353223324, 0.005464409943670034, 0.006015400867909193, 0.006423179525882006, 0.006559445522725582, 0.00669552106410265, 0.007015875540673733, 0.007066973485052586, 0.007107882294803858, 0.09668183326721191, 0.13360141217708588, 0.1116652712225914, 0.007992839440703392, 0.008046542294323444, 0.007837272249162197, 0.007842771708965302, 0.00787923764437437, 0.008085126988589764, 0.09056087583303452, 0.007732543628662825, 0.00840978417545557, 0.11059624701738358, 0.13755382597446442, 0.14892394840717316, 0.008240031078457832, 0.14387431740760803, 0.11552814394235611, 0.1207585409283638, 0.1490064114332199, 0.008800488896667957, 0.06943103671073914, 0.009747849777340889, 0.009069502353668213, 0.009661374613642693, 0.07767003029584885, 0.009788235649466515, 0.009714480489492416, 0.009424980729818344, 0.0095624765381217, 0.009026715531945229, 0.008698341436684132, 0.008450518362224102, 0.008627609349787235, 0.008028845302760601, 0.007788981311023235, 0.00827557872980833, 0.007220663130283356, 0.006974003277719021, 0.10896611958742142, 0.25774556398391724, 0.006817913148552179, 0.007008530665189028, 0.007165982853621244, 0.007360102608799934, 0.3477546274662018, 0.007552279159426689, 0.1414116621017456, 0.008332674391567707, 0.009048866108059883, 0.1183631420135498, 0.009645553305745125, 0.009651439264416695, 0.009840428829193115, 0.12858378887176514, 0.13755568861961365, 0.010404037311673164, 0.010250940918922424, 0.010647276416420937, 0.010399799793958664, 0.010494179092347622, 0.010423597879707813, 0.009874162264168262, 0.009223872795701027, 0.10479166358709335, 0.009267703630030155, 0.009265019558370113, 0.00863623060286045, 0.0916491448879242, 0.008056710474193096, 0.008036743849515915, 0.008259373717010021, 0.007496632169932127, 0.007370707578957081, 0.007118388079106808, 0.10416078567504883, 0.006690158974379301, 0.00668963510543108, 0.006545130163431168, 0.006345151923596859, 0.0062021114863455296, 0.0065035829320549965, 0.006067376583814621, 0.005748036317527294, 0.005430418532341719, 0.14568139612674713, 0.005242346785962582, 0.005410973913967609, 0.004927935544401407, 0.004870172590017319, 0.005126381758600473, 0.004569665994495153, 0.004545015282928944, 0.004374566953629255, 0.00445218151435256, 0.00409616669639945, 0.003951841499656439, 0.003890416817739606, 0.49997466802597046, 0.004294009879231453, 0.004349549766629934, 0.08857119828462601, 0.004618092440068722, 0.004722227808088064, 0.16138790547847748, 0.004946940578520298, 0.005098535679280758, 0.005353011656552553, 0.005518798250705004, 0.005638750270009041, 0.005418458953499794, 0.0056021250784397125, 0.0054078795947134495, 0.00579540291801095, 0.16114570200443268, 0.005588606931269169, 0.1619383692741394, 0.14487966895103455, 0.005672713275998831, 0.005493432283401489, 0.005992411635816097, 0.13026590645313263, 0.1327652782201767, 0.005803195759654045, 0.005858698859810829, 0.11704768240451813, 0.006106597371399403, 0.006148536689579487, 0.006266548298299313, 0.006180397234857082, 0.006228052079677582, 0.10295301675796509, 0.006281481124460697, 0.006191832944750786, 0.006208235397934914, 0.006088389549404383, 0.006364409811794758, 0.005953587591648102, 0.0059091756120324135, 0.0058272951282560825, 0.005721358582377434, 0.005539445206522942, 0.0054379673674702644, 0.005263573490083218, 0.005180129315704107, 0.0050533185712993145, 0.004961122293025255, 0.004825791344046593, 0.004615441430360079, 0.004484522622078657, 0.004541995003819466, 0.004256549756973982, 0.004186855163425207, 0.0040877992287278175, 0.0040325284935534, 0.0038131854962557554, 0.0036752652376890182, 0.003613855456933379, 0.0035557285882532597, 0.0034642890095710754, 0.003396574640646577, 0.0031842971220612526, 0.003164235968142748, 0.0030258577316999435, 0.002962449798360467, 0.0028940318152308464, 0.002789214486256242, 0.002765621291473508, 0.0026650114450603724, 0.002623755019158125, 0.0026059478987008333, 0.0025105748791247606, 0.002432173816487193, 0.0023897152859717607, 0.0023526200093328953, 0.0022969343699514866, 0.002264078939333558, 0.10524222999811172, 0.002181307878345251, 0.0021491916850209236, 0.002156830159947276, 0.002169738756492734, 0.1406341791152954, 0.0022112210281193256, 0.0022129027638584375, 0.4279562830924988, 0.00235796463675797, 0.002532136393710971, 0.11602859944105148, 0.002957577584311366, 0.003233018098399043, 0.0033198122400790453, 0.003478580852970481, 0.0038044615648686886, 0.0037554341834038496, 0.003865561680868268, 0.0038348790258169174, 0.00389664014801383, 0.004127494525164366, 0.14580969512462616, 0.004073319956660271, 0.004275785759091377, 0.004287926014512777, 0.004229495767503977, 0.004166895058006048, 0.00417283782735467, 0.004270582925528288, 0.12407787144184113, 0.004391151946038008, 0.13906560838222504, 0.004443556535989046, 0.004397645592689514, 0.4447942078113556, 0.004851007368415594, 0.005050166510045528, 0.005370158702135086, 0.0055025722831487656, 0.005878879223018885, 0.005817364435642958, 0.005984960123896599, 0.006079717539250851, 0.006163701880723238, 0.006189275532960892, 0.006357136648148298, 0.006277148146182299, 0.006216494366526604, 0.006044653709977865, 0.10686890780925751, 0.006181145552545786, 0.005977544002234936, 0.10977301001548767, 0.005935107823461294, 0.005925505887717009, 0.005802053026854992, 0.1581488996744156, 0.0060110450722277164, 0.0058019873686134815, 0.1244349256157875, 0.005789342802017927, 0.005823779851198196, 0.4429274797439575, 0.006125058978796005, 0.10787198692560196, 0.006831539794802666, 0.007284213788807392, 0.007321708370000124, 0.007363856304436922, 0.007517234887927771, 0.007688237354159355, 0.007644381374120712, 0.0993332639336586, 0.007730786222964525, 0.007724114693701267, 0.007814987562596798, 0.0076945568434894085, 0.007709919940680265, 0.1023758128285408, 0.007537324912846088, 0.00748396897688508, 0.007399377878755331, 0.007317860145121813, 0.12576843798160553, 0.007208479568362236, 0.007056313566863537, 0.007115194108337164, 0.1129874512553215, 0.09344543516635895, 0.006991180125623941, 0.006826021242886782, 0.006767300423234701, 0.006681291852146387, 0.0064817313104867935, 0.12014950811862946, 0.006406593602150679, 0.10704081505537033, 0.0064081307500600815, 0.006398456636816263, 0.006353417877107859, 0.006211068946868181, 0.006021478213369846, 0.005948339123278856, 0.005961546674370766, 0.005822896491736174, 0.005620722658932209, 0.0055198404006659985, 0.005526383873075247, 0.005229116417467594, 0.0050965119153261185, 0.004996316973119974, 0.00489103002473712, 0.004690229427069426, 0.0046755182556807995, 0.004489322658628225, 0.1444261074066162, 0.12245103716850281, 0.004336745943874121, 0.004466446582227945, 0.004336730111390352, 0.12090685963630676, 0.11940109729766846, 0.00435970863327384, 0.004415823612362146, 0.004402331542223692, 0.11480601131916046, 0.11496010422706604, 0.0046965316869318485, 0.13668465614318848, 0.004945908207446337, 0.004925304092466831, 0.005144663620740175, 0.005091405939310789, 0.13134828209877014, 0.10232498496770859, 0.005600497592240572, 0.005449546501040459, 0.38262659311294556, 0.14914169907569885, 0.006571872625499964, 0.006885218899697065, 0.007024526130408049, 0.007307369261980057, 0.007553637493401766, 0.15043312311172485, 0.00789159256964922, 0.008186622522771358, 0.008436551317572594, 0.008676129393279552, 0.008476749062538147, 0.00837173406034708, 0.008229990489780903, 0.008127166889607906, 0.008106458932161331, 0.008262095041573048, 0.007861461490392685, 0.11024744063615799, 0.007696518674492836, 0.007392934523522854, 0.007278111297637224, 0.007238592486828566, 0.007100594695657492, 0.006741443648934364, 0.0066383108496665955, 0.006425856612622738, 0.006221000105142593, 0.006108409259468317, 0.09426703304052353, 0.005779684986919165, 0.005695469211786985, 0.005568437743932009, 0.09418686479330063, 0.005410291254520416, 0.005233362782746553, 0.005209116265177727, 0.005149513483047485, 0.004996252711862326, 0.0048515950329601765, 0.004839619155973196, 0.004738722927868366, 0.004608683753758669, 0.10325509309768677, 0.13470539450645447, 0.3829123079776764, 0.004717632662504911, 0.1549059897661209, 0.005159781314432621, 0.129080131649971, 0.0057530151680111885, 0.0947703942656517, 0.0061919353902339935, 0.0064218188636004925, 0.006668476853519678, 0.00680894311517477, 0.00708002969622612, 0.007050848565995693, 0.13944055140018463, 0.007573102135211229, 0.007297144271433353, 0.007374628446996212, 0.007243748288601637, 0.007210369687527418, 0.12180153280496597, 0.35895150899887085, 0.10033606737852097, 0.13603349030017853, 0.00820496678352356, 0.008724777027964592, 0.008974047377705574, 0.09708033502101898, 0.009302203543484211, 0.14773675799369812, 0.009686379693448544, 0.06786242127418518, 0.010093186050653458, 0.01018911600112915, 0.01046794094145298, 0.010222936980426311, 0.009974186308681965, 0.009946944192051888, 0.009759421460330486, 0.009633714333176613, 0.009404764510691166, 0.13473239541053772, 0.009061581455171108, 0.12202384322881699, 0.008673135191202164, 0.008565620519220829, 0.10846788436174393, 0.008289803750813007, 0.00827009603381157, 0.09029905498027802, 0.007977546192705631, 0.007957839407026768, 0.007764417212456465, 0.007538927718997002, 0.007374946493655443, 0.007395625114440918, 0.007111945655196905, 0.006896735168993473, 0.006909065414220095, 0.13754643499851227, 0.006402166094630957, 0.00638155173510313, 0.08074229955673218, 0.006095567252486944, 0.0060747708193957806, 0.005973563063889742, 0.005763300694525242, 0.005629002116620541, 0.1046922504901886, 0.005581700708717108, 0.005368162412196398, 0.12278462946414948, 0.005318493116647005, 0.1336050182580948, 0.005330576095730066, 0.0053506880067288876, 0.13643240928649902, 0.005292117595672607, 0.005308572202920914, 0.0053354003466665745, 0.005348753184080124, 0.00544397160410881, 0.13040035963058472, 0.0053180912509560585, 0.13356846570968628, 0.10432176291942596, 0.0054384502582252026, 0.0054500531405210495, 0.0054895998910069466, 0.005601861514151096, 0.0056696804240345955, 0.005621316842734814, 0.005553206894546747, 0.005419148597866297, 0.005372168030589819, 0.005462708882987499, 0.005262765567749739, 0.005227093584835529, 0.13078509271144867, 0.005066525656729937, 0.005034981295466423, 0.004891253542155027, 0.004853381775319576, 0.12430713325738907, 0.00480616232380271, 0.41135552525520325, 0.0050482978112995625, 0.0051956139504909515, 0.005418074317276478, 0.005557655356824398, 0.0056713642552495, 0.1097828596830368, 0.005921990144997835, 0.09101922810077667, 0.006207472179085016, 0.09917204082012177, 0.38853099942207336, 0.10993847995996475, 0.007523391395807266, 0.007902869954705238, 0.008341887965798378, 0.008692929521203041, 0.008877968415617943, 0.009061616845428944, 0.009260711260139942, 0.009300959296524525, 0.34781742095947266, 0.009821061976253986, 0.10544329881668091, 0.010509682819247246, 0.01080549880862236, 0.011006779968738556, 0.01115628331899643, 0.01127498410642147, 0.08902391791343689, 0.011321085505187511, 0.011293678544461727, 0.011294272728264332, 0.011019684374332428, 0.011159355752170086, 0.010965082794427872, 0.010493732988834381, 0.010286659933626652, 0.009964138269424438, 0.009660398587584496, 0.009366903454065323, 0.6469439268112183, 0.009582499973475933, 0.009927366860210896, 0.010237529873847961, 0.010472246445715427, 0.01063441764563322, 0.100184865295887, 0.010875699110329151, 0.0957917720079422, 0.01097037736326456, 0.09157178550958633, 0.011110245250165462, 0.10629434883594513, 0.011095560155808926, 0.011062906123697758, 0.011139792390167713, 0.010918752290308475, 0.010790140368044376, 0.010624821297824383, 0.01038981694728136, 0.010099098086357117, 0.009873728267848492, 0.009687645360827446, 0.009550126269459724, 0.009124812670052052, 0.10525121539831161, 0.008581024594604969, 0.08537014573812485, 0.10585130751132965, 0.008169961161911488, 0.007985065691173077, 0.008103432133793831, 0.007781770080327988, 0.007662717718631029, 0.11428891867399216, 0.1140781119465828, 0.12379288673400879, 0.007240646984428167, 0.0073057664558291435, 0.12836940586566925, 0.0071955835446715355, 0.007150530815124512, 0.007126472424715757, 0.007100669667124748, 0.006983025930821896, 0.006842692848294973, 0.006728708278387785, 0.006606339011341333, 0.006507465615868568, 0.10720217227935791, 0.13741353154182434, 0.006282077170908451, 0.00631279032677412, 0.006188806612044573, 0.006229938007891178, 0.006086376961320639, 0.006138514261692762, 0.00608556205406785, 0.005848881788551807, 0.005725841503590345, 0.005619118921458721, 0.11891301721334457, 0.10669273138046265, 0.09158185869455338, 0.3762260675430298, 0.005827751941978931, 0.006043395027518272, 0.0062103066593408585, 0.006455770693719387, 0.006572074722498655, 0.11243300139904022, 0.11004715412855148, 0.007087052799761295, 0.0072268275544047356, 0.0074310339987277985, 0.10002274811267853, 0.10753635317087173, 0.007632572669535875, 0.0076950350776314735, 0.007731726858764887, 0.007948346436023712, 0.008115041069686413, 0.13307726383209229, 0.007960092276334763, 0.11894430220127106, 0.007873873226344585, 0.10294297337532043, 0.36604681611061096, 0.008151701651513577, 0.00847523845732212, 0.00882091373205185, 0.008957902900874615, 0.009112334810197353, 0.009149717167019844, 0.009422462433576584, 0.009348160587251186, 0.009360972791910172, 0.3268774449825287, 0.009603682905435562, 0.12032023072242737, 0.010024303570389748, 0.10463296622037888, 0.010207291692495346, 0.11761925369501114, 0.010487121529877186, 0.010861565358936787, 0.010690184310078621, 0.010759585537016392, 0.010895035229623318, 0.010546506382524967, 0.01057045254856348, 0.010286340489983559, 0.01019828300923109, 0.010070430114865303, 0.009689307771623135, 0.009537188336253166, 0.009157012216746807, 0.008840736001729965, 0.00868242233991623, 0.008528441190719604, 0.09763313829898834, 0.00791636947542429, 0.0076467436738312244, 0.007576965726912022, 0.121453195810318, 0.00716901570558548, 0.00725389551371336, 0.09432180970907211, 0.006970298942178488, 0.1385732889175415, 0.006603348068892956, 0.00653273006901145, 0.006451268680393696, 0.006370971444994211, 0.0063217743299901485, 0.0061597079038619995, 0.006133245769888163, 0.005876902956515551, 0.005968071520328522, 0.00575028732419014, 0.005662844516336918, 0.005480285733938217, 0.005289360880851746, 0.005189814604818821, 0.005026522558182478, 0.0049677882343530655, 0.004790125880390406, 0.11039518564939499, 0.004764581564813852, 0.0045938496477901936, 0.004463277757167816, 0.004472227767109871, 0.00440556276589632, 0.004250168800354004, 0.004389771725982428, 0.004076632671058178, 0.004006119444966316, 0.003941895440220833, 0.003938771318644285, 0.003813942661508918, 0.003718552878126502, 0.0036457213573157787, 0.003711405908688903, 0.0035173879005014896, 0.0034390485379844904, 0.1514909863471985, 0.0033202460035681725, 0.0033675669692456722, 0.0033121397718787193, 0.003285133047029376, 0.0032057480420917273, 0.003175742458552122, 0.0031466674990952015, 0.003143562702462077, 0.003060192335397005, 0.10416050255298615, 0.0030186267103999853, 0.10843957215547562, 0.0030712969601154327, 0.1116907149553299, 0.003107475582510233, 0.12197442352771759, 0.1294357180595398, 0.0033704121597111225, 0.003460394451394677, 0.0035533918999135494, 0.0035714092664420605, 0.0036025543231517076, 0.0036716177128255367, 0.1336234211921692, 0.0037333506625145674, 0.003802540712058544, 0.13478794693946838, 0.003937467932701111, 0.004002920817583799, 0.0040158168412745, 0.004110491834580898, 0.004140667151659727, 0.004234939347952604, 0.004125351086258888, 0.004175215493887663, 0.0041727409698069096, 0.09965979307889938, 0.13506744801998138, 0.11202610284090042, 0.10146511346101761, 0.004467756953090429, 0.0045986720360815525, 0.44259321689605713, 0.004914522636681795, 0.005210000555962324, 0.1300148218870163, 0.09812282770872116, 0.005999341607093811, 0.12000337988138199, 0.12482522428035736, 0.00694210035726428, 0.12262583523988724, 0.007525310385972261, 0.12738734483718872, 0.008184706792235374, 0.008313989266753197, 0.008339171297848225, 0.008470633067190647, 0.00876971147954464, 0.10494901239871979, 0.008816765621304512, 0.00886345561593771, 0.008806069381535053, 0.008803109638392925, 0.00863261241465807, 0.12229180335998535, 0.00875417422503233, 0.008676853962242603, 0.008587989024817944, 0.008321495726704597, 0.008108142763376236, 0.007964969612658024, 0.007951355539262295, 0.007639176212251186, 0.0074971625581383705, 0.007335180416703224, 0.10306467860937119, 0.10660839825868607, 0.006964332889765501, 0.37508633732795715, 0.007028562482446432, 0.007181351538747549, 0.007360129617154598, 0.007577953394502401, 0.007556566037237644, 0.007537269499152899, 0.007635265123099089, 0.00771206384524703, 0.007592086214572191, 0.00745055265724659, 0.007716519292443991, 0.007388674188405275, 0.007138464134186506, 0.007031312678009272, 0.006949863396584988, 0.006830455735325813, 0.006783084943890572, 0.12129372358322144, 0.006597574334591627, 0.006314651109278202, 0.006214659661054611, 0.006193881388753653, 0.006015060935169458, 0.0059422943741083145, 0.0942932739853859, 0.005689440295100212, 0.0056334733963012695, 0.005622720345854759, 0.0055318959057331085, 0.005681932438164949, 0.005218729842454195, 0.0051229544915258884, 0.005080768372863531, 0.12272016704082489, 0.005009201355278492, 0.004977433942258358, 0.00474485382437706, 0.11575014889240265, 0.004717820789664984, 0.004613216500729322, 0.10798682272434235, 0.004637667443603277, 0.004603486508131027, 0.11890043318271637, 0.13101579248905182, 0.004619689658284187, 0.004858178086578846, 0.004725004080682993, 0.004881987813860178, 0.004829282406717539, 0.004763759672641754, 0.0046972851268947124, 0.004735052585601807, 0.0928482934832573, 0.004706105682998896, 0.004641617648303509, 0.004711444023996592, 0.004661783576011658, 0.004679753910750151, 0.0044998060911893845, 0.11886707693338394, 0.004517530556768179, 0.004599158186465502, 0.12980856001377106, 0.0045311846770346165, 0.0044957902282476425, 0.004495247732847929, 0.004387169610708952, 0.004713513422757387, 0.15947481989860535, 0.13611766695976257, 0.004508223384618759, 0.0046178665943443775, 0.004800190683454275, 0.004852112848311663, 0.0044920193031430244, 0.14640642702579498, 0.004572631325572729, 0.004517400171607733, 0.004559270106256008, 0.004631249234080315, 0.11609902232885361, 0.004818709567189217, 0.004673681687563658, 0.11499069631099701, 0.004653648938983679, 0.004618441686034203, 0.13858550786972046, 0.0047340355813503265, 0.004776417277753353, 0.004769785329699516, 0.004801461938768625, 0.004761758726090193, 0.004794145002961159, 0.004721169825643301, 0.004713594913482666, 0.004874264355748892, 0.13269910216331482, 0.1267695426940918, 0.425620436668396, 0.08394692838191986, 0.00535209896042943, 0.005532332230359316, 0.005637849681079388, 0.005866008345037699, 0.006023028865456581, 0.006227961275726557, 0.07548978179693222, 0.0064482539892196655, 0.006691151298582554, 0.00651892414316535, 0.006756200455129147, 0.11631777882575989, 0.006649181246757507, 0.006728699430823326, 0.006719912867993116, 0.006724995095282793, 0.006672515068203211, 0.08003870397806168, 0.38560205698013306, 0.09424114227294922, 0.0072200605645775795, 0.00745801767334342, 0.12965625524520874, 0.007911932654678822, 0.008047135546803474, 0.00840388610959053, 0.11052991449832916, 0.008478817529976368, 0.15198810398578644, 0.00851526577025652, 0.008597027510404587, 0.14181086421012878, 0.008785288780927658, 0.00893824826925993, 0.008955016732215881, 0.008864378556609154, 0.008701546117663383, 0.008713079616427422, 0.008684756234288216, 0.008347980678081512, 0.00841041561216116, 0.008091147057712078, 0.10710079222917557, 0.007841991260647774, 0.007727988995611668, 0.3457716107368469, 0.007673780899494886, 0.008118654601275921, 0.007935264147818089, 0.008061437867581844, 0.008242333307862282, 0.12689825892448425, 0.10131713002920151, 0.008234687149524689, 0.008080326952040195, 0.008273372426629066, 0.00813562422990799, 0.09958543628454208, 0.104453444480896, 0.007972014136612415, 0.008016526699066162, 0.1168288066983223, 0.008097835816442966, 0.007955479435622692, 0.008056285791099072, 0.007812914438545704, 0.007817455567419529, 0.007637272123247385, 0.007637069094926119, 0.09879511594772339, 0.007349490188062191, 0.10167384892702103, 0.007602456025779247, 0.00719401054084301, 0.007066621445119381, 0.006958297919481993, 0.00691201351583004, 0.006780229974538088, 0.006767432205379009, 0.006533485371619463, 0.006388793233782053, 0.11825623363256454, 0.10255001485347748, 0.006334803067147732, 0.006148889660835266, 0.006056380923837423, 0.006053057033568621, 0.0991019681096077, 0.39119768142700195, 0.006378822959959507, 0.11690215766429901, 0.006479496601969004, 0.006849953904747963, 0.007303235121071339, 0.11069665104150772, 0.007160131819546223, 0.007340999785810709, 0.09438074380159378, 0.007305859588086605, 0.0074826013296842575, 0.10498540848493576, 0.007558214943856001, 0.007718553766608238, 0.007633651606738567, 0.0076096379198133945, 0.1351042538881302, 0.00756010040640831, 0.08995271474123001, 0.0992884412407875, 0.007702050264924765, 0.007840966805815697, 0.007819084450602531, 0.007677420973777771, 0.007512051612138748, 0.00788335781544447, 0.10910063982009888, 0.007262120023369789, 0.11276371031999588, 0.007446715142577887, 0.0071974992752075195, 0.007332737557590008, 0.0071704573929309845, 0.006880394648760557, 0.09294863790273666, 0.11020408570766449, 0.006802189163863659, 0.006888998206704855, 0.006903278175741434, 0.006708070635795593, 0.006691960617899895, 0.0064970930106937885, 0.006348986178636551, 0.12281651794910431, 0.0062324474565684795, 0.0064760418608784676, 0.4523864984512329, 0.006262509617954493, 0.006675574462860823, 0.006586683914065361, 0.006732790730893612, 0.007147528696805239, 0.006942844018340111, 0.006809953134506941, 0.006897646002471447, 0.36291754245758057, 0.00723239965736866, 0.007396581117063761, 0.0076950001530349255, 0.007644289638847113, 0.007787778507918119, 0.008200529031455517, 0.007903020828962326, 0.0078956987708807, 0.007845738902688026, 0.007895814254879951, 0.008061914704740047, 0.007702203001827002, 0.007757259998470545, 0.007597464136779308, 0.007405390497297049, 0.007619146257638931, 0.007337130140513182, 0.007082623429596424, 0.006976804696023464, 0.006693272385746241, 0.006687989458441734, 0.006421235855668783, 0.006462631747126579, 0.00640589464455843, 0.006065866444259882, 0.005852519068866968, 0.005753036122769117, 0.12564866244792938, 0.005470719188451767, 0.005416884087026119, 0.005440534558147192, 0.00538586126640439, 0.0050511849112808704, 0.1226501539349556, 0.004998119547963142, 0.0049433596432209015, 0.004788680467754602, 0.004714721813797951, 0.004675737582147121, 0.0046111587435007095, 0.35215646028518677, 0.004795089364051819, 0.10070923715829849, 0.12187556177377701, 0.005120089743286371, 0.005252740811556578, 0.005283951293677092, 0.005406349431723356, 0.09971769154071808, 0.005639619659632444, 0.0059665776789188385, 0.005817759782075882, 0.10302980989217758, 0.005988951772451401, 0.006073467433452606, 0.005909899715334177, 0.00589106697589159, 0.006110656540840864, 0.40120866894721985, 0.11049611866474152, 0.006352021358907223, 0.006519393529742956, 0.006880408618599176, 0.007122880779206753, 0.14080318808555603, 0.007112847175449133, 0.007302520330995321, 0.007574975490570068, 0.007473430596292019, 0.007531602401286364, 0.007368911523371935, 0.09830957651138306, 0.1294081062078476, 0.14388634264469147, 0.007481132168322802, 0.007950859144330025, 0.007784493267536163, 0.007712821941822767, 0.007477630395442247, 0.007582775317132473, 0.007556261494755745, 0.0074185337871313095, 0.10690825432538986, 0.007232373114675283, 0.007165980059653521, 0.1175646111369133, 0.007296581752598286, 0.007144033908843994, 0.00704932538792491, 0.006848662625998259, 0.006859567016363144, 0.006686607375741005, 0.006570914294570684, 0.10326137393712997, 0.006389721296727657, 0.006320228334516287, 0.006298838183283806, 0.006319892592728138, 0.10424058139324188, 0.005978398025035858, 0.006027195602655411, 0.005829331930726767, 0.005971564445644617, 0.0059526716358959675, 0.005626858212053776, 0.0056497338227927685, 0.005437355488538742, 0.005363935604691505, 0.005393872503191233, 0.00522572360932827, 0.005055150482803583, 0.005018496885895729, 0.004990752786397934, 0.11175147444009781, 0.004711258690804243, 0.39893868565559387, 0.0048307920806109905, 0.362798810005188, 0.005255461670458317, 0.0057608564384281635, 0.10464104264974594, 0.006160784978419542, 0.006575282197445631, 0.11434949934482574, 0.006756651680916548, 0.0071405270136892796, 0.007210175972431898, 0.007388466037809849, 0.007429535500705242, 0.007429154124110937, 0.11968851834535599, 0.007596639450639486, 0.007727785035967827, 0.007851988077163696, 0.12862859666347504, 0.0076479134149849415, 0.0867830216884613, 0.007654075510799885, 0.007709619589149952, 0.007885915227234364, 0.007694420870393515, 0.007519344799220562, 0.007711132522672415, 0.007342732045799494, 0.0073524354957044125, 0.007502857595682144, 0.12857960164546967, 0.007059227209538221, 0.007041478529572487, 0.0068087088875472546, 0.11883485317230225, 0.10269270837306976, 0.006668477784842253, 0.0066166105680167675, 0.007069522514939308, 0.006572851445525885, 0.006487824022769928, 0.11686377227306366, 0.0063423276878893375, 0.006571381818503141, 0.11460854858160019, 0.006379112601280212, 0.11904964596033096, 0.006471112370491028, 0.0063421111553907394, 0.10359512269496918, 0.09432940185070038, 0.006250690668821335, 0.006287695374339819, 0.006215674802660942, 0.006313834805041552, 0.00617522606626153, 0.006155714392662048, 0.006101371720433235, 0.10463077574968338, 0.0061837718822062016, 0.006060137413442135, 0.006026105023920536, 0.005942094139754772, 0.006058914586901665, 0.005804648157209158, 0.005713641177862883, 0.005685058422386646, 0.005514256656169891, 0.005484596360474825, 0.005451641511172056, 0.0053284550085663795, 0.00519197341054678, 0.005066664889454842, 0.11665090918540955, 0.11406576633453369, 0.004920887760818005, 0.005089565645903349, 0.004930687602609396, 0.004846556112170219, 0.004862811882048845, 0.1209995448589325, 0.0047974009066820145, 0.004770828410983086, 0.12924647331237793, 0.004816178698092699, 0.004842832684516907, 0.004912038333714008, 0.004795370623469353, 0.004761924967169762, 0.00473533570766449, 0.00475692143663764, 0.004656228236854076, 0.004671968054026365, 0.004527996759861708, 0.004532323684543371, 0.3608425557613373, 0.004641484469175339, 0.004663479048758745, 0.09815369546413422, 0.12487903237342834, 0.005090123508125544, 0.005163710098713636, 0.005257958546280861, 0.005287007428705692, 0.005457531660795212, 0.10984167456626892, 0.005629634018987417, 0.005711231846362352, 0.005555673968046904, 0.006048869341611862, 0.005654656793922186, 0.00555218942463398, 0.13478583097457886, 0.005540711805224419, 0.005638974718749523, 0.0055541074834764, 0.005744320806115866, 0.09464720636606216, 0.005625237710773945, 0.005724667571485043, 0.005606791935861111, 0.11049581319093704, 0.10949734598398209, 0.005437979940325022, 0.005716973915696144, 0.005581812933087349, 0.005686262622475624, 0.0054851192981004715, 0.005437973886728287, 0.11102043092250824, 0.005447361618280411, 0.005383610259741545, 0.00538407638669014, 0.00535613764077425, 0.005316890776157379, 0.11308077722787857, 0.005236822180449963, 0.0051570008508861065, 0.005290452390909195, 0.005375585984438658, 0.00521631957963109, 0.005096002481877804, 0.13215260207653046, 0.00528336688876152, 0.005389479920268059, 0.1323847621679306, 0.005037802271544933, 0.005014055408537388, 0.005043818149715662, 0.005018680356442928, 0.004974954295903444, 0.004856398794800043, 0.004938484635204077, 0.14383944869041443, 0.0046684630215168, 0.0049593690782785416, 0.0047540911473333836, 0.11719730496406555, 0.14362244307994843, 0.004703395999968052, 0.004712143912911415, 0.13270391523838043, 0.00497043551877141, 0.0047579603269696236, 0.004856278654187918, 0.10369885712862015, 0.00485777435824275, 0.005140455439686775, 0.005134943872690201, 0.13527032732963562, 0.005016046110540628, 0.10752645134925842, 0.0050016432069242, 0.005216358229517937, 0.005127116572111845, 0.005156124476343393, 0.1073656901717186, 0.005151032470166683, 0.1257302314043045, 0.11876877397298813, 0.005272957496345043, 0.005383476614952087, 0.09637035429477692, 0.0054847984574735165, 0.005768429022282362, 0.005541548132896423, 0.005612420383840799, 0.10724775493144989, 0.10165473818778992, 0.0057092271745204926, 0.005752644967287779, 0.1176680400967598, 0.005887506529688835, 0.005801199935376644, 0.005919476971030235, 0.006014032289385796, 0.006021882873028517, 0.00583759555593133, 0.005849319975823164, 0.005918246228247881, 0.00568637577816844, 0.005801653955131769, 0.005605408921837807, 0.00548175536096096, 0.12006044387817383, 0.0055544376373291016, 0.005585743114352226, 0.005332650151103735, 0.005234033800661564, 0.005357098765671253, 0.005244530737400055, 0.0050419350154697895, 0.005091432482004166, 0.005017917603254318, 0.004928005859255791, 0.004881910979747772, 0.004729775711894035, 0.15266481041908264, 0.004585201386362314, 0.09011943638324738, 0.004524679854512215, 0.004666204564273357, 0.004487429279834032, 0.0044981734827160835, 0.004512259736657143, 0.0046071698889136314, 0.004399033263325691, 0.0043272594921290874, 0.11274109035730362, 0.0042867837473750114, 0.004298488609492779, 0.004331179428845644, 0.004160179756581783, 0.004142602905631065, 0.004231185652315617, 0.004228401463478804, 0.1206476241350174, 0.004062431864440441, 0.004066193010658026, 0.0039520831778645515, 0.1284853219985962, 0.004033473785966635, 0.003967894706875086, 0.004170949570834637, 0.004006658215075731, 0.00406927615404129, 0.004041710402816534, 0.003937826491892338, 0.003912069369107485, 0.0038981898687779903, 0.40432998538017273, 0.003907994367182255, 0.004200783558189869, 0.00412928219884634, 0.004260840825736523, 0.00429975101724267, 0.12252989411354065, 0.004421859513968229, 0.0046932813711464405, 0.13946136832237244, 0.00462036207318306, 0.004773613065481186, 0.004729128442704678, 0.004906006623059511, 0.0049062855541706085, 0.004872477613389492, 0.0049840412102639675, 0.004870669450610876, 0.1049925833940506, 0.11368948966264725, 0.004847431089729071, 0.004982128273695707, 0.004960049409419298, 0.12259889394044876, 0.004977953154593706, 0.005135901737958193, 0.10868605971336365, 0.005084720905870199, 0.005192564334720373, 0.12833353877067566, 0.005129730328917503, 0.36315083503723145, 0.005416181404143572, 0.005549613386392593, 0.005789403337985277, 0.12504062056541443, 0.006058074068278074, 0.006374620832502842, 0.11916735023260117, 0.00637091975659132, 0.006772747728973627, 0.006600971799343824, 0.006649384740740061, 0.00669699115678668, 0.12473219633102417, 0.006842370610684156, 0.006811062339693308, 0.006907501257956028, 0.0068779150024056435, 0.0067444476298987865, 0.10748636722564697, 0.11254042387008667, 0.09090349078178406, 0.006995587609708309, 0.12913566827774048, 0.007033692207187414, 0.006913354154676199, 0.006901576649397612, 0.007024921476840973, 0.11809366941452026, 0.00698276748880744, 0.12785279750823975, 0.007018158677965403, 0.006975972093641758, 0.007062551099807024, 0.006984222214668989, 0.0068608964793384075, 0.006789958570152521, 0.006742938421666622, 0.006771234329789877, 0.10197779536247253, 0.006724129896610975, 0.12101326137781143, 0.006485536694526672, 0.14159469306468964, 0.006464774254709482, 0.006650190334767103, 0.006665114313364029, 0.006577029824256897, 0.17126986384391785, 0.006410117261111736, 0.006397152319550514, 0.006307532545179129, 0.1215478777885437, 0.006350039038807154, 0.006371906027197838, 0.3885282874107361, 0.006413719616830349, 0.006574329454451799, 0.0068254778161644936, 0.007035484071820974, 0.006879563909024, 0.35690823197364807, 0.007205246016383171, 0.007414132822304964, 0.0076730805449187756, 0.007775960490107536, 0.12235201150178909, 0.00835636630654335, 0.008164271712303162, 0.008231916464865208, 0.008335664868354797, 0.008614672347903252, 0.008444556966423988, 0.10936518013477325, 0.008427287451922894, 0.29794663190841675, 0.008511633612215519, 0.1304336041212082, 0.008867642842233181, 0.008989195339381695, 0.009148998185992241, 0.009285472333431244, 0.009413649328052998, 0.009314510971307755, 0.009202658198773861, 0.11403835564851761, 0.009239575825631618, 0.07759493589401245, 0.10941782593727112, 0.00921347364783287, 0.009479857049882412, 0.009226064197719097, 0.009200929664075375, 0.009113647043704987, 0.008898362517356873, 0.00876800436526537, 0.008669896982610226, 0.008680184371769428, 0.008428568951785564, 0.008241239935159683, 0.10824496299028397, 0.008030177094042301, 0.10773278027772903, 0.11135895550251007, 0.10759247094392776, 0.10771115869283676, 0.007886054925620556, 0.007769112009555101, 0.007956799119710922, 0.1054806262254715, 0.007781007792800665, 0.007808633614331484, 0.007909329608082771, 0.11506789177656174, 0.007653221487998962, 0.007792966905981302, 0.00757996179163456, 0.007452316582202911, 0.007486936170607805, 0.0074600703082978725, 0.0072367191314697266, 0.007139625959098339, 0.007056177593767643, 0.0068793813697993755, 0.11135372519493103, 0.0069655803963541985, 0.006630200892686844, 0.3458629548549652, 0.006646886933594942, 0.006912443321198225, 0.006846553646028042, 0.006898839026689529, 0.006995665840804577, 0.00699244812130928, 0.007082894444465637, 0.13056965172290802, 0.11444435268640518, 0.007048852276057005, 0.006990063935518265, 0.35822829604148865, 0.007329660467803478, 0.007436992134898901]\n",
            "Val loss 0.032236059497735926\n",
            "Val auc roc 0.5000894337467924\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c4f1ace329041e58778cd62937693e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1663.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0357\n",
            "Train Losses : [0.007697455585002899, 0.007772579323500395, 0.007929881103336811, 0.007953854277729988, 0.00780544662848115, 0.007887391373515129, 0.007859715260565281, 0.008007530122995377, 0.00776114733889699, 0.08425958454608917, 0.007706673815846443, 0.0077035692520439625, 0.10640442371368408, 0.007701050490140915, 0.007528567686676979, 0.10934582352638245, 0.10254526138305664, 0.007492689415812492, 0.007642591837793589, 0.0073723141103982925, 0.007358027156442404, 0.007294479291886091, 0.007267956156283617, 0.007175651844590902, 0.007184894289821386, 0.007025426719337702, 0.00700770178809762, 0.10464132577180862, 0.13052594661712646, 0.006714612245559692, 0.1352338194847107, 0.006666592787951231, 0.10013774782419205, 0.00669898372143507, 0.11624574661254883, 0.006679498590528965, 0.006625406444072723, 0.006625817622989416, 0.0066320267505943775, 0.11662459373474121, 0.0066575780510902405, 0.006738089025020599, 0.006639831233769655, 0.0064694625325500965, 0.0064190952107310295, 0.006353956647217274, 0.1025589257478714, 0.006261501926928759, 0.006217988207936287, 0.006188902072608471, 0.0061417738907039165, 0.006130778230726719, 0.006070129107683897, 0.0058898720890283585, 0.005865858867764473, 0.1072128564119339, 0.005729688331484795, 0.005647077690809965, 0.005620709154754877, 0.005570610519498587, 0.0054557728581130505, 0.0054353331215679646, 0.005358814261853695, 0.005270706955343485, 0.005277248565107584, 0.1321759968996048, 0.005225441884249449, 0.005124266259372234, 0.005052540916949511, 0.11216253787279129, 0.004986461251974106, 0.004881789442151785, 0.12930597364902496, 0.10755853354930878, 0.0049548703245818615, 0.1279028058052063, 0.004974927753210068, 0.0051392605528235435, 0.005173698533326387, 0.005055894143879414, 0.005043036304414272, 0.1398058384656906, 0.005114506930112839, 0.1033421978354454, 0.005073806270956993, 0.005208206363022327, 0.00512557802721858, 0.005085524637252092, 0.005140214692801237, 0.005131366662681103, 0.10391739010810852, 0.0050315470434725285, 0.005254179704934359, 0.11154218763113022, 0.005144480615854263, 0.005107004661113024, 0.1303076148033142, 0.005074580665677786, 0.005246996413916349, 0.00510453013703227, 0.00513238413259387, 0.0050547304563224316, 0.005025613587349653, 0.0050154877826571465, 0.11034710705280304, 0.005105969030410051, 0.005072783678770065, 0.12702801823616028, 0.0049615767784416676, 0.09149787575006485, 0.005017166957259178, 0.004959423560649157, 0.005059319082647562, 0.004994912538677454, 0.004993700888007879, 0.004992128815501928, 0.004916362464427948, 0.004959998652338982, 0.004883138462901115, 0.004774564411491156, 0.004756593611091375, 0.004726152401417494, 0.004772615619003773, 0.004592402838170528, 0.004578728694468737, 0.004495706874877214, 0.00447773328050971, 0.00440141512081027, 0.004307078197598457, 0.09351807832717896, 0.004237657878547907, 0.11702520400285721, 0.004217151552438736, 0.0042945812456309795, 0.00418699299916625, 0.0042159282602369785, 0.004235151689499617, 0.004225651267915964, 0.0041469912976026535, 0.004173275548964739, 0.0040205661207437515, 0.004030624404549599, 0.003978387452661991, 0.003965052310377359, 0.004020998254418373, 0.003842446021735668, 0.003772161202505231, 0.003779251594096422, 0.003766667563468218, 0.0036922774743288755, 0.0036529002245515585, 0.003584781661629677, 0.0036056283861398697, 0.409377783536911, 0.10639148950576782, 0.003767573507502675, 0.07977136224508286, 0.004010905046015978, 0.0039789569564163685, 0.0041079348884522915, 0.004157134331762791, 0.004198460839688778, 0.13423950970172882, 0.004392141476273537, 0.004485452547669411, 0.0044182781130075455, 0.11931164562702179, 0.004620514810085297, 0.004682579077780247, 0.004560777917504311, 0.004667520523071289, 0.004686097148805857, 0.004671374801546335, 0.004663432482630014, 0.004585907328873873, 0.004649741109460592, 0.004536517895758152, 0.12468423694372177, 0.0047246115282177925, 0.004536096006631851, 0.08735217154026031, 0.004520299378782511, 0.004508142359554768, 0.1279652863740921, 0.12157383561134338, 0.12877021729946136, 0.11222173273563385, 0.004782125819474459, 0.38241901993751526, 0.005048977676779032, 0.0053406343795359135, 0.005563859362155199, 0.005637256894260645, 0.005782487336546183, 0.0058296313509345055, 0.005973456427454948, 0.006321498192846775, 0.006008917465806007, 0.006049409508705139, 0.006088967900723219, 0.006252944003790617, 0.0060737659223377705, 0.006042704451829195, 0.006047341972589493, 0.005962810013443232, 0.005922927055507898, 0.006102793850004673, 0.0059251924976706505, 0.11114718019962311, 0.005776416044682264, 0.00588189996778965, 0.005784415639936924, 0.005957059562206268, 0.005548994522541761, 0.005570617504417896, 0.005517393816262484, 0.005459941923618317, 0.005338183604180813, 0.005249699577689171, 0.09800973534584045, 0.00518421083688736, 0.0051362477242946625, 0.005105154123157263, 0.005081369075924158, 0.004965431056916714, 0.00504114106297493, 0.004849121905863285, 0.004931596573442221, 0.37883031368255615, 0.0048542320728302, 0.004953052382916212, 0.00518990121781826, 0.005172173026949167, 0.00506869051605463, 0.00513598695397377, 0.005189177114516497, 0.005325144622474909, 0.005161635112017393, 0.005250278394669294, 0.005183717701584101, 0.13282595574855804, 0.005094410851597786, 0.005118494853377342, 0.005064898170530796, 0.005139900371432304, 0.10138049721717834, 0.1350220888853073, 0.005103925708681345, 0.005173631478101015, 0.005392847582697868, 0.005085355136543512, 0.005256819073110819, 0.09740309417247772, 0.0053130853921175, 0.11440341174602509, 0.005229320377111435, 0.005076186265796423, 0.005240313708782196, 0.005135012324899435, 0.005115157924592495, 0.005270959809422493, 0.005027358885854483, 0.004974561743438244, 0.005038944073021412, 0.005111044272780418, 0.13208840787410736, 0.1135617271065712, 0.004966306034475565, 0.10584858059883118, 0.004943876527249813, 0.0048934221267700195, 0.0049818833358585835, 0.004973281174898148, 0.004902031738311052, 0.004897246137261391, 0.004855212289839983, 0.0048370929434895515, 0.005193901713937521, 0.004892271012067795, 0.09576581418514252, 0.0046986425295472145, 0.004725285805761814, 0.004737827926874161, 0.004728458821773529, 0.004721186589449644, 0.0046723452396690845, 0.004538842011243105, 0.00447949580848217, 0.10336803644895554, 0.004587983712553978, 0.004393281880766153, 0.004515714943408966, 0.004356022458523512, 0.004404144827276468, 0.004318006336688995, 0.004253290127962828, 0.00420919805765152, 0.004197603091597557, 0.09485143423080444, 0.004109463654458523, 0.004119194578379393, 0.004114764742553234, 0.13974863290786743, 0.13431985676288605, 0.004152898211032152, 0.004365054424852133, 0.0043115695007145405, 0.004223459400236607, 0.004504326265305281, 0.004183387849479914, 0.004107262473553419, 0.004090047441422939, 0.0041619255207479, 0.004234234802424908, 0.004245417192578316, 0.0042246864177286625, 0.003971182741224766, 0.12689299881458282, 0.16358180344104767, 0.00393217196688056, 0.003958083223551512, 0.11262539774179459, 0.11168624460697174, 0.004199797287583351, 0.004131544381380081, 0.1254240721464157, 0.004293681122362614, 0.004679379519075155, 0.11556308716535568, 0.004325035493820906, 0.004499098751693964, 0.00441964203491807, 0.004429860506206751, 0.004423094447702169, 0.004444440361112356, 0.0047010197304189205, 0.004617700353264809, 0.004388750530779362, 0.39607977867126465, 0.08691750466823578, 0.11077088862657547, 0.1131168082356453, 0.00522603327408433, 0.005019862204790115, 0.0054422225803136826, 0.14053484797477722, 0.005427964963018894, 0.005744578316807747, 0.0055469730868935585, 0.005765658803284168, 0.006169662810862064, 0.005895611830055714, 0.16404932737350464, 0.005895448848605156, 0.00580785283818841, 0.005916428752243519, 0.005868552252650261, 0.005862723104655743, 0.10299652069807053, 0.005958830006420612, 0.0058319480158388615, 0.0059186979196965694, 0.005779420956969261, 0.0060439081862568855, 0.005749803967773914, 0.005801445804536343, 0.005924437195062637, 0.005585779435932636, 0.005781572312116623, 0.005722190253436565, 0.005613046698272228, 0.005399561952799559, 0.09490805119276047, 0.005270759575068951, 0.1053471490740776, 0.005495206452906132, 0.005299573764204979, 0.0051756007596850395, 0.005234315525740385, 0.10659704357385635, 0.09866197407245636, 0.13631123304367065, 0.12788106501102448, 0.005362056661397219, 0.005603827070444822, 0.0053749680519104, 0.12873512506484985, 0.005685362499207258, 0.13376787304878235, 0.1384141892194748, 0.07567176222801208, 0.00574854202568531, 0.3858981132507324, 0.10232879221439362, 0.09415926784276962, 0.1314031183719635, 0.10038929432630539, 0.006717261392623186, 0.007037597708404064, 0.0073760938830673695, 0.0073494031094014645, 0.12166690081357956, 0.007714203093200922, 0.007730268407613039, 0.008012142963707447, 0.13096420466899872, 0.00795699842274189, 0.008121165446937084, 0.13592587411403656, 0.008044742979109287, 0.008372832089662552, 0.008236097171902657, 0.008173270151019096, 0.008095090277493, 0.008060150779783726, 0.06072193384170532, 0.007970232516527176, 0.008154086768627167, 0.09511590749025345, 0.2690224051475525, 0.008196506649255753, 0.0079897316172719, 0.008342781104147434, 0.11153034120798111, 0.008428165689110756, 0.0898287296295166, 0.008564377203583717, 0.008997064083814621, 0.008792592212557793, 0.008416579104959965, 0.0830073431134224, 0.008808070793747902, 0.008924461901187897, 0.008526170626282692, 0.00885878223925829, 0.09616595506668091, 0.008737700991332531, 0.00829259306192398, 0.008092187345027924, 0.008063917979598045, 0.008564556017518044, 0.1341221034526825, 0.007795989513397217, 0.10465100407600403, 0.007660845294594765, 0.007678619120270014, 0.008084701374173164, 0.0075243269093334675, 0.07509410381317139, 0.007378729991614819, 0.0913742333650589, 0.0076109375804662704, 0.007262809667736292, 0.007209159433841705, 0.007657096721231937, 0.007297677453607321, 0.09341759234666824, 0.007200468797236681, 0.15087471902370453, 0.10528368502855301, 0.00710920337587595, 0.007192602846771479, 0.007488538511097431, 0.006918521597981453, 0.007111898623406887, 0.0071805380284786224, 0.006651328410953283, 0.006684388965368271, 0.006761437747627497, 0.006448457483202219, 0.11248225718736649, 0.006821231450885534, 0.0064720879308879375, 0.006666925270110369, 0.007154225371778011, 0.0065768747590482235, 0.39227575063705444, 0.006631828378885984, 0.006454868707805872, 0.0062891156412661076, 0.006374706979840994, 0.09912648797035217, 0.006662349216639996, 0.006746591534465551, 0.006396873854100704, 0.16096729040145874, 0.006976893171668053, 0.09640299528837204, 0.00704383896663785, 0.006609611678868532, 0.006796764675527811, 0.0067590391263365746, 0.006937972269952297, 0.12913690507411957, 0.006496671587228775, 0.0068809352815151215, 0.006636633072048426, 0.0067169140093028545, 0.0065863244235515594, 0.006425155326724052, 0.006990722846239805, 0.006406276952475309, 0.006371551658958197, 0.0064568049274384975, 0.006189243867993355, 0.00631680665537715, 0.13260051608085632, 0.006007434334605932, 0.005988914519548416, 0.37453722953796387, 0.006011523772031069, 0.006112286821007729, 0.11105477064847946, 0.12837126851081848, 0.006492170970886946, 0.1036539152264595, 0.006595912389457226, 0.0067875199019908905, 0.006670084316283464, 0.006741769146174192, 0.11943371593952179, 0.006742960307747126, 0.006876545958220959, 0.11702398210763931, 0.006693704519420862, 0.4100482761859894, 0.006989733781665564, 0.10222435742616653, 0.15180756151676178, 0.007373206317424774, 0.007758359424769878, 0.007986639626324177, 0.007911317981779575, 0.007739346008747816, 0.007874898612499237, 0.007777944672852755, 0.007688254117965698, 0.11811146885156631, 0.007773840334266424, 0.08200813829898834, 0.008143658749759197, 0.00817522220313549, 0.00790038239210844, 0.12967516481876373, 0.007841138169169426, 0.007849745452404022, 0.007814518176019192, 0.008003497496247292, 0.007835588417947292, 0.007851310074329376, 0.007797008380293846, 0.007550347596406937, 0.007516147568821907, 0.007514217868447304, 0.007353502791374922, 0.11358766257762909, 0.09146858751773834, 0.007342753931879997, 0.007089025340974331, 0.16593757271766663, 0.006989267189055681, 0.006873778998851776, 0.007156612351536751, 0.09484652429819107, 0.0069093224592506886, 0.08814042806625366, 0.006873325444757938, 0.1334376484155655, 0.1323656141757965, 0.006901992484927177, 0.006987669505178928, 0.13278838992118835, 0.006773912813514471, 0.007043592631816864, 0.3251056969165802, 0.006985792424529791, 0.007244833279401064, 0.007506921421736479, 0.007244485430419445, 0.007295043207705021, 0.007487613242119551, 0.007543780375272036, 0.007504415698349476, 0.37116310000419617, 0.007610890548676252, 0.007605675607919693, 0.008189192973077297, 0.008264658972620964, 0.00785615760833025, 0.008046294562518597, 0.09605401009321213, 0.008156821131706238, 0.008105261251330376, 0.09047824144363403, 0.007955615408718586, 0.008036821149289608, 0.39293161034584045, 0.00805648509413004, 0.1627519726753235, 0.08885163813829422, 0.008672475814819336, 0.008802052587270737, 0.009048931300640106, 0.008842606097459793, 0.10225299000740051, 0.008865874260663986, 0.0911419466137886, 0.008986659348011017, 0.008952377364039421, 0.008893170394003391, 0.009201022796332836, 0.009070259518921375, 0.009577245451509953, 0.008746396750211716, 0.00871781725436449, 0.08225660771131516, 0.008729622699320316, 0.008943631313741207, 0.008519290015101433, 0.009072447195649147, 0.1358383595943451, 0.008247951045632362, 0.07756627351045609, 0.09730270504951477, 0.008202336728572845, 0.008135555312037468, 0.008363449014723301, 0.008038968779146671, 0.11110014468431473, 0.008068416267633438, 0.007871937938034534, 0.008168687112629414, 0.007863050326704979, 0.007826271466910839, 0.08885164558887482, 0.007576072122901678, 0.007498516701161861, 0.11145695298910141, 0.10838575661182404, 0.007554704789072275, 0.007438088767230511, 0.007371935062110424, 0.10806140303611755, 0.007730236276984215, 0.0783490538597107, 0.007213622331619263, 0.0072664800100028515, 0.0922815278172493, 0.09146443009376526, 0.007256138604134321, 0.10524927824735641, 0.007263969164341688, 0.11774467676877975, 0.09773687273263931, 0.007335057482123375, 0.007439544424414635, 0.007671129424124956, 0.007635593879967928, 0.007262797560542822, 0.0072977058589458466, 0.007325636688619852, 0.007435740903019905, 0.007078474387526512, 0.007313678041100502, 0.00716746412217617, 0.11471348255872726, 0.007174516562372446, 0.1256805956363678, 0.007131033111363649, 0.00708496430888772, 0.006932322401553392, 0.0067940643057227135, 0.007095571141690016, 0.1235252171754837, 0.006710563786327839, 0.00682026706635952, 0.006709230598062277, 0.318659245967865, 0.11186036467552185, 0.006763656158000231, 0.30100753903388977, 0.007133645936846733, 0.007118933368474245, 0.007156155072152615, 0.007522203493863344, 0.09201301634311676, 0.007779852487146854, 0.00772491842508316, 0.00759931979700923, 0.007698900997638702, 0.008460224606096745, 0.007956137880682945, 0.007794334553182125, 0.0077554769814014435, 0.0076653179712593555, 0.0077497041784226894, 0.007663905154913664, 0.007593953516334295, 0.007676396053284407, 0.007525044493377209, 0.13811255991458893, 0.007833396084606647, 0.007670918945223093, 0.007457343861460686, 0.09573596715927124, 0.0072205690667033195, 0.1356503665447235, 0.11597524583339691, 0.007361649069935083, 0.007339477073401213, 0.08603277057409286, 0.007318414282053709, 0.0071904887445271015, 0.007018635980784893, 0.160797119140625, 0.00708480179309845, 0.00717349536716938, 0.007216149475425482, 0.007020183373242617, 0.007001493126153946, 0.007185432128608227, 0.00681304931640625, 0.1053168848156929, 0.1128462553024292, 0.14774875342845917, 0.15061834454536438, 0.3680967092514038, 0.007375012617558241, 0.10861363261938095, 0.11501093208789825, 0.007470087613910437, 0.007810204289853573, 0.007683346513658762, 0.007720182184129953, 0.007645245175808668, 0.007976849563419819, 0.00785567332059145, 0.008106129243969917, 0.007878949865698814, 0.00793471559882164, 0.007687859237194061, 0.007804675959050655, 0.008093210868537426, 0.007547910790890455, 0.43557900190353394, 0.0077455490827560425, 0.11695288121700287, 0.007845943793654442, 0.007897820323705673, 0.007846496067941189, 0.008103935047984123, 0.007916929200291634, 0.07972317188978195, 0.008276931941509247, 0.008002997376024723, 0.008167469874024391, 0.007858822122216225, 0.13681460916996002, 0.007894699461758137, 0.007972137071192265, 0.11457163840532303, 0.008141737431287766, 0.007881797850131989, 0.09238580614328384, 0.007697981782257557, 0.00808893796056509, 0.007680839393287897, 0.11297647655010223, 0.007666092365980148, 0.007901662029325962, 0.09599362313747406, 0.007758222986012697, 0.11543067544698715, 0.007785860914736986, 0.007719581481069326, 0.007744511589407921, 0.007578870747238398, 0.0677788183093071, 0.007364691235125065, 0.007419825065881014, 0.007257402408868074, 0.007268452551215887, 0.0072655752301216125, 0.007219129242002964, 0.6801548600196838, 0.007500592619180679, 0.007744803559035063, 0.007458304055035114, 0.11830689758062363, 0.007762368302792311, 0.0076731229200959206, 0.0077727241441607475, 0.09521611034870148, 0.12762707471847534, 0.00790806207805872, 0.007945694960653782, 0.007990455254912376, 0.00817651953548193, 0.00792086124420166, 0.008005299605429173, 0.008016116917133331, 0.008250197395682335, 0.007977769710123539, 0.08200892060995102, 0.007728357799351215, 0.0077866376377642155, 0.007782910950481892, 0.007704415824264288, 0.008286822587251663, 0.007692378479987383, 0.1522291600704193, 0.10881416499614716, 0.007560628931969404, 0.007461007684469223, 0.007520729675889015, 0.007410264573991299, 0.007267965003848076, 0.4418049454689026, 0.09306304156780243, 0.09371054172515869, 0.007869149558246136, 0.007892735302448273, 0.0076583498157560825, 0.10078055411577225, 0.0076848044991493225, 0.007825050503015518, 0.11487220227718353, 0.09231642633676529, 0.007972449995577335, 0.007808622904121876, 0.007867278531193733, 0.007853027433156967, 0.007983122020959854, 0.007976748049259186, 0.007834656164050102, 0.007807278539985418, 0.07788542658090591, 0.007767084054648876, 0.0077452328987419605, 0.13287028670310974, 0.008410691283643246, 0.13491171598434448, 0.007772249635308981, 0.10945186018943787, 0.09412520378828049, 0.007744729518890381, 0.007703943178057671, 0.00783366896212101, 0.0077347285114228725, 0.007784334942698479, 0.0076665328815579414, 0.007492780219763517, 0.3117944598197937, 0.09267444163560867, 0.007760860025882721, 0.007866289466619492, 0.007880904711782932, 0.00787696335464716, 0.007930905558168888, 0.007848098874092102, 0.007887362502515316, 0.007959423586726189, 0.008136955089867115, 0.007877440191805363, 0.09346753358840942, 0.007720744702965021, 0.1292795091867447, 0.13016732037067413, 0.09842664748430252, 0.09539459645748138, 0.008172763511538506, 0.007601427845656872, 0.007661823183298111, 0.00774433882907033, 0.0075799948535859585, 0.008363020606338978, 0.007937208749353886, 0.007544889114797115, 0.00769207114353776, 0.0074597629718482494, 0.007371601648628712, 0.007375963497906923, 0.007523504085838795, 0.007234422955662012, 0.007478292100131512, 0.007458875421434641, 0.007208414375782013, 0.006980108097195625, 0.0069150361232459545, 0.007248531561344862, 0.007057357579469681, 0.12780989706516266, 0.00686308229342103, 0.006715810392051935, 0.13244134187698364, 0.006623447872698307, 0.007134543266147375, 0.006608595140278339, 0.12967242300510406, 0.0067208209075033665, 0.0065508196130394936, 0.006459444295614958, 0.09812060743570328, 0.006428833585232496, 0.006359112448990345, 0.006417234893888235, 0.006291007623076439, 0.0063266693614423275, 0.11800453811883926, 0.006288665346801281, 0.11351773142814636, 0.006215228699147701, 0.0061590662226080894, 0.006213444750756025, 0.006191963795572519, 0.006165537983179092, 0.006036439444869757, 0.006197260692715645, 0.006317618303000927, 0.006095946300774813, 0.005952757317572832, 0.005910542793571949, 0.005942700430750847, 0.005933492444455624, 0.005916984751820564, 0.005775950849056244, 0.11574963480234146, 0.10662572085857391, 0.0059302207082509995, 0.005603651516139507, 0.0056172385811805725, 0.005579062737524509, 0.005573390517383814, 0.005528803449124098, 0.11118390411138535, 0.005514002405107021, 0.005538855213671923, 0.005536278709769249, 0.005697023123502731, 0.005657037254422903, 0.005615454167127609, 0.005587430205196142, 0.005530882626771927, 0.00530066154897213, 0.005588253494352102, 0.07421348989009857, 0.005251509137451649, 0.005191645585000515, 0.0053074355237185955, 0.005444538779556751, 0.005093168001621962, 0.1072758138179779, 0.005085046868771315, 0.005332707427442074, 0.005217911209911108, 0.005088654346764088, 0.12151788175106049, 0.005404763855040073, 0.39607298374176025, 0.12533456087112427, 0.10152508318424225, 0.005170709919184446, 0.005277616903185844, 0.00531598087400198, 0.005506216082721949, 0.005652580410242081, 0.13039885461330414, 0.005426711868494749, 0.005541528109461069, 0.08791819959878922, 0.10639610141515732, 0.005750257056206465, 0.005668686702847481, 0.005684313364326954, 0.005632677115499973, 0.005906107369810343, 0.005886796861886978, 0.00568600557744503, 0.005683644209057093, 0.005927207414060831, 0.0870497077703476, 0.005669178441166878, 0.005686549004167318, 0.005639016628265381, 0.12614139914512634, 0.0056749447248876095, 0.0057512917555868626, 0.1361212283372879, 0.005734281614422798, 0.005592517554759979, 0.005564815364778042, 0.09626616537570953, 0.12945257127285004, 0.005747005343437195, 0.005599870812147856, 0.005927763879299164, 0.005634746514260769, 0.005604284815490246, 0.005679278168827295, 0.0056581804528832436, 0.005598206073045731, 0.005767295137047768, 0.0055742422118783, 0.005488741677254438, 0.005562429316341877, 0.005552375689148903, 0.0056387800723314285, 0.08345623314380646, 0.0055291843600571156, 0.1186969205737114, 0.00539419986307621, 0.005367141682654619, 0.11763104796409607, 0.005405234172940254, 0.00541528919711709, 0.1368035078048706, 0.005396648775786161, 0.0053647831082344055, 0.005325731355696917, 0.11242847889661789, 0.005309492349624634, 0.0056226556189358234, 0.005332742352038622, 0.15119220316410065, 0.005334491841495037, 0.005336998030543327, 0.1250198632478714, 0.10449516773223877, 0.0053907111287117004, 0.005606707651168108, 0.005407363176345825, 0.005427288822829723, 0.005390224512666464, 0.005407880526036024, 0.0054082851856946945, 0.10080454498529434, 0.1350245326757431, 0.1362336426973343, 0.005564545281231403, 0.005432691890746355, 0.005456540267914534, 0.005634747911244631, 0.0055711581371724606, 0.10707434266805649, 0.11034383624792099, 0.11361521482467651, 0.005533731076866388, 0.005630117375403643, 0.005528602283447981, 0.00570908235386014, 0.005585928913205862, 0.08810022473335266, 0.005816296208649874, 0.005554454866796732, 0.00560849579051137, 0.005641287658363581, 0.005575715564191341, 0.0056111011654138565, 0.00558491749688983, 0.005579912569373846, 0.0056892940774559975, 0.005467465613037348, 0.005505015607923269, 0.005468476563692093, 0.005439538974314928, 0.005362466908991337, 0.005456328857690096, 0.005284124985337257, 0.0056087663397192955, 0.0052667343989014626, 0.005231160204857588, 0.00532043119892478, 0.005260249599814415, 0.00517646037042141, 0.005139176733791828, 0.11310802400112152, 0.005015937611460686, 0.005014457274228334, 0.005205856170505285, 0.10690736770629883, 0.8426735997200012, 0.11522173136472702, 0.005158198997378349, 0.005191674921661615, 0.005397850181907415, 0.005486891604959965, 0.005527140572667122, 0.00542990118265152, 0.13892410695552826, 0.10275175422430038, 0.005556139629334211, 0.08488819748163223, 0.005906932055950165, 0.005628179293125868, 0.006151010747998953, 0.005742344539612532, 0.11426548659801483, 0.005793784279376268, 0.00583273358643055, 0.0057405284605920315, 0.00587879866361618, 0.00578422611579299, 0.005916723050177097, 0.005853044800460339, 0.14487668871879578, 0.005925599951297045, 0.0060696969740092754, 0.10599425435066223, 0.0057394839823246, 0.005895512644201517, 0.005882771220058203, 0.005861223209649324, 0.00579566415399313, 0.005858742631971836, 0.0057118479162454605, 0.005788182374089956, 0.005686990916728973, 0.005865667946636677, 0.005638413596898317, 0.005707692354917526, 0.0057077775709331036, 0.11493254452943802, 0.1523163765668869, 0.09490381926298141, 0.10385285317897797, 0.005812681280076504, 0.12143120914697647, 0.005824644584208727, 0.005630949046462774, 0.005597172304987907, 0.36576932668685913, 0.005731329321861267, 0.09709947556257248, 0.13184036314487457, 0.005838616285473108, 0.1287473887205124, 0.005994852632284164, 0.006174589041620493, 0.006105467677116394, 0.006273654755204916, 0.006219983566552401, 0.006233345251530409, 0.006297840271145105, 0.0061946758069098, 0.13605226576328278, 0.006242809351533651, 0.006242440547794104, 0.006140370853245258, 0.006270912941545248, 0.0063615101389586926, 0.006286595482379198, 0.0062907044775784016, 0.006173078902065754, 0.006081837695091963, 0.37601539492607117, 0.006161131896078587, 0.0061598876491189, 0.006181775126606226, 0.006273485254496336, 0.006275221239775419, 0.006220577750355005, 0.09255287796258926, 0.006253858096897602, 0.006383699364960194, 0.00623273802921176, 0.0062769390642642975, 0.1371418982744217, 0.12702369689941406, 0.0062820990569889545, 0.006423781160265207, 0.006452601402997971, 0.006306619383394718, 0.41864487528800964, 0.006497679278254509, 0.006380925886332989, 0.14491824805736542, 0.006396613083779812, 0.006760087329894304, 0.006670934148132801, 0.00681014871224761, 0.006503617390990257, 0.0066064936108887196, 0.0066906469874084, 0.006600956432521343, 0.006698324345052242, 0.0067106205970048904, 0.0065917689353227615, 0.006524963304400444, 0.1268332600593567, 0.006655202247202396, 0.006542449351400137, 0.00650683743879199, 0.12174748629331589, 0.006516270339488983, 0.0067640794441103935, 0.00644460367038846, 0.3383559584617615, 0.006556159816682339, 0.12493547797203064, 0.006569169461727142, 0.006582076195627451, 0.006756062153726816, 0.006646459456533194, 0.0066597796976566315, 0.006666598375886679, 0.006724224891513586, 0.006652843672782183, 0.006700133439153433, 0.006567676551640034, 0.006610106211155653, 0.006584381218999624, 0.006896146107465029, 0.006557931192219257, 0.0065235416404902935, 0.12628024816513062, 0.006443616934120655, 0.0064544384367764, 0.10799407958984375, 0.11042429506778717, 0.0064912596717476845, 0.00645455764606595, 0.11201157420873642, 0.10392048209905624, 0.006565664429217577, 0.0064370958134531975, 0.14064835011959076, 0.006602248642593622, 0.006477410439401865, 0.00644031073898077, 0.00673905061557889, 0.006460926961153746, 0.006622812710702419, 0.006465068086981773, 0.006428314372897148, 0.006460920441895723, 0.006403950043022633, 0.0063622198067605495, 0.0063442387618124485, 0.006379867438226938, 0.006295089144259691, 0.13890181481838226, 0.12023540586233139, 0.122342549264431, 0.006311594508588314, 0.006251968909054995, 0.006204168312251568, 0.006220946554094553, 0.006308937445282936, 0.12253033369779587, 0.00629554083570838, 0.0063617113046348095, 0.0063525778241455555, 0.1299651712179184, 0.00626024417579174, 0.006264386232942343, 0.006292016711086035, 0.006181709934026003, 0.00618635443970561, 0.006160215474665165, 0.006210973486304283, 0.10046014189720154, 0.0061348071321845055, 0.006142677739262581, 0.006148024927824736, 0.12986674904823303, 0.006106444634497166, 0.006281720940023661, 0.07655069977045059, 0.006073999684303999, 0.11065582931041718, 0.006024717353284359, 0.006078033242374659, 0.006032908335328102, 0.00597385922446847, 0.005957889370620251, 0.09424727410078049, 0.09574710577726364, 0.006118099670857191, 0.09146246314048767, 0.006159900687634945, 0.00621778704226017, 0.006272970698773861, 0.006270418409258127, 0.006024531088769436, 0.1007598489522934, 0.1172734871506691, 0.005971767473965883, 0.006049211136996746, 0.006047965958714485, 0.1058989092707634, 0.00592802045866847, 0.006035907659679651, 0.005978593602776527, 0.00604667142033577, 0.005959006492048502, 0.006174345500767231, 0.005895144306123257, 0.006005742121487856, 0.005901525262743235, 0.005886626895517111, 0.12574926018714905, 0.006026341579854488, 0.006007161922752857, 0.005917641334235668, 0.10736218094825745, 0.09125997126102448, 0.006003933027386665, 0.005917941220104694, 0.005914931185543537, 0.005922282580286264, 0.005842291750013828, 0.005763713736087084, 0.005945185199379921, 0.005831324029713869, 0.005898632109165192, 0.005768927745521069, 0.005780852399766445, 0.005719869863241911, 0.10718294233083725, 0.005672407802194357, 0.005749172065407038, 0.005834168754518032, 0.005780047737061977, 0.00580989383161068, 0.005618521012365818, 0.11016912758350372, 0.005551502108573914, 0.005631921347230673, 0.005601861979812384, 0.0056710937060415745, 0.0057079545222222805, 0.005590112879872322, 0.005525974556803703, 0.4064170718193054, 0.0055780112743377686, 0.00560044264420867, 0.005564037710428238, 0.005723149050027132, 0.005598958116024733, 0.005676025524735451, 0.005584190133959055, 0.12945325672626495, 0.005850702989846468, 0.1607217788696289, 0.005630080588161945, 0.11205940693616867, 0.005598241928964853, 0.005645710974931717, 0.005815439857542515, 0.005750883370637894, 0.11140935122966766, 0.005743016954511404, 0.005737378727644682, 0.00565430149435997, 0.00561344251036644, 0.11699087917804718, 0.13191035389900208, 0.0056388722732663155, 0.10594800114631653, 0.005685107316821814, 0.005757369101047516, 0.0058213407173752785, 0.0056881383061409, 0.005688450299203396, 0.005708022508770227, 0.00569519679993391, 0.005612178705632687, 0.00579276867210865, 0.005816914141178131, 0.005743465386331081, 0.0057932841591537, 0.11944018304347992, 0.005625901278108358, 0.005660634022206068, 0.005706359166651964, 0.005684026516973972, 0.12708666920661926, 0.005751597695052624, 0.005579361226409674, 0.09699919074773788, 0.005636329296976328, 0.09762530773878098, 0.11268237233161926, 0.0057817185297608376, 0.005591374356299639, 0.005754698999226093, 0.005578982178121805, 0.005689202342182398, 0.005754165351390839, 0.37662243843078613, 0.005573217291384935, 0.00558900274336338, 0.005690417252480984, 0.10391836613416672, 0.005643698386847973, 0.005863418336957693, 0.005692072678357363, 0.005698608700186014, 0.005834743846207857, 0.1042771115899086, 0.005795636679977179, 0.005741542670875788, 0.005707692354917526, 0.005695002153515816, 0.005670814774930477, 0.005759429652243853, 0.12776321172714233, 0.005726681090891361, 0.09912794083356857, 0.13239456713199615, 0.0057350811548531055, 0.1153847798705101, 0.005688862409442663, 0.005791840143501759, 0.005721785593777895, 0.08598598092794418, 0.005816292017698288, 0.005703520029783249, 0.07588758319616318, 0.005727190058678389, 0.005875763949006796, 0.11476732045412064, 0.005782980006188154, 0.005793593358248472, 0.09779909253120422, 0.005846273619681597, 0.1156824603676796, 0.005871639586985111, 0.005744497291743755, 0.005785430781543255, 0.005758313462138176, 0.12134953588247299, 0.005888340063393116, 0.0057352758012712, 0.08639177680015564, 0.005887816194444895, 0.005774109158664942, 0.10362038761377335, 0.12783940136432648, 0.005867342464625835, 0.11420490592718124, 0.005860521458089352, 0.005848259199410677, 0.005905669182538986, 0.005826170556247234, 0.005771837197244167, 0.005769799463450909, 0.005800310987979174, 0.3347494304180145, 0.005949831567704678, 0.005977537017315626, 0.0062025161460042, 0.00588111812248826, 0.35947683453559875, 0.005982085131108761, 0.00591969583183527, 0.07655009627342224, 0.005934029817581177, 0.006085260771214962, 0.006079362705349922, 0.006277399603277445, 0.0060988920740783215, 0.006082594860345125, 0.006117319222539663, 0.09388501197099686, 0.005991167854517698, 0.0061752647161483765, 0.006075070705264807, 0.07321208715438843, 0.006026227027177811, 0.10439854860305786, 0.1384890228509903, 0.12732666730880737, 0.13156472146511078, 0.00603218749165535, 0.006062951870262623, 0.09694831073284149, 0.006238862406462431, 0.11904550343751907, 0.006185715086758137, 0.006219771225005388, 0.0061087156645953655, 0.006167588289827108, 0.00612264359369874, 0.13032394647598267, 0.006163278128951788, 0.006136802490800619, 0.006121672689914703, 0.11375069618225098, 0.10203151404857635, 0.0061218938790261745, 0.00619012676179409, 0.006242763716727495, 0.006250142585486174, 0.00622791750356555, 0.006212811917066574, 0.006127945613116026, 0.006173424422740936, 0.006164235528558493, 0.006170100998133421, 0.006134306080639362, 0.00634104385972023, 0.006197924260050058, 0.006107663735747337, 0.006080972496420145, 0.006102564744651318, 0.006075335666537285, 0.006123378407210112, 0.12556736171245575, 0.08577457070350647, 0.006166914477944374, 0.0061260852962732315, 0.0059899017214775085, 0.10165983438491821, 0.006003416143357754, 0.006090549286454916, 0.00614306190982461, 0.1291537582874298, 0.006168500520288944, 0.13255010545253754, 0.006138453725725412, 0.00632733479142189, 0.006057211197912693, 0.10928630828857422, 0.4016987383365631, 0.006022934801876545, 0.006026163697242737, 0.006130299996584654, 0.00611678883433342, 0.006090862676501274, 0.006174449343234301, 0.006075392477214336, 0.006147716194391251, 0.006056602578610182, 0.13679392635822296, 0.006078578531742096, 0.006231178995221853, 0.00639952439814806, 0.006055853329598904, 0.006057674530893564, 0.12699048221111298, 0.006220875773578882, 0.006268656346946955, 0.006102827377617359, 0.00610093679279089, 0.006268998142331839, 0.006155238952487707, 0.006040625274181366, 0.006229585502296686, 0.006041000131517649, 0.006072875112295151, 0.11990566551685333, 0.006079965271055698, 0.0060921343974769115, 0.00609037559479475, 0.12899304926395416, 0.12286374717950821, 0.006008798256516457, 0.13235601782798767, 0.006025138311088085, 0.00601657759398222, 0.006098636891692877, 0.0061061386950314045, 0.006045309826731682, 0.006043268367648125, 0.005999014247208834, 0.006033464800566435, 0.006064003333449364, 0.0060340785421431065, 0.11056515574455261, 0.0061836219392716885, 0.006043249741196632, 0.006086683366447687, 0.005982148461043835, 0.10958947986364365, 0.1552051305770874, 0.00599615229293704, 0.005956490058451891, 0.0060369838029146194, 0.005977518856525421, 0.006154727190732956, 0.3730764091014862, 0.006054679397493601, 0.005972779355943203, 0.005948753096163273, 0.005989159923046827, 0.006289761513471603, 0.0060797883197665215, 0.006142536178231239, 0.005978592671453953, 0.006209053564816713, 0.006057141814380884, 0.10679827630519867, 0.006217391230165958, 0.0061408900655806065, 0.005986844655126333, 0.006119773723185062, 0.0059657287783920765, 0.006051266565918922, 0.005978806875646114, 0.006002556532621384, 0.005953396204859018, 0.006018871441483498, 0.12635250389575958, 0.12560129165649414, 0.00613820506259799, 0.005969216115772724, 0.006138584576547146, 0.11947017908096313, 0.006036135833710432, 0.006025948096066713, 0.006006252486258745, 0.12068618834018707, 0.006085650529712439, 0.006061959080398083, 0.0061470759101212025, 0.0059793870896101, 0.0059730312786996365, 0.005946039687842131, 0.006024595350027084, 0.12901194393634796, 0.005952507257461548, 0.11224304884672165, 0.0059554860927164555, 0.006053526885807514, 0.005980518646538258, 0.0060722907073795795, 0.14169752597808838, 0.00616603484377265, 0.005925262346863747, 0.005980098154395819, 0.005968278273940086, 0.1327109932899475, 0.006118737626820803, 0.0059724911116063595, 0.13731636106967926, 0.005928130354732275, 0.00595302227884531, 0.006029902491718531, 0.005903749261051416, 0.006032396107912064, 0.00614007655531168, 0.006010237615555525, 0.12626592814922333, 0.005938706919550896, 0.006042395252734423, 0.005924862809479237, 0.006032535340636969, 0.006134158466011286, 0.005907224025577307, 0.005904469173401594, 0.11635193973779678, 0.006014315411448479, 0.006131977308541536, 0.005988570395857096, 0.10810236632823944, 0.005942343734204769, 0.005941418465226889, 0.006052846554666758, 0.005969058256596327, 0.005910367704927921, 0.006026763003319502, 0.005922532640397549]\n",
            "Val loss 0.03120917786848574\n",
            "Val auc roc 0.5073886033888511\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ebac03a-ef5e-48bb-9ca9-bf37cdcbf2e3"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "357c2392-bc11-45e1-f848-c50db680606f"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "437c1435-63d2-418e-e4de-ff1e629b5b9c"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "7923ecbb-7f8e-4f8c-d336-447f315eae5e"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Generalized_Hate]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ec32c9b8-06be-4aa3-b409-dac1a64be2f3"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-07-28 11:14:53.792686'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}