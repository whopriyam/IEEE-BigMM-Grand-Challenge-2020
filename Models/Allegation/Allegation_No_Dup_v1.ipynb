{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Allegation_No_Dup_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "514e6205e76b49f6b97247b088743de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c30e9dd573ab41cc8066c845cf910fb7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a81159801ff44a049c964e73d55b61c5",
              "IPY_MODEL_8f9c40ae85994d39a044e863c1d87bc5"
            ]
          }
        },
        "c30e9dd573ab41cc8066c845cf910fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a81159801ff44a049c964e73d55b61c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c2c818d8f33459b8e5373f2e5467573",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30f11283bb024b378d3bb9c22918c83d"
          }
        },
        "8f9c40ae85994d39a044e863c1d87bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a73adff4aee446a1a40fde9ab73cf4a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:12&lt;00:00, 19.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfb01cdd1f434979b7bb72d11d541fb4"
          }
        },
        "8c2c818d8f33459b8e5373f2e5467573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30f11283bb024b378d3bb9c22918c83d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a73adff4aee446a1a40fde9ab73cf4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfb01cdd1f434979b7bb72d11d541fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8727df5d6e794eb5bb8116ae954d5820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7bb06c8058543549d1c2b8afe7aab25",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ce40fdabdc54f6fa774eba0162fc886",
              "IPY_MODEL_3037870f1be94c16b006ff26589855e1"
            ]
          }
        },
        "c7bb06c8058543549d1c2b8afe7aab25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ce40fdabdc54f6fa774eba0162fc886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d37acbca2f61422c8c7743013e26e788",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_715436eecda0453d89175423a228dd11"
          }
        },
        "3037870f1be94c16b006ff26589855e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca461fdd37354537b436aebcc643870a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [1:29:31&lt;00:00,  3.37s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66692d27266f4947977b8549e4508277"
          }
        },
        "d37acbca2f61422c8c7743013e26e788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "715436eecda0453d89175423a228dd11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca461fdd37354537b436aebcc643870a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66692d27266f4947977b8549e4508277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f3bc78fd7eb4ccdb06db85379b244b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e6b498862d1a4184a4b733371b56420a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4fe71b4036ce4391a4b3fa9cdb9f2bbd",
              "IPY_MODEL_a914d2fa83f94237a397535f77c93e5d"
            ]
          }
        },
        "e6b498862d1a4184a4b733371b56420a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fe71b4036ce4391a4b3fa9cdb9f2bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43d851265db0440b8c9d4cc1f7f75357",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a836d0cbecf401085516e98499a0ebd"
          }
        },
        "a914d2fa83f94237a397535f77c93e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f26b25efff347c99cf44b8cfa4a7d12",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [29:26&lt;00:00,  1.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_444f41e53cde4c31a051ffbfb2e16a3f"
          }
        },
        "43d851265db0440b8c9d4cc1f7f75357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a836d0cbecf401085516e98499a0ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f26b25efff347c99cf44b8cfa4a7d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "444f41e53cde4c31a051ffbfb2e16a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e7ea4145a634017a26e0152871920a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49cd247389fa4ee8b1402458ba1e2842",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff836f6ec5ca444cb3b67c32455691bf",
              "IPY_MODEL_3cff07d9a9644884bc30c274cef488f0"
            ]
          }
        },
        "49cd247389fa4ee8b1402458ba1e2842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff836f6ec5ca444cb3b67c32455691bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38691ca8a5ac436193acc4f7e2db3d58",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1595,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1595,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b117066aff704e2e9372251f58e91904"
          }
        },
        "3cff07d9a9644884bc30c274cef488f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_10504240836e4fb69b08a50eaabe3ce3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1595/1595 [29:15&lt;00:00,  1.10s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afe71cc7842b473fa1190faebaf8b46f"
          }
        },
        "38691ca8a5ac436193acc4f7e2db3d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b117066aff704e2e9372251f58e91904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10504240836e4fb69b08a50eaabe3ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afe71cc7842b473fa1190faebaf8b46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b61c2b28-631f-4248-d990-9a02f60d16ec"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 33.79 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbce99d3-1c39-4e0f-d8d0-b8b6e4c8dc79"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1a16c41-10d0-4211-bf16-dcd4bc7f914c"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8d65d460-5c35-4f3e-f826-9af75f10b998"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "99107ec1-aec8-46f8-bfdc-1cf82f6c1ad9"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "38670b47-edbb-40bd-a399-76bb45b1cfc4"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4ba41f3d-97ab-4f46-e275-b49ac4d24caf"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8d7cf558-11b1-4c70-8fd5-067a58daf6f1"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "e05489a3-4a31-476e-a754-938b64f7dd1c"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d6d0ef05-9fb1-49a8-eb64-6e36de847825"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        India has #MeToo moment as minister accused  \n",
              "1                                        ption - no:2 \n",
              "2    Times Have Changed. There's A New Sheriff In T...\n",
              "3                                        ption - no:2 \n",
              "4    @sardesairajdeep Spoke like a true left winger...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cd8e8bd-d4c5-4a1c-d255-bab2c6ab2d43"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:08<00:00, 47483438.23B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0678689-73f4-4d22-aafa-218afc5d90dd"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2543048.97B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f15b0c1a-3055-4d8c-db81-3b54f0a7db47"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "966e550f-f8bb-4ff3-92aa-60d8b0c3f514"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        \n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        \n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76fbfed0-7135-43bf-a97d-99bc80cf55d4"
      },
      "source": [
        "col_name = \"Allegation\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760,
          "referenced_widgets": [
            "514e6205e76b49f6b97247b088743de9",
            "c30e9dd573ab41cc8066c845cf910fb7",
            "a81159801ff44a049c964e73d55b61c5",
            "8f9c40ae85994d39a044e863c1d87bc5",
            "8c2c818d8f33459b8e5373f2e5467573",
            "30f11283bb024b378d3bb9c22918c83d",
            "a73adff4aee446a1a40fde9ab73cf4a6",
            "bfb01cdd1f434979b7bb72d11d541fb4",
            "8727df5d6e794eb5bb8116ae954d5820",
            "c7bb06c8058543549d1c2b8afe7aab25",
            "7ce40fdabdc54f6fa774eba0162fc886",
            "3037870f1be94c16b006ff26589855e1",
            "d37acbca2f61422c8c7743013e26e788",
            "715436eecda0453d89175423a228dd11",
            "ca461fdd37354537b436aebcc643870a",
            "66692d27266f4947977b8549e4508277",
            "1f3bc78fd7eb4ccdb06db85379b244b3",
            "e6b498862d1a4184a4b733371b56420a",
            "4fe71b4036ce4391a4b3fa9cdb9f2bbd",
            "a914d2fa83f94237a397535f77c93e5d",
            "43d851265db0440b8c9d4cc1f7f75357",
            "1a836d0cbecf401085516e98499a0ebd",
            "8f26b25efff347c99cf44b8cfa4a7d12",
            "444f41e53cde4c31a051ffbfb2e16a3f",
            "9e7ea4145a634017a26e0152871920a7",
            "49cd247389fa4ee8b1402458ba1e2842",
            "ff836f6ec5ca444cb3b67c32455691bf",
            "3cff07d9a9644884bc30c274cef488f0",
            "38691ca8a5ac436193acc4f7e2db3d58",
            "b117066aff704e2e9372251f58e91904",
            "10504240836e4fb69b08a50eaabe3ce3",
            "afe71cc7842b473fa1190faebaf8b46f"
          ]
        },
        "outputId": "faa132d3-d81f-4171-da64-9b5f8abd614b"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6382\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "514e6205e76b49f6b97247b088743de9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8727df5d6e794eb5bb8116ae954d5820",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0372\n",
            "Train Losses : [0.16721850633621216, 0.5256321430206299, 0.8645496964454651, 1.3434325456619263, 0.3886810839176178, 0.8406040072441101, 0.35295578837394714, 0.187718465924263, 0.1737465262413025, 0.32629069685935974, 0.09110371768474579, 0.0953199714422226, 0.12162049859762192, 0.11055159568786621, 0.11441593617200851, 0.05384908616542816, 0.07263930886983871, 0.037487808614969254, 0.028061185032129288, 0.03325490653514862, 0.014444224536418915, 0.09708844125270844, 0.007274414412677288, 0.018980663269758224, 0.012917526066303253, 0.00863286480307579, 0.005241461098194122, 0.7129880785942078, 0.007765056565403938, 0.0017373289447277784, 0.0015827496536076069, 0.001969452714547515, 0.27682483196258545, 0.002098261145874858, 0.0006793604115955532, 0.0004964526742696762, 0.0004921620711684227, 0.23129379749298096, 0.0008877308573573828, 0.0025163961108773947, 0.00048336194595322013, 0.0006480888114310801, 0.003000029595568776, 0.04127584397792816, 0.0006987496162764728, 0.005219225771725178, 0.15232130885124207, 0.0009909484069794416, 0.003677997039631009, 0.0019212670158594847, 0.0035700281150639057, 0.0009764506830833852, 0.3136478066444397, 0.01569938287138939, 0.0015135451685637236, 0.007094332482665777, 0.01772269979119301, 0.006546742748469114, 0.010353263467550278, 0.025518614798784256, 0.00519686471670866, 1.0179673433303833, 0.00421250332146883, 0.012775777839124203, 0.010879411362111568, 0.0035934096667915583, 0.0031477625016123056, 0.0027209012769162655, 0.0014141236897557974, 0.20478177070617676, 0.0013621706748381257, 0.308057576417923, 0.0022129507269710302, 0.31343504786491394, 0.00152886426076293, 0.30501723289489746, 0.0016626325668767095, 0.0019524026429280639, 0.0025568543933331966, 0.002416769042611122, 0.003019504016265273, 0.002776798326522112, 0.0026491405442357063, 0.0036950544454157352, 0.005332984495908022, 0.003897065529599786, 0.0038243045564740896, 0.002993660746142268, 0.0030344475526362658, 0.0028000071179121733, 0.002805345691740513, 0.003119095927104354, 0.0025387415662407875, 0.002395508112385869, 0.10047457367181778, 0.004612880293279886, 0.15167580544948578, 0.27846869826316833, 0.0028034921269863844, 0.0034897425211966038, 0.003991642501205206, 0.0033827973529696465, 0.0034838616847991943, 0.6661503314971924, 0.005154119338840246, 0.004111198242753744, 0.005694400519132614, 0.006850588135421276, 0.006364992819726467, 0.0056131742894649506, 0.011174577288329601, 0.009186831302940845, 0.007852890528738499, 0.0073586576618254185, 0.03958917781710625, 0.40507936477661133, 0.0070043341256678104, 0.01094500906765461, 0.01428801380097866, 0.010900153778493404, 0.009821273386478424, 0.008022960275411606, 0.0074438913725316525, 0.00783159863203764, 0.09270855784416199, 0.008660748600959778, 0.38153836131095886, 0.011553315445780754, 0.255764901638031, 0.009606457315385342, 0.012164026498794556, 0.1378920078277588, 0.011332424357533455, 0.01018553227186203, 0.11375980079174042, 0.012988264672458172, 0.010666543617844582, 0.010623612441122532, 0.069916270673275, 0.012257225811481476, 0.009468929842114449, 0.015103350393474102, 0.008479081094264984, 0.008859877474606037, 0.0077077667228877544, 0.008842279203236103, 0.00657404912635684, 0.00792939867824316, 0.09471679478883743, 0.005114076193422079, 0.006719901692122221, 0.0055024828761816025, 0.004432838410139084, 0.0038134846836328506, 0.00540267676115036, 0.00547736044973135, 0.0039036001544445753, 0.00409638462588191, 0.003176148282364011, 0.07559677213430405, 0.003459320869296789, 0.0026321145705878735, 0.0026827515102922916, 0.00260191154666245, 0.003538417397066951, 0.002218795707449317, 0.0030624542851001024, 0.002027031034231186, 0.0022282253485172987, 0.0029496331699192524, 0.0020329684484750032, 0.0023552561178803444, 0.0026629643980413675, 0.07082904875278473, 0.0016026959056034684, 0.00320336502045393, 0.0019020610488951206, 0.0018512007081881166, 0.0018622769275680184, 0.36518022418022156, 0.0020854626782238483, 0.0016413165722042322, 0.0018540708115324378, 0.12613019347190857, 0.002241268055513501, 0.0021290031727403402, 0.001689777709543705, 0.0016457104356959462, 0.002666379325091839, 0.0028943377546966076, 0.0022100673522800207, 0.14984367787837982, 0.10189052671194077, 0.00234391912817955, 0.0028256294317543507, 0.0030836830846965313, 0.20694564282894135, 0.0038645050954073668, 0.006721741985529661, 0.10423371940851212, 0.005723489914089441, 0.00494856433942914, 0.007760823238641024, 0.00375817040912807, 0.0055868960916996, 0.004050655756145716, 0.08784131705760956, 0.011755121871829033, 0.004230745602399111, 0.0038684888277202845, 0.008248426951467991, 0.004440636839717627, 0.004844420589506626, 0.004639758262783289, 0.005628439597785473, 0.3338873088359833, 0.004476558417081833, 0.15933328866958618, 0.0034334936644881964, 0.003952957224100828, 0.0034209522418677807, 0.004748568404465914, 0.004013100638985634, 0.11235140264034271, 0.004207860678434372, 0.004434332717210054, 0.0037226169370114803, 0.4612361490726471, 0.005184426438063383, 0.005691110622137785, 0.005077890120446682, 0.005898033734411001, 0.005885906983166933, 0.005375318694859743, 0.005590396001935005, 0.23710036277770996, 0.2045435905456543, 0.007006304804235697, 0.00777233112603426, 0.006237964145839214, 0.006110356654971838, 0.0084235779941082, 0.008548022247850895, 0.006119721569120884, 0.006799636874347925, 0.1595032811164856, 0.005943525582551956, 0.13046705722808838, 0.006316710263490677, 0.005708382930606604, 0.00525343744084239, 0.006537433713674545, 0.1581597924232483, 0.10671346634626389, 0.13412444293498993, 0.005325364414602518, 0.005594083108007908, 0.0061285593546926975, 0.005627076607197523, 0.005650979001075029, 0.0066716731525957584, 0.005740529391914606, 0.11764790117740631, 0.006018477026373148, 0.12742018699645996, 0.005610050167888403, 0.4432784914970398, 0.006030395161360502, 0.006614912301301956, 0.006766414735466242, 0.0071400804445147514, 0.008291797712445259, 0.00938358437269926, 0.009044280275702477, 0.007912619039416313, 0.008568820543587208, 0.007437292020767927, 0.07162220031023026, 0.4382868707180023, 0.007904057390987873, 0.008245998993515968, 0.009560802020132542, 0.10810545086860657, 0.010780499316751957, 0.009785441681742668, 0.009575438685715199, 0.010302213951945305, 0.009885015897452831, 0.009414725005626678, 0.009554224088788033, 0.008928456343710423, 0.00842892937362194, 0.007945000194013119, 0.008055180311203003, 0.0076658399775624275, 0.0069295126013457775, 0.0064523303881287575, 0.006382651161402464, 0.005864728707820177, 0.07568663358688354, 0.0055132778361439705, 0.11165189743041992, 0.10340533405542374, 0.004708664026111364, 0.004757164511829615, 0.004950723145157099, 0.0050600082613527775, 0.00454218965023756, 0.004359412472695112, 0.004283870570361614, 0.0039695617742836475, 0.00420780386775732, 0.004660220351070166, 0.0042369612492620945, 0.004845981951802969, 0.0033449758775532246, 0.0032042895909398794, 0.0032879640348255634, 0.0032735734712332487, 0.0029170264024287462, 0.0027146143838763237, 0.10852272063493729, 0.0027437973767518997, 0.0025429129600524902, 0.0027895160019397736, 0.0031164013780653477, 0.002527572214603424, 0.0023914047051221132, 0.002522318623960018, 0.0033235785085707903, 0.09715970605611801, 0.00245272065512836, 0.0025402139872312546, 0.0026834479067474604, 0.0023121738340705633, 0.08206550776958466, 0.0023671016097068787, 0.0024240571074187756, 0.002577955601736903, 0.0032781523186713457, 0.0022955520544201136, 0.002988184569403529, 0.002873858902603388, 0.003184814937412739, 0.16412658989429474, 0.09790334105491638, 0.0033210378605872393, 0.002806333126500249, 0.003690535668283701, 0.003173095639795065, 0.003050990169867873, 0.00315931742079556, 0.003037824993953109, 0.003231947310268879, 0.003072093240916729, 0.0025979536585509777, 0.002986368490383029, 0.002925618551671505, 0.00337604689411819, 0.003141665132716298, 0.0025037508457899094, 0.0022481009364128113, 0.002214615698903799, 0.0022092796862125397, 0.002906788606196642, 0.0024685717653483152, 0.0029780403710901737, 0.10611175000667572, 0.0030753498431295156, 0.0019425215432420373, 0.1791127622127533, 0.002552472986280918, 0.09958335012197495, 0.0031644096598029137, 0.0022740275599062443, 0.0030187396332621574, 0.14339850842952728, 0.003971354104578495, 0.0032532403711229563, 0.002812041202560067, 0.0031755208037793636, 0.0036820005625486374, 0.003672071499750018, 0.0034912407863885164, 0.0030557892750948668, 0.004326339345425367, 0.004038914106786251, 0.0030300344806164503, 0.003164211055263877, 0.002835490508005023, 0.08584551513195038, 0.07686169445514679, 0.0038363116327673197, 0.004097057972103357, 0.18860268592834473, 0.0036717294715344906, 0.09111052751541138, 0.00425218278542161, 0.003439422696828842, 0.07358644157648087, 0.00491916062310338, 0.004467517603188753, 0.004685671534389257, 0.004566438961774111, 0.0051076761446893215, 0.007401461713016033, 0.006074515171349049, 0.14067287743091583, 0.004833826795220375, 0.004037403501570225, 0.005942393094301224, 0.0051930854097008705, 0.005044132471084595, 0.0054369778372347355, 0.05068047344684601, 0.007081066723912954, 0.004357756115496159, 0.004041897598654032, 0.004097842611372471, 0.0037609459832310677, 0.004518224857747555, 0.14517365396022797, 0.0036365666892379522, 0.0033363488037139177, 0.005282080732285976, 0.003574127797037363, 0.003598228096961975, 0.0045895930379629135, 0.003142398549243808, 0.002928941510617733, 0.004218277521431446, 0.0036077608820050955, 0.003116077044978738, 0.0028284629806876183, 0.003056192770600319, 0.0031351973302662373, 0.0027994054835289717, 0.002730782376602292, 0.002186673926189542, 0.00219703814946115, 0.0023453454487025738, 0.002475704299286008, 0.0020697854924947023, 0.00181203440297395, 0.001969975186511874, 0.0021186135709285736, 0.0019067478133365512, 0.10845693945884705, 0.0016159694641828537, 0.0020620955619961023, 0.0022446410730481148, 0.002529080491513014, 0.0021980900783091784, 0.0016533281886950135, 0.11070235073566437, 0.7035659551620483, 0.002246942836791277, 0.002468876540660858, 0.09147331863641739, 0.0858333557844162, 0.0034982915967702866, 0.0035212524235248566, 0.22642891108989716, 0.005150733049958944, 0.39144936203956604, 0.00823734700679779, 0.00672926614060998, 0.00908229872584343, 0.008278579451143742, 0.00904904119670391, 0.011212462559342384, 0.00975214596837759, 0.010544205084443092, 0.013534842059016228, 0.012795835733413696, 0.011265926994383335, 0.1619618982076645, 0.010368354618549347, 0.01142007578164339, 0.009709585458040237, 0.01004121359437704, 0.011000942438840866, 0.01098813395947218, 0.010172706097364426, 0.009200801141560078, 0.008366678841412067, 0.009601891040802002, 0.00659497594460845, 0.4012652039527893, 0.10112982243299484, 0.006677020341157913, 0.007270341273397207, 0.07813527435064316, 0.006564927287399769, 0.006821258459240198, 0.00849293451756239, 0.007277786266058683, 0.007876673713326454, 0.007016101386398077, 0.006386231165379286, 0.009196742437779903, 0.007352559361606836, 0.006575190462172031, 0.10622194409370422, 0.006396102719008923, 0.07867801189422607, 0.006239629816263914, 0.006354842334985733, 0.06607669591903687, 0.18274769186973572, 0.005774954333901405, 0.005619378294795752, 0.0059905569069087505, 0.1355389803647995, 0.006367852911353111, 0.005519216414541006, 0.00596508989110589, 0.005322108045220375, 0.005607281345874071, 0.005291694309562445, 0.07267128676176071, 0.0050355964340269566, 0.004748406354337931, 0.004805373027920723, 0.006329645868390799, 0.0055671920999884605, 0.20250776410102844, 0.12481903284788132, 0.12777501344680786, 0.004772400017827749, 0.005376521497964859, 0.0053839487954974174, 0.0053823115304112434, 0.005681334529072046, 0.004600865766406059, 0.005500304978340864, 0.0049645681865513325, 0.0051327538676559925, 0.004660326521843672, 0.004241240210831165, 0.004404749721288681, 0.004228321369737387, 0.07878310978412628, 0.004067056346684694, 0.0042076813988387585, 0.2330605834722519, 0.004648758098483086, 0.004066844005137682, 0.004461169242858887, 0.004804933909326792, 0.004181656986474991, 0.11718164384365082, 0.0038497101049870253, 0.004318110644817352, 0.004122530575841665, 0.0040241326205432415, 0.004015807528048754, 0.003927635960280895, 0.003669954603537917, 0.0038087284192442894, 0.003678334876894951, 0.10316228866577148, 0.14193427562713623, 0.003642081515863538, 0.004308291710913181, 0.0035789506509900093, 0.00344598270021379, 0.0035365840885788202, 0.003471611300483346, 0.0035298631992191076, 0.003658055327832699, 0.0036797162611037493, 0.0036284863017499447, 0.003923230338841677, 0.08798994868993759, 0.00337076373398304, 0.003208854468539357, 0.0036115117836743593, 0.003460443112999201, 0.15159019827842712, 0.003328850260004401, 0.003208600450307131, 0.003531590336933732, 0.003453952958807349, 0.003287004539743066, 0.16041012108325958, 0.12177233397960663, 0.0035472530871629715, 0.00391468545421958, 0.003488491987809539, 0.004240565933287144, 0.0035489744041115046, 0.0036211146507412195, 0.1611628234386444, 0.004495581146329641, 0.003930673468858004, 0.004043882247060537, 0.003723131027072668, 0.14480820298194885, 0.004503048490732908, 0.004885823465883732, 0.004037114791572094, 0.0049637784250080585, 0.003935263957828283, 0.004252581391483545, 0.0043414803221821785, 0.06722340732812881, 0.003925417084246874, 0.2138398438692093, 0.004577592946588993, 0.004395016934722662, 0.0040734754875302315, 0.003958613611757755, 0.1231565922498703, 0.00454668840393424, 0.12718893587589264, 0.13959652185440063, 0.0045198118314146996, 0.00490944180637598, 0.00472599733620882, 0.005465280264616013, 0.0053349449299275875, 0.09996914863586426, 0.09260440617799759, 0.1791001707315445, 0.00557099562138319, 0.005867882631719112, 0.1258794218301773, 0.006652376148849726, 0.00627888971939683, 0.006904694717377424, 0.006587281357496977, 0.006508721970021725, 0.00647674361243844, 0.006869373377412558, 0.006835170090198517, 0.006585089024156332, 0.006503655109554529, 0.17948076128959656, 0.5119805932044983, 0.006299862638115883, 0.006970274727791548, 0.007210993207991123, 0.007329219952225685, 0.0074936398304998875, 0.007648952305316925, 0.008205641061067581, 0.007826059125363827, 0.007702445145696402, 0.13028842210769653, 0.008048024028539658, 0.007582889404147863, 0.007530499715358019, 0.007498464547097683, 0.007269765716046095, 0.007228956092149019, 0.00688334833830595, 0.006733944173902273, 0.006314315367490053, 0.006349753122776747, 0.005831786897033453, 0.00562685914337635, 0.11318802833557129, 0.005233266390860081, 0.1288415491580963, 0.005028584040701389, 0.005062453914433718, 0.004919199272990227, 0.004817906767129898, 0.004728671163320541, 0.004769472870975733, 0.004507643636316061, 0.14119839668273926, 0.004394731018692255, 0.004429531749337912, 0.004676656797528267, 0.004204976838082075, 0.14522160589694977, 0.004129140637814999, 0.004157599061727524, 0.004121800418943167, 0.004108393099159002, 0.003989685792475939, 0.00387954106554389, 0.003961906302720308, 0.003697850275784731, 0.0036300350911915302, 0.0034959998447448015, 0.003462821478024125, 0.11754661053419113, 0.0033055192325264215, 0.15611805021762848, 0.0033490341156721115, 0.0033785635605454445, 0.003317194292321801, 0.08927260339260101, 0.0033742382656782866, 0.003432565601542592, 0.003467308124527335, 0.0034725579898804426, 0.0034927818924188614, 0.0034960475750267506, 0.00345257087610662, 0.5092799663543701, 0.12453070282936096, 0.0041509284637868404, 0.1480449140071869, 0.005042706150561571, 0.005340139381587505, 0.005736694671213627, 0.0062362803146243095, 0.006295116152614355, 0.006722021847963333, 0.006570877507328987, 0.006780903320759535, 0.006830253638327122, 0.006724277511239052, 0.006841558031737804, 0.1104133203625679, 0.0069124773144721985, 0.006839615758508444, 0.13290269672870636, 0.006602746434509754, 0.006545649375766516, 0.0065859160386025906, 0.0064491089433431625, 0.006383788771927357, 0.006316016428172588, 0.0060252477414906025, 0.005932992789894342, 0.12067520618438721, 0.10851575434207916, 0.13893751800060272, 0.005849667824804783, 0.005851880181580782, 0.0058479891158640385, 0.006005062721669674, 0.0058191921561956406, 0.005717127118259668, 0.005646116565912962, 0.005637366324663162, 0.0055176434107124805, 0.13187500834465027, 0.005242506507784128, 0.005179013125598431, 0.00517267407849431, 0.13529987633228302, 0.0050720213912427425, 0.005002121441066265, 0.004944615997374058, 0.004922604188323021, 0.004848796408623457, 0.004782465286552906, 0.004698918666690588, 0.004534626845270395, 0.0044648004695773125, 0.004298949148505926, 0.12472560256719589, 0.004187595099210739, 0.004112232476472855, 0.004007656592875719, 0.13379250466823578, 0.003924415446817875, 0.11803409457206726, 0.3947412371635437, 0.10396977514028549, 0.005091632250696421, 0.0054184929467737675, 0.00590444216504693, 0.006201876327395439, 0.006516067311167717, 0.006929840426892042, 0.006970179732888937, 0.0072211576625704765, 0.007218224927783012, 0.007479075808078051, 0.11408297717571259, 0.007518327794969082, 0.007322406396269798, 0.0072379400953650475, 0.1253850907087326, 0.007270643021911383, 0.0071416376158595085, 0.007372671272605658, 0.007101189345121384, 0.0067941537126898766, 0.006871201563626528, 0.006440324708819389, 0.006276585627347231, 0.006073702126741409, 0.005841350182890892, 0.005626552738249302, 0.00547341862693429, 0.13179266452789307, 0.004987593274563551, 0.004919099155813456, 0.12460238486528397, 0.004792642779648304, 0.004616207908838987, 0.1293555647134781, 0.004558994434773922, 0.004585708025842905, 0.14293508231639862, 0.00475182943046093, 0.004818534944206476, 0.004734216257929802, 0.11893326789140701, 0.004713716916739941, 0.11825835704803467, 0.005098626483231783, 0.10389295220375061, 0.14243203401565552, 0.005311909131705761, 0.005526318214833736, 0.005758172832429409, 0.00594981899484992, 0.005829425994306803, 0.005803520791232586, 0.005803225561976433, 0.005788943264633417, 0.0056871832348406315, 0.005590235348790884, 0.005560596007853746, 0.005381861235946417, 0.1253492534160614, 0.38181400299072266, 0.005617414601147175, 0.11968861520290375, 0.0067129055969417095, 0.006957210134714842, 0.007183243986219168, 0.007403701543807983, 0.007892993278801441, 0.007784816902130842, 0.3488672077655792, 0.008436111733317375, 0.008888084441423416, 0.009538359008729458, 0.009833887219429016, 0.009934776462614536, 0.010455522686243057, 0.010220056399703026, 0.010089931078255177, 0.10300249606370926, 0.010082033462822437, 0.010032006539404392, 0.009837484918534756, 0.11722597479820251, 0.009429961442947388, 0.009456118568778038, 0.009147942066192627, 0.008821184746921062, 0.08432282507419586, 0.00831175222992897, 0.008119662292301655, 0.11823751032352448, 0.007743262220174074, 0.007721696048974991, 0.0075306640937924385, 0.007362475153058767, 0.007391967810690403, 0.11882054805755615, 0.006553641986101866, 0.006491406820714474, 0.006266308948397636, 0.006105710286647081, 0.005899880081415176, 0.005779326893389225, 0.005504307337105274, 0.005305762402713299, 0.005156694445759058, 0.0048988861963152885, 0.004667873959988356, 0.004552275873720646, 0.004293755162507296, 0.004145422484725714, 0.003934266045689583, 0.0038250999059528112, 0.13499249517917633, 0.0036088398192077875, 0.003575084498152137, 0.0034501096233725548, 0.10433344542980194, 0.0033590917009860277, 0.003368851263076067, 0.0034430301748216152, 0.003307770937681198, 0.0032632951624691486, 0.0032423855736851692, 0.0032371862325817347, 0.0031598976347595453, 0.003283464116975665, 0.003103877417743206, 0.0029895161278545856, 0.1269650161266327, 0.13313373923301697, 0.0029377921018749475, 0.002996151801198721, 0.003031371394172311, 0.003042773110792041, 0.003182209562510252, 0.14580272138118744, 0.003272394882515073, 0.003237948752939701, 0.003261798992753029, 0.0032927098218351603, 0.0033274220768362284, 0.0033182473853230476, 0.0032365843653678894, 0.0033051976934075356, 0.003184476401656866, 0.003140560584142804, 0.003165222704410553, 0.0030466325115412474, 0.003072853432968259, 0.09703056514263153, 0.003006350016221404, 0.0029381171334534883, 0.13296470046043396, 0.0030317213386297226, 0.48315462470054626, 0.003484348999336362, 0.10600178688764572, 0.004265336785465479, 0.11989117413759232, 0.005201791878789663, 0.005436305422335863, 0.09019927680492401, 0.006274355575442314, 0.11499486863613129, 0.10618706047534943, 0.007466859184205532, 0.007856080308556557, 0.10311374813318253, 0.008634536527097225, 0.009155916050076485, 0.009080685675144196, 0.009568234905600548, 0.11991628259420395, 0.009462635964155197, 0.009501191787421703, 0.009750593453645706, 0.1083827018737793, 0.009385454468429089, 0.11177095770835876, 0.1071089580655098, 0.009351221844553947, 0.10096342116594315, 0.009258582256734371, 0.009637716226279736, 0.009444976225495338, 0.009191800840198994, 0.009157741442322731, 0.008805101737380028, 0.12968914210796356, 0.00833851471543312, 0.008150476031005383, 0.09819301962852478, 0.007897072471678257, 0.007482815533876419, 0.007357112132012844, 0.112654909491539, 0.007038583047688007, 0.007087941747158766, 0.007006242871284485, 0.006557899061590433, 0.0065467869862914085, 0.006302086636424065, 0.0060868156142532825, 0.10827931761741638, 0.0899830162525177, 0.005609700456261635, 0.005714696832001209, 0.005666120909154415, 0.005402165465056896, 0.005310889799147844, 0.005108484532684088, 0.005147878546267748, 0.004894770681858063, 0.004653819836676121, 0.0045235492289066315, 0.004482125397771597, 0.004459623247385025, 0.0041136653162539005, 0.0039469157345592976, 0.003984217997640371, 0.10958511382341385, 0.003664279356598854, 0.0035475168842822313, 0.48087191581726074, 0.003790292888879776, 0.00399435218423605, 0.11358881741762161, 0.0046339998953044415, 0.004849678836762905, 0.004952307790517807, 0.005565981846302748, 0.13865429162979126, 0.005840576719492674, 0.0057227518409490585, 0.00571749871596694, 0.005862736608833075, 0.005826249253004789, 0.0060760811902582645, 0.005903970450162888, 0.005734786856919527, 0.005931040737777948, 0.005928319878876209, 0.1277400255203247, 0.005474315956234932, 0.005453210789710283, 0.0054155136458575726, 0.00526651693508029, 0.0052214632742106915, 0.005143322981894016, 0.11808814853429794, 0.004925745539367199, 0.004908586386591196, 0.005162009969353676, 0.004861992318183184, 0.004996018018573523, 0.004617969039827585, 0.004531752783805132, 0.004605808295309544, 0.004435273353010416, 0.004376459401100874, 0.0042341058142483234, 0.003873966634273529, 0.0039945016615092754, 0.0038278475403785706, 0.003507111920043826, 0.003399593522772193, 0.003357713343575597, 0.003253708127886057, 0.0032137143425643444, 0.002972404705360532, 0.002915994729846716, 0.0029558211099356413, 0.002772040432319045, 0.13580583035945892, 0.0025993441231548786, 0.0026026186533272266, 0.002637025900185108, 0.4261957108974457, 0.0028361075092107058, 0.0030931103974580765, 0.0031891516409814358, 0.1450924128293991, 0.0036508075427263975, 0.0038782937917858362, 0.11234220117330551, 0.004606763832271099, 0.1423262059688568, 0.004766167141497135, 0.005030860658735037, 0.005322543904185295, 0.005372571758925915, 0.005563179962337017, 0.005745740607380867, 0.005671445280313492, 0.005852362606674433, 0.005770544987171888, 0.11310514807701111, 0.11619085818529129, 0.005911896470934153, 0.006050233729183674, 0.006014782004058361, 0.006070270203053951, 0.006044897250831127, 0.10277756303548813, 0.00596270989626646, 0.005862594116479158, 0.005913632456213236, 0.005988391116261482, 0.00608049426227808, 0.14906920492649078, 0.005533463321626186, 0.005489511881023645, 0.10080529749393463, 0.005444298032671213, 0.0054283118806779385, 0.0055034165270626545, 0.005436029750853777, 0.0052174413576722145, 0.0051409099251031876, 0.004993040580302477, 0.004922923166304827, 0.004872756078839302, 0.004653974901884794, 0.10267174988985062, 0.004472468513995409, 0.004388471134006977, 0.004453279543668032, 0.004284133668988943, 0.00426924554631114, 0.004189121071249247, 0.003986901603639126, 0.0039387657307088375, 0.10914583504199982, 0.003875829977914691, 0.0036949128843843937, 0.003723856760188937, 0.0035986092407256365, 0.1635228544473648, 0.003613535314798355, 0.0999239906668663, 0.00363728404045105, 0.003665618132799864, 0.0036547654308378696, 0.13098856806755066, 0.003787941997870803, 0.004059767350554466, 0.003840424120426178, 0.0038665137253701687, 0.003869057400152087, 0.003930164035409689, 0.12758633494377136, 0.1377815455198288, 0.004126605112105608, 0.004153551068156958, 0.00429859384894371, 0.004187161568552256, 0.00429597357288003, 0.0042755017057061195, 0.0041772304102778435, 0.11795591562986374, 0.004280231427401304, 0.004223409108817577, 0.004278962500393391, 0.1313103288412094, 0.0042668613605201244, 0.004352853633463383, 0.004336600191891193, 0.1174151748418808, 0.004402783699333668, 0.38811182975769043, 0.004806783515959978, 0.005222929175943136, 0.005760948173701763, 0.005798378959298134, 0.006193114910274744, 0.10744449496269226, 0.006569107994437218, 0.006673796568065882, 0.007451899815350771, 0.00692592840641737, 0.007000341080129147, 0.132083922624588, 0.007314386777579784, 0.0073326462879776955, 0.007132190745323896, 0.007127835880964994, 0.007339105475693941, 0.0070947217755019665, 0.006675065029412508, 0.006668252404779196, 0.006446365267038345, 0.006200647447258234, 0.006189599167555571, 0.0060418094508349895, 0.006001727189868689, 0.005639475304633379, 0.0053932154551148415, 0.005150936543941498, 0.004867464303970337, 0.11238448321819305, 0.0047172196209430695, 0.004596372600644827, 0.0043913996778428555, 0.004325653426349163, 0.00421137036755681, 0.004074770491570234, 0.004060722421854734, 0.003922196105122566, 0.0037187286652624607, 0.0036177844740450382, 0.0038387542590498924, 0.0034256025683134794, 0.003363666357472539, 0.0031902759801596403, 0.12980984151363373, 0.12400789558887482, 0.003161998465657234, 0.0031422318425029516, 0.0031661521643400192, 0.0033603443298488855, 0.003177720820531249, 0.003315086243674159, 0.0032711802050471306, 0.0031086821109056473, 0.0030439230613410473, 0.003136635757982731, 0.0030516330152750015, 0.0030332119204103947, 0.003011551219969988, 0.002944809617474675, 0.002848349278792739, 0.11004262417554855, 0.002955322153866291, 0.00274277338758111, 0.002712641377002001, 0.14405959844589233, 0.002796726766973734, 0.1170034408569336, 0.0028625796549022198, 0.0030354845803231, 0.003029865212738514, 0.003170355688780546, 0.00309013482183218, 0.0031405955087393522, 0.0031298312824219465, 0.0031207692809402943, 0.0031316776294261217, 0.003122079186141491, 0.0031788363121449947, 0.003176917089149356, 0.13375166058540344, 0.09016847610473633, 0.003152990248054266, 0.0031954317819327116, 0.0032671664375811815, 0.0032414114102721214, 0.1138511523604393, 0.0034221564419567585, 0.0034295052755624056, 0.003566901898011565, 0.0035593914799392223, 0.0034807927440851927, 0.003678662469610572, 0.0035472328308969736, 0.003456183709204197, 0.003478599013760686, 0.0034659327939152718, 0.13545483350753784, 0.0033883166033774614, 0.1313960999250412, 0.0034862086176872253, 0.0036383047699928284, 0.12347894161939621, 0.004032678436487913, 0.10634740442037582, 0.0039005076978355646, 0.0041829259134829044, 0.004230184014886618, 0.004086042754352093, 0.0043425350449979305, 0.004147909581661224, 0.004191778600215912, 0.004246465861797333, 0.0041886623948812485, 0.1421806514263153, 0.0041196090169250965, 0.0041205440647900105, 0.004098391160368919, 0.004486804362386465, 0.004116676282137632, 0.004033377394080162, 0.004048634320497513, 0.1348780393600464, 0.003946532960981131, 0.0039433822967112064, 0.004107257351279259, 0.003928540274500847, 0.0038472909945994616, 0.003957344219088554, 0.0037338228430598974, 0.11736901104450226, 0.003770426381379366, 0.0036743110977113247, 0.10417970269918442, 0.003900007577612996, 0.003884520847350359, 0.1403609812259674, 0.10409718006849289, 0.004005263559520245, 0.004147807601839304, 0.12288233637809753, 0.004326344933360815, 0.0044980780221521854, 0.09787801653146744, 0.004687800072133541, 0.004800509195774794, 0.005112870130687952, 0.004855005070567131, 0.004891955293715, 0.004921530373394489, 0.11497866362333298, 0.005140319932252169, 0.00521471630781889, 0.004965136758983135, 0.005188400391489267, 0.11614806205034256, 0.005411656107753515, 0.00524861179292202, 0.005086375866085291, 0.005357501562684774, 0.005090331193059683, 0.0906638354063034, 0.005014507565647364, 0.00508577935397625, 0.005119382869452238, 0.004993951413780451, 0.004668037872761488, 0.004872599150985479, 0.004673411604017019, 0.004418094176799059, 0.352984756231308, 0.004607474431395531, 0.12490272521972656, 0.005525954067707062, 0.00558170722797513, 0.0055690184235572815, 0.005719353910535574, 0.0676652193069458, 0.005966941360384226, 0.10812417417764664, 0.0067732068710029125, 0.09193576127290726, 0.0066231307573616505, 0.007651947904378176, 0.41882550716400146, 0.007270024623721838, 0.007803134620189667, 0.008121286518871784, 0.008553589694201946, 0.009193609468638897, 0.12405718117952347, 0.09977531433105469, 0.41507354378700256, 0.010393719188869, 0.011061611585319042, 0.012002045288681984, 0.012760897167026997, 0.012237741611897945, 0.012426519766449928, 0.012845471501350403, 0.012926270253956318, 0.012645881623029709, 0.11759685724973679, 0.012228843756020069, 0.012670792639255524, 0.011735299602150917, 0.012411043979227543, 0.0113380691036582, 0.12142857909202576, 0.010782639496028423, 0.009905675426125526, 0.009921986609697342, 0.009010893292725086, 0.008692307397723198, 0.008356857113540173, 0.11519794166088104, 0.15116092562675476, 0.007590971887111664, 0.0073758563958108425, 0.007463867776095867, 0.1433667540550232, 0.006876374129205942, 0.006778222043067217, 0.007445120252668858, 0.1026662290096283, 0.006805544253438711, 0.006440776865929365, 0.006060386076569557, 0.005868539679795504, 0.005739519372582436, 0.005567604675889015, 0.11285446584224701, 0.13913597166538239, 0.005418986547738314, 0.005490378011018038, 0.005440122447907925, 0.005616041366010904, 0.1391063630580902, 0.005057536531239748, 0.005191017873585224, 0.12069033831357956, 0.005058057140558958, 0.004958694335073233, 0.005099192261695862, 0.004916699603199959, 0.005092947278171778, 0.004895538557320833, 0.004786401521414518, 0.0983065813779831, 0.0047166612930595875, 0.004705389495939016, 0.10629833489656448, 0.004672214854508638, 0.004622559528797865, 0.004580059088766575, 0.004840363282710314, 0.004494953900575638, 0.13404136896133423, 0.004372299183160067, 0.00435074046254158, 0.004354100674390793, 0.14549246430397034, 0.004408828914165497, 0.0044006709940731525, 0.004662732128053904, 0.004471767693758011, 0.00444284500554204, 0.1591416597366333, 0.004264853894710541, 0.0042957435362041, 0.13527250289916992, 0.00436242762953043, 0.004458380863070488, 0.00442912895232439, 0.004599615465849638, 0.11194053292274475, 0.0044866600073874, 0.004548016004264355, 0.004648841917514801, 0.0045414273627102375, 0.004486433230340481, 0.004430018365383148, 0.46642935276031494, 0.004723880439996719, 0.005123306531459093, 0.005362365860491991, 0.0054177758283913136, 0.11032295227050781, 0.005882789846509695, 0.1258215457201004, 0.006447778083384037, 0.006362131796777248, 0.006584671791642904, 0.08738525211811066, 0.006715748924762011, 0.0069546508602797985, 0.10764224082231522, 0.006967004854232073, 0.007253332994878292, 0.007090782281011343, 0.00706246355548501, 0.007113897707313299, 0.006944330874830484, 0.0069861700758337975, 0.11553768813610077, 0.0066626183688640594, 0.006578528322279453, 0.12602491676807404, 0.006488041952252388, 0.11453712731599808, 0.11056865006685257, 0.006491926033049822, 0.0065310923382639885, 0.006626318674534559, 0.006565758492797613, 0.0065143294632434845, 0.006362651940435171, 0.10994699597358704, 0.00631546089425683, 0.006270930636674166, 0.11299943923950195, 0.006109775975346565, 0.006119397934526205, 0.11851026117801666, 0.0061226943507790565, 0.11607448011636734, 0.006092249881476164, 0.09069783240556717, 0.09019290655851364, 0.006369930226355791, 0.006334087811410427, 0.006569879129528999, 0.006349970120936632, 0.006360942497849464, 0.006268251687288284, 0.006405314430594444, 0.006256786175072193, 0.006196913309395313, 0.005863749887794256, 0.006066214293241501, 0.0056052785366773605, 0.005503635387867689, 0.005357332061976194, 0.005370638333261013, 0.005059016402810812, 0.0048662819899618626, 0.09053416550159454, 0.004806231707334518, 0.004544926807284355, 0.004431670531630516, 0.004300292581319809, 0.004231377970427275, 0.004100617486983538, 0.004246019758284092, 0.004085638094693422, 0.003905301680788398, 0.0037592079024761915, 0.0037263650447130203, 0.132968008518219, 0.003442127024754882, 0.0033798429649323225, 0.11594812572002411, 0.0034244873095303774, 0.003421872854232788, 0.003347738878801465, 0.11227861791849136, 0.0034088906832039356, 0.10123714059591293, 0.0038787468802183867, 0.11654476076364517, 0.0041957758367061615, 0.004031411837786436, 0.003924151882529259, 0.0038800223264843225, 0.004027759190648794, 0.004073664080351591, 0.00401906855404377, 0.00393889332190156, 0.003984865732491016, 0.0038307320792227983, 0.004130026791244745, 0.00393549632281065, 0.003774570766836405, 0.0038512982428073883, 0.14362239837646484, 0.003727005096152425, 0.003696444910019636, 0.0036092635709792376, 0.0037544986698776484, 0.003487436333671212, 0.003786131041124463, 0.0034303832799196243, 0.0033182098995894194, 0.08966497331857681, 0.0033471565693616867, 0.0033277622424066067, 0.4337739050388336, 0.1267644166946411, 0.13323013484477997, 0.004140033852308989, 0.10693246871232986, 0.004892907105386257, 0.0051862094551324844, 0.005542871542274952, 0.005751718766987324, 0.005930902436375618, 0.006121171172708273, 0.006285456009209156, 0.006614588666707277, 0.12066787481307983, 0.006589318159967661, 0.1189771443605423, 0.006775551941245794, 0.007139057852327824, 0.006969547364860773, 0.006936632562428713, 0.006952069699764252, 0.007012201938778162, 0.006890166085213423, 0.006826764438301325, 0.1561938226222992, 0.006602637469768524, 0.006562531925737858, 0.006686846259981394, 0.006402609404176474, 0.006386371795088053, 0.006076269783079624, 0.006655904930084944, 0.005907610524445772, 0.005577998235821724, 0.00561737734824419, 0.0890345647931099, 0.005185263697057962, 0.0903165191411972, 0.005510001443326473, 0.42752593755722046, 0.13158929347991943, 0.14606556296348572, 0.00618711207062006, 0.006455095484852791, 0.0067750997841358185, 0.10592398792505264, 0.0073824976570904255, 0.00748024694621563, 0.007724048104137182, 0.007944333367049694, 0.007941033691167831, 0.008021258749067783, 0.007975519634783268, 0.007895806804299355, 0.09091266989707947, 0.007765570655465126, 0.007891308516263962, 0.10359451174736023, 0.007596077397465706, 0.007534087169915438, 0.007643008604645729, 0.0074865324422717094, 0.00726076727733016]\n",
            "Val loss 0.03827701003307052\n",
            "Val auc roc 0.4809892328398385\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f3bc78fd7eb4ccdb06db85379b244b3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0305\n",
            "Train Losses : [0.1122780591249466, 0.006971137598156929, 0.006955107674002647, 0.0068228947930037975, 0.006673573050647974, 0.11023806780576706, 0.006516157649457455, 0.006304403301328421, 0.0062749991193413734, 0.006145915016531944, 0.005866554565727711, 0.0058780028484761715, 0.0055955252610147, 0.1000431478023529, 0.005461401771754026, 0.005293584428727627, 0.005186957772821188, 0.005080457776784897, 0.005157932173460722, 0.0048890686593949795, 0.0049852896481752396, 0.004687071777880192, 0.36056604981422424, 0.004805117379873991, 0.06277129799127579, 0.14956268668174744, 0.0054520429112017155, 0.005657515022903681, 0.005841102451086044, 0.00593396183103323, 0.006066570058465004, 0.006128625478595495, 0.006373136304318905, 0.006275690160691738, 0.006292528938502073, 0.006256726570427418, 0.006116870325058699, 0.006076189689338207, 0.0059273503720760345, 0.005834193900227547, 0.005762389395385981, 0.005579211283475161, 0.005459014326334, 0.0052716489881277084, 0.005312015302479267, 0.004902247805148363, 0.004932823125272989, 0.005118303466588259, 0.004479892551898956, 0.004632380325347185, 0.004521353170275688, 0.4594319462776184, 0.004295287653803825, 0.0044966889545321465, 0.004747648257762194, 0.0049652582965791225, 0.0048809051513671875, 0.005087798926979303, 0.00487027270719409, 0.005077153444290161, 0.004955517128109932, 0.005043474491685629, 0.11737338453531265, 0.0049099246971309185, 0.004858346190303564, 0.005445265211164951, 0.005071981344372034, 0.004820155445486307, 0.004835129249840975, 0.004742470104247332, 0.004727657418698072, 0.14382490515708923, 0.09076124429702759, 0.1402147263288498, 0.004818540532141924, 0.00494116498157382, 0.10185419768095016, 0.004904524888843298, 0.00511193135753274, 0.004980230703949928, 0.08930500596761703, 0.005233265925198793, 0.005129273049533367, 0.005121420603245497, 0.005434553138911724, 0.005147732328623533, 0.00522865355014801, 0.004957300145179033, 0.004935531411319971, 0.1338338404893875, 0.005057176575064659, 0.004824396688491106, 0.08350800722837448, 0.004890699405223131, 0.004791188985109329, 0.00519754970446229, 0.004931790288537741, 0.0049787298776209354, 0.004636104684323072, 0.005049029365181923, 0.0045775375328958035, 0.004651154391467571, 0.004340533632785082, 0.004260010551661253, 0.0043428028002381325, 0.10170776396989822, 0.004034552723169327, 0.004020806401968002, 0.0039558629505336285, 0.004288120660930872, 0.003953089937567711, 0.0038325495552271605, 0.11643510311841965, 0.1093476340174675, 0.003708665492013097, 0.0037461689207702875, 0.0038597099483013153, 0.12466053664684296, 0.10149457305669785, 0.00396276731044054, 0.13760486245155334, 0.004440284334123135, 0.004513327032327652, 0.004628926049917936, 0.00439689215272665, 0.1270654946565628, 0.004504569806158543, 0.004717168398201466, 0.0047563305124640465, 0.004926934838294983, 0.004756788723170757, 0.7720673680305481, 0.005414965562522411, 0.005932654719799757, 0.006653536111116409, 0.007589411456137896, 0.007769197691231966, 0.007964356802403927, 0.00839195679873228, 0.008544953539967537, 0.11813592910766602, 0.010023056529462337, 0.009502300061285496, 0.00951014831662178, 0.009407959878444672, 0.010349742136895657, 0.009708703495562077, 0.17401044070720673, 0.09365660697221756, 0.11884716898202896, 0.009390855208039284, 0.009491036646068096, 0.00964775774627924, 0.00954874511808157, 0.12231641262769699, 0.00942237675189972, 0.009530975483357906, 0.00878956913948059, 0.008743032813072205, 0.008546445518732071, 0.008315582759678364, 0.007947969250380993, 0.007727170363068581, 0.12658344209194183, 0.08560160547494888, 0.007273154798895121, 0.007296629250049591, 0.00714107695966959, 0.006928446236997843, 0.0068763261660933495, 0.006690592970699072, 0.11235956847667694, 0.006558319553732872, 0.006268927827477455, 0.08079386502504349, 0.006247203331440687, 0.005910775624215603, 0.006052739452570677, 0.14054591953754425, 0.005700470879673958, 0.005783255212008953, 0.11055950820446014, 0.006079566199332476, 0.005598585586994886, 0.005437913816422224, 0.005379135254770517, 0.005358383059501648, 0.00531679717823863, 0.00541431549936533, 0.005052501801401377, 0.005250347778201103, 0.004938534460961819, 0.004830753430724144, 0.004935442470014095, 0.004476809874176979, 0.19450342655181885, 0.004341565538197756, 0.004339700099080801, 0.11192506551742554, 0.11298123747110367, 0.004290740936994553, 0.004389375913888216, 0.0044645881280303, 0.10844404250383377, 0.004344341345131397, 0.004521550145000219, 0.004587825853377581, 0.004402666352689266, 0.004456303548067808, 0.004377863835543394, 0.004336206242442131, 0.129155233502388, 0.004377939738333225, 0.004286730661988258, 0.0044883061200380325, 0.004272314254194498, 0.0044334824196994305, 0.004169240593910217, 0.004195413552224636, 0.004170756787061691, 0.003994837868958712, 0.003955464344471693, 0.004200990777462721, 0.003859381191432476, 0.08673711121082306, 0.0038319285959005356, 0.003665699390694499, 0.1283193826675415, 0.003842886770144105, 0.0036719944328069687, 0.003665168071165681, 0.0036263815127313137, 0.003619791241362691, 0.003616783069446683, 0.0036020774859935045, 0.003588377730920911, 0.11465602368116379, 0.0035316830035299063, 0.003526948858052492, 0.0035153881181031466, 0.0034889436792582273, 0.0033993853721767664, 0.0033856998197734356, 0.0033727865666151047, 0.003299905452877283, 0.0033639513421803713, 0.0031881935428828, 0.0031983673106878996, 0.0032278166618198156, 0.0030576419085264206, 0.003179950872436166, 0.0031158803030848503, 0.0028913747519254684, 0.002977021038532257, 0.002784516429528594, 0.0027364641427993774, 0.0026863724924623966, 0.002791576087474823, 0.002665267325937748, 0.002545396564528346, 0.002562380861490965, 0.0024776640348136425, 0.0025679480750113726, 0.002355886623263359, 0.00230418611317873, 0.0022904351353645325, 0.0022173377219587564, 0.14296577870845795, 0.14329469203948975, 0.47279539704322815, 0.0025554082822054625, 0.002672443399205804, 0.002932978328317404, 0.0031948948744684458, 0.0033114682883024216, 0.0035220254212617874, 0.0036918753758072853, 0.0038937253411859274, 0.12410875409841537, 0.004330592695623636, 0.004289751406759024, 0.004395901225507259, 0.004692187998443842, 0.13813455402851105, 0.0045055910013616085, 0.004719567019492388, 0.0046747769229114056, 0.004911752417683601, 0.005130789242684841, 0.0047924756072461605, 0.004911039024591446, 0.1258292943239212, 0.10907087475061417, 0.004888555500656366, 0.004885292612016201, 0.005121869500726461, 0.004989926237612963, 0.005007034633308649, 0.09002327173948288, 0.005345622543245554, 0.0050199516117572784, 0.005023773293942213, 0.004998325370252132, 0.11768961697816849, 0.005054079927504063, 0.00503831310197711, 0.0051101441495120525, 0.00494059594348073, 0.11524228751659393, 0.005018480122089386, 0.10579606145620346, 0.004920496139675379, 0.005051391199231148, 0.005308839026838541, 0.004972860217094421, 0.1297815442085266, 0.005259719677269459, 0.005042740143835545, 0.0050655328668653965, 0.005005225073546171, 0.005038468167185783, 0.0049636391922831535, 0.004841435234993696, 0.004815203603357077, 0.004793787840753794, 0.004579027649015188, 0.004621046595275402, 0.004619278945028782, 0.10137028247117996, 0.1392548531293869, 0.14881248772144318, 0.12106738239526749, 0.004822292365133762, 0.004781041759997606, 0.13416875898838043, 0.004790537524968386, 0.12907803058624268, 0.005264224950224161, 0.00524811539798975, 0.005150828510522842, 0.005592613946646452, 0.005263682920485735, 0.005289887078106403, 0.005316333845257759, 0.005334270186722279, 0.005306985229253769, 0.005178919993340969, 0.005191662348806858, 0.005192064680159092, 0.00494120130315423, 0.00482202647253871, 0.004923670087009668, 0.004761107265949249, 0.004701955243945122, 0.004545271396636963, 0.11173427850008011, 0.12413384765386581, 0.13090795278549194, 0.0043928129598498344, 0.13636593520641327, 0.00457237521186471, 0.0046603381633758545, 0.00467334920540452, 0.004697907716035843, 0.004793199244886637, 0.08235377818346024, 0.004775411915034056, 0.0049918461591005325, 0.13495753705501556, 0.004774043336510658, 0.127450630068779, 0.00494561530649662, 0.09536537528038025, 0.13347740471363068, 0.005429677665233612, 0.005412769969552755, 0.005680692382156849, 0.005452745594084263, 0.005584098398685455, 0.005754207726567984, 0.005510055460035801, 0.005564084276556969, 0.005529856774955988, 0.005414721090346575, 0.005372227169573307, 0.0053129177540540695, 0.005333708133548498, 0.09646748751401901, 0.005167291034013033, 0.005125844851136208, 0.0052743819542229176, 0.0048857941292226315, 0.004865816328674555, 0.41416990756988525, 0.0051737502217292786, 0.005254584830254316, 0.005354364402592182, 0.005408226512372494, 0.1286192089319229, 0.005755891557782888, 0.00571992015466094, 0.005875508766621351, 0.005830076057463884, 0.005877995863556862, 0.12869974970817566, 0.13961230218410492, 0.09284663200378418, 0.0064372471533715725, 0.14275726675987244, 0.006424224469810724, 0.006561914458870888, 0.006711756810545921, 0.006680076941847801, 0.006775334477424622, 0.11672897636890411, 0.006691151764243841, 0.10859530419111252, 0.006803053896874189, 0.006794976536184549, 0.1383417248725891, 0.0068341633304953575, 0.006951161194592714, 0.006962182000279427, 0.007071846630424261, 0.11844940483570099, 0.129710391163826, 0.006778075825423002, 0.006985244806855917, 0.006807663477957249, 0.006795287132263184, 0.006855128798633814, 0.006855836138129234, 0.00668077589944005, 0.006855164188891649, 0.006420582067221403, 0.09944988787174225, 0.006326284725219011, 0.0060961367562413216, 0.0061336904764175415, 0.005976620130240917, 0.00581010477617383, 0.12244171649217606, 0.005885615479201078, 0.00569072226062417, 0.005599840544164181, 0.005780770909041166, 0.00525147607550025, 0.0052420697174966335, 0.36844879388809204, 0.12745989859104156, 0.005669353064149618, 0.00570134911686182, 0.005993973463773727, 0.0060610538348555565, 0.006168123334646225, 0.006469827610999346, 0.0062539284117519855, 0.006330370903015137, 0.11563324183225632, 0.09469904005527496, 0.006503687240183353, 0.1254960149526596, 0.006593301426619291, 0.006786264944821596, 0.11433840543031693, 0.006765979807823896, 0.007282003294676542, 0.00684773363173008, 0.006992187816649675, 0.007122335955500603, 0.10391874611377716, 0.006812144070863724, 0.006703047547489405, 0.006735834293067455, 0.006782295648008585, 0.006810031831264496, 0.006493682973086834, 0.11976758390665054, 0.006257044617086649, 0.006417000666260719, 0.006105352193117142, 0.12755168974399567, 0.006048609968274832, 0.1370997279882431, 0.0060000731609761715, 0.005951135419309139, 0.006033481564372778, 0.006017903331667185, 0.005772179923951626, 0.0872490331530571, 0.005664037540555, 0.09557553380727768, 0.09932098537683487, 0.005761855281889439, 0.005687001161277294, 0.005637721158564091, 0.005718010012060404, 0.00579610001295805, 0.005538610741496086, 0.005497762933373451, 0.005493277218192816, 0.005484444089233875, 0.0053289891220629215, 0.005195967387408018, 0.005045267287641764, 0.004929305054247379, 0.004833902232348919, 0.004719555377960205, 0.004665631800889969, 0.004598487168550491, 0.004414512310177088, 0.004259556531906128, 0.004303736612200737, 0.00408140430226922, 0.00399140827357769, 0.0040733409114181995, 0.003836866468191147, 0.0037661725655198097, 0.0036322881933301687, 0.0034959600307047367, 0.003458081977441907, 0.11882660537958145, 0.0033904456067830324, 0.003356833476573229, 0.0031963177025318146, 0.15243393182754517, 0.003212775569409132, 0.003173877252265811, 0.003204990178346634, 0.0031879846937954426, 0.09350845962762833, 0.0031881157774478197, 0.003190614515915513, 0.0032339091412723064, 0.0032147755846381187, 0.12626810371875763, 0.003396071493625641, 0.10366291552782059, 0.1325709968805313, 0.003396126674488187, 0.0036040006671100855, 0.0036437271628528833, 0.003705310169607401, 0.0036964763421565294, 0.0036990423686802387, 0.08297200500965118, 0.0038075402844697237, 0.00407046265900135, 0.0038316790014505386, 0.11281444877386093, 0.0039508771151304245, 0.003975588362663984, 0.0041589257307350636, 0.00405137287452817, 0.004035872407257557, 0.003988847602158785, 0.004049038514494896, 0.003995257429778576, 0.004091736860573292, 0.10688835382461548, 0.003883304540067911, 0.09565453976392746, 0.003865310689434409, 0.0038978522643446922, 0.13329562544822693, 0.09317750483751297, 0.004059092607349157, 0.0043191914446651936, 0.004343823064118624, 0.004349878057837486, 0.09545773267745972, 0.004337053745985031, 0.0046633100137114525, 0.004472747910767794, 0.0046037063002586365, 0.004450241103768349, 0.004407387226819992, 0.004416154697537422, 0.004468223080039024, 0.004542776383459568, 0.004259707406163216, 0.0044774399138987064, 0.004446511622518301, 0.004109297413378954, 0.004165977705270052, 0.003940383438020945, 0.0042038061656057835, 0.11728493124246597, 0.0038905662950128317, 0.0037487067747861147, 0.0037766413297504187, 0.1436593234539032, 0.0037089274264872074, 0.003772734198719263, 0.003715407568961382, 0.0037338649854063988, 0.0039100684225559235, 0.003969267476350069, 0.003668509889394045, 0.0035794975701719522, 0.0035695615224540234, 0.0035912960302084684, 0.4404796063899994, 0.003951198421418667, 0.13833627104759216, 0.004003502894192934, 0.004214623011648655, 0.004643852822482586, 0.0047689941711723804, 0.004677410703152418, 0.004625160247087479, 0.11832448095083237, 0.004968131426721811, 0.005080385133624077, 0.005011571571230888, 0.005070233717560768, 0.005103451665490866, 0.005201290361583233, 0.005025915335863829, 0.005457592662423849, 0.0051023694686591625, 0.005031719338148832, 0.004919002298265696, 0.004852684680372477, 0.004838837776333094, 0.13771939277648926, 0.004713017493486404, 0.00462699681520462, 0.004607626236975193, 0.004565971437841654, 0.004764457233250141, 0.10165836662054062, 0.004572880920022726, 0.004685513209551573, 0.11053100973367691, 0.00440939050167799, 0.004421972203999758, 0.004439531359821558, 0.0044815074652433395, 0.004422768950462341, 0.004361673723906279, 0.004289125092327595, 0.12138190865516663, 0.004344448912888765, 0.004467821214348078, 0.0042871213518083096, 0.0042496416717767715, 0.13050095736980438, 0.09983795881271362, 0.00421990966424346, 0.004263959359377623, 0.1272859275341034, 0.004541412461549044, 0.004634553100913763, 0.0046445392072200775, 0.10956147313117981, 0.0046317074447870255, 0.004552233964204788, 0.004604763351380825, 0.004855010658502579, 0.004633490927517414, 0.004689240362495184, 0.14740720391273499, 0.0045752450823783875, 0.00466138543561101, 0.08405184745788574, 0.004588904790580273, 0.004730675369501114, 0.09210606664419174, 0.004748218227177858, 0.00465991348028183, 0.004681297577917576, 0.004683776758611202, 0.004777533933520317, 0.00488646887242794, 0.00481641199439764, 0.004810051992535591, 0.00463424576446414, 0.12594056129455566, 0.0044343117624521255, 0.004666160326451063, 0.004457085859030485, 0.004416860640048981, 0.12398026138544083, 0.0043390896171331406, 0.004404623527079821, 0.0826805830001831, 0.004360151011496782, 0.004332991782575846, 0.0044474550522863865, 0.004351351410150528, 0.00458072405308485, 0.09644660353660583, 0.004521950148046017, 0.09738378971815109, 0.004396694712340832, 0.10336485505104065, 0.13879576325416565, 0.10746186971664429, 0.0052699982188642025, 0.004974201321601868, 0.005285908468067646, 0.005286816507577896, 0.0050307465717196465, 0.16329160332679749, 0.005287065636366606, 0.005174348130822182, 0.005192319396883249, 0.005262174643576145, 0.0053550247102975845, 0.005464380607008934, 0.00534703116863966, 0.005291099660098553, 0.11113083362579346, 0.005064352881163359, 0.005395214073359966, 0.004986761603504419, 0.005162789952009916, 0.004909529350697994, 0.004890843760222197, 0.004791438113898039, 0.13374829292297363, 0.004914780147373676, 0.004670329857617617, 0.004653486888855696, 0.004722520709037781, 0.004733110778033733, 0.11354676634073257, 0.004944074898958206, 0.12070468068122864, 0.0045153056271374226, 0.004420080687850714, 0.004559821914881468, 0.004402320832014084, 0.004575240891426802, 0.004310686606913805, 0.004322615917772055, 0.004459715913981199, 0.10218171775341034, 0.004179907962679863, 0.1030549630522728, 0.004463577177375555, 0.00416202237829566, 0.004454223904758692, 0.004158152267336845, 0.0043044020421803, 0.004123591352254152, 0.004181690514087677, 0.004119579680263996, 0.004140825010836124, 0.1421635001897812, 0.12937675416469574, 0.13179798424243927, 0.004158239811658859, 0.004116675350815058, 0.004380036145448685, 0.00436871824786067, 0.0043650041334331036, 0.1049051508307457, 0.45056504011154175, 0.004650825634598732, 0.004891313146799803, 0.0052107227966189384, 0.005414673592895269, 0.005621957592666149, 0.006168225314468145, 0.005857117939740419, 0.00594676798209548, 0.005988001823425293, 0.006432258524000645, 0.006183867808431387, 0.14798904955387115, 0.006144663784652948, 0.0063623483292758465, 0.00630846805870533, 0.006298285908997059, 0.0060746874660253525, 0.09947127103805542, 0.00617483863607049, 0.006349771283566952, 0.06333322077989578, 0.006031198427081108, 0.006109506823122501, 0.006076066289097071, 0.005841018166393042, 0.005951937288045883, 0.005907224491238594, 0.005653488449752331, 0.0055451891385018826, 0.005495395977050066, 0.1406724452972412, 0.00532022537663579, 0.005233665928244591, 0.005391827784478664, 0.00525794830173254, 0.005061781033873558, 0.005013086833059788, 0.004995313473045826, 0.004990419838577509, 0.1138913705945015, 0.004894408863037825, 0.004698461852967739, 0.004625826142728329, 0.00445329025387764, 0.004426243714988232, 0.0044659581035375595, 0.004332844167947769, 0.004252729471772909, 0.13760188221931458, 0.004309406969696283, 0.12216704338788986, 0.004476120695471764, 0.10319593548774719, 0.1243022233247757, 0.004216540604829788, 0.004364871419966221, 0.4218252897262573, 0.00474255345761776, 0.004837700165808201, 0.0051383706741034985, 0.005270263645797968, 0.005571797024458647, 0.12025180459022522, 0.005743101704865694, 0.006035921163856983, 0.006374673452228308, 0.13202397525310516, 0.006501356605440378, 0.006567541044205427, 0.006681176368147135, 0.006566993892192841, 0.006562343332916498, 0.006625446490943432, 0.006505677476525307, 0.11333458870649338, 0.006389076355844736, 0.0064679039642214775, 0.006499509327113628, 0.0063033197075128555, 0.006282956805080175, 0.0061321500688791275, 0.00613391725346446, 0.08765510469675064, 0.005859031807631254, 0.00592862069606781, 0.005731500219553709, 0.005779241677373648, 0.005733244586735964, 0.005603231023997068, 0.0053634801879525185, 0.005356632173061371, 0.005301568191498518, 0.0051737381145358086, 0.004932499025017023, 0.00503260362893343, 0.004859644453972578, 0.004820179659873247, 0.004565972834825516, 0.004495847038924694, 0.00433229049667716, 0.004234823398292065, 0.004092090763151646, 0.004182006232440472, 0.004044151399284601, 0.003796054981648922, 0.0038411200512200594, 0.0038689165376126766, 0.0036580234300345182, 0.0035071989987045527, 0.0034332103095948696, 0.1018439531326294, 0.0033164387568831444, 0.0035070234443992376, 0.0032045654952526093, 0.13180683553218842, 0.16206762194633484, 0.00361756538040936, 0.0034322557039558887, 0.15105141699314117, 0.0033488867338746786, 0.0035261171869933605, 0.0036457309033721685, 0.0035683743190020323, 0.003571313340216875, 0.0035612094216048717, 0.0036188308149576187, 0.0036279517225921154, 0.003737398888915777, 0.00357298506423831, 0.0035157985985279083, 0.10983188450336456, 0.0035756465513259172, 0.15395501255989075, 0.0035855057649314404, 0.4231611490249634, 0.003941848408430815, 0.004050987772643566, 0.004304986447095871, 0.004496078472584486, 0.004677139222621918, 0.004714044742286205, 0.00497537013143301, 0.005023013800382614, 0.005195647943764925, 0.005362482741475105, 0.005081020761281252, 0.005119685549288988, 0.005240817554295063, 0.005300679709762335, 0.0050826347433030605, 0.0050360714085400105, 0.13563893735408783, 0.0052017588168382645, 0.005009395070374012, 0.005361834540963173, 0.005013149231672287, 0.12092579901218414, 0.0049539473839104176, 0.004901539999991655, 0.004877237603068352, 0.004816063679754734, 0.004972152877599001, 0.004799467511475086, 0.004704009275883436, 0.0047363536432385445, 0.004596183076500893, 0.004502657800912857, 0.004469792824238539, 0.004324426408857107, 0.004227424040436745, 0.00423188554123044, 0.004253405146300793, 0.004149401094764471, 0.004052110947668552, 0.0038871662691235542, 0.003760196501389146, 0.0037116254679858685, 0.0037222150713205338, 0.0036230527330189943, 0.1033012866973877, 0.003526645479723811, 0.0034781303256750107, 0.0033965581096708775, 0.003329974366351962, 0.15028223395347595, 0.0033036957029253244, 0.12564723193645477, 0.0033882223069667816, 0.0034853757824748755, 0.0034440881572663784, 0.0034195270854979753, 0.003417638596147299, 0.0034020161256194115, 0.14318864047527313, 0.0036131006199866533, 0.11102665215730667, 0.13169999420642853, 0.003666296601295471, 0.003676025662571192, 0.003770507173612714, 0.0038163207937031984, 0.0038655023090541363, 0.003899581031873822, 0.003920895978808403, 0.0038829739205539227, 0.10492374747991562, 0.0039868722669780254, 0.003935058601200581, 0.004013026598840952, 0.003958096262067556, 0.004028109833598137, 0.004046866670250893, 0.003987406380474567, 0.0039444114081561565, 0.4246801435947418, 0.0041073886677622795, 0.004362800624221563, 0.004573152866214514, 0.004502898547798395, 0.004765206482261419, 0.004880871623754501, 0.004809142556041479, 0.0047694602981209755, 0.005100977141410112, 0.004842706490308046, 0.11371621489524841, 0.004865278489887714, 0.004992219153791666, 0.09926003217697144, 0.00493377260863781, 0.005019958596676588, 0.005197971593588591, 0.1307443231344223, 0.005236541386693716, 0.005097195506095886, 0.005101913120597601, 0.15092788636684418, 0.0051858508959412575, 0.005259174853563309, 0.005279333330690861, 0.005236967001110315, 0.005230993032455444, 0.005103243049234152, 0.12978006899356842, 0.005072294268757105, 0.11253442615270615, 0.005157478153705597, 0.1325705200433731, 0.005353829823434353, 0.005400465801358223, 0.11479180306196213, 0.005355396773666143, 0.005378894507884979, 0.3576895594596863, 0.005641100462526083, 0.005910313222557306, 0.006130862981081009, 0.006259347777813673, 0.006426576990634203, 0.006624136120080948, 0.006581263151019812, 0.006679938640445471, 0.00677966233342886, 0.006667569745332003, 0.006749297957867384, 0.006639176048338413, 0.1146366149187088, 0.0069769625551998615, 0.006616585422307253, 0.006474231369793415, 0.11851655691862106, 0.006391928531229496, 0.08639832586050034, 0.00639421446248889, 0.11837934702634811, 0.0064680748619139194, 0.006629382725805044, 0.13048146665096283, 0.00647053262218833, 0.006502663716673851, 0.006551181897521019, 0.006427768152207136, 0.006316610611975193, 0.006296035833656788, 0.00629787240177393, 0.006116819102317095, 0.3459641635417938, 0.0063045141287148, 0.006483430974185467, 0.00665392866358161, 0.006564644165337086, 0.12218385189771652, 0.006799397058784962, 0.00681112427264452, 0.007082081399857998, 0.006855999119579792, 0.0069169276393949986, 0.006910824682563543, 0.006976991891860962, 0.13595110177993774, 0.006739112548530102, 0.10181128233671188, 0.006797869689762592, 0.006700555793941021, 0.10590971261262894, 0.006764709949493408, 0.00671320641413331, 0.006600445136427879, 0.006607653573155403, 0.0065246704034507275, 0.00643931282684207, 0.006491086445748806, 0.006285907234996557, 0.1176765114068985, 0.006098578684031963, 0.07941612601280212, 0.006120079196989536, 0.15645825862884521, 0.006062595639377832, 0.006041822023689747, 0.005964950192719698, 0.10069026052951813, 0.005981783848255873, 0.005903113633394241, 0.005936961155384779, 0.11510233581066132, 0.0058815814554691315, 0.005899368319660425, 0.100631944835186, 0.1017189472913742, 0.005835231859236956, 0.0840001255273819, 0.00588641781359911, 0.00606148224323988, 0.006068394519388676, 0.0061364127323031425, 0.1194472461938858, 0.005971728824079037, 0.005987466778606176, 0.0059504760429263115, 0.005956603679805994, 0.005995476618409157, 0.005796420853585005, 0.005769357085227966, 0.10698018968105316, 0.00572773814201355, 0.0056981900706887245, 0.0057776872999966145, 0.00568197900429368, 0.005441863089799881, 0.005407170858234167, 0.005305297672748566, 0.00524973776191473, 0.0052294740453362465, 0.005359357222914696, 0.004938330035656691, 0.004910046700388193, 0.004755567759275436, 0.004793178290128708, 0.0045610046945512295, 0.14279387891292572, 0.004582205321639776, 0.004498534835875034, 0.14559009671211243, 0.004369508940726519, 0.004695931449532509, 0.13312369585037231, 0.0043667093850672245, 0.13766761124134064, 0.004496440291404724, 0.11110738664865494, 0.0045497664250433445, 0.004590415395796299, 0.10348378121852875, 0.004744264297187328, 0.004782266914844513, 0.004779473412781954, 0.0048779272474348545, 0.0048414189368486404, 0.004843404050916433, 0.004838603548705578, 0.004824159201234579, 0.004916718695312738, 0.0046955677680671215, 0.004644945729523897, 0.0047993422485888, 0.11346375942230225, 0.004545446019619703, 0.004652682226151228, 0.004635212942957878, 0.004563780501484871, 0.004511601757258177, 0.0044622295536100864, 0.004354570992290974, 0.004335511941462755, 0.0802900493144989, 0.004172023385763168, 0.004292747937142849, 0.004137342795729637, 0.004147143103182316, 0.004036255646497011, 0.004015367478132248, 0.003965763840824366, 0.00395938428118825, 0.0037964084185659885, 0.003775831777602434, 0.0037103404756635427, 0.0036626572255045176, 0.0036767220590263605, 0.003525653388351202, 0.0035976157523691654, 0.0034583015367388725, 0.0033533433452248573, 0.0033359606750309467, 0.11161857098340988, 0.0032108223531395197, 0.003295714734122157, 0.003182467073202133, 0.15922869741916656, 0.0031735834199935198, 0.0032956067007035017, 0.42864152789115906, 0.14834608137607574, 0.0036880129482597113, 0.0038756937719881535, 0.004021577537059784, 0.004072727169841528, 0.12627483904361725, 0.3570316433906555, 0.0047935983166098595, 0.10812581330537796, 0.0054193781688809395, 0.0057898773811757565, 0.005959933158010244, 0.006230271887034178, 0.00670325243845582, 0.006675736512988806, 0.006785496138036251, 0.007097321562469006, 0.007105601020157337, 0.007020103745162487, 0.007209778763353825, 0.007261523511260748, 0.007186938542872667, 0.0071018533781170845, 0.006929492577910423, 0.0072347610257565975, 0.007309109438210726, 0.11221388727426529, 0.0069903042167425156, 0.006840846501290798, 0.006560954265296459, 0.006464389152824879, 0.00639115646481514, 0.006256850901991129, 0.0061615100130438805, 0.006191466003656387, 0.00597745506092906, 0.12437034398317337, 0.005823316518217325, 0.005778018850833178, 0.005663861986249685, 0.005557313561439514, 0.005455325823277235, 0.0053674909286201, 0.005271083675324917, 0.005181996617466211, 0.09576309472322464, 0.12214743345975876, 0.004988320171833038, 0.004956600721925497, 0.004980575293302536, 0.0049121263436973095, 0.005074154119938612, 0.004873718600720167, 0.1197831779718399, 0.11426377296447754, 0.004897154867649078, 0.11887215077877045, 0.004858998581767082, 0.00481405621394515, 0.004936589393764734, 0.004851171746850014, 0.004876084625720978, 0.004805879667401314, 0.09684004634618759, 0.004826848860830069, 0.004835293162614107, 0.004825406242161989, 0.004794755484908819, 0.004767852369695902, 0.00488440552726388, 0.004636305384337902, 0.00459375511854887, 0.004693035501986742, 0.14257711172103882, 0.0044479696080088615, 0.004646087531000376, 0.004475418012589216, 0.11601138114929199, 0.004365126136690378, 0.004372716881334782, 0.00436409329995513, 0.10852227360010147, 0.00435181288048625, 0.004374532029032707, 0.004400580655783415, 0.0043428074568510056, 0.004345341585576534, 0.004347209352999926, 0.004346734378486872, 0.004237860441207886, 0.004245870281010866, 0.10577757656574249, 0.004099560901522636, 0.14020520448684692, 0.004131801892071962, 0.004224959295243025, 0.09428176283836365, 0.11474372446537018, 0.00425140094012022, 0.004287663847208023, 0.004416292533278465, 0.0044470494613051414, 0.004460466559976339, 0.004436897113919258, 0.10684021562337875, 0.00449034571647644, 0.00440542446449399, 0.004449308849871159, 0.004555906169116497, 0.004478753078728914, 0.004392111673951149, 0.0910549908876419, 0.004448650870472193, 0.004461289383471012, 0.004475502762943506, 0.004343801643699408, 0.0043757581152021885, 0.004428214393556118, 0.004245800897479057, 0.14007212221622467, 0.004242683760821819, 0.004247557837516069, 0.004160826560109854, 0.004192935768514872, 0.0041573625057935715, 0.004317556973546743, 0.1036931723356247, 0.004067943897098303, 0.004047001246362925, 0.004021734930574894, 0.004081940744072199, 0.0040473113767802715, 0.0040571377612650394, 0.0038933525793254375, 0.10776641964912415, 0.003963995724916458, 0.003878088900819421, 0.003841759404167533, 0.0038326140493154526, 0.003839087439700961, 0.0037392203230410814, 0.003719832981005311, 0.0036784340627491474, 0.003649133024737239, 0.0036883377470076084, 0.003530892077833414, 0.0035412798170000315, 0.0034634529147297144, 0.003466525347903371, 0.4410058557987213, 0.12016428261995316, 0.11807273328304291, 0.003840618534013629, 0.46984103322029114, 0.004374646581709385, 0.004712068475782871, 0.005048581399023533, 0.005242203362286091, 0.005500370636582375, 0.005781238898634911, 0.0059828669764101505, 0.006146376486867666, 0.006261989939957857, 0.10135394334793091, 0.1415058821439743, 0.006589419208467007, 0.0067255133762955666, 0.006779667921364307, 0.0069330004043877125, 0.006978838238865137, 0.0068882969208061695, 0.007147649768739939, 0.006938926409929991, 0.0068825832568109035, 0.006859432440251112, 0.006853886879980564, 0.006735514849424362, 0.006598098669201136, 0.006554051768034697, 0.0064291623421013355, 0.006428877357393503, 0.006191208492964506, 0.006266555283218622, 0.1277409791946411, 0.39536190032958984, 0.006144055165350437, 0.006672189570963383, 0.006467435974627733, 0.006635863333940506, 0.006513299886137247, 0.006613362114876509, 0.006626803427934647, 0.0069643487222492695, 0.12197338789701462, 0.0066203707829117775, 0.00677202083170414, 0.006626755930483341, 0.11939053237438202, 0.006736087612807751, 0.00667665246874094, 0.00656146602705121, 0.006608440540730953, 0.006559942848980427, 0.10667495429515839, 0.006424158811569214, 0.10221689939498901, 0.0063450573943555355, 0.00633282633498311, 0.006294334307312965, 0.006269969046115875, 0.006270906422287226, 0.006160285789519548, 0.0061891027726233006, 0.005953145679086447, 0.005929881241172552, 0.005935007240623236, 0.005723293870687485, 0.005665873177349567, 0.005618293769657612, 0.12320227921009064, 0.005358149763196707, 0.005349517334252596, 0.09241319447755814, 0.005216565448790789, 0.00525271613150835, 0.005137482192367315, 0.005157807841897011, 0.00516272708773613, 0.004989237058907747, 0.15112048387527466, 0.004987160675227642, 0.00486472062766552, 0.004892670549452305, 0.10379748046398163, 0.11509990692138672, 0.126290962100029, 0.005012880079448223, 0.11466415226459503, 0.004982640501111746, 0.005076582543551922, 0.005123045761138201, 0.13796579837799072, 0.005155317485332489, 0.005222513806074858, 0.005275915376842022, 0.0053048161789774895, 0.08208397030830383, 0.005297912284731865, 0.005282306112349033, 0.12607571482658386, 0.005344188306480646, 0.005331940948963165, 0.10798180103302002, 0.005534443538635969, 0.005449169781059027, 0.10605824738740921, 0.005434067919850349, 0.005480817519128323, 0.08224569261074066, 0.005616153124719858, 0.005468021146953106, 0.005602607037872076, 0.005621199030429125, 0.005479373969137669, 0.005540813319385052, 0.005754103418439627, 0.005328622180968523, 0.0054280939511954784, 0.3941950798034668, 0.005464865826070309, 0.005509651266038418, 0.005637860391288996, 0.00580915343016386, 0.005842067766934633, 0.006008608266711235, 0.006025772076100111, 0.005949710961431265, 0.10105287283658981, 0.0058790650218725204, 0.00603900384157896, 0.00597517192363739, 0.1136920154094696, 0.10482466965913773, 0.1480896770954132, 0.006114749703556299, 0.10259168595075607, 0.0061470093205571175, 0.11010514944791794, 0.006330475211143494, 0.006415410898625851, 0.006457601673901081, 0.13586266338825226, 0.006578649859875441, 0.0067323376424610615, 0.006610556971281767, 0.006586031056940556, 0.11163202673196793, 0.10084648430347443, 0.006577971391379833, 0.006686948239803314, 0.006703327875584364, 0.10290860384702682, 0.006659558042883873, 0.006844475399702787, 0.006741559598594904, 0.006625431124120951, 0.39657726883888245, 0.006736517418175936, 0.007048741914331913, 0.00698046525940299, 0.0070940349251031876, 0.007276793941855431, 0.12025921791791916, 0.00740167498588562, 0.007324646692723036, 0.11698825657367706, 0.007619630079716444, 0.007435918319970369, 0.00754969147965312, 0.2850990295410156, 0.00785287469625473, 0.00792365986853838, 0.007991730235517025, 0.11999351531267166, 0.008286934345960617, 0.008337026461958885, 0.008406678214669228, 0.008436695672571659, 0.008414071053266525, 0.00842960737645626, 0.008365089073777199, 0.008290702477097511, 0.00825223233550787, 0.08523356169462204, 0.00815101433545351, 0.008204404264688492, 0.007995889522135258, 0.00814633909612894, 0.007860276848077774, 0.007669006008654833, 0.007541704922914505, 0.10710851848125458, 0.3447812795639038, 0.007561172358691692, 0.007716157007962465, 0.08748843520879745, 0.00779223395511508, 0.007901052013039589, 0.008124272339046001, 0.007951227016746998, 0.008042827248573303, 0.09248102456331253, 0.00801829807460308, 0.14200644195079803, 0.008017036132514477, 0.008073313161730766, 0.007954535074532032, 0.007932282984256744, 0.007924284785985947, 0.007840205915272236, 0.007657342590391636, 0.007607535924762487, 0.12752628326416016, 0.007423570845276117, 0.0073448531329631805, 0.1109442338347435, 0.007176435086876154, 0.007310550194233656, 0.007094865664839745, 0.007106367964297533, 0.007021167315542698, 0.09662085771560669, 0.006753176916390657, 0.09600120782852173, 0.006671136245131493, 0.006867185700684786, 0.006632348522543907, 0.006524437572807074, 0.08482610434293747, 0.006509330123662949, 0.006611637305468321, 0.3352234959602356, 0.006554558873176575, 0.11092523485422134, 0.006726483348757029, 0.006982855964452028, 0.006928998976945877, 0.00704229436814785, 0.007182637695223093, 0.007263766136020422, 0.007078313268721104, 0.007258715573698282, 0.0071525247767567635, 0.006953584961593151, 0.09909253567457199, 0.11390428990125656, 0.00715540861710906, 0.006898159626871347, 0.007055213674902916, 0.007397163659334183, 0.006977895274758339, 0.006775457877665758, 0.007173368241637945, 0.006673620082437992, 0.10328098386526108, 0.006515174172818661, 0.10798437893390656, 0.006425949279218912, 0.11360348761081696, 0.0065346225164830685, 0.006520260591059923, 0.13431017100811005, 0.006378836464136839]\n",
            "Val loss 0.040670085002791914\n",
            "Val auc roc 0.5063440597087973\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e7ea4145a634017a26e0152871920a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1595.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0300\n",
            "Train Losses : [0.006610665004700422, 0.006446121726185083, 0.006511798594146967, 0.006248570047318935, 0.14385178685188293, 0.006211280822753906, 0.0062214708887040615, 0.00612229947000742, 0.0061709098517894745, 0.005995261948555708, 0.11805681139230728, 0.005974878557026386, 0.09610767662525177, 0.005970106925815344, 0.006036756094545126, 0.12668545544147491, 0.005941398907452822, 0.005925693549215794, 0.005922070238739252, 0.10948000848293304, 0.1110197976231575, 0.005843610502779484, 0.005872521083801985, 0.005922448355704546, 0.00597417913377285, 0.006045674905180931, 0.00598375266417861, 0.005846558604389429, 0.005801652558147907, 0.12482874095439911, 0.09671038389205933, 0.0056674848310649395, 0.005667608231306076, 0.005776986479759216, 0.005712268408387899, 0.005685003008693457, 0.005636731628328562, 0.13823053240776062, 0.13226181268692017, 0.10946816951036453, 0.005607058294117451, 0.005631492473185062, 0.005735576152801514, 0.0056625897996127605, 0.005720373708754778, 0.13623157143592834, 0.005722275469452143, 0.005681000184267759, 0.0056489999406039715, 0.005641540512442589, 0.005673549138009548, 0.0058159008622169495, 0.005506833083927631, 0.005512008909136057, 0.005659808870404959, 0.005373124964535236, 0.09375694394111633, 0.005359862465411425, 0.11657562106847763, 0.0052222576923668385, 0.005282918456941843, 0.0053506651893258095, 0.0053347013890743256, 0.005164670757949352, 0.0051167551428079605, 0.005067035090178251, 0.0049935802817344666, 0.005118398927152157, 0.11257579922676086, 0.0048629711382091045, 0.004852836951613426, 0.1269918829202652, 0.004994633607566357, 0.004892447497695684, 0.004875041078776121, 0.004773196764290333, 0.004711785353720188, 0.004759468603879213, 0.004724499303847551, 0.1450953185558319, 0.44100767374038696, 0.004749559797346592, 0.00493979686871171, 0.08893107622861862, 0.005280360579490662, 0.005322959739714861, 0.0054023731499910355, 0.005478122271597385, 0.4080052673816681, 0.005730297416448593, 0.10336997359991074, 0.006125668063759804, 0.006419395096600056, 0.006561477202922106, 0.006630355957895517, 0.006839334033429623, 0.006902200635522604, 0.006851203739643097, 0.0871201902627945, 0.00698008481413126, 0.0071558705531060696, 0.007321569137275219, 0.007080836687237024, 0.007058367133140564, 0.007119013462215662, 0.007216213271021843, 0.11584488302469254, 0.007016928866505623, 0.006887473165988922, 0.006917269434779882, 0.006760603282600641, 0.13176760077476501, 0.006659733597189188, 0.1330813765525818, 0.006631652358919382, 0.006815501023083925, 0.1354626566171646, 0.0066117579117417336, 0.006604519672691822, 0.006639447994530201, 0.00654718978330493, 0.0064820097759366035, 0.006412421353161335, 0.0064123994670808315, 0.12181688100099564, 0.006270990241318941, 0.11954484134912491, 0.0062746088951826096, 0.006228351034224033, 0.0061636632308363914, 0.006223130039870739, 0.006184793543070555, 0.006203543860465288, 0.006041426211595535, 0.11773043870925903, 0.005901960656046867, 0.0059128147549927235, 0.005793150048702955, 0.005835097748786211, 0.10745635628700256, 0.11690561473369598, 0.00577545166015625, 0.005840782076120377, 0.0056753684766590595, 0.005692910403013229, 0.005675920285284519, 0.005560630466789007, 0.005620949901640415, 0.005504949484020472, 0.005415348801761866, 0.09241873770952225, 0.005341554060578346, 0.005340367555618286, 0.005441267509013414, 0.005291059613227844, 0.005200118292123079, 0.005267385859042406, 0.005085764918476343, 0.11014780402183533, 0.4220256507396698, 0.005250405054539442, 0.005310299340635538, 0.005424869246780872, 0.005414179991930723, 0.11223969608545303, 0.005645734257996082, 0.09834972769021988, 0.005785167682915926, 0.005874429363757372, 0.005864680744707584, 0.005870783235877752, 0.006047120317816734, 0.005916766356676817, 0.00598438223823905, 0.00630501564592123, 0.005845957435667515, 0.005858655087649822, 0.005884349811822176, 0.0058166286908090115, 0.09350335597991943, 0.10121981799602509, 0.00569280656054616, 0.005746677052229643, 0.005654125940054655, 0.005755407270044088, 0.0056100026704370975, 0.005649084225296974, 0.00559040904045105, 0.005556859541684389, 0.005565124563872814, 0.005554269067943096, 0.00539402524009347, 0.0052351802587509155, 0.005164244212210178, 0.13442599773406982, 0.005089040379971266, 0.005114022176712751, 0.0049856011755764484, 0.0049446760676801205, 0.005006435327231884, 0.004876537248492241, 0.0048275236040353775, 0.0048226299695670605, 0.10206054896116257, 0.13251353800296783, 0.0047073629684746265, 0.004658246412873268, 0.004781548399478197, 0.004712362308055162, 0.004664857406169176, 0.11497294157743454, 0.10670676082372665, 0.11082121729850769, 0.004678248893469572, 0.004770067986100912, 0.004814682994037867, 0.10891159623861313, 0.0047991154715418816, 0.12782251834869385, 0.004970744252204895, 0.0048811184242367744, 0.10500907897949219, 0.004970967303961515, 0.005026996601372957, 0.005101664923131466, 0.1167086586356163, 0.005163284484297037, 0.1338939517736435, 0.005206695757806301, 0.005241967737674713, 0.005208451300859451, 0.005302380304783583, 0.005256825592368841, 0.005212736781686544, 0.09418945759534836, 0.005314224865287542, 0.005252072587609291, 0.005228092428296804, 0.005252694245427847, 0.0052010491490364075, 0.005191816948354244, 0.005162601359188557, 0.15496502816677094, 0.00521755451336503, 0.005051583517342806, 0.005049319472163916, 0.005027689039707184, 0.004958207719027996, 0.004933548159897327, 0.004896045662462711, 0.004845906980335712, 0.1112428605556488, 0.0048298039473593235, 0.004857425112277269, 0.004798840265721083, 0.09917083382606506, 0.004695473704487085, 0.0046988180838525295, 0.1429530382156372, 0.004773358348757029, 0.004704706836491823, 0.004658621735870838, 0.004855522885918617, 0.0046263160184025764, 0.004750130232423544, 0.12404275685548782, 0.11556511372327805, 0.10743872821331024, 0.12611408531665802, 0.1420833170413971, 0.004922471009194851, 0.00495104817673564, 0.0049657514318823814, 0.005063892807811499, 0.005096282809972763, 0.00527208624407649, 0.005239896941930056, 0.0051648481748998165, 0.09052717685699463, 0.005107265431433916, 0.005172247067093849, 0.005140344612300396, 0.00523727759718895, 0.005130817648023367, 0.005135885905474424, 0.00509750097990036, 0.0050611961632966995, 0.005097064655274153, 0.005071369465440512, 0.005043825600296259, 0.0048297373577952385, 0.004842224530875683, 0.111825130879879, 0.004825926385819912, 0.004837184213101864, 0.11741338670253754, 0.004681671969592571, 0.004774780943989754, 0.11068514734506607, 0.004695308860391378, 0.004685241263359785, 0.0048213498666882515, 0.004903688561171293, 0.004686697386205196, 0.0046057142317295074, 0.004597275052219629, 0.004546624608337879, 0.004505139775574207, 0.004533835686743259, 0.004477786365896463, 0.004466688726097345, 0.12849782407283783, 0.004405698738992214, 0.4185592532157898, 0.004481032490730286, 0.004563529510051012, 0.004684189334511757, 0.004755476024001837, 0.004805378615856171, 0.004833359271287918, 0.10954928398132324, 0.00494412612169981, 0.00500142015516758, 0.0050153774209320545, 0.005205335095524788, 0.005091841332614422, 0.005194126628339291, 0.005054068751633167, 0.005232542287558317, 0.0051092966459691525, 0.12232938408851624, 0.12699726223945618, 0.0051443446427583694, 0.005075239576399326, 0.005063763819634914, 0.005042381584644318, 0.005106939468532801, 0.005043507553637028, 0.005044798366725445, 0.0050561134703457355, 0.005024604499340057, 0.10645981878042221, 0.004969277419149876, 0.004911413416266441, 0.13412818312644958, 0.004924469161778688, 0.004912407603114843, 0.004882123786956072, 0.004865941591560841, 0.004924357403069735, 0.004869923926889896, 0.004933656193315983, 0.004805079195648432, 0.1069241613149643, 0.004861606750637293, 0.0048504723235964775, 0.004781941417604685, 0.0046280319802463055, 0.00462085148319602, 0.004563791211694479, 0.11197826266288757, 0.004527891520410776, 0.0045441510155797005, 0.09048952162265778, 0.14300575852394104, 0.0045415437780320644, 0.004586516879498959, 0.0045883385464549065, 0.0045684026554226875, 0.004546306561678648, 0.004646139685064554, 0.004611270036548376, 0.0045297350734472275, 0.004477858543395996, 0.004486504010856152, 0.004483573604375124, 0.004405847284942865, 0.004380680620670319, 0.004349992144852877, 0.004314271733164787, 0.004265196155756712, 0.004209059756249189, 0.004215606953948736, 0.004154288209974766, 0.1267484724521637, 0.004120408091694117, 0.004057274200022221, 0.0040522669441998005, 0.004033622331917286, 0.00403283117339015, 0.003968844190239906, 0.003955308347940445, 0.003923092037439346, 0.1362341046333313, 0.119831882417202, 0.11955410987138748, 0.0039476146921515465, 0.003925096709281206, 0.004012484103441238, 0.11918509751558304, 0.003986453637480736, 0.0040106638334691525, 0.0041043199598789215, 0.00409343745559454, 0.004134406801313162, 0.0040541053749620914, 0.0040868958458304405, 0.0041746534407138824, 0.004047418478876352, 0.004072355106472969, 0.004030487034469843, 0.004082174506038427, 0.004064809065312147, 0.003931117244064808, 0.0039031493943184614, 0.0038744816556572914, 0.0038321735337376595, 0.0038185035809874535, 0.003800196573138237, 0.003752673976123333, 0.003934162203222513, 0.003724021604284644, 0.0036934507079422474, 0.00366750406101346, 0.0036542904563248158, 0.0035657999105751514, 0.0034859327133744955, 0.003483088919892907, 0.4391665756702423, 0.13073523342609406, 0.0035851532593369484, 0.003687987569719553, 0.0038837166503071785, 0.0038377109449356794, 0.00395551323890686, 0.004007740877568722, 0.0039822980761528015, 0.004057065583765507, 0.004003506153821945, 0.004058597143739462, 0.004064408130943775, 0.004086033906787634, 0.10607732087373734, 0.00414638128131628, 0.004067011643201113, 0.004150087479501963, 0.11614230275154114, 0.1058400422334671, 0.004093150142580271, 0.13644111156463623, 0.004230363294482231, 0.1384890079498291, 0.004353357013314962, 0.004432367626577616, 0.13508722186088562, 0.11787325143814087, 0.09489595144987106, 0.004603017587214708, 0.0047687990590929985, 0.0047536189667880535, 0.004858178086578846, 0.004861137829720974, 0.004836330655962229, 0.004969167057424784, 0.004997473210096359, 0.005032255779951811, 0.00496939430013299, 0.0049718525260686874, 0.004866897128522396, 0.10759089142084122, 0.13775382936000824, 0.004855686333030462, 0.11779920011758804, 0.005036558024585247, 0.004987339023500681, 0.004993458278477192, 0.004954449832439423, 0.004973806440830231, 0.00502694072201848, 0.0049399398267269135, 0.005000775214284658, 0.005123672541230917, 0.004885653033852577, 0.00485851988196373, 0.13291126489639282, 0.0049608550034463406, 0.004781892988830805, 0.13650096952915192, 0.004772065207362175, 0.11422577500343323, 0.004819380585104227, 0.0048252493143081665, 0.004972423426806927, 0.12808115780353546, 0.004891193937510252, 0.10189805179834366, 0.00491234241053462, 0.004910046700388193, 0.004969322122633457, 0.004928628448396921, 0.13137705624103546, 0.0049479007720947266, 0.0050710090436041355, 0.004969029221683741, 0.005018765106797218, 0.005090950522571802, 0.004957375582307577, 0.0049165720120072365, 0.004992371890693903, 0.0048581017181277275, 0.12709873914718628, 0.004921089857816696, 0.1219191625714302, 0.004835682921111584, 0.10669096559286118, 0.004902614746242762, 0.004913906566798687, 0.004922822583466768, 0.004879047628492117, 0.1216660812497139, 0.004891012329608202, 0.004968768917024136, 0.004926108755171299, 0.10268880426883698, 0.004955814685672522, 0.11835623532533646, 0.004925914574414492, 0.10074786096811295, 0.004982443526387215, 0.005093466490507126, 0.005019317846745253, 0.005033417604863644, 0.005066989455372095, 0.0050508081912994385, 0.005114428233355284, 0.005089364014565945, 0.0050331479869782925, 0.00494519155472517, 0.004924158565700054, 0.004946592729538679, 0.00490042706951499, 0.004824999254196882, 0.004828010685741901, 0.004841119982302189, 0.0047898185439407825, 0.004754429217427969, 0.0046645402908325195, 0.004562360234558582, 0.004503225442022085, 0.004475609865039587, 0.004476748872548342, 0.004462773445993662, 0.11928988993167877, 0.004314563237130642, 0.004303736612200737, 0.004247767850756645, 0.004252552054822445, 0.0042234198190271854, 0.0042040059342980385, 0.004137012176215649, 0.004103223327547312, 0.004050567280501127, 0.004066661931574345, 0.003993714228272438, 0.0040100147016346455, 0.003932647872716188, 0.13294456899166107, 0.003919429611414671, 0.0038473636377602816, 0.003938506357371807, 0.11855154484510422, 0.0038029029965400696, 0.003903706092387438, 0.12349720299243927, 0.11483009904623032, 0.003877598326653242, 0.0038859315682202578, 0.14137421548366547, 0.003916148096323013, 0.1273476481437683, 0.004025059286504984, 0.004035483114421368, 0.004083611071109772, 0.00415304210036993, 0.12973718345165253, 0.004215824883431196, 0.004183311015367508, 0.004239661153405905, 0.004209903534501791, 0.0042803105898201466, 0.004211790859699249, 0.1301523745059967, 0.0042470176704227924, 0.004281996749341488, 0.12579184770584106, 0.12261704355478287, 0.004315502475947142, 0.0043791173957288265, 0.004387347958981991, 0.004407197702676058, 0.11927788704633713, 0.004538769833743572, 0.12292308360338211, 0.1278815120458603, 0.004589807707816362, 0.004590105265378952, 0.004683727864176035, 0.10927215218544006, 0.004756669979542494, 0.004726697225123644, 0.004789371974766254, 0.004764888901263475, 0.004805339500308037, 0.3659411072731018, 0.004942778963595629, 0.1220492422580719, 0.005115737672895193, 0.005298166070133448, 0.005293377209454775, 0.005401779431849718, 0.005524936597794294, 0.005473637022078037, 0.0054895528592169285, 0.005578000098466873, 0.005554752890020609, 0.0055771018378436565, 0.005604160018265247, 0.005521650426089764, 0.11735455691814423, 0.005562677513808012, 0.40637901425361633, 0.005646042991429567, 0.005773033015429974, 0.005824459251016378, 0.005932554602622986, 0.006038706284016371, 0.006152970250695944, 0.006024532951414585, 0.006104343105107546, 0.09620192646980286, 0.006100745406001806, 0.1315465271472931, 0.006202824879437685, 0.10740283131599426, 0.11185473948717117, 0.006297234911471605, 0.00639714440330863, 0.11317895352840424, 0.006443999242037535, 0.10215731710195541, 0.006462331395596266, 0.0064935628324747086, 0.12549687922000885, 0.00658064428716898, 0.1288437694311142, 0.006592561490833759, 0.006609680596739054, 0.006606315728276968, 0.006681786850094795, 0.006643543019890785, 0.00663604075089097, 0.0065684751607477665, 0.006628924049437046, 0.10541944205760956, 0.1233561784029007, 0.1100982204079628, 0.006577890831977129, 0.006585082039237022, 0.10440874844789505, 0.00658061308786273, 0.006612404249608517, 0.11767080426216125, 0.006644195877015591, 0.006596485618501902, 0.006618569605052471, 0.09601135551929474, 0.006709672044962645, 0.006641878746449947, 0.006578494794666767, 0.0065737878903746605, 0.006517263129353523, 0.006493121851235628, 0.00644699577242136, 0.006405352149158716, 0.006385864224284887, 0.006318224593997002, 0.0063017914071679115, 0.11845163255929947, 0.006234008353203535, 0.006145271472632885, 0.006177322473376989, 0.006185160484164953, 0.006284905131906271, 0.005954332184046507, 0.005953636486083269, 0.005869298707693815, 0.005820308346301317, 0.005743898916989565, 0.005704727489501238, 0.005607875529676676, 0.005585588049143553, 0.005581102333962917, 0.005501516163349152, 0.005425905343145132, 0.0053871688432991505, 0.10132671892642975, 0.005256918724626303, 0.005225144326686859, 0.005178113002330065, 0.005159006454050541, 0.005194421391934156, 0.005037188995629549, 0.0050308494828641415, 0.00495825195685029, 0.0049219983629882336, 0.11635797470808029, 0.11178173124790192, 0.004865734372287989, 0.0048250118270516396, 0.004809743259102106, 0.004791043698787689, 0.004781328607350588, 0.09822148829698563, 0.004739923402667046, 0.004734463058412075, 0.11509319394826889, 0.0047751376405358315, 0.004710607696324587, 0.0048047699965536594, 0.004713911563158035, 0.004682620987296104, 0.00467712851241231, 0.11024580150842667, 0.0046602278016507626, 0.00471947668120265, 0.004660474602133036, 0.004652972798794508, 0.004604652523994446, 0.004667412955313921, 0.004542541690170765, 0.004567896015942097, 0.004490975756198168, 0.12259428203105927, 0.12057307362556458, 0.11626558005809784, 0.004538520704954863, 0.0045062280260026455, 0.3936055302619934, 0.0046815695241093636, 0.004791800398379564, 0.004841237794607878, 0.004904298577457666, 0.00494542857632041, 0.004992257338017225, 0.0050446768291294575, 0.005126838106662035, 0.0051757716573774815, 0.3868676424026489, 0.005232640076428652, 0.005339637864381075, 0.005448714829981327, 0.1366395652294159, 0.005570637062191963, 0.0056343674659729, 0.005704347975552082, 0.0057460893876850605, 0.005757724866271019, 0.005772008094936609, 0.005837978329509497, 0.005846948362886906, 0.005811665207147598, 0.005801911931484938, 0.005791360978037119, 0.005908783990889788, 0.09720855206251144, 0.005755170248448849, 0.005770615767687559, 0.005735562648624182, 0.005713097285479307, 0.005726674571633339, 0.005763398949056864, 0.005627438426017761, 0.00560033181682229, 0.005541457328945398, 0.005558543838560581, 0.0054709515534341335, 0.005489566829055548, 0.005523315165191889, 0.00537561671808362, 0.005348644219338894, 0.005296987481415272, 0.005219701211899519, 0.005171589087694883, 0.12095942348241806, 0.005175298545509577, 0.12940949201583862, 0.09211235493421555, 0.11135103553533554, 0.005099662113934755, 0.005120852030813694, 0.005110143683850765, 0.005161601584404707, 0.005121564492583275, 0.0050852661952376366, 0.005078064743429422, 0.005086734890937805, 0.005069843493402004, 0.005009104497730732, 0.005011783912777901, 0.005031993612647057, 0.004943442530930042, 0.004896228667348623, 0.00492671225219965, 0.004863405600190163, 0.12851369380950928, 0.004773083608597517, 0.004784654825925827, 0.004780405201017857, 0.0048212031833827496, 0.004698514938354492, 0.00467846542596817, 0.004655763041228056, 0.10558300465345383, 0.11757546663284302, 0.1265658438205719, 0.004656561184674501, 0.004660146310925484, 0.004664068575948477, 0.004647598601877689, 0.00466106878593564, 0.004727051593363285, 0.00465101795271039, 0.0046226754784584045, 0.004618399310857058, 0.004678680561482906, 0.004595029633492231, 0.004564311821013689, 0.004593622870743275, 0.004571324214339256, 0.00447059515863657, 0.004443651996552944, 0.004447834566235542, 0.09845901280641556, 0.1181395947933197, 0.11245670169591904, 0.004430027678608894, 0.0044235410168766975, 0.004467856138944626, 0.004445025231689215, 0.004435053560882807, 0.0044063664972782135, 0.0044572134502232075, 0.004418099764734507, 0.004483481403440237, 0.004373086150735617, 0.0043565030209720135, 0.00437841797247529, 0.10709290951490402, 0.11791004240512848, 0.0923687294125557, 0.004346043802797794, 0.10420125722885132, 0.004370690323412418, 0.004403385799378157, 0.00440670782700181, 0.004433831200003624, 0.004469503182917833, 0.08863256871700287, 0.12905952334403992, 0.0045091561041772366, 0.004524745978415012, 0.004729693755507469, 0.00473996065557003, 0.004515722393989563, 0.004577155690640211, 0.00458373362198472, 0.004488090053200722, 0.004644982051104307, 0.00462491437792778, 0.004614020697772503, 0.004562813322991133, 0.004510574508458376, 0.004434654489159584, 0.004405285697430372, 0.004351405892521143, 0.004495574161410332, 0.09745030850172043, 0.10274612158536911, 0.004329012241214514, 0.10844182968139648, 0.0043016355484724045, 0.004308382980525494, 0.13832052052021027, 0.004397050943225622, 0.004383474122732878, 0.0043767886236310005, 0.004418712109327316, 0.004353333730250597, 0.0044578309170901775, 0.10908640176057816, 0.004357169847935438, 0.004411251284182072, 0.0044824811629951, 0.004380513448268175, 0.1258016973733902, 0.004351441748440266, 0.11588302254676819, 0.004390322603285313, 0.10356822609901428, 0.00443915044888854, 0.004424869082868099, 0.004468396306037903, 0.004458786454051733, 0.004458111710846424, 0.004690603818744421, 0.12153055518865585, 0.004474060609936714, 0.004520387388765812, 0.004466821905225515, 0.004544139839708805, 0.1152975931763649, 0.09507577866315842, 0.004492585547268391, 0.00462975213304162, 0.004559091757982969, 0.004636415280401707, 0.004596540704369545, 0.004526074044406414, 0.004502288997173309, 0.004507392179220915, 0.004504874814301729, 0.00446624681353569, 0.11217792332172394, 0.004444886930286884, 0.004640808328986168, 0.004425862338393927, 0.004442384000867605, 0.004475507885217667, 0.00445758318528533, 0.004478440620005131, 0.004417390562593937, 0.09118691086769104, 0.004336217418313026, 0.1235736757516861, 0.004363987594842911, 0.004421138670295477, 0.004383118357509375, 0.0043449425138533115, 0.004388207104057074, 0.004303201101720333, 0.004305888898670673, 0.004365003202110529, 0.004397086799144745, 0.004367106128484011, 0.004341082647442818, 0.004293660167604685, 0.10162308812141418, 0.00420457823202014, 0.0042494856752455235, 0.0042354087345302105, 0.004200156312435865, 0.004344796296209097, 0.4119006097316742, 0.00424712710082531, 0.0044281985610723495, 0.004289001226425171, 0.4800606071949005, 0.004500069655478001, 0.0045431507751345634, 0.004859692417085171, 0.004711053799837828, 0.0047238473780453205, 0.004816398955881596, 0.0048571364022791386, 0.004976292606443167, 0.004856927786022425, 0.005125786643475294, 0.004883721936494112, 0.1020059883594513, 0.3141302466392517, 0.13705983757972717, 0.005144288297742605, 0.005246173590421677, 0.005282293539494276, 0.005386522505432367, 0.005373131949454546, 0.005542441736906767, 0.005499313585460186, 0.1319817304611206, 0.005609176121652126, 0.005581219214946032, 0.005558496341109276, 0.005550175439566374, 0.11012512445449829, 0.005603158846497536, 0.005623571574687958, 0.005656642839312553, 0.11825141310691833, 0.005692374426871538, 0.133531391620636, 0.13121533393859863, 0.15096944570541382, 0.005781922489404678, 0.10677747428417206, 0.005806011147797108, 0.005826318170875311, 0.005972313228994608, 0.005905140191316605, 0.005882378201931715, 0.006027998868376017, 0.005955171771347523, 0.005920300725847483, 0.005831473972648382, 0.005876168608665466, 0.005806730594485998, 0.0058823986910283566, 0.00575949577614665, 0.005930732935667038, 0.005743806716054678, 0.14886458218097687, 0.09254983067512512, 0.005704221315681934, 0.09731351584196091, 0.005769350565969944, 0.005713530816137791, 0.005705243442207575, 0.005710185039788485, 0.005932354833930731, 0.005677178502082825, 0.12283845990896225, 0.005656569264829159, 0.11249109357595444, 0.005650206468999386, 0.005678647663444281, 0.005738805513828993, 0.005664169788360596, 0.005589195527136326, 0.005574834533035755, 0.005683303344994783, 0.005540142767131329, 0.005640998482704163, 0.005480432417243719, 0.005481865257024765, 0.005525203887373209, 0.005542700178921223, 0.00542086735367775, 0.005396374501287937, 0.005341909825801849, 0.005304100923240185, 0.005456611514091492, 0.005239165388047695, 0.005257780663669109, 0.005164075177162886, 0.0051130387000739574, 0.005343311000615358, 0.005092564970254898, 0.005110312253236771, 0.0050185020081698895, 0.0050515467301011086, 0.004973764531314373, 0.004999137949198484, 0.004910034593194723, 0.0048930770717561245, 0.004808369558304548, 0.1322433203458786, 0.004748244304209948, 0.12105739116668701, 0.11774873733520508, 0.004754036199301481, 0.004797261208295822, 0.004838092718273401, 0.004736778326332569, 0.0047315265983343124, 0.0047034015879035, 0.004785663913935423, 0.004882677458226681, 0.004769772756844759, 0.0047486950643360615, 0.004669651389122009, 0.00483403354883194, 0.004686400759965181, 0.004595749080181122, 0.004566334653645754, 0.004718444775789976, 0.004557277541607618, 0.004625699482858181, 0.0045523070730268955, 0.12717317044734955, 0.00460868189111352, 0.0045505668967962265, 0.12971356511116028, 0.10435014963150024, 0.1055523082613945, 0.004485391546040773, 0.004533466417342424, 0.004538498818874359, 0.004556798841804266, 0.004523505922406912, 0.004559190943837166, 0.11211714893579483, 0.13073568046092987, 0.1316394805908203, 0.39586132764816284, 0.004705358296632767, 0.004751052241772413, 0.004743665922433138, 0.11119396239519119, 0.004930936265736818, 0.10933181643486023, 0.004979351535439491, 0.11651169508695602, 0.005169829353690147, 0.005066541489213705, 0.005128900054842234, 0.005159781314432621, 0.005218129139393568, 0.005175834055989981, 0.005231337621808052, 0.0052328589372336864, 0.005334115121513605, 0.005294129718095064, 0.13662026822566986, 0.005201402585953474, 0.005250950809568167, 0.005327827297151089, 0.0052427430637180805, 0.13922996819019318, 0.00526049267500639, 0.3827713429927826, 0.005365792661905289, 0.005372063722461462, 0.005381749477237463, 0.00549382995814085, 0.11489789932966232, 0.005520228296518326, 0.005547698587179184, 0.10666482895612717, 0.10078371316194534, 0.005558754317462444, 0.005728723015636206, 0.005612060893326998, 0.005727989133447409, 0.005742204375565052, 0.005770664196461439, 0.10843899846076965, 0.11065299063920975, 0.005744866095483303, 0.005768890492618084, 0.005794276017695665, 0.005781214218586683, 0.005762873217463493, 0.005768245551735163, 0.09880298376083374, 0.005711114965379238, 0.005777259357273579, 0.005796377081423998, 0.0057948315516114235, 0.005814106669276953, 0.005775901488959789, 0.005636679474264383, 0.005692631937563419, 0.005790499038994312, 0.0057626161724328995, 0.005659397691488266, 0.005620679818093777, 0.005557098891586065, 0.005522876046597958, 0.0055336845107376575, 0.0054353876039385796, 0.005509531125426292, 0.005420582368969917, 0.11563965678215027, 0.005379481706768274, 0.10504929721355438, 0.005342753138393164, 0.0053011467680335045, 0.11050938069820404, 0.005316942930221558, 0.005334050394594669, 0.00532122515141964, 0.12274307757616043, 0.1261710375547409, 0.0056357248686254025, 0.005409122910350561, 0.11006011068820953, 0.005351060535758734, 0.14052505791187286, 0.0053625828586518764, 0.3792140781879425, 0.005467886105179787, 0.005472536198794842, 0.005562559701502323, 0.005595915485173464, 0.0056539261713624, 0.005670614540576935, 0.005652453750371933, 0.005721402820199728, 0.106299988925457, 0.005812737159430981, 0.005699415225535631, 0.0057077486999332905, 0.005703357979655266, 0.005770742427557707, 0.005786039866507053, 0.005687203258275986, 0.005840324331074953, 0.005766791757196188, 0.005788106936961412, 0.005696656182408333, 0.005635490640997887, 0.11399468779563904, 0.005603009834885597, 0.005787077825516462, 0.005555810406804085, 0.005675723310559988, 0.00571453059092164, 0.005806047469377518, 0.005611517000943422, 0.005501725245267153, 0.09886370599269867, 0.005468175746500492, 0.005493146367371082, 0.005462802480906248, 0.005461531691253185, 0.005513894371688366, 0.0054185460321605206, 0.005544255953282118, 0.0054044886492192745, 0.005368250887840986, 0.005324870813637972, 0.005370528902858496, 0.005412681959569454, 0.11758258193731308, 0.10776127129793167, 0.005308195948600769, 0.0054483977146446705, 0.005282713565975428, 0.11129166930913925, 0.005283253267407417, 0.005208601709455252, 0.005219265352934599, 0.09457588940858841, 0.12216323614120483, 0.005327953025698662, 0.005233868025243282, 0.00520696584135294, 0.005370726343244314, 0.00548918591812253, 0.0052870470099151134, 0.0052606407552957535, 0.005296824499964714, 0.00522465817630291, 0.005163716617971659, 0.10829436779022217, 0.005152808036655188, 0.005165053531527519, 0.005149859003722668, 0.005319181364029646, 0.005180573556572199, 0.005107630975544453, 0.0051160771399736404, 0.005091192666441202, 0.005108828656375408, 0.005052949767559767, 0.005024787969887257, 0.005090212449431419, 0.005031869746744633, 0.00499872537329793, 0.0049810586497187614, 0.005151663441210985, 0.004942267667502165, 0.0050436630845069885, 0.004891632124781609, 0.004941484425216913, 0.1259741336107254, 0.0049271597526967525, 0.13428229093551636, 0.004878547508269548, 0.004888126160949469, 0.004910539370030165, 0.00481494190171361, 0.004813621751964092, 0.004834732040762901, 0.004857767838984728, 0.13226944208145142, 0.0048396955244243145, 0.004905148409307003, 0.004847785457968712, 0.004810339771211147, 0.004938043188303709, 0.11992581933736801, 0.004828924313187599, 0.004851426929235458, 0.004821957554668188, 0.004944911226630211, 0.00486419815570116, 0.004787547048181295, 0.004719765391200781, 0.00477621890604496, 0.004783366806805134, 0.004733456764370203, 0.00469784252345562, 0.0047023179940879345, 0.11388050764799118, 0.004690080881118774, 0.004674102645367384, 0.004676130600273609, 0.10881742089986801, 0.004677182994782925, 0.004624376073479652, 0.004699926357716322, 0.0046237073838710785, 0.004715427290648222, 0.09346362948417664, 0.004613253753632307, 0.004655672237277031, 0.004591053817421198, 0.11843962222337723, 0.004592675715684891, 0.00456760311499238, 0.00459638936445117, 0.004666771739721298, 0.004603154957294464, 0.004617631435394287, 0.004546635784208775, 0.004718161188066006, 0.004531242419034243, 0.004551432561129332, 0.004512554965913296, 0.004519034177064896, 0.1321340948343277, 0.004544478841125965, 0.004587515257298946, 0.12752866744995117, 0.00447134068235755, 0.004500327631831169, 0.004475089721381664, 0.004523941315710545, 0.004468366503715515, 0.004485766403377056, 0.16154055297374725, 0.004551554098725319, 0.004539430607110262, 0.1211206465959549, 0.1340135931968689, 0.004557479172945023, 0.004600582644343376, 0.004476738628000021, 0.004577704705297947, 0.004614961799234152, 0.004547129850834608, 0.004542812705039978, 0.004487020894885063, 0.004476359114050865, 0.004587405361235142, 0.10955259203910828, 0.004480572417378426, 0.004483482800424099, 0.004531159996986389, 0.004447275772690773, 0.004510265775024891, 0.004579649772495031, 0.004545572213828564, 0.00454977061599493, 0.004464739467948675, 0.00445406511425972, 0.004434855189174414, 0.004400787875056267, 0.004434389993548393, 0.004479994997382164, 0.004413271322846413, 0.004360373597592115, 0.367317259311676, 0.004380027297884226, 0.004378850106149912, 0.0044113220646977425, 0.00442003458738327, 0.004433389287441969, 0.004482738673686981, 0.1228252500295639, 0.004595144651830196, 0.102424755692482, 0.10870184004306793, 0.004497721791267395, 0.004505441058427095, 0.00452197901904583, 0.004587381146848202, 0.004595098551362753, 0.004510242957621813, 0.004506154451519251, 0.004487976431846619, 0.12488044798374176, 0.00448468467220664, 0.13693933188915253, 0.13403938710689545, 0.004593424964696169, 0.004609765484929085, 0.004610138945281506, 0.42678141593933105, 0.004581713117659092, 0.11949703842401505, 0.11547867208719254, 0.004749849438667297, 0.004691784270107746, 0.1116708517074585, 0.004779262002557516, 0.0047085159458220005, 0.004728325176984072, 0.004936737008392811, 0.00475503783673048, 0.004806161858141422, 0.004844709299504757, 0.004809505771845579, 0.004793134517967701, 0.004807719029486179, 0.004791325889527798, 0.004789009224623442, 0.004786074161529541, 0.11113379895687103, 0.004819923080503941, 0.004772921558469534, 0.116562120616436, 0.004803711548447609, 0.004842843860387802, 0.004756352864205837, 0.12807616591453552, 0.004844361916184425, 0.0047728531062603, 0.004791213199496269, 0.005022651515901089, 0.004849672317504883, 0.004754365421831608, 0.004789886064827442, 0.004778724163770676, 0.1132153645157814, 0.004808660130947828, 0.004759588278830051, 0.004921663086861372, 0.004779359791427851, 0.00481727859005332, 0.004749581683427095, 0.004802662879228592, 0.004870424512773752, 0.1260194480419159, 0.004761833697557449, 0.004743988160043955, 0.0046996851451694965, 0.004774532746523619, 0.004789404105395079, 0.004807818681001663, 0.39445462822914124, 0.09137130528688431, 0.004774926230311394, 0.11885910481214523, 0.00477426964789629, 0.3865138590335846, 0.004869507625699043, 0.004811108577996492, 0.004905746318399906, 0.004869386088103056, 0.12775437533855438, 0.13812774419784546, 0.005089879967272282, 0.005009873770177364, 0.004934787284582853, 0.005017464514821768, 0.004954328294843435, 0.004928112030029297, 0.004957208875566721, 0.11623812466859818, 0.005056163761764765, 0.00503663532435894, 0.0049458760768175125, 0.005040687974542379, 0.005242419894784689, 0.005081075243651867, 0.005088662728667259, 0.005045951344072819, 0.004984815139323473, 0.005001721438020468, 0.0050391568802297115, 0.005137186963111162, 0.00498870387673378, 0.00494152819737792, 0.136556014418602, 0.11786840856075287, 0.004928567446768284, 0.0049684313125908375, 0.10494246333837509, 0.12691383063793182, 0.10431384295225143, 0.005141090136021376, 0.005002310965210199, 0.005056724883615971, 0.12206190079450607, 0.10861881077289581, 0.005020827986299992, 0.004966693464666605, 0.005102154333144426, 0.005104211159050465, 0.0050497171469032764, 0.00500830402597785, 0.005058080889284611, 0.005095371510833502, 0.1014568880200386, 0.0050059109926223755, 0.005025519989430904, 0.12020574510097504, 0.004981723614037037, 0.005046638660132885, 0.005102082621306181, 0.10879454761743546, 0.005016902927309275, 0.13242951035499573, 0.00499864062294364, 0.005028326064348221, 0.00498531199991703, 0.005021775607019663, 0.004986579529941082, 0.0050049638375639915, 0.005155967082828283, 0.1219349056482315, 0.004983325954526663, 0.005046599078923464, 0.004973037634044886, 0.004988159518688917, 0.005079841706901789, 0.12471991777420044, 0.005053563509136438, 0.005064988508820534, 0.005080132279545069, 0.00519552081823349, 0.0050009326077997684, 0.005012474954128265, 0.10484138876199722, 0.1276262402534485, 0.004970956593751907, 0.3828710615634918, 0.005098469089716673, 0.005045996513217688, 0.005122880917042494, 0.005100017413496971, 0.005030663218349218, 0.004991053603589535, 0.005044523626565933, 0.00503303250297904, 0.005002171266824007, 0.09795617312192917, 0.12173318862915039, 0.11431631445884705, 0.005141312722116709, 0.005178795196115971, 0.0050476971082389355, 0.005182830151170492, 0.00513438880443573, 0.005035221576690674, 0.1270957738161087, 0.005058018025010824, 0.0050217085517942905, 0.005062830168753862, 0.0050146677531301975, 0.10885027050971985, 0.005035897716879845, 0.0050207446329295635, 0.005059507675468922, 0.12332504242658615, 0.00505378982052207, 0.0051948935724794865, 0.0050471872091293335, 0.005059604998677969, 0.10452014952898026, 0.005085288546979427, 0.005064275581389666, 0.005145854316651821, 0.005071886349469423, 0.0050512743182480335, 0.0050355419516563416, 0.0050443075597286224, 0.005054638255387545, 0.0050390614196658134, 0.005130161996930838, 0.005058819428086281, 0.00509343296289444, 0.004994274117052555, 0.00504827406257391, 0.00501755578443408, 0.00505263265222311, 0.005002633668482304, 0.005082369782030582, 0.12003429979085922, 0.005119212903082371, 0.00508283032104373, 0.13645470142364502, 0.10598404705524445, 0.005070868879556656]\n",
            "Val loss 0.04017670992248339\n",
            "Val auc roc 0.47509176556955834\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2bec2b6-c494-4dab-efd3-772044fd8b0b"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e2926d2-a63a-4439-f20b-039c6bdc188c"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c4609c6-f672-4ba5-89d1-4046a100f8dd"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "e87a7c2c-d24f-41df-cce2-a536d7f2cd31"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Allegation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Allegation]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11f9230e-3fc8-4def-e259-8c77974e388c"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-08-06 17:35:35.080960'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}