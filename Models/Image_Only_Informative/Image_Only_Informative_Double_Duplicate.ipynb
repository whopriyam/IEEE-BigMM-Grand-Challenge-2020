{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Only_Informative_Double_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f22cd4b558b43f999e2c79ca7dbef41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2594a248ce7d4e82b45885deca5dccb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a85551a9cfdc42be8328909b0129c015",
              "IPY_MODEL_710414656b9445238362368d7720e463"
            ]
          }
        },
        "2594a248ce7d4e82b45885deca5dccb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a85551a9cfdc42be8328909b0129c015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_32ec7d0a94934b98b89b64706d4a0741",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60ba88361fe94c5e97ca1a57672ba338"
          }
        },
        "710414656b9445238362368d7720e463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14343c3b1cff4060951d01cb8910a7a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2656/2656 [47:39&lt;00:00,  1.08s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e1743fc17314b5792b0ff8404e843cc"
          }
        },
        "32ec7d0a94934b98b89b64706d4a0741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60ba88361fe94c5e97ca1a57672ba338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14343c3b1cff4060951d01cb8910a7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e1743fc17314b5792b0ff8404e843cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "794e3d8a7baa44cda684d99375305c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9fadf2221ee74f7f939cd9c9b363802d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fdb4010ed0f74cb2804795c84e3b6590",
              "IPY_MODEL_86db82bd6bab463080bdfd186b5a5ab5"
            ]
          }
        },
        "9fadf2221ee74f7f939cd9c9b363802d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdb4010ed0f74cb2804795c84e3b6590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aebc21aa29104e51803d0d5d80b35f7b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a17768cc69a4700bab61f1095f61129"
          }
        },
        "86db82bd6bab463080bdfd186b5a5ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f70af8e2352f4b1691636df6570fd000",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2656/2656 [47:42&lt;00:00,  1.08s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae2c5969d5d9461fb2e2a7aaa7d9d376"
          }
        },
        "aebc21aa29104e51803d0d5d80b35f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a17768cc69a4700bab61f1095f61129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f70af8e2352f4b1691636df6570fd000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae2c5969d5d9461fb2e2a7aaa7d9d376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc4e6f3039db41118f4db5719fcda0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a99fa68471f49a89fe94942607a45cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d258b00788974eb682e2e80983785ee1",
              "IPY_MODEL_35e21a57b0c8476b954be5d133af38a2"
            ]
          }
        },
        "1a99fa68471f49a89fe94942607a45cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d258b00788974eb682e2e80983785ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01f0991f1a4f4b47afc58e4829288199",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2095949e42b34f089dcfbe11c73bc13a"
          }
        },
        "35e21a57b0c8476b954be5d133af38a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0860a5442d5d48dda55a804ad0405d20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2656/2656 [47:30&lt;00:00,  1.07s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3986713602004695ac7ac755c7a78118"
          }
        },
        "01f0991f1a4f4b47afc58e4829288199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2095949e42b34f089dcfbe11c73bc13a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0860a5442d5d48dda55a804ad0405d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3986713602004695ac7ac755c7a78118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1ecff95-eb94-4980-985f-8d235d4b59f1"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ieee-bigmm-images' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7d7a288-84c2-4a18-b8e4-4cb9d4bfb1b2"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10080eb8-0fb3-4430-c334-08d0e8284529"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "45fe0f70-2bf2-4b1c-9038-44ba7d1d491a"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "cf5ffd48-a3a3-4878-a05a-dca6a7cda672"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " clean_datav5.csv\n",
            " clean_datav6.csv\n",
            " Data_without-invalid_cells.csv\n",
            " final_dataset.csv\n",
            " final_test2.csv\n",
            " final_test3_unpreprocessed.csv\n",
            " model_state_dict.pth\n",
            " README.md\n",
            " test_data_cleaned.csv\n",
            " \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "'test_labels_actual_2020-08-05 09:55:24.292705_.txt'\n",
            "'test_labels_pred_2020-08-05 09:55:24.292705_.txt'\n",
            " test_tweet_2.csv\n",
            " \u001b[01;34mtrain_images\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "7176afc7-2ec3-4763-b9e8-06fe84a44182"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.5.1+cu101)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.5.1+cu101 in /usr/local/lib/python3.6/dist-packages (1.5.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.6.1+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ad516ac4-b2e7-4042-b95d-b19e9fc2ebb9"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2d958ebc-045f-4d23-980e-2e4746a16f3b"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "2e75e010-1e89-46bc-93de-da621b908736"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasnâ€™t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Natureâ€™s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4e480b78-8ca2-4dde-81a3-e9b11d47fdb7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Fung supporter just now: @GinaRaimondo support...\n",
              "1    Raveena Tandon on the #MeToo and Bollywood mov...\n",
              "2    @abhisar_sharma Who betrayed the real #MeToo m...\n",
              "3    Rajnath Singh mocks Congress, says party's all...\n",
              "4    . @sangeetha_bhat shares her #MeToo tale  #MeT...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "1e553de8-5ef5-4e41-9e1b-98ac8902b777"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b9c1677-7906-40df-e664-543a392bbee7"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            random.shuffle(text)\n",
        "            text3 = ' '.join(text)\n",
        "            df3['text'][i]=text3\n",
        "        self.data = self.data.append(df2, ignore_index=True)\n",
        "        self.data = self.data.append(df3, ignore_index=True)\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c327c6b8-cf8b-4031-f8f8-7c280706518b"
      },
      "source": [
        "col_name = \"Image_Only_Informative\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796,
          "referenced_widgets": [
            "8f22cd4b558b43f999e2c79ca7dbef41",
            "2594a248ce7d4e82b45885deca5dccb5",
            "a85551a9cfdc42be8328909b0129c015",
            "710414656b9445238362368d7720e463",
            "32ec7d0a94934b98b89b64706d4a0741",
            "60ba88361fe94c5e97ca1a57672ba338",
            "14343c3b1cff4060951d01cb8910a7a6",
            "5e1743fc17314b5792b0ff8404e843cc",
            "794e3d8a7baa44cda684d99375305c2b",
            "9fadf2221ee74f7f939cd9c9b363802d",
            "fdb4010ed0f74cb2804795c84e3b6590",
            "86db82bd6bab463080bdfd186b5a5ab5",
            "aebc21aa29104e51803d0d5d80b35f7b",
            "1a17768cc69a4700bab61f1095f61129",
            "f70af8e2352f4b1691636df6570fd000",
            "ae2c5969d5d9461fb2e2a7aaa7d9d376",
            "fc4e6f3039db41118f4db5719fcda0bd",
            "1a99fa68471f49a89fe94942607a45cc",
            "d258b00788974eb682e2e80983785ee1",
            "35e21a57b0c8476b954be5d133af38a2",
            "01f0991f1a4f4b47afc58e4829288199",
            "2095949e42b34f089dcfbe11c73bc13a",
            "0860a5442d5d48dda55a804ad0405d20",
            "3986713602004695ac7ac755c7a78118"
          ]
        },
        "outputId": "d5674582-7c21-40f6-9ba3-08a0e363e29e"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New data length : 10624\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 2624\n",
            "Loaded previous model state successfully!\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f22cd4b558b43f999e2c79ca7dbef41",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2656.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1687\n",
            "Train Losses : [0.23388616740703583, 0.14057557284832, 0.2406662255525589, 0.16860048472881317, 0.1594020575284958, 0.20926497876644135, 0.16998536884784698, 0.17890390753746033, 0.1644188016653061, 0.18213652074337006, 0.229124054312706, 0.18405750393867493, 0.144708052277565, 0.18719519674777985, 0.20897245407104492, 0.17695409059524536, 0.19274698197841644, 0.2238704264163971, 0.1900591105222702, 0.20998989045619965, 0.15429894626140594, 0.15928258001804352, 0.18646448850631714, 0.1407930552959442, 0.20137523114681244, 0.14294371008872986, 0.14361631870269775, 0.16871239244937897, 0.23736923933029175, 0.15809884667396545, 0.21213747560977936, 0.19889405369758606, 0.1728338897228241, 0.1872037798166275, 0.1900179088115692, 0.13808272778987885, 0.15895159542560577, 0.13608969748020172, 0.18999457359313965, 0.14757485687732697, 0.2050120234489441, 0.138066366314888, 0.166306734085083, 0.16044902801513672, 0.11166822165250778, 0.14050889015197754, 0.243507519364357, 0.15726934373378754, 0.08524100482463837, 0.290510356426239, 0.2589099705219269, 0.3079902231693268, 0.18255773186683655, 0.10868177562952042, 0.09326809644699097, 0.09175495058298111, 0.2573458254337311, 0.3040943741798401, 0.2872348129749298, 0.1172829195857048, 0.14871300756931305, 0.12894301116466522, 0.15494264662265778, 0.19750234484672546, 0.2091553509235382, 0.14454202353954315, 0.20260056853294373, 0.12449903041124344, 0.22871561348438263, 0.15624001622200012, 0.14982345700263977, 0.13384021818637848, 0.21489401161670685, 0.1660906970500946, 0.1648605465888977, 0.22632156312465668, 0.2375340759754181, 0.1471889615058899, 0.2221849411725998, 0.1630634218454361, 0.18965905904769897, 0.16090889275074005, 0.18099799752235413, 0.13901014626026154, 0.17179062962532043, 0.1707039624452591, 0.17914457619190216, 0.13527649641036987, 0.1618482917547226, 0.13603343069553375, 0.17462003231048584, 0.18457408249378204, 0.2054329365491867, 0.24775630235671997, 0.19156737625598907, 0.24339890480041504, 0.20267894864082336, 0.14599190652370453, 0.13152122497558594, 0.14694136381149292, 0.18159040808677673, 0.13622702658176422, 0.204246386885643, 0.15938399732112885, 0.1555812954902649, 0.1577722728252411, 0.2212894856929779, 0.20490144193172455, 0.13901929557323456, 0.13329719007015228, 0.19588954746723175, 0.20940668880939484, 0.1524374783039093, 0.1522349715232849, 0.1475936472415924, 0.23231780529022217, 0.20530685782432556, 0.13169752061367035, 0.3317672312259674, 0.3846704661846161, 0.2001715451478958, 0.16915448009967804, 0.18728232383728027, 0.22124913334846497, 0.12061604112386703, 0.5262273550033569, 0.07943310588598251, 0.12218373268842697, 0.29536381363868713, 0.2262275367975235, 0.2165168970823288, 0.1310916393995285, 0.23919866979122162, 0.46106836199760437, 0.2583475410938263, 0.1774595081806183, 0.15721598267555237, 0.309919148683548, 0.21636338531970978, 0.25835511088371277, 0.10183089226484299, 0.3909379243850708, 0.0565079040825367, 0.0922800749540329, 0.07563606649637222, 0.18361270427703857, 0.16708607971668243, 1.0534934997558594, 0.1700943410396576, 0.19744014739990234, 0.13304303586483002, 0.21264803409576416, 0.07768499106168747, 0.3070876896381378, 0.14712411165237427, 0.24562066793441772, 0.2261858582496643, 0.45046210289001465, 0.2513541281223297, 0.1312086284160614, 0.667028546333313, 0.19200165569782257, 0.3050467073917389, 0.509955644607544, 0.10983727127313614, 0.33963727951049805, 0.161249041557312, 0.09398203343153, 0.19423486292362213, 0.3155895173549652, 0.236301451921463, 0.11785952746868134, 0.17239868640899658, 0.1383092999458313, 0.09171801805496216, 0.07571522891521454, 0.09169890731573105, 0.19153304398059845, 0.22819621860980988, 0.14012542366981506, 0.29022735357284546, 0.11924515664577484, 0.2111973613500595, 0.16378429532051086, 0.1881105899810791, 0.1545318067073822, 0.10911914706230164, 0.17990438640117645, 0.11421038210391998, 0.1877276748418808, 0.12415824085474014, 0.2010008692741394, 0.16020101308822632, 0.16772694885730743, 0.3780726194381714, 0.06744599342346191, 0.20212322473526, 0.21406656503677368, 0.38622525334358215, 0.12070418894290924, 0.12195242196321487, 0.043485552072525024, 0.22223317623138428, 0.20612524449825287, 0.18187403678894043, 0.24369500577449799, 0.09835577756166458, 0.3620271384716034, 0.10456325113773346, 0.20150965452194214, 0.2865349352359772, 0.2837854325771332, 0.14202821254730225, 0.11905956268310547, 0.4723914563655853, 0.11882815510034561, 0.18137969076633453, 0.12316493690013885, 0.21782365441322327, 0.09810948371887207, 0.12443608790636063, 0.20610171556472778, 0.23348793387413025, 0.18981340527534485, 0.15064866840839386, 0.14585377275943756, 0.3573012948036194, 0.19470055401325226, 0.0922730341553688, 0.13686305284500122, 0.07357658445835114, 0.18595106899738312, 0.13621453940868378, 0.3776150643825531, 0.20092523097991943, 0.23390629887580872, 0.20393583178520203, 0.09316997230052948, 0.22035853564739227, 0.09062892943620682, 0.08719666302204132, 0.08858329057693481, 0.13720303773880005, 0.2658642828464508, 0.19698549807071686, 0.11418496072292328, 0.09830264002084732, 0.23576971888542175, 0.12116794288158417, 0.13116183876991272, 0.09489069133996964, 0.2089352160692215, 0.1785484105348587, 0.10389997065067291, 0.2698114812374115, 0.10566741973161697, 0.13275876641273499, 0.22088558971881866, 0.3332844078540802, 0.2891453802585602, 0.1677081435918808, 0.17704620957374573, 0.09975618124008179, 0.13736744225025177, 0.11122249811887741, 0.24460271000862122, 0.2168201357126236, 0.13841813802719116, 0.14550158381462097, 0.11669003218412399, 0.22388431429862976, 0.18453556299209595, 0.14182056486606598, 0.18240882456302643, 0.1334599256515503, 0.24334944784641266, 0.13106442987918854, 0.22976848483085632, 0.15298992395401, 0.12512245774269104, 0.1796652227640152, 0.11016983538866043, 0.16990606486797333, 0.18877071142196655, 0.21908408403396606, 0.21550290286540985, 0.11586564779281616, 0.1656748354434967, 0.13756561279296875, 0.25763875246047974, 0.15019284188747406, 0.23845522105693817, 0.18002551794052124, 0.21984127163887024, 0.14819249510765076, 0.1686176210641861, 0.16143658757209778, 0.22652985155582428, 0.15041011571884155, 0.1395525336265564, 0.15042732656002045, 0.23891861736774445, 0.2367170751094818, 0.1560695618391037, 0.16663140058517456, 0.2151649445295334, 0.14734740555286407, 0.22210240364074707, 0.15107594430446625, 0.1887245625257492, 0.26967814564704895, 0.15672552585601807, 0.11404905468225479, 0.13263778388500214, 0.11043991148471832, 0.2435998171567917, 0.18889617919921875, 0.11764261871576309, 0.17869223654270172, 0.24467384815216064, 0.11033786088228226, 0.20422133803367615, 0.10124540328979492, 0.18449938297271729, 0.1275206357240677, 0.16908963024616241, 0.11417941749095917, 0.16259217262268066, 0.20659960806369781, 0.18639841675758362, 0.20016926527023315, 0.1804797649383545, 0.2231265902519226, 0.1479882299900055, 0.11231827735900879, 0.17463624477386475, 0.14145489037036896, 0.24036504328250885, 0.26160797476768494, 0.22551314532756805, 0.16406412422657013, 0.16319486498832703, 0.13601861894130707, 0.21820569038391113, 0.15966321527957916, 0.15157191455364227, 0.23504993319511414, 0.19733808934688568, 0.10907862335443497, 0.1939081996679306, 0.24212409555912018, 0.21003106236457825, 0.14793510735034943, 0.16015809774398804, 0.1612514853477478, 0.16364270448684692, 0.19940558075904846, 0.17838643491268158, 0.13949450850486755, 0.1637844294309616, 0.17920011281967163, 0.2091328650712967, 0.20130635797977448, 0.13582086563110352, 0.17866528034210205, 0.16916321218013763, 0.23134420812129974, 0.15200559794902802, 0.17947383224964142, 0.16712479293346405, 0.18429774045944214, 0.224721297621727, 0.11732611060142517, 0.18552547693252563, 0.2224733531475067, 0.13191772997379303, 0.14145927131175995, 0.18304938077926636, 0.10673605650663376, 0.14732582867145538, 0.23703767359256744, 0.18248747289180756, 0.210398867726326, 0.17224283516407013, 0.1599559336900711, 0.15741890668869019, 0.18951337039470673, 0.12988197803497314, 0.1614151895046234, 0.1474023163318634, 0.14137223362922668, 0.1301254779100418, 0.15895530581474304, 0.2672920227050781, 0.1729784905910492, 0.11041431128978729, 0.14962312579154968, 0.22995662689208984, 0.22862498462200165, 0.21380220353603363, 0.14961087703704834, 0.11322983354330063, 0.15051481127738953, 0.15667936205863953, 0.13178609311580658, 0.21343058347702026, 0.21052369475364685, 0.11775229126214981, 0.1656239628791809, 0.13185708224773407, 0.2054937183856964, 0.10656379163265228, 0.10519911348819733, 0.23102159798145294, 0.14268304407596588, 0.14511293172836304, 0.1302393674850464, 0.130645751953125, 0.21369126439094543, 0.2917039394378662, 0.18847596645355225, 0.1668117791414261, 0.1329704374074936, 0.18596282601356506, 0.19865857064723969, 0.12360202521085739, 0.13596203923225403, 0.1805924028158188, 0.26741454005241394, 0.1137150302529335, 0.24140362441539764, 0.13006125390529633, 0.113841213285923, 0.19767597317695618, 0.11897169798612595, 0.21497087180614471, 0.1537301391363144, 0.14798188209533691, 0.12391944229602814, 0.14655224978923798, 0.14742696285247803, 0.1544438898563385, 0.15619754791259766, 0.11884945631027222, 0.16117630898952484, 0.1929292231798172, 0.12441159039735794, 0.2190767228603363, 0.2263617366552353, 0.2027982771396637, 0.1463005393743515, 0.18169161677360535, 0.22419781982898712, 0.11555618047714233, 0.1918063461780548, 0.11202660202980042, 0.14870098233222961, 0.10544130951166153, 0.2749742865562439, 0.14196643233299255, 0.10655392706394196, 0.1919582039117813, 0.1311480700969696, 0.17075803875923157, 0.2115846574306488, 0.17707833647727966, 0.13965222239494324, 0.1975899636745453, 0.23266825079917908, 0.282121866941452, 0.15651404857635498, 0.12631864845752716, 0.10944561660289764, 0.1768750250339508, 0.122677743434906, 0.12136203795671463, 0.14308464527130127, 0.2807287871837616, 0.11476533859968185, 0.2689502537250519, 0.23667629063129425, 0.11781586706638336, 0.2526718080043793, 0.13136149942874908, 0.13850457966327667, 0.14961828291416168, 0.14083625376224518, 0.15684115886688232, 0.18056797981262207, 0.12428278475999832, 0.1722812056541443, 0.19327670335769653, 0.24838131666183472, 0.12974365055561066, 0.08772125095129013, 0.1752479374408722, 0.17143939435482025, 0.13764648139476776, 0.1281890869140625, 0.12435844540596008, 0.250196248292923, 0.2422030121088028, 0.12178608030080795, 0.14061123132705688, 0.1866045892238617, 0.1343497931957245, 0.19795042276382446, 0.16711276769638062, 0.2080269753932953, 0.17149865627288818, 0.1432109773159027, 0.15367238223552704, 0.09362899512052536, 0.298634797334671, 0.12813714146614075, 0.15508118271827698, 0.18954280018806458, 0.13458006083965302, 0.17982442677021027, 0.13883854448795319, 0.13316607475280762, 0.22212237119674683, 0.1532614380121231, 0.2396632879972458, 0.17126739025115967, 0.175715371966362, 0.13429567217826843, 0.14058610796928406, 0.18309369683265686, 0.1691194772720337, 0.1271122843027115, 0.10342122614383698, 0.2698662579059601, 0.1680591106414795, 0.1315140277147293, 0.18323485553264618, 0.22705626487731934, 0.09067299216985703, 0.22280293703079224, 0.3197147846221924, 0.22916342318058014, 0.20739416778087616, 0.13998951017856598, 0.11477421969175339, 0.09164237231016159, 0.10865618288516998, 0.24909602105617523, 0.11638407409191132, 0.22024962306022644, 0.11677465587854385, 0.16827930510044098, 0.21335850656032562, 0.17003467679023743, 0.17083604633808136, 0.09388335049152374, 0.12535986304283142, 0.09372156858444214, 0.3051776587963104, 0.1473546177148819, 0.19224250316619873, 0.1837756633758545, 0.13704445958137512, 0.2331910878419876, 0.17558476328849792, 0.17280429601669312, 0.1905064880847931, 0.0984581857919693, 0.10945631563663483, 0.19849926233291626, 0.18670639395713806, 0.09912214428186417, 0.2131728082895279, 0.289411336183548, 0.22288164496421814, 0.14268600940704346, 0.13124164938926697, 0.1958838552236557, 0.2459421306848526, 0.14159919321537018, 0.1351938247680664, 0.20097100734710693, 0.1565389186143875, 0.11618231236934662, 0.2198454588651657, 0.1903005987405777, 0.17765706777572632, 0.19086694717407227, 0.14365513622760773, 0.24631774425506592, 0.1916290819644928, 0.20552141964435577, 0.18814511597156525, 0.19976158440113068, 0.219016894698143, 0.19247335195541382, 0.16415876150131226, 0.1598900705575943, 0.17363397777080536, 0.17927828431129456, 0.13765117526054382, 0.14218871295452118, 0.177658811211586, 0.17988888919353485, 0.13644440472126007, 0.1551114320755005, 0.21116943657398224, 0.13327383995056152, 0.14646968245506287, 0.19368518888950348, 0.20352506637573242, 0.21247589588165283, 0.1666242778301239, 0.1680401861667633, 0.16933752596378326, 0.15026512742042542, 0.22772210836410522, 0.15837053954601288, 0.1892143040895462, 0.13515470921993256, 0.17035476863384247, 0.13433513045310974, 0.14343629777431488, 0.15569642186164856, 0.17687028646469116, 0.17282350361347198, 0.21203500032424927, 0.15707409381866455, 0.1890314370393753, 0.13751620054244995, 0.17477039992809296, 0.15486527979373932, 0.161285862326622, 0.14609023928642273, 0.16488704085350037, 0.1917767971754074, 0.165132537484169, 0.16679459810256958, 0.18687564134597778, 0.1523723155260086, 0.11725227534770966, 0.11574439704418182, 0.11468444019556046, 0.1950468271970749, 0.1593807339668274, 0.20312175154685974, 0.16819965839385986, 0.1608697921037674, 0.16194680333137512, 0.23488128185272217, 0.10485567152500153, 0.14333908259868622, 0.2270556539297104, 0.10367017239332199, 0.18747344613075256, 0.13371595740318298, 0.10210191458463669, 0.1426810920238495, 0.15000130236148834, 0.18319018185138702, 0.20552948117256165, 0.2064058631658554, 0.12900400161743164, 0.1512063592672348, 0.17601050436496735, 0.1419120877981186, 0.2055104523897171, 0.24587680399417877, 0.09500189125537872, 0.15655656158924103, 0.13335862755775452, 0.15029142796993256, 0.14012131094932556, 0.22405573725700378, 0.21519187092781067, 0.14144383370876312, 0.13309639692306519, 0.18568041920661926, 0.12505383789539337, 0.18882372975349426, 0.08774446696043015, 0.2351621836423874, 0.25992152094841003, 0.2628345787525177, 0.08907175809144974, 0.12068759649991989, 0.19526079297065735, 0.30514171719551086, 0.1686689406633377, 0.23091790080070496, 0.1803067922592163, 0.17331743240356445, 0.2806175649166107, 0.14042282104492188, 0.18049941956996918, 0.21181747317314148, 0.1803215742111206, 0.19966106116771698, 0.1177278608083725, 0.11955395340919495, 0.22100695967674255, 0.1493513286113739, 0.1797909289598465, 0.16534996032714844, 0.12593360245227814, 0.1264093667268753, 0.12593482434749603, 0.18330800533294678, 0.17811420559883118, 0.17913946509361267, 0.16081497073173523, 0.16598115861415863, 0.17953045666217804, 0.200478658080101, 0.2025420069694519, 0.15369869768619537, 0.16646915674209595, 0.14812374114990234, 0.18651941418647766, 0.15452243387699127, 0.23697343468666077, 0.1582660973072052, 0.2347991168498993, 0.20693427324295044, 0.18896490335464478, 0.17057645320892334, 0.1424102932214737, 0.2220739722251892, 0.19841782748699188, 0.16724064946174622, 0.19877436757087708, 0.15408958494663239, 0.19278626143932343, 0.1798352599143982, 0.18565090000629425, 0.14968006312847137, 0.1695677638053894, 0.1622229814529419, 0.1799524426460266, 0.1683966964483261, 0.17268189787864685, 0.18428534269332886, 0.19534282386302948, 0.15137411653995514, 0.16258487105369568, 0.185185968875885, 0.14824971556663513, 0.1822982132434845, 0.1600470095872879, 0.1590975672006607, 0.16579268872737885, 0.17793422937393188, 0.13773518800735474, 0.1880791187286377, 0.15053293108940125, 0.2083887904882431, 0.13955536484718323, 0.15377959609031677, 0.146458238363266, 0.18726061284542084, 0.1516554206609726, 0.13772380352020264, 0.18087857961654663, 0.17133758962154388, 0.21981948614120483, 0.11747926473617554, 0.18226496875286102, 0.18837392330169678, 0.14874093234539032, 0.19110648334026337, 0.21051497757434845, 0.11416904628276825, 0.17286863923072815, 0.1656809151172638, 0.17155557870864868, 0.1660589724779129, 0.13954198360443115, 0.20167218148708344, 0.13439056277275085, 0.19251896440982819, 0.14333264529705048, 0.19005556404590607, 0.1922769546508789, 0.14990240335464478, 0.16257770359516144, 0.19010405242443085, 0.19110167026519775, 0.2006804496049881, 0.19313068687915802, 0.24987410008907318, 0.15113402903079987, 0.13954590260982513, 0.14871127903461456, 0.1525871753692627, 0.1664905548095703, 0.16619059443473816, 0.1590488702058792, 0.1886817067861557, 0.18024879693984985, 0.19073255360126495, 0.23970317840576172, 0.12121103703975677, 0.20801161229610443, 0.12119042128324509, 0.14710699021816254, 0.19011349976062775, 0.23132900893688202, 0.14893877506256104, 0.12009097635746002, 0.1749289184808731, 0.14301496744155884, 0.15365780889987946, 0.11744193732738495, 0.11632199585437775, 0.22150516510009766, 0.14092592895030975, 0.17190960049629211, 0.11171502619981766, 0.1618092656135559, 0.12631841003894806, 0.18792662024497986, 0.10683578252792358, 0.183735653758049, 0.18133831024169922, 0.15902943909168243, 0.18366718292236328, 0.18050827085971832, 0.1569308489561081, 0.14922671020030975, 0.10134387016296387, 0.10034069418907166, 0.20125362277030945, 0.17160244286060333, 0.09736305475234985, 0.16768498718738556, 0.21918131411075592, 0.0950215607881546, 0.14127667248249054, 0.11897288262844086, 0.23341239988803864, 0.09227658808231354, 0.09144692122936249, 0.0902036800980568, 0.22120201587677002, 0.13852745294570923, 0.17138701677322388, 0.10988479107618332, 0.08650634437799454, 0.08512797206640244, 0.21846678853034973, 0.13806886970996857, 0.20276309549808502, 0.18725547194480896, 0.19373242557048798, 0.1725582480430603, 0.0790039524435997, 0.1073446124792099, 0.11581844836473465, 0.25878843665122986, 0.26332801580429077, 0.23689444363117218, 0.16806232929229736, 0.1931547075510025, 0.1441638320684433, 0.15427455306053162, 0.11668458580970764, 0.08295770734548569, 0.120660699903965, 0.08315940201282501, 0.17161014676094055, 0.13302108645439148, 0.1824951469898224, 0.1818203330039978, 0.1928001046180725, 0.14187771081924438, 0.14124824106693268, 0.24641846120357513, 0.08064945042133331, 0.1084200069308281, 0.18530169129371643, 0.15782499313354492, 0.18594574928283691, 0.22473911941051483, 0.24306310713291168, 0.27255162596702576, 0.0827421322464943, 0.1514774113893509, 0.11146797239780426, 0.11469464749097824, 0.08511047065258026, 0.24425506591796875, 0.08554842323064804, 0.08550525456666946, 0.12034899741411209, 0.13536731898784637, 0.08331770449876785, 0.08259443193674088, 0.13032056391239166, 0.14407356083393097, 0.25829941034317017, 0.1295003741979599, 0.13084957003593445, 0.20287592709064484, 0.0753595232963562, 0.10921383649110794, 0.20409731566905975, 0.15912634134292603, 0.2050495445728302, 0.13940809667110443, 0.20533998310565948, 0.27023375034332275, 0.07164068520069122, 0.07236015796661377, 0.2020387202501297, 0.1361490935087204, 0.1822122484445572, 0.07100404798984528, 0.21049591898918152, 0.17189139127731323, 0.25975337624549866, 0.12691634893417358, 0.189516082406044, 0.14624184370040894, 0.07255687564611435, 0.12252109497785568, 0.270485520362854, 0.21520689129829407, 0.189016655087471, 0.3544174134731293, 0.15871086716651917, 0.26191291213035583, 0.20424270629882812, 0.18893569707870483, 0.22966459393501282, 0.25232356786727905, 0.1224205419421196, 0.18310518562793732, 0.29552602767944336, 0.2880863845348358, 0.17308774590492249, 0.10501101613044739, 0.22613756358623505, 0.17591586709022522, 0.17643719911575317, 0.18788093328475952, 0.14442570507526398, 0.21710331737995148, 0.14196820557117462, 0.21050740778446198, 0.19792328774929047, 0.20793597400188446, 0.17082998156547546, 0.1934279203414917, 0.15161095559597015, 0.14871349930763245, 0.16259832680225372, 0.16554035246372223, 0.18160025775432587, 0.17262491583824158, 0.1725044548511505, 0.17754021286964417, 0.13629481196403503, 0.13622866570949554, 0.20495779812335968, 0.17193709313869476, 0.15551523864269257, 0.16371317207813263, 0.15304189920425415, 0.22233889997005463, 0.22290484607219696, 0.1550547182559967, 0.186786487698555, 0.17731212079524994, 0.16089338064193726, 0.18981778621673584, 0.20351171493530273, 0.12880383431911469, 0.19709213078022003, 0.16129185259342194, 0.21943159401416779, 0.17228849232196808, 0.18291202187538147, 0.1876489818096161, 0.1660590022802353, 0.13966962695121765, 0.13988512754440308, 0.1777665913105011, 0.16304033994674683, 0.16402079164981842, 0.17469587922096252, 0.16069725155830383, 0.1409669667482376, 0.17343536019325256, 0.1776338666677475, 0.160500168800354, 0.16055485606193542, 0.16273857653141022, 0.13383962213993073, 0.16982975602149963, 0.1308448761701584, 0.1294025480747223, 0.1479065865278244, 0.12651926279067993, 0.19891999661922455, 0.16447851061820984, 0.19370704889297485, 0.15872828662395477, 0.14772194623947144, 0.14710724353790283, 0.15334241092205048, 0.17629234492778778, 0.1161092221736908, 0.11468794196844101, 0.1765630543231964, 0.2131611853837967, 0.13859955966472626, 0.1305512934923172, 0.14645236730575562, 0.13815677165985107, 0.23824794590473175, 0.12639708817005157, 0.18089032173156738, 0.1690702587366104, 0.16817666590213776, 0.1794320046901703, 0.1445780098438263, 0.16214588284492493, 0.1326146423816681, 0.12952928245067596, 0.14886832237243652, 0.18123869597911835, 0.17961756885051727, 0.10261576622724533, 0.181729257106781, 0.19031375646591187, 0.13505862653255463, 0.14716792106628418, 0.14240024983882904, 0.09926676005125046, 0.1524418592453003, 0.1355392187833786, 0.22294555604457855, 0.0964440107345581, 0.2939814627170563, 0.14485661685466766, 0.14432701468467712, 0.12985964119434357, 0.095071941614151, 0.13006816804409027, 0.17445962131023407, 0.18020862340927124, 0.15468384325504303, 0.13799898326396942, 0.16643938422203064, 0.09194696694612503, 0.16312584280967712, 0.14529235661029816, 0.12483134120702744, 0.21034862101078033, 0.17652586102485657, 0.08866091072559357, 0.13218513131141663, 0.16835111379623413, 0.22467055916786194, 0.12418995052576065, 0.13092419505119324, 0.17106086015701294, 0.12077665328979492, 0.19268803298473358, 0.23579910397529602, 0.08432406932115555, 0.12609051167964935, 0.16024596989154816, 0.08244766294956207, 0.18694274127483368, 0.11481770128011703, 0.25707173347473145, 0.20089243352413177, 0.08029179275035858, 0.07994173467159271, 0.1952495276927948, 0.07968240231275558, 0.2588788866996765, 0.16732950508594513, 0.2020016461610794, 0.21376961469650269, 0.079165019094944, 0.18198581039905548, 0.19992360472679138, 0.12368144094944, 0.07961451262235641, 0.2157728672027588, 0.18363696336746216, 0.12872952222824097, 0.19842350482940674, 0.0798541009426117, 0.19567067921161652, 0.12115518003702164, 0.12826265394687653, 0.260097861289978, 0.07900704443454742, 0.1853371560573578, 0.07818001508712769, 0.24143682420253754, 0.2177339345216751, 0.11872506886720657, 0.14903458952903748, 0.14635829627513885, 0.1986941695213318, 0.18119923770427704, 0.1800607144832611, 0.1730658859014511, 0.12194736301898956, 0.08095705509185791, 0.18650440871715546, 0.1742428094148636, 0.19784238934516907, 0.13078591227531433, 0.18417039513587952, 0.2770093083381653, 0.12302777171134949, 0.18487416207790375, 0.16312843561172485, 0.22610782086849213, 0.21366026997566223, 0.08573870360851288, 0.1188000962138176, 0.17225544154644012, 0.08649206906557083, 0.1399640589952469, 0.14664708077907562, 0.08570809662342072, 0.11966372281312943, 0.14309047162532806, 0.19407179951667786, 0.12119339406490326, 0.14041483402252197, 0.13997605443000793, 0.1777598261833191, 0.07961763441562653, 0.07893578708171844, 0.2525361180305481, 0.07684469223022461, 0.253406286239624, 0.17124223709106445, 0.1807728111743927, 0.12882541120052338, 0.12631544470787048, 0.18051449954509735, 0.2889363467693329, 0.17839501798152924, 0.12390273064374924, 0.19083377718925476, 0.2671358287334442, 0.12148601561784744, 0.12702414393424988, 0.07996205240488052, 0.0803941860795021, 0.08006051927804947, 0.26047560572624207, 0.12499187886714935, 0.17838944494724274, 0.25372880697250366, 0.08046633750200272, 0.13237717747688293, 0.2519685924053192, 0.08096453547477722, 0.08118832856416702, 0.12814943492412567, 0.17834897339344025, 0.25589126348495483, 0.08073190599679947, 0.20714826881885529, 0.11541362851858139, 0.19807665050029755, 0.24545566737651825, 0.18636217713356018, 0.1298774629831314, 0.24232028424739838, 0.14523433148860931, 0.27547118067741394, 0.2124193012714386, 0.18320854008197784, 0.2188551276922226, 0.12657076120376587, 0.17646855115890503, 0.20220763981342316, 0.14144904911518097, 0.09365910291671753, 0.17922931909561157, 0.15408742427825928, 0.21634076535701752, 0.17319506406784058, 0.1518981009721756, 0.17628219723701477, 0.17763850092887878, 0.15989768505096436, 0.13029253482818604, 0.2043096423149109, 0.17875634133815765, 0.19665682315826416, 0.09767121821641922, 0.17414455115795135, 0.18678751587867737, 0.19856852293014526, 0.13129748404026031, 0.1362019032239914, 0.11612985283136368, 0.16288669407367706, 0.12590551376342773, 0.1399262249469757, 0.1556960940361023, 0.23531989753246307, 0.12922140955924988, 0.18226918578147888, 0.1368061900138855, 0.1605094075202942, 0.1318366974592209, 0.13684892654418945, 0.14294575154781342, 0.17828235030174255, 0.1719919741153717, 0.13944007456302643, 0.20594559609889984, 0.23280586302280426, 0.09277134388685226, 0.22559724748134613, 0.24494820833206177, 0.25996875762939453, 0.09467960894107819, 0.14781725406646729, 0.23955437541007996, 0.16363520920276642, 0.09695115685462952, 0.13510137796401978, 0.16233688592910767, 0.21120864152908325, 0.1561942994594574, 0.13277067244052887, 0.17726483941078186, 0.1398618519306183, 0.13539020717144012, 0.12320107966661453, 0.12606756389141083, 0.22087714076042175, 0.13674834370613098, 0.1882261484861374, 0.13056786358356476, 0.19181883335113525, 0.14552739262580872, 0.12422426044940948, 0.09746649116277695, 0.1473698616027832, 0.09586340188980103, 0.17181500792503357, 0.14310206472873688, 0.16714777052402496, 0.1282423883676529, 0.1666753888130188, 0.1963585913181305, 0.19543443620204926, 0.21996067464351654, 0.09029567241668701, 0.17605708539485931, 0.20352277159690857, 0.17343463003635406, 0.13140380382537842, 0.08992721140384674, 0.0893133357167244, 0.16077174246311188, 0.08849986642599106, 0.08785105496644974, 0.1847999542951584, 0.1857638955116272, 0.2023867815732956, 0.18673762679100037, 0.24935200810432434, 0.18492621183395386, 0.13740327954292297, 0.14193576574325562, 0.1080455407500267, 0.12962165474891663, 0.2560417652130127, 0.17944295704364777, 0.17394402623176575, 0.08527866005897522, 0.15667685866355896, 0.12525516748428345, 0.0849638432264328, 0.17682592570781708, 0.14205402135849, 0.12863223254680634, 0.11164499074220657, 0.2724124789237976, 0.19130034744739532, 0.08213510364294052, 0.12030797451734543, 0.10819492489099503, 0.19054141640663147, 0.1395396590232849, 0.26087525486946106, 0.07988564670085907, 0.12381139397621155, 0.07947271317243576, 0.20055121183395386, 0.3424288034439087, 0.1791219413280487, 0.1316252499818802, 0.26246026158332825, 0.16625384986400604, 0.10617424547672272, 0.14398247003555298, 0.19425198435783386, 0.13755807280540466, 0.19313254952430725, 0.13905228674411774, 0.1423233300447464, 0.1329534500837326, 0.12513941526412964, 0.19401989877223969, 0.20914573967456818, 0.08419551700353622, 0.15665239095687866, 0.16749048233032227, 0.23591971397399902, 0.0838584452867508, 0.17234362661838531, 0.17590393126010895, 0.1421760767698288, 0.18728843331336975, 0.11906033009290695, 0.2008594572544098, 0.16989485919475555, 0.20291897654533386, 0.0853055939078331, 0.12339809536933899, 0.08518321067094803, 0.20956876873970032, 0.11918357759714127, 0.16389112174510956, 0.141821950674057, 0.1933814436197281, 0.13884581625461578, 0.2385842204093933, 0.19281615316867828, 0.08301853388547897, 0.15326479077339172, 0.12665396928787231, 0.18935434520244598, 0.13224507868289948, 0.251857727766037, 0.08188792318105698, 0.08182044327259064, 0.12718193233013153, 0.2218911498785019, 0.33470505475997925, 0.0812501385807991, 0.08159581571817398, 0.19483128190040588, 0.17244096100330353, 0.2023121416568756, 0.10924500972032547, 0.19953182339668274, 0.1258476972579956, 0.1969718486070633, 0.08203793317079544, 0.08222511410713196, 0.08199052512645721, 0.2629610300064087, 0.18550674617290497, 0.12230151146650314, 0.263785183429718, 0.19442513585090637, 0.18242518603801727, 0.17013633251190186, 0.23507463932037354, 0.1419428437948227, 0.2350298911333084, 0.17004676163196564, 0.12121372669935226, 0.27093371748924255, 0.16461990773677826, 0.18919268250465393, 0.17421302199363708, 0.16835960745811462, 0.13107885420322418, 0.12327777594327927, 0.09473192691802979, 0.09488286823034286, 0.23045819997787476, 0.17984315752983093, 0.13655436038970947, 0.19265635311603546, 0.20411500334739685, 0.18685965240001678, 0.2249654084444046, 0.1930636614561081, 0.1271745264530182, 0.19441817700862885, 0.13610488176345825, 0.16799233853816986, 0.18054348230361938, 0.24133950471878052, 0.1013936772942543, 0.17461706697940826, 0.15593741834163666, 0.14053043723106384, 0.20037800073623657, 0.10204639285802841, 0.18099142611026764, 0.10173553228378296, 0.1012612134218216, 0.17285923659801483, 0.1491280347108841, 0.1861877143383026, 0.15941286087036133, 0.09875413775444031, 0.1411796361207962, 0.17590245604515076, 0.1831354796886444, 0.18061180412769318, 0.11605457961559296, 0.13284070789813995, 0.12192563712596893, 0.24305209517478943, 0.2005539834499359, 0.2403678148984909, 0.09413766860961914, 0.17066322267055511, 0.09398852288722992, 0.13737131655216217, 0.17232204973697662, 0.1974896788597107, 0.22350342571735382, 0.17531466484069824, 0.17003194987773895, 0.1764795482158661, 0.24821993708610535, 0.09527362883090973, 0.13148482143878937, 0.13353495299816132, 0.21644817292690277, 0.167872816324234, 0.0961742252111435, 0.13417743146419525, 0.1670800745487213, 0.13888832926750183, 0.14414472877979279, 0.23916465044021606, 0.12860353291034698, 0.18046626448631287, 0.15423035621643066, 0.1662798970937729, 0.0946553647518158, 0.18247748911380768, 0.2410622388124466, 0.1958693563938141, 0.18655358254909515, 0.19409522414207458, 0.09543686360120773, 0.0958884134888649, 0.24562522768974304, 0.11715187877416611, 0.14446890354156494, 0.15080074965953827, 0.17588749527931213, 0.29737570881843567, 0.2377537339925766, 0.09667394310235977, 0.16341334581375122, 0.09759968519210815, 0.1815900355577469, 0.14829228818416595, 0.19901415705680847, 0.09833060204982758, 0.09871704131364822, 0.1467527598142624, 0.24817867577075958, 0.09741691499948502, 0.12789051234722137, 0.13664518296718597, 0.16964225471019745, 0.19248659908771515, 0.1262681633234024, 0.29623833298683167, 0.19179090857505798, 0.1405448168516159, 0.2375311404466629, 0.09598976373672485, 0.12016520649194717, 0.19377456605434418, 0.09660398960113525, 0.13550400733947754, 0.13831894099712372, 0.13582968711853027, 0.13112321496009827, 0.2339850515127182, 0.134726881980896, 0.17548151314258575, 0.13909000158309937, 0.16097256541252136, 0.09307021647691727, 0.12168539315462112, 0.12255760282278061, 0.2160288393497467, 0.12577982246875763, 0.18738366663455963, 0.14195263385772705, 0.08833134919404984, 0.31387102603912354, 0.17227524518966675, 0.12362402677536011, 0.12272948026657104, 0.17910660803318024, 0.13938529789447784, 0.23887036740779877, 0.14135301113128662, 0.11801512539386749, 0.11553920805454254, 0.08866412937641144, 0.1469232589006424, 0.13014130294322968, 0.2036580741405487, 0.1476743370294571, 0.08748156577348709, 0.17081913352012634, 0.20357473194599152, 0.08579467982053757, 0.0853767991065979, 0.17394579946994781, 0.24079900979995728, 0.3039662539958954, 0.10147909820079803, 0.18343499302864075, 0.1160966232419014, 0.24817140400409698, 0.22019873559474945, 0.15681932866573334, 0.20236432552337646, 0.1573392152786255, 0.15146787464618683, 0.12216547131538391, 0.18765944242477417, 0.13051877915859222, 0.2012769728899002, 0.25843650102615356, 0.18311068415641785, 0.24571287631988525, 0.09099537879228592, 0.20255541801452637, 0.15029937028884888, 0.09276052564382553, 0.1434219926595688, 0.2522910237312317, 0.16655480861663818, 0.12533101439476013, 0.19790686666965485, 0.20977529883384705, 0.14871159195899963, 0.12587477266788483, 0.1341949850320816, 0.09496793150901794, 0.29564177989959717, 0.29427671432495117, 0.17797665297985077, 0.17393507063388824, 0.13088223338127136, 0.2248275727033615, 0.18148452043533325, 0.23476561903953552, 0.1753956377506256, 0.2103956639766693, 0.15599113702774048, 0.13654577732086182, 0.16797813773155212, 0.17499764263629913, 0.14876475930213928, 0.16501201689243317, 0.1801978349685669, 0.11220945417881012, 0.1762511134147644, 0.18182365596294403, 0.2583923637866974, 0.11351572722196579, 0.1340053230524063, 0.2148638367652893, 0.22956441342830658, 0.14352785050868988, 0.22032858431339264, 0.14686714112758636, 0.1444520354270935, 0.11761762201786041, 0.13876807689666748, 0.1837596297264099, 0.1955166608095169, 0.19752629101276398, 0.1890845000743866, 0.12281275540590286, 0.1978152096271515, 0.1833665668964386, 0.1417246311903, 0.18958523869514465, 0.12042032182216644, 0.19064398109912872, 0.1201440766453743, 0.18301384150981903, 0.1559053659439087, 0.19817902147769928, 0.15092650055885315, 0.2128402292728424, 0.18985486030578613, 0.15062734484672546, 0.1992955207824707, 0.2275734394788742, 0.15828678011894226, 0.20700867474079132, 0.2011176496744156, 0.13479062914848328, 0.16489361226558685, 0.18945708870887756, 0.16353440284729004, 0.1821250170469284, 0.1587558090686798, 0.1532072275876999, 0.1561519056558609, 0.15242767333984375, 0.15351709723472595, 0.20308607816696167, 0.12079513818025589, 0.12867118418216705, 0.20780625939369202, 0.20177721977233887, 0.1765855997800827, 0.17526748776435852, 0.22668176889419556, 0.14520899951457977, 0.15067055821418762, 0.20279106497764587, 0.17831741273403168, 0.1438133269548416, 0.2230033278465271, 0.1426665484905243, 0.17715637385845184, 0.12083441764116287, 0.1660975068807602, 0.12024658918380737, 0.13384492695331573, 0.11907356232404709, 0.18759390711784363, 0.194014310836792, 0.14162099361419678, 0.22077354788780212, 0.13571594655513763, 0.18095776438713074, 0.19647040963172913, 0.16333162784576416, 0.1457662433385849, 0.11453364044427872, 0.16914679110050201, 0.1426686942577362, 0.11186249554157257, 0.18758641183376312, 0.10955724865198135, 0.13458359241485596, 0.10734111815690994, 0.1537735015153885, 0.143381267786026, 0.21933206915855408, 0.21556474268436432, 0.10203062742948532, 0.14089064300060272, 0.12539063394069672, 0.12090469896793365, 0.12887144088745117, 0.18613335490226746, 0.14818550646305084, 0.19326461851596832, 0.21996767818927765, 0.17928747832775116, 0.13614077866077423, 0.09457477182149887, 0.2306523472070694, 0.1333589404821396, 0.29822757840156555, 0.1676151305437088, 0.22809311747550964, 0.13567493855953217, 0.09649855643510818, 0.09651366621255875, 0.1833307296037674, 0.16318129003047943, 0.2298094481229782, 0.1898627132177353, 0.09757554531097412, 0.09794694930315018, 0.23319201171398163, 0.09769967943429947, 0.18208825588226318, 0.1293112188577652, 0.2892998456954956, 0.13654109835624695, 0.13956378400325775, 0.09911515563726425, 0.17776542901992798, 0.09862024337053299, 0.1387961208820343, 0.22391995787620544, 0.09753373265266418, 0.13307622075080872, 0.14381425082683563, 0.14102286100387573, 0.09578223526477814, 0.2519278824329376, 0.13335654139518738, 0.13107110559940338, 0.15207090973854065, 0.1848093718290329, 0.12540878355503082, 0.18874751031398773, 0.1906816065311432, 0.09111686050891876, 0.2528899312019348, 0.09060845524072647, 0.12442371994256973, 0.08977524936199188, 0.16536620259284973, 0.25807592272758484, 0.31138691306114197, 0.08972278237342834, 0.22188404202461243, 0.2258433699607849, 0.1251092404127121, 0.18918099999427795, 0.22434237599372864, 0.1345294862985611, 0.17011430859565735, 0.13888460397720337, 0.17700588703155518, 0.20592743158340454, 0.09760354459285736, 0.18666377663612366, 0.1906069666147232, 0.1792224496603012, 0.09897025674581528, 0.14531448483467102, 0.21459807455539703, 0.16998648643493652, 0.17831553518772125, 0.10026198625564575, 0.14906099438667297, 0.1865306943655014, 0.12473893165588379, 0.17123666405677795, 0.099558025598526, 0.14654657244682312, 0.17446160316467285, 0.17822538316249847, 0.18678225576877594, 0.162894144654274, 0.2197582870721817, 0.09798981994390488, 0.09827037900686264, 0.0982719361782074, 0.22276253998279572, 0.1608046144247055, 0.14094343781471252, 0.1632876843214035, 0.2392055243253708, 0.14168502390384674, 0.15146349370479584, 0.1347697228193283, 0.18452389538288116, 0.19141577184200287, 0.1835235208272934, 0.16348110139369965, 0.17090368270874023, 0.19103604555130005, 0.09721620380878448, 0.1501983404159546, 0.15215270221233368, 0.16664643585681915, 0.1556534767150879, 0.19782443344593048, 0.1732441931962967, 0.1978304386138916, 0.11694230884313583, 0.09609513729810715, 0.14709627628326416, 0.09560726583003998, 0.23400108516216278, 0.1180516928434372, 0.15245401859283447, 0.16785448789596558, 0.1415555626153946, 0.17409929633140564, 0.13647647202014923, 0.17339642345905304, 0.2129838764667511, 0.17102862894535065, 0.09121289849281311, 0.24022789299488068, 0.17519284784793854, 0.11148995161056519, 0.1404724270105362, 0.1349649727344513, 0.17364080250263214, 0.18337607383728027, 0.30694788694381714, 0.22334812581539154, 0.13681788742542267, 0.12371675670146942, 0.14459967613220215, 0.0943872258067131, 0.09410016238689423, 0.12414462864398956, 0.14845022559165955, 0.18749117851257324, 0.09262308478355408, 0.1293763667345047, 0.09088997542858124, 0.09001858532428741, 0.15044453740119934, 0.14956921339035034, 0.19054104387760162, 0.2594355642795563, 0.17124561965465546, 0.08517230302095413, 0.3230162262916565, 0.13346964120864868, 0.17509834468364716, 0.1954471468925476, 0.18497490882873535, 0.0857662558555603, 0.1857205033302307, 0.13748310506343842, 0.18644651770591736, 0.23715440928936005, 0.18375158309936523, 0.3159084618091583, 0.2607533633708954, 0.08992202579975128, 0.24755175411701202, 0.13712023198604584, 0.1784110963344574, 0.1318051815032959, 0.09591929614543915, 0.1888774186372757, 0.13329064846038818, 0.09690798074007034, 0.1774148792028427, 0.1314365714788437, 0.29155203700065613, 0.15097640454769135, 0.15610457956790924, 0.20352602005004883, 0.18386760354042053, 0.19466239213943481, 0.1696566492319107, 0.1490309238433838, 0.16393540799617767, 0.18380384147167206, 0.19126328825950623, 0.18572191894054413, 0.13244828581809998, 0.18447118997573853, 0.10252027213573456, 0.24465057253837585, 0.17130932211875916, 0.24229303002357483, 0.2442636340856552, 0.10484705865383148, 0.10525861382484436, 0.10586512833833694, 0.10525782406330109, 0.21160313487052917, 0.18147240579128265, 0.18374726176261902, 0.13428913056850433, 0.10517394542694092, 0.12943659722805023, 0.19960087537765503, 0.22685489058494568, 0.16377341747283936, 0.209818497300148, 0.13681301474571228, 0.15567608177661896, 0.19813232123851776, 0.2748737931251526, 0.15793302655220032, 0.14170366525650024, 0.10597192496061325, 0.10630816966295242, 0.10526935011148453, 0.20942188799381256, 0.10448277741670609, 0.1038205698132515, 0.15393340587615967, 0.2159235030412674, 0.15877552330493927, 0.12540124356746674, 0.22185645997524261, 0.18223977088928223, 0.28295955061912537, 0.15379983186721802, 0.1770806461572647, 0.20825143158435822, 0.2184765338897705, 0.18959908187389374, 0.1541171818971634, 0.18072034418582916, 0.15542533993721008, 0.16555427014827728, 0.18671530485153198, 0.10756954550743103, 0.10786677896976471, 0.24427855014801025, 0.21797753870487213, 0.22254985570907593, 0.17973801493644714, 0.1106136366724968, 0.1373765915632248, 0.13346506655216217, 0.14725583791732788, 0.15712466835975647, 0.13709679245948792, 0.11027295142412186, 0.10951684415340424, 0.1305837631225586, 0.13487769663333893, 0.19910117983818054, 0.13478705286979675, 0.17340685427188873, 0.185255765914917, 0.14899931848049164, 0.1579882651567459, 0.22981011867523193, 0.21386198699474335, 0.20573294162750244, 0.1732020378112793, 0.10583097487688065, 0.16019505262374878, 0.21980969607830048, 0.21668218076229095, 0.16089680790901184, 0.1456819623708725, 0.2695860266685486, 0.1360287070274353, 0.10910627990961075, 0.13482950627803802, 0.2263653576374054, 0.18494731187820435, 0.15215176343917847, 0.1764613389968872, 0.15737326443195343, 0.13167694211006165, 0.1409473419189453, 0.18434742093086243, 0.1420903354883194, 0.1580071598291397, 0.23101426661014557, 0.16527405381202698, 0.15851254761219025, 0.15550725162029266, 0.16875462234020233, 0.26014411449432373, 0.1778683066368103, 0.14758040010929108, 0.23235057294368744, 0.19270318746566772, 0.22884882986545563, 0.15505211055278778, 0.16376835107803345, 0.1784173548221588, 0.16327618062496185, 0.1499665081501007, 0.14457407593727112, 0.19993092119693756, 0.2182166427373886, 0.13167627155780792, 0.14260348677635193, 0.13116081058979034, 0.11982990056276321, 0.12059886753559113, 0.1579824984073639, 0.13073018193244934, 0.11868447810411453, 0.21238397061824799, 0.13907165825366974, 0.21396376192569733, 0.18869975209236145, 0.20566052198410034, 0.15674613416194916, 0.25371477007865906, 0.25300657749176025, 0.1493220180273056, 0.1280727982521057, 0.11702030897140503, 0.11734405159950256, 0.11715362221002579, 0.20640474557876587, 0.13628025352954865, 0.2032221257686615, 0.16981950402259827, 0.1940755397081375, 0.11641748994588852, 0.11576659977436066, 0.11642084270715714, 0.25421953201293945, 0.21645431220531464, 0.2106740027666092, 0.1520555466413498, 0.11552058160305023, 0.21890124678611755, 0.12097055464982986, 0.2034602165222168, 0.17200356721878052, 0.19925133883953094, 0.18612739443778992, 0.11929172277450562, 0.175650492310524, 0.11512310802936554, 0.13673613965511322, 0.15100491046905518, 0.18141064047813416, 0.15740950405597687, 0.1150791198015213, 0.11292920261621475, 0.19451430439949036, 0.1970704048871994, 0.18904586136341095, 0.17327755689620972, 0.11007789522409439, 0.16365894675254822, 0.16625937819480896, 0.1399848610162735, 0.14092442393302917, 0.16269542276859283, 0.17115303874015808, 0.18934853374958038, 0.11001674085855484, 0.159727081656456, 0.20303866267204285, 0.19668500125408173, 0.12528732419013977, 0.18989136815071106, 0.10509838908910751, 0.21404586732387543, 0.17815545201301575, 0.19612525403499603, 0.18409115076065063, 0.18984870612621307, 0.22123171389102936, 0.10467269271612167, 0.10456415265798569, 0.11253642290830612, 0.1432599574327469, 0.23572786152362823, 0.19542257487773895, 0.1994054615497589, 0.14840443432331085, 0.1690647155046463, 0.17568571865558624, 0.2066836655139923, 0.18327608704566956, 0.1680448204278946, 0.16998951137065887, 0.16277046501636505, 0.19531431794166565, 0.16109693050384521, 0.1861095428466797, 0.1396998018026352, 0.17859143018722534, 0.15565289556980133, 0.1871027648448944, 0.15137790143489838, 0.1370111107826233, 0.24695636332035065, 0.1315232366323471, 0.15375463664531708, 0.17730073630809784, 0.20445656776428223, 0.10787194222211838, 0.10749130696058273, 0.21517081558704376, 0.22940286993980408, 0.14195357263088226, 0.22292298078536987, 0.10721401125192642, 0.1772991567850113, 0.12720906734466553, 0.19984155893325806, 0.22200223803520203, 0.22313274443149567, 0.16965395212173462, 0.17775194346904755, 0.16920125484466553, 0.17223136126995087, 0.16932624578475952, 0.16399869322776794, 0.261393278837204, 0.13796192407608032, 0.14912138879299164, 0.11326916515827179, 0.1137622743844986, 0.13832677900791168, 0.19219188392162323, 0.11370540410280228, 0.13146354258060455, 0.12252552807331085, 0.11176525801420212, 0.1526474803686142, 0.18279573321342468, 0.1318511962890625, 0.2018982470035553, 0.1949557065963745, 0.22959446907043457, 0.17338183522224426, 0.15475986897945404, 0.13632506132125854, 0.1396109163761139, 0.1076846495270729, 0.18919329345226288, 0.19686558842658997, 0.20894265174865723, 0.18159055709838867, 0.1495170295238495, 0.1350531280040741, 0.2085784375667572, 0.15853649377822876, 0.2740221321582794, 0.13646629452705383, 0.2320248931646347, 0.10549426078796387, 0.23354937136173248, 0.1498745083808899, 0.10649415105581284, 0.17272566258907318, 0.15438061952590942, 0.1484324336051941, 0.16226844489574432, 0.22038641571998596, 0.15648558735847473, 0.14712390303611755, 0.14695903658866882, 0.14889702200889587, 0.13516327738761902, 0.22909477353096008, 0.1831085979938507, 0.21278999745845795, 0.16875885426998138, 0.10620938241481781, 0.1373194456100464, 0.16868294775485992, 0.1430368572473526, 0.1496638059616089, 0.23762457072734833, 0.15409062802791595, 0.192595437169075, 0.1534840166568756, 0.14548785984516144, 0.18131455779075623, 0.1323367804288864, 0.27402108907699585, 0.23668476939201355, 0.12747792899608612, 0.20507942140102386, 0.17529667913913727, 0.14198599755764008, 0.20256337523460388, 0.20181234180927277, 0.20835451781749725, 0.18694785237312317, 0.1095508486032486, 0.2625490427017212, 0.16322065889835358, 0.20374330878257751, 0.18708209693431854, 0.2563326358795166, 0.13987292349338531, 0.20301085710525513, 0.1451849490404129, 0.17982137203216553, 0.15767693519592285, 0.24524325132369995, 0.15782664716243744, 0.18368250131607056, 0.20419830083847046, 0.1889890730381012, 0.14866207540035248, 0.12501400709152222, 0.15283316373825073, 0.1862621307373047, 0.1763017326593399, 0.16557444632053375, 0.18124213814735413, 0.18658073246479034, 0.19083468616008759, 0.15089963376522064, 0.1644643247127533, 0.1442405730485916, 0.14123688638210297, 0.17884598672389984, 0.16904819011688232, 0.15003728866577148, 0.206995889544487, 0.15919704735279083, 0.13867580890655518, 0.15519355237483978, 0.15269260108470917, 0.16520023345947266, 0.14495813846588135, 0.18279454112052917, 0.20893526077270508, 0.15079103410243988, 0.15161269903182983, 0.14459718763828278, 0.20310640335083008, 0.16759425401687622, 0.19231685996055603, 0.21601006388664246, 0.1717815399169922, 0.12334838509559631, 0.13844314217567444, 0.23894743621349335, 0.1622517704963684, 0.15479178726673126, 0.14404083788394928, 0.18132354319095612, 0.1449422985315323, 0.15939699113368988, 0.14844518899917603, 0.14546966552734375, 0.14956726133823395, 0.16847869753837585, 0.14713752269744873, 0.16872000694274902, 0.11982588469982147, 0.21206027269363403, 0.141461580991745, 0.14858342707157135, 0.11674737930297852, 0.22661660611629486, 0.17296800017356873, 0.157189279794693, 0.1705295890569687, 0.11470415443181992, 0.23111964762210846, 0.17952074110507965, 0.2125065177679062, 0.18502919375896454, 0.15395468473434448, 0.18768994510173798, 0.14587974548339844, 0.15148676931858063, 0.14491669833660126, 0.18395473062992096, 0.2082574963569641, 0.12901079654693604, 0.16753938794136047, 0.1427089422941208, 0.1838322877883911, 0.16462144255638123, 0.1781335175037384, 0.11423519253730774, 0.15444734692573547, 0.2071056216955185, 0.1752462387084961, 0.15397799015045166, 0.1551767885684967, 0.13645493984222412, 0.2138105034828186, 0.15252359211444855, 0.23338550329208374, 0.20008353888988495, 0.12778350710868835, 0.20284898579120636, 0.18424564599990845, 0.14195631444454193, 0.1505585014820099, 0.1580834835767746, 0.19383510947227478, 0.15132908523082733, 0.1149744987487793, 0.17720507085323334, 0.19802941381931305, 0.14728473126888275, 0.1739952266216278, 0.11361759901046753, 0.18825483322143555, 0.22511222958564758, 0.13938702642917633, 0.11252681910991669, 0.153318852186203, 0.16939027607440948, 0.14001677930355072, 0.16374339163303375, 0.1108398586511612, 0.17806166410446167, 0.1739078164100647, 0.13077324628829956, 0.14454109966754913, 0.18290770053863525, 0.10834526270627975, 0.1906050741672516, 0.1991492211818695, 0.14412669837474823, 0.1070229560136795, 0.16940690577030182, 0.14089317619800568, 0.12618236243724823, 0.20768897235393524, 0.1989404559135437, 0.16811592876911163, 0.16609442234039307, 0.12830284237861633, 0.194322407245636, 0.17544493079185486, 0.22062668204307556, 0.20328423380851746, 0.13924464583396912, 0.16180884838104248, 0.1834646314382553, 0.23023061454296112, 0.105839803814888, 0.218017578125, 0.14018328487873077, 0.22339564561843872, 0.17213322222232819, 0.21806009113788605, 0.22325950860977173, 0.1823975294828415, 0.1704733967781067, 0.1701844334602356, 0.19820424914360046, 0.11242201924324036, 0.1536739319562912, 0.14088080823421478, 0.1380462497472763, 0.13874906301498413, 0.19327428936958313, 0.13919711112976074, 0.11320308595895767, 0.19902871549129486, 0.12393082678318024, 0.1345122903585434, 0.16731171309947968, 0.11165128648281097, 0.19903238117694855, 0.16197940707206726, 0.19762204587459564, 0.1535276621580124, 0.20508795976638794, 0.19111552834510803, 0.19713431596755981, 0.24200542271137238, 0.1835726946592331, 0.1452900469303131, 0.14940427243709564, 0.1485600769519806, 0.174381822347641, 0.13450267910957336, 0.13027144968509674, 0.1502055525779724, 0.11035074293613434, 0.15292426943778992, 0.17168450355529785, 0.1346435844898224, 0.1843787431716919, 0.26812654733657837, 0.15435940027236938, 0.10804160684347153, 0.14676518738269806, 0.19326277077198029, 0.13352864980697632, 0.10674670338630676, 0.10600309818983078, 0.18844765424728394, 0.10458781570196152, 0.14707137644290924, 0.17013415694236755, 0.13709069788455963, 0.19351020455360413, 0.10026794672012329, 0.13037148118019104, 0.13640926778316498, 0.16151617467403412, 0.09686383605003357, 0.20252986252307892, 0.1932005137205124, 0.2296246588230133, 0.11955978721380234, 0.15861807763576508, 0.18045362830162048, 0.16703477501869202, 0.13752727210521698, 0.16076858341693878, 0.17140702903270721, 0.0919923484325409, 0.21812228858470917, 0.127230703830719, 0.23245054483413696, 0.11482642590999603, 0.23806920647621155, 0.19581645727157593, 0.17851749062538147, 0.1795356124639511, 0.14071926474571228, 0.166005939245224, 0.2726317048072815, 0.12512528896331787, 0.1244540587067604, 0.15408062934875488, 0.14907819032669067, 0.14141809940338135, 0.18555085361003876, 0.13096551597118378, 0.14075160026550293, 0.14608289301395416, 0.18032227456569672, 0.1754966825246811, 0.22542673349380493, 0.12453378736972809, 0.1631016731262207, 0.14222998917102814, 0.22057269513607025, 0.14316894114017487, 0.1701168417930603, 0.1610683649778366, 0.14631988108158112, 0.29282206296920776, 0.14353951811790466, 0.16477997601032257, 0.14160606265068054, 0.1701086312532425, 0.19072291254997253, 0.09869451820850372, 0.18609611690044403, 0.1334628313779831, 0.22241416573524475, 0.09922659397125244, 0.244631826877594, 0.18314698338508606, 0.2279534488916397, 0.18022003769874573, 0.18877409398555756, 0.17828671634197235, 0.21554464101791382, 0.15833677351474762, 0.14280007779598236, 0.22691772878170013, 0.2296673059463501, 0.10517657548189163, 0.14264339208602905, 0.1752937287092209, 0.2228965014219284, 0.10798721015453339, 0.20218044519424438, 0.151544451713562, 0.2010326236486435, 0.1770978569984436, 0.11087365448474884, 0.1677662581205368, 0.23623119294643402, 0.18018896877765656, 0.13358521461486816, 0.1746021807193756, 0.20636488497257233, 0.17755469679832458, 0.16783657670021057, 0.16132229566574097, 0.16764022409915924, 0.16323791444301605, 0.17164191603660583, 0.12157507985830307, 0.12379595637321472, 0.21579410135746002, 0.20098665356636047, 0.16016660630702972, 0.1428295224905014, 0.14854155480861664, 0.14791235327720642, 0.11302404850721359, 0.14804118871688843, 0.17241108417510986, 0.19807618856430054, 0.16126888990402222, 0.19229592382907867, 0.2085556536912918, 0.1974746435880661, 0.19778279960155487, 0.18177221715450287, 0.11471698433160782, 0.21279335021972656, 0.11348569393157959, 0.11352433264255524, 0.14875981211662292, 0.16956524550914764, 0.13564307987689972, 0.18334366381168365, 0.18228447437286377, 0.12322867661714554, 0.18281486630439758, 0.2221064567565918, 0.17216044664382935, 0.16561660170555115, 0.2625325322151184, 0.13076810538768768, 0.2229984998703003, 0.17179007828235626, 0.14455965161323547, 0.14052589237689972, 0.1658472865819931, 0.17171357572078705, 0.16044479608535767, 0.13463234901428223, 0.19853617250919342, 0.14553998410701752, 0.19406962394714355, 0.18862682580947876, 0.17972314357757568, 0.17246975004673004, 0.16837729513645172, 0.20180627703666687, 0.17634829878807068, 0.17328615486621857, 0.20911356806755066, 0.1967504322528839, 0.21170005202293396, 0.16157478094100952, 0.14359210431575775, 0.11913938820362091, 0.15062083303928375, 0.1665431559085846, 0.24705097079277039, 0.1204325258731842, 0.15356089174747467, 0.11027476191520691, 0.11827783286571503, 0.1497681885957718, 0.17697246372699738, 0.11710945516824722, 0.18850643932819366, 0.11665170639753342, 0.1987450122833252, 0.13165156543254852, 0.20608554780483246, 0.11435595899820328, 0.13971774280071259, 0.12093568593263626, 0.11219623684883118, 0.1115799993276596, 0.1416236013174057, 0.25513890385627747, 0.1801239252090454, 0.17171931266784668, 0.10764329135417938, 0.20759843289852142, 0.11910050362348557, 0.1808641105890274, 0.10589125007390976, 0.18649794161319733, 0.11832697689533234, 0.19301272928714752, 0.17799687385559082, 0.15115869045257568, 0.11097556352615356, 0.10184371471405029, 0.24270878732204437, 0.12728053331375122, 0.21354594826698303, 0.18154031038284302, 0.20053768157958984, 0.20965228974819183, 0.1194009855389595, 0.16076503694057465, 0.14117549359798431, 0.14930066466331482, 0.13438060879707336, 0.16166038811206818, 0.09851425141096115, 0.2188183218240738, 0.17551185190677643, 0.2054237574338913, 0.14711646735668182, 0.16803286969661713, 0.21264715492725372, 0.17379635572433472, 0.18947327136993408, 0.18125417828559875, 0.13200736045837402, 0.1299283653497696, 0.12698256969451904, 0.2534090578556061, 0.26792803406715393, 0.09548943489789963, 0.14267951250076294, 0.12653420865535736, 0.2940191924571991, 0.24350474774837494, 0.12936460971832275, 0.17927947640419006, 0.1366998553276062, 0.1768360286951065, 0.2379896491765976, 0.23444437980651855, 0.14167408645153046, 0.1007450520992279, 0.22688239812850952, 0.1372402310371399, 0.10264142602682114, 0.13005568087100983, 0.12591823935508728, 0.14579129219055176, 0.17318738996982574, 0.1886143982410431, 0.10187918692827225, 0.12797997891902924, 0.17584607005119324, 0.18873123824596405, 0.24070532619953156, 0.12369873374700546, 0.19646187126636505, 0.12397554516792297, 0.1945258229970932, 0.22093889117240906, 0.17058074474334717, 0.22560223937034607, 0.13440823554992676, 0.10180719196796417, 0.2075193226337433, 0.14069600403308868, 0.2509630620479584, 0.17896118760108948, 0.18547216057777405, 0.11445116996765137, 0.15648294985294342, 0.16105841100215912, 0.278189092874527, 0.19819651544094086, 0.1546851396560669, 0.14618456363677979, 0.1741165667772293, 0.12887203693389893, 0.14201472699642181, 0.15877175331115723, 0.2255173623561859, 0.10625269263982773, 0.21550579369068146, 0.15338577330112457, 0.2207246720790863, 0.15102940797805786, 0.14919403195381165, 0.2166910171508789, 0.2548471689224243, 0.26723405718803406, 0.14400503039360046, 0.12920646369457245]\n",
            "Val loss 0.16746534947760222\n",
            "Val auc roc 0.4958122657997511\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "794e3d8a7baa44cda684d99375305c2b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2656.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1661\n",
            "Train Losses : [0.1469523161649704, 0.19223061203956604, 0.13578678667545319, 0.12483471632003784, 0.20469553768634796, 0.14543059468269348, 0.12903296947479248, 0.2253483533859253, 0.20186427235603333, 0.14235906302928925, 0.13720065355300903, 0.11571120470762253, 0.20711404085159302, 0.11588021367788315, 0.15091173350811005, 0.15510059893131256, 0.13325166702270508, 0.11586035788059235, 0.15790842473506927, 0.13110662996768951, 0.13820791244506836, 0.22573529183864594, 0.130761057138443, 0.21142618358135223, 0.22952719032764435, 0.12250157445669174, 0.2558504045009613, 0.16839668154716492, 0.15270093083381653, 0.1645243763923645, 0.139680415391922, 0.158225879073143, 0.12725304067134857, 0.18117183446884155, 0.15465883910655975, 0.16013169288635254, 0.22025370597839355, 0.11920425295829773, 0.22709566354751587, 0.12459614872932434, 0.18752717971801758, 0.2341853380203247, 0.21239154040813446, 0.12596556544303894, 0.21553632616996765, 0.20606698095798492, 0.14338800311088562, 0.15865083038806915, 0.16546648740768433, 0.11768724024295807, 0.18615813553333282, 0.18679232895374298, 0.16639474034309387, 0.1647402048110962, 0.23423901200294495, 0.15121351182460785, 0.11394213885068893, 0.15467751026153564, 0.11868388950824738, 0.15148253738880157, 0.11722198128700256, 0.19250036776065826, 0.17695832252502441, 0.19104310870170593, 0.21291153132915497, 0.16955693066120148, 0.12244067341089249, 0.15578894317150116, 0.15956243872642517, 0.1161637082695961, 0.15892143547534943, 0.17845816910266876, 0.20821617543697357, 0.13039883971214294, 0.21641485393047333, 0.1712227761745453, 0.1292244791984558, 0.21200188994407654, 0.2084977775812149, 0.15234649181365967, 0.2109164446592331, 0.19218479096889496, 0.11552694439888, 0.11524102836847305, 0.11646920442581177, 0.1353757232427597, 0.15343785285949707, 0.11416458338499069, 0.17095991969108582, 0.14773638546466827, 0.11216802150011063, 0.1115158200263977, 0.12652751803398132, 0.1099407821893692, 0.18364840745925903, 0.1775309294462204, 0.16555523872375488, 0.10658111423254013, 0.16230963170528412, 0.15676113963127136, 0.2272910177707672, 0.13611586391925812, 0.12514540553092957, 0.23423202335834503, 0.2788151204586029, 0.1762372851371765, 0.1564965546131134, 0.19689466059207916, 0.10481381416320801, 0.1668909341096878, 0.1793447732925415, 0.18429726362228394, 0.13672204315662384, 0.19766832888126373, 0.15022706985473633, 0.1823480874300003, 0.13213291764259338, 0.14852766692638397, 0.1385086476802826, 0.23264674842357635, 0.14120936393737793, 0.12463685870170593, 0.13558124005794525, 0.15940092504024506, 0.15899595618247986, 0.10635773092508316, 0.17363637685775757, 0.16268418729305267, 0.1323246955871582, 0.11425307393074036, 0.1439853012561798, 0.13295519351959229, 0.2214784324169159, 0.1732562929391861, 0.11627937108278275, 0.16586194932460785, 0.1725856214761734, 0.18923531472682953, 0.152250275015831, 0.2753259539604187, 0.16101184487342834, 0.21309894323349, 0.13422349095344543, 0.1007169559597969, 0.1551370918750763, 0.24564749002456665, 0.13219943642616272, 0.28562241792678833, 0.12245451658964157, 0.28873923420906067, 0.10119886696338654, 0.18761597573757172, 0.10420814901590347, 0.15528371930122375, 0.11819108575582504, 0.13272790610790253, 0.18950757384300232, 0.12913617491722107, 0.1112862378358841, 0.14891698956489563, 0.1329188197851181, 0.13404454290866852, 0.12922725081443787, 0.14480262994766235, 0.13218656182289124, 0.133486807346344, 0.13360828161239624, 0.1560279279947281, 0.14609144628047943, 0.15911035239696503, 0.12092963606119156, 0.09281079471111298, 0.18586879968643188, 0.30593499541282654, 0.12917843461036682, 0.09120958298444748, 0.13071341812610626, 0.25248271226882935, 0.15319915115833282, 0.23792462050914764, 0.17474889755249023, 0.09088234603404999, 0.18275736272335052, 0.09072016924619675, 0.1349242776632309, 0.11063109338283539, 0.169769749045372, 0.1644725352525711, 0.312486469745636, 0.3126660883426666, 0.13144288957118988, 0.13281945884227753, 0.13904725015163422, 0.09364578127861023, 0.18433262407779694, 0.12490584701299667, 0.236162930727005, 0.16083523631095886, 0.20093609392642975, 0.15112444758415222, 0.1449609398841858, 0.09392158687114716, 0.14162057638168335, 0.187139630317688, 0.20009082555770874, 0.24093230068683624, 0.1452666074037552, 0.12646298110485077, 0.14419445395469666, 0.14371740818023682, 0.12383314222097397, 0.24173913896083832, 0.16996218264102936, 0.15724937617778778, 0.17482821643352509, 0.09681840986013412, 0.20620226860046387, 0.22188697755336761, 0.2939344644546509, 0.1575775146484375, 0.2000674307346344, 0.0996938943862915, 0.09816745668649673, 0.22044266760349274, 0.17016348242759705, 0.1269645094871521, 0.17224106192588806, 0.18378955125808716, 0.15171487629413605, 0.1301778256893158, 0.17647196352481842, 0.28607437014579773, 0.20134881138801575, 0.1013011559844017, 0.17658263444900513, 0.18393388390541077, 0.10275118052959442, 0.10172834992408752, 0.18361403048038483, 0.18906792998313904, 0.15951862931251526, 0.15235060453414917, 0.24270355701446533, 0.2674826383590698, 0.14314065873622894, 0.15047088265419006, 0.10270076245069504, 0.11366742849349976, 0.14063546061515808, 0.12451878935098648, 0.22689320147037506, 0.14542891085147858, 0.14497414231300354, 0.10182469338178635, 0.10249548405408859, 0.13171623647212982, 0.18383830785751343, 0.2392796277999878, 0.1337081342935562, 0.11616335064172745, 0.2050577700138092, 0.16356965899467468, 0.21915572881698608, 0.12610094249248505, 0.11084870249032974, 0.24789319932460785, 0.19149520993232727, 0.1393517404794693, 0.17680935561656952, 0.1498900204896927, 0.1688828468322754, 0.18857625126838684, 0.1554557979106903, 0.24484513700008392, 0.1437043696641922, 0.14017783105373383, 0.13494990766048431, 0.11587060987949371, 0.16409413516521454, 0.18152882158756256, 0.15728867053985596, 0.10040581226348877, 0.10031299293041229, 0.15511305630207062, 0.15884800255298615, 0.19892239570617676, 0.09864649176597595, 0.13140477240085602, 0.09807746857404709, 0.22601570188999176, 0.18544791638851166, 0.096537284553051, 0.17349204421043396, 0.26979419589042664, 0.25864678621292114, 0.2337961047887802, 0.24874639511108398, 0.1610502153635025, 0.2092953473329544, 0.09920495748519897, 0.19449573755264282, 0.21528008580207825, 0.28320127725601196, 0.23255448043346405, 0.1736714392900467, 0.10478460043668747, 0.15769650042057037, 0.13561470806598663, 0.13391080498695374, 0.15321558713912964, 0.14594624936580658, 0.1543494462966919, 0.12513050436973572, 0.15712767839431763, 0.11364182084798813, 0.19311273097991943, 0.1625933051109314, 0.10712103545665741, 0.14299461245536804, 0.10593646764755249, 0.10614821314811707, 0.16668401658535004, 0.13228580355644226, 0.2110084742307663, 0.1851760745048523, 0.27961474657058716, 0.1032104641199112, 0.14357684552669525, 0.13287712633609772, 0.20559801161289215, 0.25345510244369507, 0.2263958752155304, 0.1369807869195938, 0.23159313201904297, 0.17092980444431305, 0.17992569506168365, 0.1448749452829361, 0.14539335668087006, 0.1394643783569336, 0.15637320280075073, 0.22587043046951294, 0.14678803086280823, 0.18166926503181458, 0.12517397105693817, 0.26130661368370056, 0.18488407135009766, 0.19282729923725128, 0.13701769709587097, 0.19152353703975677, 0.13404160737991333, 0.14149127900600433, 0.24118712544441223, 0.1414606273174286, 0.2087194323539734, 0.24821798503398895, 0.1455494463443756, 0.13661712408065796, 0.20218868553638458, 0.14907017350196838, 0.10937689244747162, 0.2688722014427185, 0.17165687680244446, 0.12613224983215332, 0.12390797585248947, 0.10840315371751785, 0.2149229347705841, 0.1521141529083252, 0.1493535339832306, 0.19787493348121643, 0.2677191197872162, 0.10841131210327148, 0.16674338281154633, 0.20998643338680267, 0.22601839900016785, 0.14989234507083893, 0.10940326005220413, 0.1613623946905136, 0.1752297282218933, 0.19991008937358856, 0.11676476895809174, 0.12268184125423431, 0.15467901527881622, 0.1416255384683609, 0.20783543586730957, 0.16222414374351501, 0.14775517582893372, 0.26877087354660034, 0.15630783140659332, 0.16619151830673218, 0.15903082489967346, 0.2329300045967102, 0.14499551057815552, 0.17257043719291687, 0.12812715768814087, 0.23540617525577545, 0.18256676197052002, 0.2649337947368622, 0.23128613829612732, 0.2056800276041031, 0.21191169321537018, 0.1640271246433258, 0.19987988471984863, 0.20716364681720734, 0.13336725533008575, 0.14303012192249298, 0.18758268654346466, 0.2005823850631714, 0.15032197535037994, 0.18742160499095917, 0.1418287605047226, 0.2446768581867218, 0.17650116980075836, 0.14737959206104279, 0.18592169880867004, 0.17912156879901886, 0.17162010073661804, 0.18443579971790314, 0.22305521368980408, 0.21779614686965942, 0.1259104460477829, 0.15555866062641144, 0.18181730806827545, 0.1587880402803421, 0.15838943421840668, 0.20191779732704163, 0.22066140174865723, 0.15212714672088623, 0.19567379355430603, 0.20318001508712769, 0.21040324866771698, 0.21494537591934204, 0.18123795092105865, 0.1516895294189453, 0.15629005432128906, 0.133183553814888, 0.18805058300495148, 0.17225714027881622, 0.14135926961898804, 0.14634279906749725, 0.16704896092414856, 0.16525337100028992, 0.18281115591526031, 0.13410861790180206, 0.16677062213420868, 0.1863158643245697, 0.17087405920028687, 0.21502715349197388, 0.13211901485919952, 0.13963477313518524, 0.14614073932170868, 0.1510600447654724, 0.14846302568912506, 0.15225104987621307, 0.14350993931293488, 0.1835077404975891, 0.12995851039886475, 0.16083723306655884, 0.12964943051338196, 0.19805674254894257, 0.19201214611530304, 0.2335149198770523, 0.16666863858699799, 0.23109500110149384, 0.14670898020267487, 0.13654419779777527, 0.18298183381557465, 0.139461487531662, 0.158289834856987, 0.168020099401474, 0.14779093861579895, 0.18562628328800201, 0.16418728232383728, 0.21993952989578247, 0.15183992683887482, 0.1257900595664978, 0.12521231174468994, 0.2438909113407135, 0.16785262525081635, 0.15184590220451355, 0.14957848191261292, 0.18410955369472504, 0.14712221920490265, 0.19758492708206177, 0.12405277043581009, 0.127873957157135, 0.19792021811008453, 0.14191576838493347, 0.1553548127412796, 0.18283461034297943, 0.18276704847812653, 0.1593172699213028, 0.16409820318222046, 0.11990410834550858, 0.1619858294725418, 0.1741526871919632, 0.14390356838703156, 0.17105422914028168, 0.1367289125919342, 0.16169336438179016, 0.11789309978485107, 0.13203026354312897, 0.2209094613790512, 0.1780538260936737, 0.19416269659996033, 0.1524374783039093, 0.20429104566574097, 0.11505239456892014, 0.15239714086055756, 0.1598675549030304, 0.1777891367673874, 0.16245879232883453, 0.13624414801597595, 0.1416730284690857, 0.1129024550318718, 0.1352233588695526, 0.17377285659313202, 0.15774080157279968, 0.1621944159269333, 0.14677591621875763, 0.17527537047863007, 0.17202427983283997, 0.12495395541191101, 0.10831830650568008, 0.1234816387295723, 0.15228360891342163, 0.17814017832279205, 0.1429562121629715, 0.2707504332065582, 0.12292810529470444, 0.1897750198841095, 0.26774927973747253, 0.15034887194633484, 0.10765588283538818, 0.12430111318826675, 0.17111189663410187, 0.1508040428161621, 0.21117235720157623, 0.1736479252576828, 0.11355288326740265, 0.16028742492198944, 0.15167202055454254, 0.1685796082019806, 0.20084315538406372, 0.15847763419151306, 0.1813814342021942, 0.13769781589508057, 0.1693434864282608, 0.2554609775543213, 0.10796623677015305, 0.21716852486133575, 0.1978200078010559, 0.16067256033420563, 0.19267070293426514, 0.14091962575912476, 0.13038547337055206, 0.2047642320394516, 0.11017978191375732, 0.1718386858701706, 0.14166463911533356, 0.1089436262845993, 0.15286009013652802, 0.16868866980075836, 0.13386432826519012, 0.10836175084114075, 0.12303496897220612, 0.10562773048877716, 0.13362544775009155, 0.1522962599992752, 0.1835595816373825, 0.1026049330830574, 0.17640653252601624, 0.1618576943874359, 0.13979662954807281, 0.13412782549858093, 0.13622501492500305, 0.09792733192443848, 0.2147424817085266, 0.17633551359176636, 0.21032610535621643, 0.1906217634677887, 0.09471134841442108, 0.1777014434337616, 0.14662668108940125, 0.1627405881881714, 0.18436114490032196, 0.3047657608985901, 0.14119897782802582, 0.16102877259254456, 0.09234660118818283, 0.23760885000228882, 0.09173987805843353, 0.18206512928009033, 0.1404317319393158, 0.23614904284477234, 0.21331150829792023, 0.09197921305894852, 0.24340412020683289, 0.271696001291275, 0.2334524244070053, 0.25142109394073486, 0.18335957825183868, 0.0956788882613182, 0.12283273041248322, 0.20100519061088562, 0.12707696855068207, 0.2043902575969696, 0.16704349219799042, 0.13298429548740387, 0.1652892827987671, 0.1810717135667801, 0.16266727447509766, 0.23414146900177002, 0.14001740515232086, 0.2856944501399994, 0.13038022816181183, 0.20611688494682312, 0.2204923778772354, 0.14606697857379913, 0.18131627142429352, 0.1029147207736969, 0.14220458269119263, 0.13704684376716614, 0.2763560712337494, 0.21885505318641663, 0.14260222017765045, 0.21820366382598877, 0.13898597657680511, 0.14828705787658691, 0.144590824842453, 0.14687375724315643, 0.22557266056537628, 0.14335188269615173, 0.10650905221700668, 0.1993045061826706, 0.1910420060157776, 0.17830707132816315, 0.12778164446353912, 0.1354949176311493, 0.13857832551002502, 0.18729268014431, 0.141823410987854, 0.12487165629863739, 0.16380976140499115, 0.2216387242078781, 0.18880760669708252, 0.21677763760089874, 0.19491003453731537, 0.1438053995370865, 0.1859147697687149, 0.16410258412361145, 0.1278422772884369, 0.1468544900417328, 0.15681393444538116, 0.20073963701725006, 0.10565687716007233, 0.21207493543624878, 0.13725709915161133, 0.19785401225090027, 0.15230897068977356, 0.12672196328639984, 0.1833435297012329, 0.15331512689590454, 0.20754283666610718, 0.16515801846981049, 0.2771803140640259, 0.14727430045604706, 0.2387574315071106, 0.1375139057636261, 0.22496169805526733, 0.15189528465270996, 0.20674669742584229, 0.16001412272453308, 0.14551396667957306, 0.1968410760164261, 0.1405782699584961, 0.12474965304136276, 0.2184118777513504, 0.17626677453517914, 0.1780879646539688, 0.15472668409347534, 0.1543726623058319, 0.2666027247905731, 0.17002840340137482, 0.23048599064350128, 0.18438780307769775, 0.11036946624517441, 0.11023691296577454, 0.1521674543619156, 0.2377619743347168, 0.11081314086914062, 0.18752238154411316, 0.14659887552261353, 0.1112009733915329, 0.1513984650373459, 0.11110448837280273, 0.11043044924736023, 0.23001261055469513, 0.1386202871799469, 0.2119320183992386, 0.22395940124988556, 0.10963990539312363, 0.16157539188861847, 0.16904328763484955, 0.14907900989055634, 0.21539092063903809, 0.13425248861312866, 0.18181262910366058, 0.15780234336853027, 0.1376694142818451, 0.18660730123519897, 0.12363699823617935, 0.1977846771478653, 0.1492975652217865, 0.15880031883716583, 0.10843376815319061, 0.18321508169174194, 0.2203340083360672, 0.17640525102615356, 0.10831566900014877, 0.15649114549160004, 0.16367235779762268, 0.1289796233177185, 0.15023858845233917, 0.13762110471725464, 0.16309088468551636, 0.136156365275383, 0.14578162133693695, 0.14719800651073456, 0.15306447446346283, 0.1895042359828949, 0.19413107633590698, 0.17282196879386902, 0.1279253363609314, 0.20087486505508423, 0.1989475041627884, 0.14345192909240723, 0.12063663452863693, 0.10093557089567184, 0.14446650445461273, 0.13321945071220398, 0.182378351688385, 0.17479386925697327, 0.16775399446487427, 0.17989978194236755, 0.1927640587091446, 0.15614376962184906, 0.20257987082004547, 0.16565896570682526, 0.25398480892181396, 0.12211555987596512, 0.22310160100460052, 0.14748260378837585, 0.09970343112945557, 0.22891157865524292, 0.12715831398963928, 0.15073835849761963, 0.1388852745294571, 0.17631469666957855, 0.1347409039735794, 0.1732703000307083, 0.09991687536239624, 0.13398703932762146, 0.09970613569021225, 0.09855134785175323, 0.17171597480773926, 0.1781236231327057, 0.09714732319116592, 0.2243034541606903, 0.14733640849590302, 0.18323811888694763, 0.18812590837478638, 0.15483160316944122, 0.1337902545928955, 0.20388832688331604, 0.09466735273599625, 0.12616680562496185, 0.29883548617362976, 0.12806016206741333, 0.17591097950935364, 0.09372277557849884, 0.11320040374994278, 0.20108090341091156, 0.18004092574119568, 0.1795753538608551, 0.2316884547472, 0.27773720026016235, 0.11292356252670288, 0.12051181495189667, 0.09506884962320328, 0.12469309568405151, 0.12217237800359726, 0.1767343282699585, 0.1819186955690384, 0.13368293642997742, 0.09415936470031738, 0.09371241182088852, 0.1369200497865677, 0.17541275918483734, 0.26356300711631775, 0.1454540640115738, 0.21379004418849945, 0.09203758835792542, 0.09139268845319748, 0.18488311767578125, 0.14110945165157318, 0.2245853990316391, 0.12152349948883057, 0.19962142407894135, 0.21821977198123932, 0.13415376842021942, 0.2666986882686615, 0.2017926573753357, 0.17494313418865204, 0.23608960211277008, 0.09139968454837799, 0.1380125880241394, 0.1839173436164856, 0.09117694944143295, 0.19776450097560883, 0.12649321556091309, 0.16900788247585297, 0.1328408420085907, 0.2558804154396057, 0.09127531945705414, 0.2417839914560318, 0.22959652543067932, 0.1477874368429184, 0.17176301777362823, 0.13812308013439178, 0.23010718822479248, 0.14214186370372772, 0.11330733448266983, 0.0934714525938034, 0.29856953024864197, 0.16832581162452698, 0.18213771283626556, 0.2551073133945465, 0.17180193960666656, 0.19831553101539612, 0.20040127635002136, 0.16521696746349335, 0.20095300674438477, 0.22536325454711914, 0.15573418140411377, 0.23745837807655334, 0.19272048771381378, 0.24978961050510406, 0.1878928393125534, 0.14548327028751373, 0.256259948015213, 0.10439996421337128, 0.18667732179164886, 0.2131870985031128, 0.10625895857810974, 0.16519878804683685, 0.10699007660150528, 0.14161063730716705, 0.2683663070201874, 0.1410880833864212, 0.1342725306749344, 0.15977324545383453, 0.178111732006073, 0.18256843090057373, 0.18578656017780304, 0.10900169610977173, 0.18435649573802948, 0.18032345175743103, 0.21130876243114471, 0.18067222833633423, 0.1493552327156067, 0.1672244668006897, 0.11029787361621857, 0.15640339255332947, 0.17344878613948822, 0.1517159789800644, 0.1099969893693924, 0.12564127147197723, 0.21080927550792694, 0.16823120415210724, 0.1633201390504837, 0.1751800775527954, 0.14672033488750458, 0.14676719903945923, 0.19039089977741241, 0.13812677562236786, 0.17123180627822876, 0.10842939466238022, 0.1692076027393341, 0.21393465995788574, 0.22772924602031708, 0.16720300912857056, 0.18821249902248383, 0.23171335458755493, 0.13814817368984222, 0.16786068677902222, 0.10894465446472168, 0.22272729873657227, 0.1456129103899002, 0.23791584372520447, 0.10934942215681076, 0.15468749403953552, 0.14683467149734497, 0.18801431357860565, 0.14906243979930878, 0.17198291420936584, 0.15252946317195892, 0.1856991946697235, 0.19351734220981598, 0.13520081341266632, 0.19526390731334686, 0.14247111976146698, 0.1282239854335785, 0.21888799965381622, 0.10889153927564621, 0.22398854792118073, 0.1272532194852829, 0.15839043259620667, 0.1371416598558426, 0.17214763164520264, 0.15703564882278442, 0.1748531609773636, 0.16471624374389648, 0.24507303535938263, 0.1672174632549286, 0.18815968930721283, 0.10934647917747498, 0.264291375875473, 0.20317073166370392, 0.22065840661525726, 0.21079836785793304, 0.20644479990005493, 0.19994015991687775, 0.1542167067527771, 0.2352098524570465, 0.14334197342395782, 0.16055752336978912, 0.1878533512353897, 0.11564238369464874, 0.11639618873596191, 0.15496404469013214, 0.14278776943683624, 0.11594513803720474, 0.22001881897449493, 0.14434239268302917, 0.1332409530878067, 0.16104328632354736, 0.1307218223810196, 0.19155167043209076, 0.14751891791820526, 0.1523696631193161, 0.1438119113445282, 0.254733145236969, 0.17915435135364532, 0.13386783003807068, 0.14121121168136597, 0.14002305269241333, 0.13971099257469177, 0.12908291816711426, 0.1169365793466568, 0.15306930243968964, 0.16206614673137665, 0.15642553567886353, 0.19308742880821228, 0.17538833618164062, 0.19880987703800201, 0.1422644853591919, 0.13347157835960388, 0.19997772574424744, 0.1744249165058136, 0.2607213258743286, 0.1751500517129898, 0.14273999631404877, 0.15936681628227234, 0.17094498872756958, 0.23126830160617828, 0.15047301352024078, 0.11391130089759827, 0.14940610527992249, 0.15820527076721191, 0.21852906048297882, 0.15197215974330902, 0.13839097321033478, 0.182595357298851, 0.1346026062965393, 0.17475971579551697, 0.15334552526474, 0.17348545789718628, 0.11170860379934311, 0.14207451045513153, 0.21414263546466827, 0.18437281250953674, 0.12591767311096191, 0.18792100250720978, 0.11063538491725922, 0.1311418116092682, 0.18045252561569214, 0.24622124433517456, 0.157807394862175, 0.20680803060531616, 0.2642871141433716, 0.17089152336120605, 0.1103656068444252, 0.16550102829933167, 0.11078139394521713, 0.16572712361812592, 0.1978842318058014, 0.17709524929523468, 0.1826261729001999, 0.2036333978176117, 0.15865793824195862, 0.18963554501533508, 0.1605616956949234, 0.16430886089801788, 0.1972094625234604, 0.22825540602207184, 0.1492362916469574, 0.21440398693084717, 0.15855082869529724, 0.18428856134414673, 0.19902968406677246, 0.11426610499620438, 0.22499674558639526, 0.11489187926054001, 0.15677668154239655, 0.16271458566188812, 0.1819506287574768, 0.11388494074344635, 0.1977381855249405, 0.16873255372047424, 0.154802143573761, 0.1134667620062828, 0.11282172054052353, 0.16317468881607056, 0.1384943425655365, 0.11160358041524887, 0.16203486919403076, 0.1737588793039322, 0.14568482339382172, 0.13319140672683716, 0.17535501718521118, 0.10805417597293854, 0.17936742305755615, 0.1501363217830658, 0.1701819747686386, 0.15000677108764648, 0.1664290726184845, 0.1747743934392929, 0.27592235803604126, 0.17316515743732452, 0.10388341546058655, 0.2379857897758484, 0.12527646124362946, 0.1329272836446762, 0.12663190066814423, 0.18620291352272034, 0.10334429889917374, 0.10365498811006546, 0.1845548450946808, 0.1346869319677353, 0.16304375231266022, 0.20552770793437958, 0.14377042651176453, 0.18943443894386292, 0.13710032403469086, 0.1519559919834137, 0.10064958035945892, 0.1431499719619751, 0.19111788272857666, 0.09857706725597382, 0.09820160269737244, 0.13427042961120605, 0.13123223185539246, 0.09660493582487106, 0.22822371125221252, 0.18906132876873016, 0.16698190569877625, 0.21197792887687683, 0.14181794226169586, 0.14899294078350067, 0.09310804307460785, 0.130211740732193, 0.25203996896743774, 0.14736974239349365, 0.23059719800949097, 0.17858022451400757, 0.18534404039382935, 0.2487105429172516, 0.13404329121112823, 0.19195382297039032, 0.3030751049518585, 0.20705930888652802, 0.16350463032722473, 0.0942368283867836, 0.23667651414871216, 0.09496614336967468, 0.24529750645160675, 0.1698695719242096, 0.09668497741222382, 0.184156134724617, 0.1383313536643982, 0.17158570885658264, 0.14266853034496307, 0.18920940160751343, 0.09774753451347351, 0.1272156834602356, 0.1315603256225586, 0.14779789745807648, 0.29063934087753296, 0.17888128757476807, 0.09756436944007874, 0.25287920236587524, 0.18409335613250732, 0.12179556488990784, 0.14842550456523895, 0.1748390793800354, 0.28814682364463806, 0.23780524730682373, 0.24560454487800598, 0.19230881333351135, 0.28209415078163147, 0.10182332247495651, 0.18254774808883667, 0.146169975399971, 0.1547708809375763, 0.17704419791698456, 0.2322951853275299, 0.22345677018165588, 0.13013547658920288, 0.1259060502052307, 0.23579174280166626, 0.14054721593856812, 0.175254687666893, 0.22083280980587006, 0.13313175737857819, 0.22743342816829681, 0.16035324335098267, 0.16946570575237274, 0.1690070927143097, 0.1422499716281891, 0.14171992242336273, 0.1469568908214569, 0.14493702352046967, 0.19418619573116302, 0.18078024685382843, 0.13301678001880646, 0.17860281467437744, 0.14064162969589233, 0.24300168454647064, 0.18686363101005554, 0.13955409824848175, 0.1510670781135559, 0.1820235401391983, 0.1345680058002472, 0.14376309514045715, 0.184006005525589, 0.2162914127111435, 0.11158682405948639, 0.16305994987487793, 0.15964463353157043, 0.19079412519931793, 0.13796815276145935, 0.21234959363937378, 0.22241699695587158, 0.17675460875034332, 0.18546578288078308, 0.12686438858509064, 0.11227485537528992, 0.18998005986213684, 0.18815197050571442, 0.14315950870513916, 0.11221998929977417, 0.1890144795179367, 0.15075112879276276, 0.18179185688495636, 0.21997907757759094, 0.22009344398975372, 0.18601176142692566, 0.12980027496814728, 0.22335916757583618, 0.16580696403980255, 0.1635185182094574, 0.16951240599155426, 0.16708628833293915, 0.11341714859008789, 0.15495231747627258, 0.14756518602371216, 0.1426883041858673, 0.19302065670490265, 0.11254430562257767, 0.1125277429819107, 0.25843554735183716, 0.14966513216495514, 0.19504867494106293, 0.13180048763751984, 0.20164133608341217, 0.1436348259449005, 0.14379210770130157, 0.15098612010478973, 0.14374947547912598, 0.15064463019371033, 0.11056186258792877, 0.13786952197551727, 0.14704620838165283, 0.13931122422218323, 0.18537521362304688, 0.1084357500076294, 0.12913759052753448, 0.10719684511423111, 0.22851695120334625, 0.13528084754943848, 0.15326324105262756, 0.16248206794261932, 0.1046842634677887, 0.12745265662670135, 0.13334748148918152, 0.134972482919693, 0.13920696079730988, 0.13156293332576752, 0.1441550999879837, 0.13892818987369537, 0.13032189011573792, 0.14564232528209686, 0.17507629096508026, 0.19203698635101318, 0.18837660551071167, 0.09702133387327194, 0.24382862448692322, 0.14831548929214478, 0.20369449257850647, 0.15404188632965088, 0.18010704219341278, 0.1850576102733612, 0.14975892007350922, 0.1923963874578476, 0.187431201338768, 0.12314005196094513, 0.1714683324098587, 0.12751449644565582, 0.13569073379039764, 0.18904724717140198, 0.13170424103736877, 0.1617056131362915, 0.2092709243297577, 0.15008635818958282, 0.22027307748794556, 0.2297428846359253, 0.25032737851142883, 0.1326810121536255, 0.1377524733543396, 0.17884443700313568, 0.196999654173851, 0.1965664178133011, 0.13818389177322388, 0.1305551826953888, 0.13546694815158844, 0.14128535985946655, 0.2502148449420929, 0.14235179126262665, 0.17663337290287018, 0.22030597925186157, 0.09681712836027145, 0.1684139370918274, 0.17394843697547913, 0.24146808683872223, 0.12782606482505798, 0.18981081247329712, 0.24071604013442993, 0.11775466799736023, 0.15196286141872406, 0.14052173495292664, 0.13235752284526825, 0.1363089382648468, 0.09884092211723328, 0.09865830093622208, 0.15524588525295258, 0.13851234316825867, 0.13484743237495422, 0.12865178287029266, 0.11998171359300613, 0.13582733273506165, 0.17767693102359772, 0.19487790763378143, 0.19144892692565918, 0.1692526936531067, 0.19733887910842896, 0.13968081772327423, 0.18279266357421875, 0.13787662982940674, 0.1269942969083786, 0.18517808616161346, 0.13896292448043823, 0.13020002841949463, 0.09233276546001434, 0.20370101928710938, 0.18658079206943512, 0.13299021124839783, 0.13943807780742645, 0.17564502358436584, 0.25864994525909424, 0.1762254238128662, 0.3079613149166107, 0.12677569687366486, 0.12151575088500977, 0.13277235627174377, 0.21810799837112427, 0.13996978104114532, 0.1736612468957901, 0.17327120900154114, 0.14442503452301025, 0.18427884578704834, 0.1254165917634964, 0.19020499289035797, 0.2247951179742813, 0.25386515259742737, 0.09402800351381302, 0.24450013041496277, 0.13883277773857117, 0.09505536407232285, 0.22691604495048523, 0.09542692452669144, 0.12764698266983032, 0.187247171998024, 0.18947166204452515, 0.16609914600849152, 0.2348128706216812, 0.09641795605421066, 0.14286550879478455, 0.16913393139839172, 0.173683762550354, 0.13338637351989746, 0.1405337005853653, 0.09674285352230072, 0.232192724943161, 0.197520449757576, 0.2425021529197693, 0.19119969010353088, 0.24273644387722015, 0.17171739041805267, 0.22899554669857025, 0.18433722853660583, 0.2157319039106369, 0.21116480231285095, 0.1362965852022171, 0.1898898482322693, 0.127059668302536, 0.22916854918003082, 0.12463867664337158, 0.10296516865491867, 0.2183951586484909, 0.22142378985881805, 0.1822991818189621, 0.13107901811599731, 0.1514025777578354, 0.13983792066574097, 0.17778971791267395, 0.18353353440761566, 0.19675305485725403, 0.1456325650215149, 0.13868820667266846, 0.2055777907371521, 0.10630179941654205, 0.10651268064975739, 0.17903614044189453, 0.18752330541610718, 0.16588030755519867, 0.22245635092258453, 0.1580599695444107, 0.14578810334205627, 0.1754884123802185, 0.15844525396823883, 0.10674164444208145, 0.1543348878622055, 0.12644922733306885, 0.17446576058864594, 0.1382426619529724, 0.13465970754623413, 0.14119546115398407, 0.22753436863422394, 0.14331458508968353, 0.17202937602996826, 0.18343879282474518, 0.1475059539079666, 0.191936656832695, 0.2228648066520691, 0.19327591359615326, 0.10392798483371735, 0.10380508005619049, 0.17859967052936554, 0.15537302196025848, 0.10301496833562851, 0.1479065865278244, 0.17897546291351318, 0.1243593841791153, 0.1364111751317978, 0.10131088644266129, 0.10077288746833801, 0.172893226146698, 0.16464588046073914, 0.099507175385952, 0.23772092163562775, 0.17788948118686676, 0.1432076096534729, 0.1224721297621727, 0.12617020308971405, 0.097391776740551, 0.18378210067749023, 0.19906391203403473, 0.23201878368854523, 0.1804877668619156, 0.17319513857364655, 0.16256184875965118, 0.1762278527021408, 0.18762654066085815, 0.15588326752185822, 0.18750324845314026, 0.09630195796489716, 0.1328069418668747, 0.18139737844467163, 0.18598735332489014, 0.19191540777683258, 0.22947239875793457, 0.21564336121082306, 0.12219875305891037, 0.19350525736808777, 0.17967559397220612, 0.20939218997955322, 0.13674302399158478, 0.12408750504255295, 0.09808702021837234, 0.18742580711841583, 0.2329254299402237, 0.17249467968940735, 0.09863214939832687, 0.17443135380744934, 0.24827544391155243, 0.09909916669130325, 0.15154118835926056, 0.09885641932487488, 0.16985048353672028, 0.13194511830806732, 0.14079473912715912, 0.1478375643491745, 0.13692022860050201, 0.1408311277627945, 0.23651523888111115, 0.15192534029483795, 0.260726660490036, 0.14661844074726105, 0.121430903673172, 0.13736064732074738, 0.18731753528118134, 0.1401253491640091, 0.16976946592330933, 0.1870269775390625, 0.12244930118322372, 0.1479891538619995, 0.09573958069086075, 0.17102207243442535, 0.23921066522598267, 0.17973031103610992, 0.18825483322143555, 0.13275207579135895, 0.18575294315814972, 0.133199542760849, 0.14413663744926453, 0.1811254322528839, 0.16997233033180237, 0.13910193741321564, 0.14378395676612854, 0.13170938193798065, 0.1827836036682129, 0.17890605330467224, 0.1379583477973938, 0.14627383649349213, 0.09381576627492905, 0.09328529983758926, 0.17155222594738007, 0.1544710248708725, 0.2220858931541443, 0.13991133868694305, 0.13089120388031006, 0.09116971492767334, 0.22640779614448547, 0.16677457094192505, 0.13330644369125366, 0.24718447029590607, 0.13270659744739532, 0.23781290650367737, 0.2534683346748352, 0.0908493921160698, 0.09115616977214813, 0.18242135643959045, 0.16765828430652618, 0.23755094408988953, 0.24484339356422424, 0.3024582862854004, 0.2557106614112854, 0.18975478410720825, 0.1386423259973526, 0.14800597727298737, 0.24944192171096802, 0.13654088973999023, 0.20375381410121918, 0.22950425744056702, 0.16934235394001007, 0.1347121149301529, 0.2537841796875, 0.24390415847301483, 0.1415526568889618, 0.18198876082897186, 0.12784527242183685, 0.13308009505271912, 0.14664827287197113, 0.1228664219379425, 0.18716803193092346, 0.10359333455562592, 0.24125511944293976, 0.27675527334213257, 0.10440193116664886, 0.20492886006832123, 0.16550570726394653, 0.1290142983198166, 0.22146077454090118, 0.14293794333934784, 0.13954663276672363, 0.16200174391269684, 0.1999267339706421, 0.14302489161491394, 0.13270032405853271, 0.15201148390769958, 0.13803431391716003, 0.19781789183616638, 0.22875210642814636, 0.2085164338350296, 0.10719817876815796, 0.13606992363929749, 0.2676675319671631, 0.10763442516326904, 0.2669404447078705, 0.16896915435791016, 0.23119811713695526, 0.20756903290748596, 0.1382836550474167, 0.1875251680612564, 0.1997406929731369, 0.13774417340755463, 0.11225322633981705, 0.22871173918247223, 0.2254513055086136, 0.14871841669082642, 0.20418621599674225, 0.11384996026754379, 0.19561374187469482, 0.22996552288532257, 0.13830254971981049, 0.14724397659301758, 0.13424144685268402, 0.21772952377796173, 0.18024995923042297, 0.2193021923303604, 0.19759848713874817, 0.18064400553703308, 0.11681318283081055, 0.18749859929084778, 0.16895830631256104, 0.14226162433624268, 0.1375373899936676, 0.11677905917167664, 0.18999703228473663, 0.15342886745929718, 0.20665283501148224, 0.180754154920578, 0.17045830190181732, 0.11641979962587357, 0.13475126028060913, 0.17797604203224182, 0.11598032712936401, 0.11549992859363556, 0.21148206293582916, 0.11484510451555252, 0.11448753625154495, 0.11434094607830048, 0.16730764508247375, 0.13413658738136292, 0.13446524739265442, 0.17442846298217773, 0.1752820760011673, 0.11107978224754333, 0.17611294984817505, 0.1749686300754547, 0.23121286928653717, 0.14191125333309174, 0.22788166999816895, 0.10958385467529297, 0.17075763642787933, 0.13405367732048035, 0.1296897828578949, 0.22676680982112885, 0.14125753939151764, 0.10884926468133926, 0.11796107888221741, 0.14327575266361237, 0.16653667390346527, 0.1397731900215149, 0.1365956813097, 0.16693776845932007, 0.106859490275383, 0.23931120336055756, 0.1945829689502716, 0.10576507449150085, 0.21988345682621002, 0.2001868635416031, 0.13932378590106964, 0.10510464012622833, 0.178026020526886, 0.14319263398647308, 0.19464169442653656, 0.15082813799381256, 0.23090647161006927, 0.21054397523403168, 0.16887733340263367, 0.2291734665632248, 0.16713932156562805, 0.14184999465942383, 0.18722756206989288, 0.10545847564935684, 0.27223917841911316, 0.17066779732704163, 0.18597908318042755, 0.13979758322238922, 0.12507085502147675, 0.10646276921033859, 0.10669022053480148, 0.2261877804994583, 0.14403653144836426, 0.1837969720363617, 0.19077064096927643, 0.21665377914905548, 0.1318620890378952, 0.16416454315185547, 0.2223283052444458, 0.10671339929103851, 0.1598283350467682, 0.1718735545873642, 0.14826273918151855, 0.16568523645401, 0.22318412363529205, 0.17140360176563263, 0.22347450256347656, 0.23624162375926971, 0.10822521150112152, 0.2038193792104721, 0.21414966881275177, 0.23659594357013702, 0.22760683298110962, 0.17690497636795044, 0.11106262356042862, 0.22404006123542786, 0.11223814636468887, 0.11235079914331436, 0.1388920396566391, 0.11307381838560104, 0.22390025854110718, 0.1774013340473175, 0.18397948145866394, 0.13799932599067688, 0.11305543035268784, 0.1622052788734436, 0.16587623953819275, 0.1707915961742401, 0.18883316218852997, 0.15889398753643036, 0.20256271958351135, 0.18605108559131622, 0.1487894505262375, 0.1768176406621933, 0.15603861212730408, 0.18588367104530334, 0.13113272190093994, 0.15224981307983398, 0.14131994545459747, 0.11266161501407623, 0.14108194410800934, 0.1519113928079605, 0.12182574719190598, 0.12341458350419998, 0.2031434029340744, 0.1688566356897354, 0.1312306970357895, 0.17247556149959564, 0.14356093108654022, 0.12849679589271545, 0.2340599149465561, 0.137823686003685, 0.1410713940858841, 0.13187432289123535, 0.17624539136886597, 0.16575852036476135, 0.23687008023262024, 0.14618396759033203, 0.1979874223470688, 0.16886721551418304, 0.12535980343818665, 0.16116124391555786, 0.13301615417003632, 0.10953271389007568, 0.16331267356872559, 0.1397256851196289, 0.145891010761261, 0.13297177851200104, 0.19097095727920532, 0.12933121621608734, 0.13345980644226074, 0.13062652945518494, 0.17992658913135529, 0.1839272528886795, 0.206525981426239, 0.14877940714359283, 0.1315484493970871, 0.16611920297145844, 0.19988878071308136, 0.1696455478668213, 0.16958217322826385, 0.27774688601493835, 0.2158171832561493, 0.13502366840839386, 0.16696803271770477, 0.1515677124261856, 0.16145779192447662, 0.15399213135242462, 0.17440670728683472, 0.14186005294322968, 0.236068457365036, 0.16859324276447296, 0.13919824361801147, 0.13720154762268066, 0.24673251807689667, 0.13032874464988708, 0.21049880981445312, 0.20780442655086517, 0.18541359901428223, 0.1446680724620819, 0.1056908667087555, 0.1743493229150772, 0.17149075865745544, 0.10577967762947083, 0.14434310793876648, 0.21019431948661804, 0.18920576572418213, 0.18068282306194305, 0.17818321287631989, 0.16997458040714264, 0.22081561386585236, 0.17776614427566528, 0.18297384679317474, 0.1390007883310318, 0.13050968945026398, 0.1383696347475052, 0.14737364649772644, 0.14088039100170135, 0.19571976363658905, 0.10677564144134521, 0.14533278346061707, 0.1684289425611496, 0.17953768372535706, 0.10578051209449768, 0.10558519512414932, 0.10523726791143417, 0.19814123213291168, 0.20391426980495453, 0.10411396622657776, 0.103766068816185, 0.18905960023403168, 0.16869305074214935, 0.19393928349018097, 0.1467292159795761, 0.2211531698703766, 0.10304238647222519, 0.13665913045406342, 0.1456691324710846, 0.24413235485553741, 0.1752835363149643, 0.17250977456569672, 0.1725383847951889, 0.12695273756980896, 0.16730950772762299, 0.10178841650485992, 0.13386942446231842, 0.10147036612033844, 0.19380062818527222, 0.1738317757844925, 0.13251493871212006, 0.2072119563817978, 0.10070119053125381, 0.15717464685440063, 0.10017546266317368, 0.20324957370758057, 0.1318243443965912, 0.18320386111736298, 0.09863417595624924, 0.13861921429634094, 0.13824015855789185, 0.14616110920906067, 0.11678551882505417, 0.27147892117500305, 0.140921488404274, 0.1898602992296219, 0.23446135222911835, 0.23757275938987732, 0.21382084488868713, 0.22707223892211914, 0.1657894253730774, 0.22631718218326569, 0.18780866265296936, 0.24674102663993835, 0.21622861921787262, 0.2847049832344055, 0.23234699666500092, 0.15991894900798798, 0.1032186970114708, 0.14530690014362335, 0.23209407925605774, 0.21322225034236908, 0.17350433766841888, 0.2183518409729004, 0.2224821150302887, 0.22710902988910675, 0.12278570979833603, 0.1378725916147232, 0.1992187649011612, 0.10993847995996475, 0.11044158041477203, 0.20315194129943848, 0.11041548103094101, 0.16976001858711243, 0.1201971173286438, 0.1964278221130371, 0.19345629215240479, 0.16349180042743683, 0.12590132653713226, 0.19312162697315216, 0.11077412217855453, 0.21857872605323792, 0.1253216415643692, 0.15981556475162506, 0.18054966628551483, 0.1350272297859192, 0.14306636154651642, 0.21825185418128967, 0.12470876425504684, 0.13331840932369232, 0.13302236795425415, 0.1550660878419876, 0.19574831426143646, 0.2049119621515274, 0.10981959849596024, 0.17137247323989868, 0.16061265766620636, 0.2638525664806366, 0.16285353899002075, 0.16053280234336853, 0.23602156341075897, 0.20221616327762604, 0.14834368228912354, 0.19093723595142365, 0.1507517546415329, 0.1764412373304367, 0.1776113212108612, 0.16111955046653748, 0.1707581877708435, 0.1566935032606125, 0.14835099875926971, 0.14817723631858826, 0.179317444562912, 0.23150454461574554, 0.13622967898845673, 0.19621145725250244, 0.1706528216600418, 0.15155798196792603, 0.21477597951889038, 0.2252870351076126, 0.1433405876159668, 0.16259188950061798, 0.1555052399635315, 0.111808642745018, 0.1785784214735031, 0.1396939605474472, 0.17239804565906525, 0.2207237035036087, 0.1359516680240631, 0.19493691623210907, 0.2064809650182724, 0.15807685256004333, 0.13489897549152374, 0.19737665355205536, 0.16623526811599731, 0.1475030779838562, 0.11178310215473175, 0.16726934909820557, 0.17011943459510803, 0.20905913412570953, 0.17105165123939514, 0.13757944107055664, 0.191685751080513, 0.1464506834745407, 0.11139728128910065, 0.15305398404598236, 0.11123010516166687, 0.1901121288537979, 0.16996455192565918, 0.22875583171844482, 0.20049701631069183, 0.1349174678325653, 0.15312959253787994, 0.1574498564004898, 0.15263882279396057, 0.14576128125190735, 0.18271644413471222, 0.15070918202400208, 0.16532671451568604, 0.16379976272583008, 0.16928523778915405, 0.16374734044075012, 0.1887679100036621, 0.13740739226341248, 0.17337101697921753, 0.12725596129894257, 0.1852225810289383, 0.23512591421604156, 0.13848939538002014, 0.1386856883764267, 0.15101668238639832, 0.1091354489326477, 0.14153781533241272, 0.15627263486385345, 0.18527638912200928, 0.10838646441698074, 0.14473284780979156, 0.162088543176651, 0.22575770318508148, 0.16226215660572052, 0.2706400752067566, 0.12870337069034576, 0.23320646584033966, 0.10699135810136795, 0.1854046732187271, 0.16670870780944824, 0.1387913078069687, 0.23066820204257965, 0.12613297998905182, 0.1345469355583191, 0.17800690233707428, 0.10779427736997604, 0.1598004847764969, 0.15669943392276764, 0.14090240001678467, 0.12769731879234314, 0.18795616924762726, 0.14576102793216705, 0.1842803955078125, 0.2167084664106369, 0.14079952239990234, 0.1328074187040329, 0.12331008911132812, 0.2175077348947525, 0.20135261118412018, 0.12642554938793182, 0.14045198261737823, 0.14875872433185577, 0.18848298490047455, 0.10541083663702011, 0.10489845275878906, 0.12819454073905945, 0.13622619211673737, 0.19166603684425354, 0.20987796783447266, 0.17993903160095215, 0.13827118277549744, 0.13834242522716522, 0.10246876627206802, 0.11956871300935745, 0.14467346668243408, 0.1798856407403946, 0.25216707587242126, 0.10105342417955399, 0.10063163936138153, 0.18974192440509796, 0.14641647040843964, 0.14402323961257935, 0.12031731754541397, 0.1881917268037796, 0.09862960129976273, 0.25589829683303833, 0.24774809181690216, 0.24322059750556946, 0.1412157118320465, 0.2144455760717392, 0.1441623717546463, 0.2186797708272934, 0.18248413503170013, 0.18472333252429962, 0.1488533914089203, 0.2287651002407074, 0.2431664764881134, 0.1005713939666748, 0.1997007429599762, 0.2024173140525818, 0.1433320790529251, 0.22142480313777924, 0.15286286175251007, 0.12889353930950165, 0.19247889518737793, 0.10266415774822235, 0.10265273600816727, 0.13847395777702332, 0.16774919629096985, 0.12552763521671295, 0.10124700516462326, 0.14153318107128143, 0.23798945546150208, 0.2821388840675354, 0.17306025326251984, 0.10090194642543793, 0.24937233328819275, 0.19541196525096893, 0.14308127760887146, 0.16379228234291077, 0.12644731998443604, 0.16451644897460938, 0.19148215651512146, 0.13216495513916016, 0.10202724486589432, 0.12493422627449036, 0.12783198058605194, 0.22928546369075775, 0.1285213679075241, 0.22742505371570587, 0.20526167750358582, 0.13908812403678894, 0.14145274460315704, 0.1885213404893875, 0.18822750449180603, 0.1345919966697693, 0.28050926327705383, 0.13081344962120056, 0.10186617076396942, 0.14183680713176727, 0.23029938340187073, 0.14261475205421448, 0.10170776396989822, 0.1450580507516861, 0.2305469810962677, 0.13072852790355682, 0.10170549899339676, 0.12886987626552582, 0.21099494397640228, 0.22226883471012115, 0.1811555027961731, 0.2808815836906433, 0.14535284042358398, 0.1313367336988449, 0.1554064303636551, 0.1465950608253479, 0.1023198813199997, 0.1450766623020172, 0.18237952888011932, 0.16108253598213196, 0.11650561541318893, 0.22947169840335846, 0.18024174869060516, 0.14194460213184357, 0.21260759234428406, 0.27924275398254395, 0.10219008475542068, 0.14976131916046143, 0.27735769748687744, 0.10306329280138016, 0.14312151074409485, 0.19320066273212433, 0.1481533646583557, 0.19837935268878937, 0.13977770507335663, 0.17300479114055634, 0.22281591594219208, 0.16189227998256683, 0.18570540845394135, 0.164774551987648, 0.15733486413955688, 0.12538011372089386, 0.13175135850906372, 0.17543856799602509, 0.13946622610092163, 0.12651848793029785, 0.10420649498701096, 0.2203764170408249, 0.23061054944992065, 0.17539241909980774, 0.2274610698223114, 0.19339770078659058, 0.1874915510416031, 0.1368424892425537, 0.211147278547287, 0.13795000314712524, 0.13017576932907104, 0.27161604166030884, 0.12877115607261658, 0.18166814744472504, 0.10616303235292435, 0.19384023547172546, 0.13468950986862183, 0.13793878257274628, 0.14005570113658905, 0.1976410448551178, 0.13370750844478607, 0.18649078905582428, 0.2422686666250229, 0.13862136006355286, 0.21875546872615814, 0.15451528131961823, 0.2681650221347809, 0.17377270758152008, 0.1929623782634735, 0.16419824957847595, 0.16044069826602936, 0.19151002168655396, 0.18995219469070435, 0.17537547647953033, 0.190639927983284, 0.14006203413009644, 0.17750082910060883, 0.15670375525951385, 0.14832626283168793, 0.14850369095802307, 0.19083400070667267, 0.14980535209178925, 0.11033410578966141, 0.11061788350343704, 0.135910764336586, 0.13159239292144775, 0.10943514853715897, 0.16918398439884186, 0.1823888123035431, 0.1731877475976944, 0.22669865190982819, 0.21903038024902344, 0.16608266532421112, 0.19690896570682526, 0.17528720200061798, 0.179390087723732, 0.19226783514022827, 0.2653832733631134, 0.12960033118724823, 0.18224723637104034, 0.2305317521095276, 0.18281517922878265, 0.1680128127336502, 0.179533451795578, 0.1904536783695221, 0.13657395541667938, 0.1945248693227768, 0.14826083183288574, 0.14385467767715454, 0.18897196650505066, 0.14072252810001373, 0.17365576326847076, 0.21221257746219635, 0.21063289046287537, 0.11232578754425049, 0.1815633922815323, 0.13866865634918213, 0.15361595153808594, 0.13374030590057373, 0.18123754858970642, 0.14087305963039398, 0.1663152128458023, 0.19913794100284576, 0.14391054213047028, 0.17180950939655304, 0.14376038312911987, 0.1806805580854416, 0.1938340812921524, 0.1634766161441803, 0.23128581047058105, 0.15329277515411377, 0.1725485473871231, 0.14211200177669525, 0.1537996381521225, 0.13813240826129913, 0.15282563865184784, 0.11255232989788055, 0.1531895250082016, 0.11173983663320541, 0.21465431153774261, 0.22745709121227264, 0.22013194859027863, 0.18421418964862823, 0.13366830348968506, 0.1959345042705536, 0.16748540103435516, 0.1366669237613678, 0.13916443288326263, 0.13881254196166992, 0.18498755991458893, 0.13386720418930054, 0.11037515848875046, 0.11064567416906357, 0.1761806756258011, 0.1402411311864853, 0.20085160434246063, 0.18356363475322723, 0.2204314023256302, 0.18234676122665405, 0.10876912623643875, 0.23159225285053253, 0.2353498786687851, 0.18503007292747498, 0.1754126101732254, 0.16921095550060272, 0.13649535179138184, 0.18324874341487885, 0.20027491450309753, 0.1259881556034088, 0.22735777497291565, 0.2624545395374298, 0.11018063873052597, 0.17131128907203674, 0.24550122022628784, 0.16674722731113434, 0.14471763372421265, 0.18392783403396606, 0.14484256505966187, 0.18660640716552734, 0.1931791603565216, 0.2574370205402374, 0.21251879632472992, 0.21366813778877258, 0.1505395472049713, 0.14251112937927246, 0.11470994353294373, 0.2143736332654953, 0.11496713012456894, 0.17653709650039673, 0.11505258828401566, 0.11514073610305786, 0.2027694284915924, 0.1601816564798355, 0.13785098493099213, 0.2526046931743622, 0.1878052055835724, 0.14851202070713043, 0.18192283809185028, 0.11577046662569046, 0.13527755439281464, 0.18010252714157104, 0.1390421986579895, 0.15655134618282318, 0.17375396192073822, 0.1597357541322708, 0.15357786417007446, 0.1935747265815735, 0.17886631190776825, 0.21807482838630676, 0.17693036794662476, 0.25238892436027527, 0.17865413427352905, 0.14305900037288666, 0.20985831320285797, 0.13776826858520508, 0.1555214524269104, 0.12296155840158463, 0.21734249591827393, 0.1618299037218094, 0.16525371372699738, 0.18185681104660034, 0.22407524287700653, 0.11765531450510025, 0.1392088383436203, 0.2211000770330429, 0.14803697168827057, 0.11792752891778946, 0.16774572432041168, 0.16435861587524414, 0.16685204207897186, 0.14326047897338867, 0.17551125586032867, 0.20909568667411804, 0.20780669152736664, 0.11771516501903534, 0.1421874314546585, 0.20635917782783508, 0.14235009253025055, 0.1471521109342575, 0.15265725553035736, 0.1480787694454193, 0.16434502601623535, 0.16809667646884918, 0.11768628656864166, 0.1457642763853073, 0.20282691717147827, 0.14207640290260315, 0.17536380887031555, 0.11610858887434006, 0.15785422921180725, 0.18157905340194702, 0.11526430398225784, 0.16032744944095612, 0.15936540067195892, 0.11463149636983871, 0.17568592727184296, 0.14461100101470947, 0.2334318310022354, 0.11327293515205383, 0.13779564201831818, 0.15929371118545532, 0.14418698847293854, 0.11253060400485992, 0.20845450460910797, 0.13981963694095612, 0.14074936509132385, 0.14447101950645447, 0.13675706088542938, 0.13427037000656128, 0.10972065478563309, 0.18916140496730804, 0.10854639858007431, 0.23264934122562408, 0.19074897468090057, 0.18224258720874786, 0.1239708662033081, 0.10734599828720093, 0.10673723369836807, 0.18508346378803253, 0.19711831212043762, 0.138901025056839, 0.14154253900051117, 0.17982590198516846, 0.14414983987808228, 0.1769523024559021, 0.12987267971038818, 0.1383238285779953, 0.1450180858373642, 0.14709144830703735, 0.14525766670703888, 0.2779502868652344, 0.14894446730613708, 0.1728975623846054, 0.20046108961105347, 0.2789531946182251, 0.1791914403438568, 0.13268135488033295, 0.1354767233133316, 0.19610533118247986, 0.14900615811347961, 0.17007078230381012, 0.18177810311317444, 0.1333119124174118, 0.1436501443386078, 0.14739778637886047, 0.13206163048744202, 0.18168681859970093, 0.13576890528202057, 0.13112418353557587, 0.15247869491577148, 0.13334862887859344, 0.14797064661979675, 0.24006617069244385, 0.13311278820037842, 0.2315683811903, 0.13564838469028473, 0.10085363686084747, 0.23609687387943268, 0.12735921144485474, 0.21563492715358734, 0.16231942176818848, 0.281674325466156, 0.1928124576807022, 0.1483243703842163, 0.14006607234477997, 0.12714806199073792, 0.1017814502120018, 0.18117140233516693, 0.10173344612121582, 0.22917664051055908, 0.1018490269780159, 0.1415148675441742, 0.10135790705680847, 0.13852904736995697, 0.1319446712732315, 0.10054143518209457, 0.16321691870689392, 0.17077399790287018, 0.17283985018730164, 0.09923336654901505, 0.16180957853794098, 0.13658615946769714, 0.2355138659477234, 0.18364964425563812, 0.13128048181533813, 0.17763009667396545, 0.1717008650302887, 0.12765340507030487, 0.09781350940465927, 0.1318611055612564, 0.14303776621818542, 0.13066904246807098, 0.15149331092834473, 0.186949223279953, 0.09618113189935684, 0.23248839378356934, 0.09545193612575531, 0.2439730167388916, 0.1332409381866455, 0.17941606044769287, 0.13588854670524597, 0.16729065775871277, 0.12986834347248077, 0.09441778808832169, 0.189426988363266, 0.16559916734695435, 0.14111097157001495, 0.1352265328168869, 0.23662623763084412, 0.13585758209228516, 0.09316392987966537, 0.1401321291923523, 0.09289022535085678, 0.09235860407352448, 0.25491055846214294, 0.17538020014762878, 0.1439574509859085, 0.12766368687152863, 0.30519968271255493, 0.16472724080085754, 0.2539888918399811, 0.18669675290584564, 0.18840324878692627, 0.24236512184143066, 0.14031079411506653, 0.14866730570793152, 0.13135483860969543, 0.18237030506134033, 0.09332481771707535, 0.16464956104755402, 0.1769326776266098, 0.1853828728199005, 0.14087824523448944, 0.18750858306884766, 0.29783162474632263, 0.18451480567455292, 0.1706785261631012, 0.13622547686100006, 0.2124590426683426, 0.24866336584091187, 0.12929296493530273, 0.13642369210720062, 0.18136896193027496, 0.18450522422790527, 0.12278739362955093, 0.18021845817565918, 0.13584330677986145, 0.1366496980190277, 0.24811112880706787, 0.18884031474590302, 0.16356121003627777, 0.09833040833473206, 0.23246152698993683, 0.13956661522388458, 0.16938157379627228, 0.12679925560951233, 0.1803274154663086, 0.09921040385961533, 0.2255605012178421, 0.13189956545829773, 0.14195990562438965, 0.232266366481781, 0.16200605034828186, 0.09944184124469757, 0.14658068120479584, 0.1399657428264618, 0.12664145231246948, 0.23069430887699127, 0.17236283421516418, 0.09924425929784775, 0.22541572153568268, 0.22318010032176971, 0.24752962589263916, 0.1297612190246582, 0.18922936916351318, 0.17521394789218903, 0.15372294187545776, 0.2239988148212433, 0.28176331520080566, 0.13693030178546906, 0.27988722920417786, 0.10240643471479416, 0.1821010559797287, 0.2348327338695526, 0.2281631976366043, 0.1937621682882309, 0.16586938500404358, 0.1725999265909195, 0.188680961728096, 0.13119524717330933, 0.15728557109832764, 0.17817921936511993, 0.14752109348773956, 0.17952467501163483, 0.1800815314054489, 0.1459760218858719, 0.14857301115989685, 0.2151528298854828, 0.1618576943874359, 0.17244890332221985, 0.2170931100845337, 0.188193216919899, 0.16649246215820312, 0.14196746051311493, 0.10855818539857864, 0.10885106772184372, 0.1805046796798706, 0.13842391967773438, 0.20342007279396057, 0.10883646458387375, 0.13985852897167206, 0.1781911551952362, 0.21303875744342804, 0.18822892010211945, 0.1083773747086525, 0.10839620232582092, 0.17981235682964325, 0.1637893170118332, 0.21681036055088043, 0.18405196070671082, 0.2664349377155304, 0.22722814977169037, 0.1342640072107315, 0.23845617473125458, 0.1391981542110443, 0.17895662784576416, 0.17287613451480865, 0.1546146720647812, 0.1887662261724472, 0.14047646522521973, 0.1307728886604309, 0.1453753262758255, 0.14473745226860046, 0.1699773222208023, 0.17939788103103638, 0.23723605275154114, 0.12941761314868927, 0.2208251804113388, 0.11037612706422806, 0.21185725927352905, 0.16575846076011658, 0.14261400699615479, 0.13582496345043182, 0.16328442096710205, 0.14756256341934204, 0.1375965178012848, 0.17893971502780914, 0.11050882190465927, 0.1820768266916275, 0.2112085074186325, 0.16462060809135437, 0.2337784618139267, 0.1785053312778473, 0.22484451532363892, 0.17860308289527893, 0.14506883919239044, 0.12636695802211761, 0.14235860109329224, 0.1779298037290573, 0.14515027403831482, 0.1947450339794159, 0.1739407330751419, 0.11143691092729568, 0.2166917771100998, 0.17281579971313477, 0.1860225349664688, 0.1782323569059372, 0.15226133167743683, 0.1492442637681961, 0.14203105866909027, 0.1685112714767456, 0.1443193405866623, 0.2234627902507782, 0.1572965830564499, 0.17063584923744202, 0.2256510853767395, 0.14786304533481598, 0.18451380729675293, 0.14720389246940613, 0.12555934488773346, 0.17076711356639862, 0.1282770037651062, 0.20997288823127747, 0.11081960052251816, 0.22697708010673523, 0.17679151892662048, 0.14372028410434723, 0.16032050549983978, 0.20840102434158325, 0.20992377400398254, 0.1410110741853714, 0.12892396748065948, 0.14107516407966614, 0.21027889847755432, 0.19246606528759003, 0.25938934087753296, 0.14341872930526733, 0.17214462161064148, 0.1510467380285263, 0.14163444936275482, 0.17750166356563568, 0.18604937195777893, 0.13801634311676025, 0.11294299364089966, 0.14276552200317383, 0.20400823652744293, 0.23106448352336884, 0.2205275446176529, 0.18539124727249146, 0.1513538956642151, 0.11307206004858017, 0.1850474625825882, 0.11299194395542145, 0.17713025212287903, 0.11290205270051956, 0.11260487884283066, 0.1774735003709793, 0.17229782044887543, 0.1730952113866806, 0.22342966496944427, 0.13722772896289825, 0.1326015740633011, 0.11139395087957382, 0.21645668148994446, 0.17441600561141968, 0.11110976338386536, 0.20862233638763428, 0.21429196000099182, 0.11088690906763077, 0.15475711226463318, 0.14097721874713898, 0.11086705327033997, 0.14542526006698608, 0.20698806643486023, 0.2216089367866516, 0.14546410739421844, 0.21809153258800507, 0.13139097392559052, 0.13703835010528564, 0.20415501296520233, 0.16547946631908417, 0.1369161158800125, 0.18580453097820282]\n",
            "Val loss 0.16697019765653262\n",
            "Val auc roc 0.4989882788993817\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc4e6f3039db41118f4db5719fcda0bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2656.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1655\n",
            "Train Losses : [0.16276243329048157, 0.17033153772354126, 0.13716672360897064, 0.1834382563829422, 0.14252248406410217, 0.21108992397785187, 0.2619292140007019, 0.13490930199623108, 0.11091547459363937, 0.2341112494468689, 0.19681119918823242, 0.26043495535850525, 0.1860228031873703, 0.17367373406887054, 0.25839221477508545, 0.2576170563697815, 0.22385789453983307, 0.15179651975631714, 0.1646805852651596, 0.1325715333223343, 0.1541685163974762, 0.165797621011734, 0.11586647480726242, 0.13750983774662018, 0.2189265489578247, 0.18440639972686768, 0.18907320499420166, 0.19434404373168945, 0.2091744840145111, 0.17829349637031555, 0.11745540797710419, 0.22014132142066956, 0.20252995193004608, 0.1827966272830963, 0.15483298897743225, 0.14617709815502167, 0.16971781849861145, 0.15851253271102905, 0.19256849586963654, 0.119437076151371, 0.1760108470916748, 0.1552022397518158, 0.11911079287528992, 0.2304987907409668, 0.1803576648235321, 0.11898060888051987, 0.15636293590068817, 0.1992509961128235, 0.11862815171480179, 0.16049137711524963, 0.17506037652492523, 0.1488914042711258, 0.17962440848350525, 0.21664372086524963, 0.15904884040355682, 0.2058621197938919, 0.12609459459781647, 0.15286442637443542, 0.11860940605401993, 0.20051874220371246, 0.1397763043642044, 0.1179913803935051, 0.18766385316848755, 0.13935059309005737, 0.16385796666145325, 0.18023309111595154, 0.23283009231090546, 0.16723261773586273, 0.1925322413444519, 0.13912732899188995, 0.1416575014591217, 0.18211962282657623, 0.1878562718629837, 0.17697009444236755, 0.1610112488269806, 0.20204496383666992, 0.13653412461280823, 0.24927394092082977, 0.17108586430549622, 0.13497543334960938, 0.17056286334991455, 0.2483479231595993, 0.1535976082086563, 0.11818265914916992, 0.16847604513168335, 0.24762700498104095, 0.21506419777870178, 0.11878795176744461, 0.1424942910671234, 0.11863749474287033, 0.17245309054851532, 0.20296484231948853, 0.15451458096504211, 0.16233059763908386, 0.17853236198425293, 0.13211341202259064, 0.1306631863117218, 0.15098606050014496, 0.14833597838878632, 0.21071994304656982, 0.13770003616809845, 0.1660735011100769, 0.2096666842699051, 0.11813841760158539, 0.14843270182609558, 0.16033804416656494, 0.1178552433848381, 0.1747925877571106, 0.18193840980529785, 0.15205281972885132, 0.1527480036020279, 0.1514139175415039, 0.23061706125736237, 0.1484483927488327, 0.16827693581581116, 0.17586520314216614, 0.2126428633928299, 0.1884901076555252, 0.15133407711982727, 0.14362689852714539, 0.11638198047876358, 0.16076624393463135, 0.19653502106666565, 0.13877621293067932, 0.15284086763858795, 0.17187073826789856, 0.21253113448619843, 0.18058474361896515, 0.1946699470281601, 0.17284053564071655, 0.1337195783853531, 0.18778689205646515, 0.11567101627588272, 0.17117643356323242, 0.18747329711914062, 0.18349206447601318, 0.21455521881580353, 0.1268656849861145, 0.18437771499156952, 0.1866152435541153, 0.14281746745109558, 0.17535042762756348, 0.2512754499912262, 0.1705532670021057, 0.18287929892539978, 0.1874825656414032, 0.16529804468154907, 0.2097654640674591, 0.11684399843215942, 0.22453553974628448, 0.18639998137950897, 0.14652207493782043, 0.1803806722164154, 0.1947837620973587, 0.1984301060438156, 0.20421047508716583, 0.11839045584201813, 0.15545259416103363, 0.14411531388759613, 0.21063421666622162, 0.1396019458770752, 0.20857006311416626, 0.18521368503570557, 0.1188204288482666, 0.19431674480438232, 0.22116298973560333, 0.15044647455215454, 0.17991478741168976, 0.18592266738414764, 0.15216633677482605, 0.21085110306739807, 0.16001445055007935, 0.16284480690956116, 0.14258335530757904, 0.11929476261138916, 0.18745775520801544, 0.11932528018951416, 0.16324245929718018, 0.17444802820682526, 0.1678123027086258, 0.22830726206302643, 0.17297594249248505, 0.15475401282310486, 0.16172535717487335, 0.14620845019817352, 0.1786181628704071, 0.11925346404314041, 0.20193630456924438, 0.1184643879532814, 0.18385209143161774, 0.19251155853271484, 0.1605149656534195, 0.18678149580955505, 0.11822284758090973, 0.15388694405555725, 0.15253429114818573, 0.15068745613098145, 0.15132372081279755, 0.14482150971889496, 0.1681746542453766, 0.1170048862695694, 0.15981385111808777, 0.1637781858444214, 0.11603491753339767, 0.17199930548667908, 0.17007091641426086, 0.14908985793590546, 0.1327660232782364, 0.19930453598499298, 0.16859930753707886, 0.18744732439517975, 0.1824129819869995, 0.1357654333114624, 0.1770566999912262, 0.1771286576986313, 0.18374578654766083, 0.16862237453460693, 0.1383160501718521, 0.18679341673851013, 0.1991054266691208, 0.16181446611881256, 0.21916872262954712, 0.25608983635902405, 0.20630501210689545, 0.1686697155237198, 0.21523268520832062, 0.13627460598945618, 0.17530393600463867, 0.1380963921546936, 0.18896383047103882, 0.13419972360134125, 0.1409725397825241, 0.23477095365524292, 0.14220744371414185, 0.15110820531845093, 0.17840005457401276, 0.1579122543334961, 0.17340095341205597, 0.14211486279964447, 0.18243815004825592, 0.23484115302562714, 0.16840621829032898, 0.1476987898349762, 0.13626904785633087, 0.11559557914733887, 0.17402833700180054, 0.1622772514820099, 0.22592079639434814, 0.20711037516593933, 0.1559973806142807, 0.16098134219646454, 0.14356045424938202, 0.18282216787338257, 0.22448496520519257, 0.13859443366527557, 0.21049635112285614, 0.18647243082523346, 0.1748247891664505, 0.20656880736351013, 0.18512627482414246, 0.18777675926685333, 0.19603753089904785, 0.11631666123867035, 0.1471709907054901, 0.11686202138662338, 0.1599016934633255, 0.21575571596622467, 0.13527312874794006, 0.11610572785139084, 0.2189570516347885, 0.21670065820217133, 0.1416359543800354, 0.11603932827711105, 0.17516444623470306, 0.15112164616584778, 0.11580304801464081, 0.21593497693538666, 0.1715707778930664, 0.14218291640281677, 0.1448795199394226, 0.1543818563222885, 0.2525748014450073, 0.18144604563713074, 0.1865110993385315, 0.1860228031873703, 0.14426375925540924, 0.11517564207315445, 0.25266075134277344, 0.17948634922504425, 0.25214630365371704, 0.18054218590259552, 0.17546546459197998, 0.1762753576040268, 0.11621937900781631, 0.17408502101898193, 0.13180585205554962, 0.13079272210597992, 0.13557301461696625, 0.17429430782794952, 0.2137013077735901, 0.25010165572166443, 0.18123693764209747, 0.21650129556655884, 0.16608533263206482, 0.17346778512001038, 0.2483641356229782, 0.11783408373594284, 0.18315567076206207, 0.16960008442401886, 0.1845107078552246, 0.14743848145008087, 0.13761688768863678, 0.11913923174142838, 0.17777210474014282, 0.17645420134067535, 0.11922702938318253, 0.14546962082386017, 0.18758386373519897, 0.17557677626609802, 0.14555971324443817, 0.2021627277135849, 0.22597995400428772, 0.1715371012687683, 0.1188487559556961, 0.14019432663917542, 0.16946865618228912, 0.18813717365264893, 0.1392965018749237, 0.14761854708194733, 0.14016376435756683, 0.15052001178264618, 0.17558209598064423, 0.19490619003772736, 0.20738819241523743, 0.18977630138397217, 0.11824285984039307, 0.20734484493732452, 0.1626131534576416, 0.17704042792320251, 0.11837023496627808, 0.13723082840442657, 0.1421021670103073, 0.14000937342643738, 0.1512119323015213, 0.11774339526891708, 0.11756377667188644, 0.1521202027797699, 0.14244765043258667, 0.1568123996257782, 0.20975585281848907, 0.14447267353534698, 0.1946597695350647, 0.14330138266086578, 0.1793370246887207, 0.16556933522224426, 0.21986816823482513, 0.16358418762683868, 0.2213001549243927, 0.13829077780246735, 0.21372373402118683, 0.18869592249393463, 0.2061370462179184, 0.18717384338378906, 0.11567935347557068, 0.14690473675727844, 0.1842624992132187, 0.18727603554725647, 0.11584436893463135, 0.1666964441537857, 0.17922340333461761, 0.17641209065914154, 0.11594758927822113, 0.19912970066070557, 0.13769502937793732, 0.2109595239162445, 0.14645281434059143, 0.17049650847911835, 0.14011982083320618, 0.15065695345401764, 0.11558586359024048, 0.17790387570858002, 0.15261316299438477, 0.15265876054763794, 0.15321196615695953, 0.18372207880020142, 0.15187346935272217, 0.19732879102230072, 0.1286032497882843, 0.11392305046319962, 0.11373236030340195, 0.25589704513549805, 0.2172568142414093, 0.15143518149852753, 0.2093568742275238, 0.25599682331085205, 0.144480898976326, 0.1658555567264557, 0.11377131193876266, 0.11352413147687912, 0.20721828937530518, 0.1489117592573166, 0.14548707008361816, 0.15765148401260376, 0.13212570548057556, 0.13548530638217926, 0.11343538761138916, 0.18734042346477509, 0.14492486417293549, 0.14277814328670502, 0.19078581035137177, 0.1805247813463211, 0.20451784133911133, 0.18817883729934692, 0.18233640491962433, 0.2188435196876526, 0.1417277753353119, 0.2134632021188736, 0.11240117996931076, 0.14911741018295288, 0.1455731838941574, 0.13225500285625458, 0.2283298224210739, 0.2016785889863968, 0.18392740190029144, 0.1444116234779358, 0.18435049057006836, 0.1467566341161728, 0.14057250320911407, 0.17301912605762482, 0.1405181586742401, 0.2214668244123459, 0.22898542881011963, 0.15122242271900177, 0.23039565980434418, 0.11272568255662918, 0.17272759974002838, 0.2054881900548935, 0.2060607373714447, 0.11335163563489914, 0.20260076224803925, 0.14050738513469696, 0.17906619608402252, 0.19002263247966766, 0.18349729478359222, 0.22308661043643951, 0.18041466176509857, 0.15467160940170288, 0.14145679771900177, 0.215672567486763, 0.1741132140159607, 0.22661150991916656, 0.11480202525854111, 0.15647797286510468, 0.11511853337287903, 0.13882045447826385, 0.2081075757741928, 0.1360321342945099, 0.1575775444507599, 0.16681025922298431, 0.14601626992225647, 0.20624056458473206, 0.18361596763134003, 0.14815299212932587, 0.17111748456954956, 0.13410423696041107, 0.17223475873470306, 0.17600855231285095, 0.20490823686122894, 0.15059880912303925, 0.2177152782678604, 0.1376163512468338, 0.15810857713222504, 0.18310897052288055, 0.11549656093120575, 0.14576798677444458, 0.14275456964969635, 0.2055470496416092, 0.21804176270961761, 0.14304566383361816, 0.1577516496181488, 0.11508118361234665, 0.2528366446495056, 0.1752348244190216, 0.17441129684448242, 0.11527891457080841, 0.14208891987800598, 0.1759757399559021, 0.17540831863880157, 0.1754179745912552, 0.17236073315143585, 0.1812644898891449, 0.18060769140720367, 0.18143092095851898, 0.11506524682044983, 0.1768423616886139, 0.1652890145778656, 0.11495725810527802, 0.20980392396450043, 0.1549452692270279, 0.11493466794490814, 0.1863454133272171, 0.22207507491111755, 0.11453382670879364, 0.18252809345722198, 0.1751115471124649, 0.1489882618188858, 0.18429024517536163, 0.18944603204727173, 0.16626803576946259, 0.14103923738002777, 0.18920020759105682, 0.16112519800662994, 0.14928798377513885, 0.14000453054904938, 0.1139741912484169, 0.1803545355796814, 0.14293500781059265, 0.1532050222158432, 0.15913599729537964, 0.2171570211648941, 0.18618343770503998, 0.16571839153766632, 0.16351552307605743, 0.1994989663362503, 0.2275296151638031, 0.14803028106689453, 0.1399458944797516, 0.14850644767284393, 0.13836689293384552, 0.1892598569393158, 0.17787717282772064, 0.2093547135591507, 0.22522322833538055, 0.182090625166893, 0.1467958390712738, 0.16826333105564117, 0.16972775757312775, 0.13825403153896332, 0.146651953458786, 0.17518945038318634, 0.1409432590007782, 0.21814775466918945, 0.13905012607574463, 0.25656387209892273, 0.11321253329515457, 0.12953102588653564, 0.14136698842048645, 0.1729564368724823, 0.1984652727842331, 0.19496864080429077, 0.1135200634598732, 0.18061310052871704, 0.13992780447006226, 0.14525994658470154, 0.14840088784694672, 0.11345327645540237, 0.14108940958976746, 0.15449783205986023, 0.13513146340847015, 0.11246329545974731, 0.17623543739318848, 0.11193056404590607, 0.19335490465164185, 0.13825492560863495, 0.1671844869852066, 0.22305572032928467, 0.2032020539045334, 0.18065497279167175, 0.11102467030286789, 0.14124035835266113, 0.14331592619419098, 0.18504740297794342, 0.14133931696414948, 0.14752449095249176, 0.18791623413562775, 0.10970420390367508, 0.15601855516433716, 0.10935687273740768, 0.18846240639686584, 0.10893193632364273, 0.19840338826179504, 0.13160453736782074, 0.1935749053955078, 0.10872197151184082, 0.1077343225479126, 0.13898038864135742, 0.15999606251716614, 0.22090426087379456, 0.1337515413761139, 0.16951946914196014, 0.14066274464130402, 0.15001434087753296, 0.22296452522277832, 0.1744467169046402, 0.15935100615024567, 0.10571050643920898, 0.19346310198307037, 0.2281075119972229, 0.1512456089258194, 0.18496465682983398, 0.16304360330104828, 0.17955641448497772, 0.18237030506134033, 0.16634200513362885, 0.1672014445066452, 0.22399723529815674, 0.2063422054052353, 0.16563211381435394, 0.13716411590576172, 0.1399543434381485, 0.22282908856868744, 0.1831793636083603, 0.1500607281923294, 0.13476350903511047, 0.15873852372169495, 0.15847037732601166, 0.1511126160621643, 0.1830815225839615, 0.16495263576507568, 0.19467313587665558, 0.13449805974960327, 0.17805416882038116, 0.13694538176059723, 0.17064788937568665, 0.10570685565471649, 0.10566731542348862, 0.191763237118721, 0.1415482610464096, 0.13968992233276367, 0.19199813902378082, 0.1902833729982376, 0.10469693690538406, 0.17963874340057373, 0.21065378189086914, 0.14163044095039368, 0.18272021412849426, 0.18880145251750946, 0.1801224797964096, 0.145856574177742, 0.19246703386306763, 0.22845600545406342, 0.20810461044311523, 0.13715040683746338, 0.13919079303741455, 0.1329965889453888, 0.17886975407600403, 0.13265331089496613, 0.14915083348751068, 0.17662420868873596, 0.17839066684246063, 0.14853152632713318, 0.14489373564720154, 0.27446886897087097, 0.1780358999967575, 0.17043527960777283, 0.16490308940410614, 0.1423812061548233, 0.21984347701072693, 0.16842402517795563, 0.10478334128856659, 0.17049193382263184, 0.1470147669315338, 0.10476585477590561, 0.22808603942394257, 0.1347818672657013, 0.22712065279483795, 0.19367197155952454, 0.14467743039131165, 0.18209019303321838, 0.17813116312026978, 0.18311816453933716, 0.2182427942752838, 0.186448335647583, 0.1818627119064331, 0.21015214920043945, 0.18376146256923676, 0.17696304619312286, 0.10663775354623795, 0.2066841870546341, 0.1419147402048111, 0.16755637526512146, 0.16864031553268433, 0.14313794672489166, 0.2198069989681244, 0.15363973379135132, 0.17524006962776184, 0.13734309375286102, 0.23233847320079803, 0.19568131864070892, 0.18243955075740814, 0.1080188900232315, 0.13927727937698364, 0.1340302675962448, 0.20779958367347717, 0.17526443302631378, 0.12434101849794388, 0.14199215173721313, 0.10802857577800751, 0.1390816569328308, 0.16421093046665192, 0.1980179399251938, 0.18839246034622192, 0.10749021172523499, 0.18699108064174652, 0.13681678473949432, 0.10723701119422913, 0.14187370240688324, 0.17565426230430603, 0.2314034402370453, 0.10655658692121506, 0.23800264298915863, 0.269378662109375, 0.1752929836511612, 0.18399831652641296, 0.156783789396286, 0.1762564331293106, 0.2209368795156479, 0.17764176428318024, 0.14226402342319489, 0.10736154019832611, 0.21596916019916534, 0.223241925239563, 0.17238131165504456, 0.14435838162899017, 0.22091785073280334, 0.14051300287246704, 0.26558324694633484, 0.1597624272108078, 0.18065600097179413, 0.17647074162960052, 0.10933002829551697, 0.13988415896892548, 0.18774749338626862, 0.10928606241941452, 0.17321979999542236, 0.17636191844940186, 0.14705735445022583, 0.14146146178245544, 0.10909254848957062, 0.17011916637420654, 0.18369409441947937, 0.14613282680511475, 0.2310338169336319, 0.10874281823635101, 0.10881038755178452, 0.10841120779514313, 0.13500258326530457, 0.17916053533554077, 0.1287083476781845, 0.1076558455824852, 0.16463389992713928, 0.23842698335647583, 0.22614535689353943, 0.14132027328014374, 0.18567432463169098, 0.23057731986045837, 0.13159088790416718, 0.17485301196575165, 0.1682855784893036, 0.10699371248483658, 0.14797550439834595, 0.17322833836078644, 0.17975784838199615, 0.10670740902423859, 0.18667976558208466, 0.14291219413280487, 0.1415589153766632, 0.21086320281028748, 0.18511168658733368, 0.14356955885887146, 0.12662887573242188, 0.14236383140087128, 0.13915874063968658, 0.21587282419204712, 0.22607295215129852, 0.17754609882831573, 0.18283119797706604, 0.10586035251617432, 0.2241172194480896, 0.23804745078086853, 0.16902677714824677, 0.106554314494133, 0.17449721693992615, 0.10626587271690369, 0.1340039074420929, 0.14614364504814148, 0.18450212478637695, 0.18273770809173584, 0.13579867780208588, 0.1402815580368042, 0.10591749101877213, 0.14764133095741272, 0.16858789324760437, 0.10531948506832123, 0.17600366473197937, 0.13232403993606567, 0.17951485514640808, 0.1365528255701065, 0.13389961421489716, 0.1750643402338028, 0.18442794680595398, 0.12591178715229034, 0.23142655193805695, 0.17768986523151398, 0.1791725903749466, 0.10370909422636032, 0.1731913685798645, 0.19364574551582336, 0.23103609681129456, 0.14281336963176727, 0.14950773119926453, 0.14088134467601776, 0.17114922404289246, 0.1766931414604187, 0.13417331874370575, 0.142194926738739, 0.10332760959863663, 0.10325434058904648, 0.19274753332138062, 0.1027897447347641, 0.1847875565290451, 0.23159462213516235, 0.18309806287288666, 0.17516736686229706, 0.13501548767089844, 0.18102800846099854, 0.14448875188827515, 0.1453927606344223, 0.17582714557647705, 0.18041634559631348, 0.22540296614170074, 0.1368156224489212, 0.17968885600566864, 0.23441080749034882, 0.14106179773807526, 0.14293843507766724, 0.10183069854974747, 0.1811167448759079, 0.14705103635787964, 0.13298474252223969, 0.17289230227470398, 0.13543084263801575, 0.10133809596300125, 0.2358827143907547, 0.13193342089653015, 0.18571455776691437, 0.184872567653656, 0.17589104175567627, 0.13024452328681946, 0.10089638829231262, 0.17804671823978424, 0.17794331908226013, 0.10080717504024506, 0.18197278678417206, 0.18779271841049194, 0.2825619578361511, 0.18646802008152008, 0.13090233504772186, 0.17272348701953888, 0.13273288309574127, 0.12546402215957642, 0.1380385011434555, 0.10052072256803513, 0.10046188533306122, 0.1394457221031189, 0.18414703011512756, 0.23008975386619568, 0.09977144747972488, 0.12999960780143738, 0.17111825942993164, 0.09952015429735184, 0.09932985156774521, 0.13270950317382812, 0.19433043897151947, 0.1355578452348709, 0.09832048416137695, 0.23173858225345612, 0.12600095570087433, 0.2335064709186554, 0.14074937999248505, 0.1839139312505722, 0.09766914695501328, 0.13315729796886444, 0.17372432351112366, 0.09725531190633774, 0.17640092968940735, 0.13171356916427612, 0.23231883347034454, 0.2913387417793274, 0.1717206984758377, 0.12533248960971832, 0.17738206684589386, 0.1885211169719696, 0.1297791600227356, 0.1897764503955841, 0.1356293112039566, 0.2254122495651245, 0.13154463469982147, 0.12979982793331146, 0.24083250761032104, 0.18095862865447998, 0.2262227088212967, 0.13397882878780365, 0.288005530834198, 0.17990806698799133, 0.17372560501098633, 0.09880998730659485, 0.22883173823356628, 0.18546578288078308, 0.14183901250362396, 0.17822612822055817, 0.1391890048980713, 0.14222858846187592, 0.14160244166851044, 0.282943993806839, 0.176084503531456, 0.14568257331848145, 0.16980452835559845, 0.22922208905220032, 0.19293446838855743, 0.22916194796562195, 0.16873860359191895, 0.22999750077724457, 0.2202494889497757, 0.13170787692070007, 0.14051204919815063, 0.1028716117143631, 0.1823408603668213, 0.13744975626468658, 0.18614612519741058, 0.14439186453819275, 0.10330062359571457, 0.10322442650794983, 0.1344039887189865, 0.1715143769979477, 0.18867303431034088, 0.1447618305683136, 0.13435639441013336, 0.13603749871253967, 0.13994011282920837, 0.13879701495170593, 0.1370110660791397, 0.14107970893383026, 0.1862812042236328, 0.18440459668636322, 0.10160573571920395, 0.10134981572628021, 0.17987306416034698, 0.10100162029266357, 0.18657150864601135, 0.18122795224189758, 0.16896894574165344, 0.1737504005432129, 0.1947806179523468, 0.13001836836338043, 0.0997207760810852, 0.09956763684749603, 0.09954184293746948, 0.18297863006591797, 0.09891178458929062, 0.1307287961244583, 0.20074068009853363, 0.14060603082180023, 0.13940338790416718, 0.13691991567611694, 0.13506555557250977, 0.1391274482011795, 0.14283107221126556, 0.1306871920824051, 0.16535688936710358, 0.18415845930576324, 0.12719666957855225, 0.2938053011894226, 0.16845038533210754, 0.14153572916984558, 0.24403880536556244, 0.1281193643808365, 0.23496532440185547, 0.13447728753089905, 0.17609523236751556, 0.1286284178495407, 0.23524689674377441, 0.09594975411891937, 0.13848717510700226, 0.1848989725112915, 0.09599534422159195, 0.17655880749225616, 0.14441806077957153, 0.13326331973075867, 0.17264950275421143, 0.18045392632484436, 0.12826310098171234, 0.17743906378746033, 0.13107150793075562, 0.23951518535614014, 0.18240581452846527, 0.13724219799041748, 0.17492665350437164, 0.13609378039836884, 0.1852758824825287, 0.13696768879890442, 0.14189307391643524, 0.17042334377765656, 0.13238613307476044, 0.17614372074604034, 0.13924197852611542, 0.18200117349624634, 0.09514165669679642, 0.1786358654499054, 0.13794784247875214, 0.13472121953964233, 0.13386346399784088, 0.14280305802822113, 0.17798112332820892, 0.1746060848236084, 0.09412989765405655, 0.1405569463968277, 0.09379074722528458, 0.17197410762310028, 0.18531227111816406, 0.25019925832748413, 0.17142818868160248, 0.1428402215242386, 0.1328379511833191, 0.14066185057163239, 0.2413409948348999, 0.13324128091335297, 0.1791035383939743, 0.13068147003650665, 0.09305183589458466, 0.19485871493816376, 0.3009551465511322, 0.1847561001777649, 0.12482759356498718, 0.18073755502700806, 0.3000265061855316, 0.18949322402477264, 0.17996998131275177, 0.12649835646152496, 0.1276494413614273, 0.09395650029182434, 0.18906435370445251, 0.24354976415634155, 0.2320176213979721, 0.22822768986225128, 0.19930435717105865, 0.18105575442314148, 0.17545339465141296, 0.18530552089214325, 0.24349689483642578, 0.18747647106647491, 0.13948765397071838, 0.1686609983444214, 0.1783735454082489, 0.22276091575622559, 0.2893757224082947, 0.17300578951835632, 0.18120995163917542, 0.13121195137500763, 0.0988181084394455, 0.17989926040172577, 0.14295020699501038, 0.1974145472049713, 0.13477495312690735, 0.23727130889892578, 0.2840234637260437, 0.17084023356437683, 0.10064169764518738, 0.1369512379169464, 0.10060150921344757, 0.1362738311290741, 0.1779988557100296, 0.18557380139827728, 0.10072753578424454, 0.13550150394439697, 0.10061335563659668, 0.23292523622512817, 0.13399766385555267, 0.1787213534116745, 0.17391978204250336, 0.13955378532409668, 0.17591972649097443, 0.14097127318382263, 0.10035290569067001, 0.13555175065994263, 0.18380412459373474, 0.12225061655044556, 0.16925352811813354, 0.1475367397069931, 0.1912982016801834, 0.22733470797538757, 0.18154208362102509, 0.16615284979343414, 0.09992418438196182, 0.17957517504692078, 0.1827695220708847, 0.1344754695892334, 0.24410495162010193, 0.13447746634483337, 0.1593143492937088, 0.19142505526542664, 0.14207665622234344, 0.24378205835819244, 0.09963542968034744, 0.22070921957492828, 0.17290984094142914, 0.14316681027412415, 0.2266720086336136, 0.1847589910030365, 0.13682760298252106, 0.17660248279571533, 0.137217178940773, 0.14108268916606903, 0.14197900891304016, 0.13188084959983826, 0.1374366134405136, 0.2415473908185959, 0.23383793234825134, 0.14510145783424377, 0.10041863471269608, 0.22917607426643372, 0.1359085887670517, 0.22708019614219666, 0.1969020515680313, 0.10036711394786835, 0.1762305200099945, 0.1787668615579605, 0.10054855793714523, 0.13892795145511627, 0.23291319608688354, 0.18938830494880676, 0.2256467193365097, 0.17924121022224426, 0.18471486866474152, 0.22834397852420807, 0.10108885169029236, 0.18208052217960358, 0.1323055624961853, 0.18842484056949615, 0.14288750290870667, 0.2056192308664322, 0.17761601507663727, 0.2204739898443222, 0.18591327965259552, 0.10207024216651917, 0.1775052845478058, 0.22940252721309662, 0.18349787592887878, 0.17343711853027344, 0.13004270195960999, 0.10263194143772125, 0.13732634484767914, 0.12990060448646545, 0.13714362680912018, 0.18245258927345276, 0.1681874394416809, 0.13764707744121552, 0.16858093440532684, 0.1648348718881607, 0.1322043538093567, 0.17550869286060333, 0.23013803362846375, 0.234887033700943, 0.16496415436267853, 0.146046981215477, 0.2238510549068451, 0.1306363195180893, 0.12138012796640396, 0.2164774090051651, 0.13892503082752228, 0.14433108270168304, 0.1030527651309967, 0.13031068444252014, 0.13655301928520203, 0.22041885554790497, 0.1887405514717102, 0.18169943988323212, 0.1891854703426361, 0.1721283346414566, 0.24962292611598969, 0.10304955393075943, 0.23419089615345, 0.19664287567138672, 0.23888511955738068, 0.12990768253803253, 0.14198563992977142, 0.27512267231941223, 0.14792363345623016, 0.14905034005641937, 0.16871771216392517, 0.20727872848510742, 0.1356862485408783, 0.1794816255569458, 0.13795524835586548, 0.1640419065952301, 0.13696186244487762, 0.10472610592842102, 0.13884839415550232, 0.13603125512599945, 0.17942124605178833, 0.180205836892128, 0.1820799708366394, 0.14534325897693634, 0.19610582292079926, 0.1382233053445816, 0.13690415024757385, 0.16854293644428253, 0.22399048507213593, 0.10437323898077011, 0.10416324436664581, 0.18419180810451508, 0.18633851408958435, 0.1360214501619339, 0.18126356601715088, 0.19357837736606598, 0.1039334312081337, 0.22892752289772034, 0.1857280731201172, 0.17948849499225616, 0.174671471118927, 0.10374755412340164, 0.21278931200504303, 0.13541777431964874, 0.22665823996067047, 0.1506030261516571, 0.22781461477279663, 0.13391482830047607, 0.17751021683216095, 0.17629645764827728, 0.17443208396434784, 0.18076269328594208, 0.2741107940673828, 0.2735474109649658, 0.22319144010543823, 0.1487671434879303, 0.1428995281457901, 0.2171093374490738, 0.14373408257961273, 0.10583871603012085, 0.14323469996452332, 0.10607554018497467, 0.14878812432289124, 0.1429930031299591, 0.16490378975868225, 0.14437401294708252, 0.13202247023582458, 0.1837104856967926, 0.17293468117713928, 0.17078721523284912, 0.1443079710006714, 0.1791517287492752, 0.14356260001659393, 0.13766641914844513, 0.14077311754226685, 0.14583832025527954, 0.23312954604625702, 0.17417725920677185, 0.1309463083744049, 0.18995630741119385, 0.14033298194408417, 0.18039126694202423, 0.13392135500907898, 0.23404614627361298, 0.17944207787513733, 0.1752719134092331, 0.2116180956363678, 0.16511720418930054, 0.18528544902801514, 0.1362801492214203, 0.10552904009819031, 0.17880955338478088, 0.2423955649137497, 0.20765475928783417, 0.13820470869541168, 0.1354982554912567, 0.22953654825687408, 0.1422768235206604, 0.18821582198143005, 0.1688435971736908, 0.2315826565027237, 0.1455567330121994, 0.2275051325559616, 0.18533392250537872, 0.10636205226182938, 0.1334111988544464, 0.22884391248226166, 0.22293436527252197, 0.10683273524045944, 0.1384052038192749, 0.14054974913597107, 0.180769681930542, 0.22333887219429016, 0.1821887195110321, 0.18581390380859375, 0.1071113720536232, 0.140432208776474, 0.14509668946266174, 0.14218316972255707, 0.2161616086959839, 0.21341544389724731, 0.26823684573173523, 0.18252187967300415, 0.21438288688659668, 0.13727165758609772, 0.18296128511428833, 0.10790982842445374, 0.18257981538772583, 0.22441016137599945, 0.13550244271755219, 0.10824614763259888, 0.14408329129219055, 0.16891039907932281, 0.14117658138275146, 0.14190424978733063, 0.17230747640132904, 0.14082619547843933, 0.14114537835121155, 0.10800420492887497, 0.16478364169597626, 0.14811189472675323, 0.1488187462091446, 0.14479413628578186, 0.17242254316806793, 0.10729385167360306, 0.19214917719364166, 0.18042869865894318, 0.2342720627784729, 0.22012625634670258, 0.14596149325370789, 0.2243872582912445, 0.10683132708072662, 0.142850860953331, 0.22373327612876892, 0.18876700103282928, 0.10694313049316406, 0.17362385988235474, 0.2190214991569519, 0.10700853914022446, 0.17655940353870392, 0.1789686679840088, 0.15462635457515717, 0.14198905229568481, 0.22262555360794067, 0.26861175894737244, 0.14153458178043365, 0.10696123540401459, 0.21627551317214966, 0.10735700279474258, 0.17201219499111176, 0.18402770161628723, 0.1856945902109146, 0.1442604809999466, 0.17413854598999023, 0.10729818791151047, 0.10726161301136017, 0.1489628255367279, 0.1885087937116623, 0.14832313358783722, 0.14145325124263763, 0.21850459277629852, 0.2184719443321228, 0.10665777325630188, 0.10669627040624619, 0.13578253984451294, 0.14402180910110474, 0.22472375631332397, 0.22535349428653717, 0.18594828248023987, 0.17465907335281372, 0.17109937965869904, 0.17719881236553192, 0.10671824961900711, 0.2333632856607437, 0.1726178675889969, 0.1306503862142563, 0.14630086719989777, 0.13247622549533844, 0.2694341242313385, 0.17926092445850372, 0.1516026258468628, 0.12455913424491882, 0.26877450942993164, 0.10684701055288315, 0.18292462825775146, 0.13583654165267944, 0.10710442811250687, 0.2309696227312088, 0.13458561897277832, 0.2174530178308487, 0.14358386397361755, 0.2179625779390335, 0.14592868089675903, 0.16057007014751434, 0.1916610449552536, 0.12737348675727844, 0.14076852798461914, 0.13114072382450104, 0.1786973476409912, 0.26745665073394775, 0.17625971138477325, 0.1813034862279892, 0.1496785432100296, 0.10774040222167969, 0.17131438851356506, 0.14208965003490448, 0.1370590627193451, 0.13193340599536896, 0.13625988364219666, 0.18300679326057434, 0.18634000420570374, 0.1072956919670105, 0.14478670060634613, 0.1826591044664383, 0.1070990115404129, 0.10706282407045364, 0.19129571318626404, 0.2689530849456787, 0.23604777455329895, 0.13402894139289856, 0.13779497146606445, 0.18225440382957458, 0.1851925253868103, 0.19443850219249725, 0.18282216787338257, 0.17526812851428986, 0.18389318883419037, 0.1403675079345703, 0.18219494819641113, 0.14054247736930847, 0.17846541106700897, 0.1971418708562851, 0.1350892335176468, 0.13706256449222565, 0.220550075173378, 0.10701646655797958, 0.13292057812213898, 0.1626696139574051, 0.17956705391407013, 0.10678011178970337, 0.10672535002231598, 0.17711983621120453, 0.12418650090694427, 0.10649998486042023, 0.17429594695568085, 0.1859816461801529, 0.21389876306056976, 0.22366371750831604, 0.14711537957191467, 0.14250311255455017, 0.17179234325885773, 0.22334875166416168, 0.17790453135967255, 0.14052753150463104, 0.18262025713920593, 0.22240248322486877, 0.18984080851078033, 0.17518667876720428, 0.26946935057640076, 0.1467619389295578, 0.17676159739494324, 0.22981131076812744, 0.18069034814834595, 0.13728153705596924, 0.17887207865715027, 0.12930446863174438, 0.1336650550365448, 0.14806093275547028, 0.17483197152614594, 0.14642827212810516, 0.1725381761789322, 0.22862863540649414, 0.1837691366672516, 0.1077430248260498, 0.13919441401958466, 0.1419215351343155, 0.17785438895225525, 0.13816039264202118, 0.10747841000556946, 0.2326919287443161, 0.17243564128875732, 0.18926608562469482, 0.17840832471847534, 0.2675735652446747, 0.1332533359527588, 0.17779023945331573, 0.18148723244667053, 0.18518249690532684, 0.19114704430103302, 0.1772438883781433, 0.1925399750471115, 0.22349222004413605, 0.18310533463954926, 0.14493976533412933, 0.13288912177085876, 0.18118683993816376, 0.14097358286380768, 0.136762335896492, 0.1363009512424469, 0.14543716609477997, 0.178192600607872, 0.1083228662610054, 0.22175239026546478, 0.17029622197151184, 0.2107134461402893, 0.15098892152309418, 0.22415673732757568, 0.1809026598930359, 0.1455642580986023, 0.10840747505426407, 0.18369413912296295, 0.21783684194087982, 0.21524955332279205, 0.22258631885051727, 0.10883454978466034, 0.14323431253433228, 0.1465240865945816, 0.22761978209018707, 0.1793200671672821, 0.1370488703250885, 0.22164368629455566, 0.13792291283607483, 0.18547487258911133, 0.18527404963970184, 0.13544631004333496, 0.1353108137845993, 0.17543253302574158, 0.10913337767124176, 0.22327351570129395, 0.17383021116256714, 0.10924477130174637, 0.2145499289035797, 0.17714379727840424, 0.21542960405349731, 0.14088675379753113, 0.10917485505342484, 0.18106774985790253, 0.14992955327033997, 0.1777261197566986, 0.13752150535583496, 0.14083699882030487, 0.18163509666919708, 0.17126525938510895, 0.17781400680541992, 0.2163514792919159, 0.15008386969566345, 0.17986278235912323, 0.16970482468605042, 0.17657563090324402, 0.1748671680688858, 0.18251195549964905, 0.1477697640657425, 0.17643214762210846, 0.10918144881725311, 0.16973839700222015, 0.22070488333702087, 0.26367756724357605, 0.18361486494541168, 0.1914564073085785, 0.18429160118103027, 0.1879175901412964, 0.14410081505775452, 0.14139026403427124, 0.16639365255832672, 0.16011154651641846, 0.15002326667308807, 0.10987956076860428, 0.22607733309268951, 0.14340108633041382, 0.178592249751091, 0.214603990316391, 0.15347877144813538, 0.18804165720939636, 0.1451074779033661, 0.14506208896636963, 0.18265627324581146, 0.10989221185445786, 0.26245343685150146, 0.13051077723503113, 0.13296057283878326, 0.14204955101013184, 0.17899414896965027, 0.14856675267219543, 0.16581052541732788, 0.17003001272678375, 0.21639855206012726, 0.10972793400287628, 0.22053642570972443, 0.22474291920661926, 0.14135348796844482, 0.14431951940059662, 0.22607854008674622, 0.19009913504123688, 0.16777296364307404, 0.17631687223911285, 0.11017798632383347, 0.1395290493965149, 0.17946816980838776, 0.16935837268829346, 0.11005865037441254, 0.14445438981056213, 0.18496330082416534, 0.16889308393001556, 0.1398782879114151, 0.14047719538211823, 0.15255875885486603, 0.10969654470682144, 0.21446406841278076, 0.13686560094356537, 0.18533656001091003, 0.1093875914812088, 0.18255162239074707, 0.21682648360729218, 0.18530026078224182, 0.10931356251239777, 0.1858142763376236, 0.18068993091583252, 0.1445348709821701, 0.10903862863779068, 0.1789839118719101, 0.10891041159629822, 0.18612641096115112, 0.21413691341876984, 0.1305249035358429, 0.14811189472675323, 0.178726926445961, 0.17980782687664032, 0.14126476645469666, 0.21296851336956024, 0.13918659090995789, 0.1405096799135208, 0.18593016266822815, 0.14436973631381989, 0.14536163210868835, 0.17947745323181152, 0.1749688982963562, 0.18806448578834534, 0.10828126221895218, 0.15088719129562378, 0.1325000524520874, 0.2146473228931427, 0.10796386748552322, 0.2257482260465622, 0.17992614209651947, 0.14251619577407837, 0.1743578165769577, 0.18032371997833252, 0.14771109819412231, 0.17700114846229553, 0.2253045290708542, 0.13635481894016266, 0.10763734579086304, 0.16758844256401062, 0.17263838648796082, 0.18257461488246918, 0.18454809486865997, 0.21691381931304932, 0.18092936277389526, 0.10774371027946472, 0.14863181114196777, 0.22310766577720642, 0.10767743736505508, 0.13558195531368256, 0.2202177345752716, 0.26686689257621765, 0.14608712494373322, 0.1367657631635666, 0.14129169285297394, 0.14292006194591522, 0.14382138848304749, 0.13803653419017792, 0.17892512679100037, 0.14710336923599243, 0.18139150738716125, 0.1077437549829483, 0.15153992176055908, 0.17832614481449127, 0.17822405695915222, 0.18166106939315796, 0.21839569509029388, 0.18035998940467834, 0.14085699617862701, 0.13931071758270264, 0.14676538109779358, 0.14138169586658478, 0.10731200873851776, 0.1380433887243271, 0.18743085861206055, 0.18236865103244781, 0.18753862380981445, 0.17695613205432892, 0.22876031696796417, 0.18313631415367126, 0.1394353210926056, 0.21942242980003357, 0.17339326441287994, 0.17885765433311462, 0.1352696269750595, 0.23080269992351532, 0.10709255933761597, 0.1817084401845932, 0.10722094774246216, 0.13283273577690125, 0.10704397410154343, 0.17876321077346802, 0.10708526521921158, 0.18341729044914246, 0.10677932947874069, 0.14316153526306152, 0.14042972028255463, 0.21807090938091278, 0.14183880388736725, 0.13939502835273743, 0.18924109637737274, 0.10621775686740875, 0.18103551864624023, 0.176569864153862, 0.1416061520576477, 0.13644376397132874, 0.13667599856853485, 0.18462619185447693, 0.17617012560367584, 0.17203332483768463, 0.10550741851329803, 0.10551411658525467, 0.13687457144260406, 0.1752130091190338, 0.17240044474601746, 0.13525733351707458, 0.13819092512130737, 0.16921448707580566, 0.14132772386074066, 0.10476657748222351, 0.18304023146629333, 0.13858641684055328, 0.10436730086803436, 0.17365433275699615, 0.13706032931804657, 0.13819091022014618, 0.13577185571193695, 0.13241887092590332, 0.13339568674564362, 0.14407749474048615, 0.2757595181465149, 0.175409734249115, 0.1383604109287262, 0.1806619018316269, 0.1338924914598465, 0.10306181013584137, 0.1407984495162964, 0.17868927121162415, 0.22727082669734955, 0.13791318237781525, 0.13721497356891632, 0.1026851013302803, 0.18331260979175568, 0.19014248251914978, 0.14220428466796875, 0.14235828816890717, 0.187343567609787, 0.1388649344444275, 0.18457633256912231, 0.14045095443725586, 0.23472371697425842, 0.13850902020931244, 0.18170519173145294, 0.17785212397575378, 0.23077358305454254, 0.2395683228969574, 0.13746967911720276, 0.13520056009292603, 0.16992498934268951, 0.14331580698490143, 0.10218384116888046, 0.2189302295446396, 0.21629855036735535, 0.17941558361053467, 0.17945115268230438, 0.17105889320373535, 0.13253794610500336, 0.13512475788593292, 0.13385716080665588, 0.10243626683950424, 0.13699455559253693, 0.13379310071468353, 0.17103327810764313, 0.18903374671936035, 0.17712505161762238, 0.22951704263687134, 0.229618102312088, 0.1683281809091568, 0.17046478390693665, 0.14478559792041779, 0.14337290823459625, 0.1354917734861374, 0.13630710542201996, 0.10241403430700302, 0.17585717141628265, 0.18278701603412628, 0.17628328502178192, 0.1418936848640442, 0.21871602535247803, 0.1404867023229599, 0.18513578176498413, 0.1382921040058136, 0.10229324549436569, 0.2783657908439636, 0.17851850390434265, 0.18058864772319794, 0.17881280183792114, 0.17146693170070648, 0.17200428247451782, 0.14602985978126526, 0.14268924295902252, 0.1764698326587677, 0.14052365720272064, 0.18403521180152893, 0.13407446444034576, 0.1851176917552948, 0.14230941236019135, 0.1455599069595337, 0.17678818106651306, 0.13228417932987213, 0.17642037570476532, 0.13681797683238983, 0.17779211699962616, 0.10222821682691574, 0.16579066216945648, 0.17263977229595184, 0.13788007199764252, 0.22422708570957184, 0.18690185248851776, 0.1323680877685547, 0.21591506898403168, 0.17705968022346497, 0.17332421243190765, 0.18058672547340393, 0.1782134622335434, 0.13313798606395721, 0.22965623438358307, 0.1811295598745346, 0.14413250982761383, 0.10240518301725388, 0.2258971482515335, 0.18337799608707428, 0.1782081425189972, 0.17230229079723358, 0.17275597155094147, 0.13584592938423157, 0.23682965338230133, 0.18207968771457672, 0.1765073835849762, 0.14262650907039642, 0.231106698513031, 0.1402013897895813, 0.17100347578525543, 0.13188539445400238, 0.14282961189746857, 0.13915163278579712, 0.1856957972049713, 0.18344061076641083, 0.23004920780658722, 0.175686314702034, 0.1349557340145111, 0.184027761220932, 0.13827356696128845, 0.22424466907978058, 0.13759510219097137, 0.1358112245798111, 0.17430981993675232, 0.2393607497215271, 0.10347994416952133, 0.1036020964384079, 0.10348426550626755, 0.1739782840013504, 0.13301923871040344, 0.1350541114807129, 0.18580804765224457, 0.10323541611433029, 0.17826354503631592, 0.1030711904168129, 0.16976234316825867, 0.14314183592796326, 0.14518852531909943, 0.18816150724887848, 0.16687913239002228, 0.17355778813362122, 0.21990863978862762, 0.1364850103855133, 0.14517632126808167, 0.10251832008361816, 0.10245881229639053, 0.14247822761535645, 0.14325402677059174, 0.13547518849372864, 0.10212550312280655, 0.1337887942790985, 0.17229203879833221, 0.14018918573856354, 0.12731753289699554, 0.1381901204586029, 0.1364104151725769, 0.22810803353786469, 0.22262343764305115, 0.183828204870224, 0.13639312982559204, 0.1349630504846573, 0.19207842648029327, 0.1371501088142395, 0.16759176552295685, 0.13487839698791504, 0.22864574193954468, 0.14104396104812622, 0.1690800040960312, 0.17933930456638336, 0.18651555478572845, 0.16677306592464447, 0.17946642637252808, 0.14302697777748108, 0.2354416698217392, 0.13051371276378632, 0.17631889879703522, 0.14659906923770905, 0.171406552195549, 0.18398632109165192, 0.1011187881231308, 0.13362091779708862, 0.22758854925632477, 0.18527378141880035, 0.1354222595691681, 0.1895105093717575, 0.23964373767375946, 0.14142869412899017, 0.1843559890985489, 0.19275137782096863, 0.18013355135917664, 0.28045764565467834, 0.14543487131595612, 0.13573451340198517, 0.18174195289611816, 0.27974170446395874, 0.14131757616996765, 0.17998526990413666, 0.17816075682640076, 0.13110019266605377, 0.17176102101802826, 0.1019403487443924, 0.19199368357658386, 0.1416030377149582, 0.22324103116989136, 0.23524895310401917, 0.13288059830665588, 0.22821074724197388, 0.1024286076426506, 0.10237529128789902, 0.18508562445640564, 0.17812027037143707, 0.14221996068954468, 0.10237232595682144, 0.13892106711864471, 0.14010120928287506, 0.12815867364406586, 0.1307319551706314, 0.1924894005060196, 0.1020561158657074, 0.17246797680854797, 0.22912415862083435, 0.13297855854034424, 0.14125707745552063, 0.2789047956466675, 0.1357635110616684, 0.10191119462251663, 0.18678446114063263, 0.13310182094573975, 0.16892056167125702, 0.17217864096164703, 0.10179848223924637, 0.1809462159872055, 0.13161109387874603, 0.1866496056318283, 0.10161500424146652, 0.10164331644773483, 0.13342079520225525, 0.14007937908172607, 0.13831110298633575, 0.10125724226236343, 0.17597271502017975, 0.1749187707901001, 0.18377377092838287, 0.22949865460395813, 0.19279521703720093, 0.1814427524805069, 0.18601004779338837, 0.2217828631401062, 0.1008676290512085, 0.2809828221797943, 0.18514598906040192, 0.22574004530906677, 0.21937763690948486, 0.1358555108308792, 0.14619791507720947, 0.2218899428844452, 0.13813340663909912, 0.17296230792999268, 0.13652370870113373, 0.22251732647418976, 0.14159725606441498, 0.18771356344223022, 0.18075446784496307, 0.13978952169418335, 0.22747570276260376, 0.18544045090675354, 0.1732812523841858, 0.14314095675945282, 0.14298798143863678, 0.1352921724319458, 0.1816890984773636, 0.23105494678020477, 0.13833162188529968, 0.18322227895259857, 0.22257143259048462, 0.18192492425441742, 0.14073263108730316, 0.10245934128761292, 0.13354487717151642, 0.18268172442913055, 0.10238884389400482, 0.181378573179245, 0.13944043219089508, 0.18260841071605682, 0.18002627789974213, 0.1459653675556183, 0.17216463387012482, 0.1419316828250885, 0.21872495114803314, 0.23109057545661926, 0.1796134114265442, 0.22807282209396362, 0.19500957429409027, 0.18027067184448242, 0.13557535409927368, 0.18474777042865753, 0.17284418642520905, 0.14288972318172455, 0.10290664434432983, 0.1433287411928177, 0.18666721880435944, 0.1449936479330063, 0.1798253357410431, 0.12635011970996857, 0.1367776244878769, 0.27730515599250793, 0.10288843512535095, 0.13483315706253052, 0.14331361651420593, 0.10267557948827744, 0.1388579159975052, 0.17692086100578308, 0.13733500242233276, 0.1455240547657013, 0.1370270699262619, 0.22114939987659454, 0.18440964818000793, 0.18217644095420837, 0.17907769978046417, 0.1377870887517929, 0.22805655002593994, 0.148729607462883, 0.17887656390666962, 0.13614946603775024, 0.14637620747089386, 0.17850130796432495, 0.18080119788646698, 0.1787390112876892, 0.27830561995506287, 0.1344595104455948, 0.13200193643569946, 0.1623377501964569, 0.2187795341014862, 0.19116821885108948, 0.18104788661003113, 0.13940230011940002, 0.18581019341945648, 0.13866382837295532, 0.18301211297512054, 0.17203088104724884, 0.13314321637153625, 0.10255253314971924, 0.1025175154209137, 0.13687005639076233, 0.1408221423625946, 0.17982041835784912, 0.18613828718662262, 0.2226010411977768, 0.22307704389095306, 0.1848132461309433, 0.10248977690935135, 0.14807669818401337, 0.10247781872749329, 0.21558533608913422, 0.1761654019355774, 0.27796465158462524, 0.1379155069589615, 0.1833893060684204, 0.1754295974969864, 0.18321619927883148, 0.14742320775985718, 0.22643554210662842, 0.10261591523885727, 0.15272653102874756, 0.10261090099811554, 0.1364845484495163, 0.13536061346530914, 0.18596844375133514, 0.1406707465648651, 0.235752135515213, 0.22122985124588013, 0.14511118829250336, 0.10249626636505127, 0.1510840207338333, 0.17946824431419373, 0.22770914435386658, 0.18241572380065918, 0.13216224312782288, 0.10246718674898148, 0.18889965116977692, 0.15158073604106903, 0.18626172840595245, 0.13232959806919098, 0.13399440050125122, 0.22862322628498077, 0.13688747584819794, 0.1421107053756714, 0.10229136794805527, 0.10223681479692459, 0.17919740080833435, 0.17681528627872467, 0.18327756226062775, 0.2343227118253708, 0.17128191888332367, 0.10209992527961731, 0.22801384329795837, 0.18403999507427216, 0.10208762437105179, 0.1764235496520996, 0.18436996638774872, 0.1864124834537506, 0.13635984063148499, 0.1762717068195343, 0.19244824349880219, 0.18355171382427216, 0.22699502110481262, 0.19158096611499786, 0.22269733250141144, 0.13824684917926788, 0.22549761831760406, 0.14197783172130585, 0.18568731844425201, 0.19243597984313965, 0.18336738646030426, 0.22469842433929443, 0.14739897847175598, 0.14185403287410736, 0.14414380490779877, 0.22129277884960175, 0.13512985408306122, 0.1434047818183899, 0.18401211500167847, 0.22845053672790527, 0.1812688112258911, 0.19495250284671783, 0.17945945262908936, 0.14118222892284393, 0.14002075791358948, 0.10289005190134048, 0.13165691494941711, 0.13625112175941467, 0.13817694783210754, 0.1785270720720291, 0.22519506514072418, 0.10276662558317184, 0.17817901074886322, 0.1797662079334259, 0.2265162169933319, 0.2289131134748459, 0.17914645373821259, 0.14122948050498962, 0.10281500220298767, 0.13545642793178558, 0.1395578682422638, 0.175214022397995, 0.10278616845607758, 0.10274812579154968, 0.14099179208278656, 0.18189135193824768, 0.17924560606479645, 0.18080738186836243, 0.1861366331577301, 0.14556512236595154, 0.1783583015203476, 0.13274551928043365, 0.13673873245716095, 0.1024431437253952, 0.18074814975261688, 0.102352574467659, 0.22899232804775238, 0.10229205340147018, 0.13615010678768158, 0.1372940093278885, 0.2782111167907715, 0.13520634174346924, 0.13606306910514832, 0.22925497591495514, 0.10209318995475769, 0.22325779497623444, 0.14507964253425598, 0.17849969863891602, 0.2274724543094635, 0.18371345102787018, 0.22509683668613434, 0.16806049644947052, 0.13652749359607697, 0.18736353516578674, 0.14067082107067108, 0.18324054777622223, 0.17712274193763733, 0.13508975505828857, 0.17769885063171387, 0.10240350663661957, 0.13526615500450134, 0.13741643726825714, 0.13602016866207123, 0.13794183731079102, 0.17305579781532288, 0.17793139815330505, 0.17524535953998566, 0.1378372758626938, 0.13825049996376038, 0.27818262577056885, 0.10211252421140671, 0.22194825112819672, 0.17587333917617798, 0.14443473517894745, 0.17486128211021423, 0.13683611154556274, 0.14025026559829712, 0.13421182334423065, 0.18664157390594482, 0.2345459759235382, 0.22125378251075745, 0.12993206083774567, 0.18224363029003143, 0.18747837841510773, 0.2221456915140152, 0.13856790959835052, 0.1381385624408722, 0.10232483595609665, 0.18388628959655762, 0.13581112027168274, 0.17621804773807526, 0.22496184706687927, 0.13449743390083313, 0.10234148800373077, 0.1785190850496292, 0.10229380428791046, 0.10233082622289658, 0.1872042715549469, 0.18363966047763824, 0.23124651610851288, 0.13483130931854248, 0.1397019624710083, 0.1810695230960846, 0.13791057467460632, 0.18802008032798767, 0.1804797649383545, 0.13589884340763092, 0.1835656613111496, 0.13353663682937622, 0.10216237604618073, 0.23001635074615479, 0.16879677772521973, 0.14212095737457275, 0.10212492197751999, 0.17847971618175507, 0.18027107417583466, 0.1416851431131363, 0.13283859193325043, 0.14106076955795288, 0.17819979786872864, 0.14447849988937378, 0.18733155727386475, 0.1792365312576294, 0.16933196783065796, 0.13958068192005157, 0.17810942232608795, 0.13663576543331146, 0.1311367005109787, 0.13896480202674866, 0.13504961133003235, 0.10164851695299149, 0.10162162780761719, 0.1344243586063385, 0.1794113665819168, 0.19044478237628937, 0.10151325911283493, 0.1364911049604416, 0.10134334862232208, 0.23173373937606812, 0.13715580105781555, 0.13494929671287537, 0.178248792886734, 0.22446955740451813, 0.17966505885124207, 0.2804846465587616, 0.10119908303022385, 0.22741606831550598, 0.2325340360403061, 0.1816856861114502, 0.17670732736587524, 0.13859723508358002, 0.21903292834758759, 0.17579832673072815, 0.16917060315608978, 0.10140709578990936, 0.17153026163578033, 0.18519271910190582, 0.18279553949832916, 0.1395784616470337, 0.1335112601518631, 0.1810334026813507, 0.17043191194534302, 0.13826675713062286, 0.1389474719762802, 0.1726788580417633, 0.17140628397464752, 0.2213180959224701, 0.148959219455719, 0.17684505879878998, 0.2795169949531555, 0.22462010383605957, 0.1307477056980133, 0.18175767362117767, 0.18605032563209534, 0.13837981224060059, 0.1341876983642578, 0.17529495060443878, 0.14381666481494904, 0.1824784278869629, 0.18623006343841553, 0.22908054292201996, 0.279110848903656, 0.178107351064682, 0.1019357368350029, 0.14146843552589417, 0.18251211941242218, 0.1020423173904419, 0.13852857053279877, 0.17590047419071198, 0.17997603118419647, 0.18138626217842102, 0.1393081396818161, 0.22822237014770508, 0.13516074419021606, 0.2783345580101013, 0.18304306268692017, 0.18582424521446228, 0.14200608432292938, 0.22046644985675812, 0.17922791838645935, 0.17449761927127838, 0.1391599327325821, 0.18430712819099426, 0.1777409017086029, 0.2298942506313324, 0.18137814104557037, 0.13989566266536713, 0.17548079788684845, 0.13775908946990967, 0.14520075917243958, 0.1331097036600113, 0.17016781866550446, 0.1705981343984604, 0.2288389950990677, 0.18452949821949005, 0.10256393253803253, 0.1807803064584732, 0.10258732736110687, 0.13313212990760803, 0.13842542469501495, 0.17780256271362305, 0.1716698557138443, 0.10252445191144943, 0.22539874911308289, 0.13237173855304718, 0.10245794802904129, 0.18010981380939484, 0.180124431848526, 0.21860811114311218, 0.17934373021125793, 0.10246991366147995, 0.10245341807603836, 0.22737398743629456, 0.13761736452579498, 0.18311631679534912, 0.10248773545026779, 0.1389152556657791, 0.17868764698505402, 0.2299758642911911, 0.21897800266742706, 0.23525458574295044, 0.10249295830726624, 0.22646181285381317, 0.10244760662317276, 0.10243313759565353, 0.18043303489685059, 0.1393236666917801, 0.18484604358673096, 0.18152157962322235, 0.18600064516067505, 0.18124857544898987, 0.1387064903974533, 0.18104837834835052, 0.13894325494766235, 0.18051868677139282, 0.14213888347148895, 0.18565091490745544, 0.14306187629699707, 0.13406652212142944, 0.18458323180675507, 0.18836772441864014, 0.14426298439502716, 0.10236600041389465, 0.17650361359119415, 0.18475119769573212, 0.22534185647964478, 0.13658994436264038, 0.10237155854701996, 0.17344963550567627, 0.13343796133995056, 0.14185553789138794, 0.1333242654800415, 0.13454781472682953, 0.22155830264091492, 0.14200648665428162, 0.13730135560035706, 0.10230527818202972, 0.23436133563518524, 0.10225726664066315, 0.14200295507907867, 0.13363279402256012, 0.22777441143989563, 0.14197418093681335, 0.2290397435426712, 0.14221307635307312, 0.27827775478363037, 0.14208152890205383, 0.17249219119548798, 0.1381167471408844, 0.13640081882476807, 0.1852153241634369, 0.14080068469047546, 0.12986624240875244, 0.22086501121520996, 0.13219551742076874, 0.22461451590061188, 0.16732044517993927, 0.15114206075668335, 0.14517371356487274, 0.14763253927230835, 0.1371910274028778, 0.19036196172237396, 0.22127380967140198, 0.14303433895111084, 0.17044800519943237, 0.16846318542957306, 0.18125268816947937, 0.18040971457958221, 0.18329675495624542, 0.1435997039079666, 0.1870025396347046, 0.2221783846616745, 0.2306365817785263, 0.13029515743255615, 0.102199487388134, 0.14146360754966736, 0.13541042804718018, 0.17008768022060394, 0.13434717059135437, 0.1767006665468216, 0.17140525579452515, 0.14545796811580658, 0.1318427324295044, 0.10215885192155838, 0.13186515867710114, 0.13963089883327484, 0.10213541984558105, 0.13555051386356354, 0.14400675892829895, 0.1818685233592987, 0.23091217875480652, 0.13837526738643646, 0.17826710641384125, 0.18258842825889587, 0.10206396132707596, 0.13530270755290985, 0.17492377758026123, 0.17603419721126556, 0.17427867650985718, 0.22532705962657928, 0.18230696022510529, 0.17597681283950806, 0.17394287884235382, 0.10199321806430817, 0.13762600719928741, 0.17775915563106537, 0.1441579908132553, 0.19058392941951752, 0.18163879215717316, 0.14092616736888885, 0.17437268793582916, 0.13822856545448303, 0.2786496877670288, 0.18337468802928925, 0.13643063604831696, 0.1743881106376648, 0.22445863485336304, 0.1462920606136322, 0.1340080350637436, 0.1816280037164688, 0.18422280251979828, 0.18342901766300201, 0.23307161033153534, 0.18177193403244019, 0.17813292145729065, 0.1366857886314392, 0.14034919440746307, 0.21561387181282043, 0.10208411514759064, 0.13143408298492432, 0.13867658376693726, 0.13095629215240479, 0.18061111867427826, 0.13581660389900208, 0.1859128624200821, 0.14070677757263184, 0.18276208639144897, 0.18127606809139252, 0.10209328681230545, 0.14257101714611053, 0.13255785405635834, 0.13591478765010834, 0.1021045446395874, 0.22006374597549438, 0.13694283366203308, 0.10198751091957092, 0.12972944974899292, 0.10200375318527222, 0.22215710580348969, 0.17305421829223633, 0.18784384429454803, 0.23319610953330994, 0.1366007775068283, 0.10194399207830429, 0.2265140414237976, 0.18541017174720764, 0.1801983267068863, 0.14016230404376984, 0.21796609461307526, 0.1298804134130478, 0.10200279951095581, 0.2285824567079544, 0.2786253094673157, 0.21807314455509186, 0.1352228969335556, 0.14868468046188354, 0.10193412005901337, 0.18263640999794006, 0.13942743837833405, 0.17691536247730255, 0.13408292829990387, 0.17654286324977875, 0.10197421908378601, 0.18802732229232788, 0.1819174438714981, 0.17752833664417267, 0.1803966760635376, 0.22235265374183655, 0.17813760042190552, 0.13780638575553894, 0.1452077031135559, 0.13591979444026947, 0.23519665002822876, 0.17222923040390015, 0.1388029158115387, 0.10202297568321228, 0.1743631809949875, 0.10202259570360184, 0.22736181318759918, 0.10201015323400497, 0.1379198133945465, 0.1377272605895996, 0.14741387963294983, 0.18153485655784607, 0.2787072956562042, 0.10193703323602676, 0.18664492666721344, 0.1797834038734436, 0.1390627771615982, 0.14328160881996155, 0.17274808883666992, 0.1720748096704483, 0.17855627834796906, 0.13292507827281952, 0.23388011753559113, 0.10202554613351822, 0.14435255527496338, 0.1775701940059662, 0.10193455219268799, 0.17658869922161102, 0.13867983222007751, 0.10194949060678482, 0.17854368686676025, 0.22250141203403473, 0.13757401704788208, 0.18090766668319702, 0.22356709837913513, 0.10197190195322037, 0.10199502110481262, 0.13283081352710724, 0.10197631269693375, 0.1837904453277588, 0.18136924505233765, 0.18901854753494263, 0.14003349840641022, 0.10196344554424286, 0.22456876933574677, 0.1401863992214203, 0.1364528089761734, 0.16941510140895844, 0.13487717509269714, 0.18525110185146332, 0.2272675335407257, 0.1758950650691986, 0.1331600397825241, 0.10198608040809631, 0.22416804730892181, 0.10205747187137604, 0.13996575772762299, 0.17643943428993225, 0.17385433614253998, 0.21945428848266602, 0.13709649443626404, 0.17970949411392212, 0.1422538161277771, 0.1371970772743225, 0.2319840043783188, 0.14516784250736237]\n",
            "Val loss 0.16672122858964453\n",
            "Val auc roc 0.5\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df11765-217c-474c-e5c5-478009c7d790"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "357c2392-bc11-45e1-f848-c50db680606f"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "437c1435-63d2-418e-e4de-ff1e629b5b9c"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "7923ecbb-7f8e-4f8c-d336-447f315eae5e"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Generalized_Hate]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ec32c9b8-06be-4aa3-b409-dac1a64be2f3"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-07-28 11:14:53.792686'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}