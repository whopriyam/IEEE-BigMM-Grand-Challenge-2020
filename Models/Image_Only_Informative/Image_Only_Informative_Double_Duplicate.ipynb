{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Only_Informative_Double_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbe296aac73f4f899728f4c6b11a39b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0da31fc6fd024f81882d41811052ee1d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8a6770c576d4d16922247a8937925c7",
              "IPY_MODEL_9669b6490acc444b8a00efbb0632d95f"
            ]
          }
        },
        "0da31fc6fd024f81882d41811052ee1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8a6770c576d4d16922247a8937925c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a9ae4f1e0df14767908a29c77c16f82d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7eadb62a83664acbbb2c4a8204d90508"
          }
        },
        "9669b6490acc444b8a00efbb0632d95f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f0f67d2e5dd4a50819fb56da83ba6ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:05&lt;00:00, 41.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa7f4478536b424ebbd9459273fb0929"
          }
        },
        "a9ae4f1e0df14767908a29c77c16f82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7eadb62a83664acbbb2c4a8204d90508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f0f67d2e5dd4a50819fb56da83ba6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa7f4478536b424ebbd9459273fb0929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7dc628c46314cd0b402c2de9b48a051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7631ce823d284a5f95379c9207658c7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fbb798161ed2437fbc52d03fdd00a95b",
              "IPY_MODEL_2ef496af955a456ba722e9aad49bd563"
            ]
          }
        },
        "7631ce823d284a5f95379c9207658c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbb798161ed2437fbc52d03fdd00a95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01d895c6ad1248dc9cce469669ebc1f2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a776c521d0cc4f31b52aaa4db266dc48"
          }
        },
        "2ef496af955a456ba722e9aad49bd563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1648e64e2f14d61abc545fd00991333",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2656/2656 [2:22:33&lt;00:00,  3.22s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc8503febee647a8ab73fc6daf9d071b"
          }
        },
        "01d895c6ad1248dc9cce469669ebc1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a776c521d0cc4f31b52aaa4db266dc48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1648e64e2f14d61abc545fd00991333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc8503febee647a8ab73fc6daf9d071b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fca0db3f23fa4377807876ac735932eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b5a7525126344cd8a7d054b9e353e90a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1718953501b0429a8a282d59432a8eff",
              "IPY_MODEL_12fa3bcf9c4b47d3a71d5b35d410fe23"
            ]
          }
        },
        "b5a7525126344cd8a7d054b9e353e90a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1718953501b0429a8a282d59432a8eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fcd01643ea624b1a940c3ed6db57d0f4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39c36024bdb54a1eb488ab43e3da1753"
          }
        },
        "12fa3bcf9c4b47d3a71d5b35d410fe23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_010e9cda646a42e2834dfd91fe6ddcd3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2656/2656 [45:54&lt;00:00,  1.04s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa5e6767262a4041b9951d1d53c0dac2"
          }
        },
        "fcd01643ea624b1a940c3ed6db57d0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39c36024bdb54a1eb488ab43e3da1753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "010e9cda646a42e2834dfd91fe6ddcd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa5e6767262a4041b9951d1d53c0dac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9478b6bb9566476d917e2c64df504ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a1f2c340633d4e91b5724ed53791f45a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_579d491ef5d44825a7ff1e5ac54270eb",
              "IPY_MODEL_11adcf7f8ada4cdc9efe47aabc41759e"
            ]
          }
        },
        "a1f2c340633d4e91b5724ed53791f45a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "579d491ef5d44825a7ff1e5ac54270eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07322a9edfc94abd8f873488689180a9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f581f45309824c79bbb4db8e8c6fe1ff"
          }
        },
        "11adcf7f8ada4cdc9efe47aabc41759e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9a4af5b64f6b43a7a19d28502d34d785",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2656/2656 [45:38&lt;00:00,  1.03s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbfa40cc04214a67bae1abf82d8080ad"
          }
        },
        "07322a9edfc94abd8f873488689180a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f581f45309824c79bbb4db8e8c6fe1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a4af5b64f6b43a7a19d28502d34d785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbfa40cc04214a67bae1abf82d8080ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1d03f1e6-fb85-49af-9903-3ea391a4aab8"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 15.42 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4d5926e-2351-487c-9e5e-5519a312a728"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d59d327-f34b-41fb-9944-9a14cc494491"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "459bf7b5-df0c-47e9-c1ef-1f1e9fd3b2b5"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bd55ec84-5761-41af-a0d4-c1a7f3c226d3"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "c6717390-ffa4-472f-bb2e-abf6f9629689"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/torchvision/\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c3988af8-58c3-44eb-884d-d35f5b2447bd"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ab6cf67b-30db-45bc-f26a-c3e802cdafd3"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "bec6f2d7-1943-4b9c-d03d-239e44583b82"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e650609d-b4ce-4e60-d2a1-f53f64d9445e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    #MeToo shakes India, why is movement important...\n",
              "1    A man has just explained the #MeToo  movement ...\n",
              "2    Apparently YETI was #MeToo ‘d back in the day ...\n",
              "3    #MeToo: #VarunGrover seeks 'closure' with open...\n",
              "4                                        ption - no:2 \n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "843e574c-a06c-45f0-8c08-5b6b7be27a88"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:28<00:00, 14246672.39B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9557d76-9d3b-4c06-caca-6675c91c6c17"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 310921.58B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c1ab7147-29d4-4966-ba01-5bac33ae8fce"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cb1deb1-011f-43a1-f1c2-63a0e2a5268e"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            random.shuffle(text)\n",
        "            text3 = ' '.join(text)\n",
        "            df3['text'][i]=text3\n",
        "        self.data = self.data.append(df2, ignore_index=True)\n",
        "        self.data = self.data.append(df3, ignore_index=True)\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41406ace-b597-410d-b298-047dca63a9fd"
      },
      "source": [
        "col_name = \"Image_Only_Informative\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896,
          "referenced_widgets": [
            "cbe296aac73f4f899728f4c6b11a39b7",
            "0da31fc6fd024f81882d41811052ee1d",
            "d8a6770c576d4d16922247a8937925c7",
            "9669b6490acc444b8a00efbb0632d95f",
            "a9ae4f1e0df14767908a29c77c16f82d",
            "7eadb62a83664acbbb2c4a8204d90508",
            "3f0f67d2e5dd4a50819fb56da83ba6ca",
            "aa7f4478536b424ebbd9459273fb0929",
            "e7dc628c46314cd0b402c2de9b48a051",
            "7631ce823d284a5f95379c9207658c7d",
            "fbb798161ed2437fbc52d03fdd00a95b",
            "2ef496af955a456ba722e9aad49bd563",
            "01d895c6ad1248dc9cce469669ebc1f2",
            "a776c521d0cc4f31b52aaa4db266dc48",
            "e1648e64e2f14d61abc545fd00991333",
            "dc8503febee647a8ab73fc6daf9d071b",
            "fca0db3f23fa4377807876ac735932eb",
            "b5a7525126344cd8a7d054b9e353e90a",
            "1718953501b0429a8a282d59432a8eff",
            "12fa3bcf9c4b47d3a71d5b35d410fe23",
            "fcd01643ea624b1a940c3ed6db57d0f4",
            "39c36024bdb54a1eb488ab43e3da1753",
            "010e9cda646a42e2834dfd91fe6ddcd3",
            "aa5e6767262a4041b9951d1d53c0dac2",
            "9478b6bb9566476d917e2c64df504ac1",
            "a1f2c340633d4e91b5724ed53791f45a",
            "579d491ef5d44825a7ff1e5ac54270eb",
            "11adcf7f8ada4cdc9efe47aabc41759e",
            "07322a9edfc94abd8f873488689180a9",
            "f581f45309824c79bbb4db8e8c6fe1ff",
            "9a4af5b64f6b43a7a19d28502d34d785",
            "cbfa40cc04214a67bae1abf82d8080ad"
          ]
        },
        "outputId": "3efbc242-742e-4fcc-bf32-273ddf34be0f"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New data length : 10626\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 2622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbe296aac73f4f899728f4c6b11a39b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7dc628c46314cd0b402c2de9b48a051",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2656.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1747\n",
            "Train Losses : [0.22920000553131104, 0.2720686197280884, 0.03858200088143349, 4.137943744659424, 1.8087536096572876, 2.2952136993408203, 1.3876978158950806, 0.3023172914981842, 0.23854348063468933, 0.26569023728370667, 1.3534272909164429, 1.1936722993850708, 1.1908025741577148, 0.5548096895217896, 0.6840572953224182, 0.1943003088235855, 0.14460261166095734, 0.019362814724445343, 0.09120859950780869, 0.9922268986701965, 0.747309148311615, 0.4145759344100952, 0.08301092684268951, 0.30985793471336365, 0.39021652936935425, 0.16399361193180084, 0.1606774926185608, 0.15833750367164612, 0.06996931880712509, 0.2140474170446396, 0.16327159106731415, 0.41190847754478455, 0.1737089902162552, 0.5581939816474915, 0.1087174192070961, 0.3373550772666931, 0.30783823132514954, 0.177610382437706, 0.18089811503887177, 0.06640175729990005, 0.06605464965105057, 0.09677814692258835, 0.2647928297519684, 0.15012122690677643, 0.055531397461891174, 0.17119701206684113, 0.1841394305229187, 0.14666958153247833, 0.2874915897846222, 0.346831738948822, 0.3986361622810364, 0.18653234839439392, 0.1891666054725647, 0.12831446528434753, 0.19464914500713348, 0.11256235837936401, 0.14642246067523956, 0.5544918179512024, 0.17885559797286987, 0.12942346930503845, 0.2615373134613037, 0.1693865954875946, 0.07440845668315887, 0.13009491562843323, 0.3037521243095398, 0.05714043229818344, 0.2286624014377594, 0.2246510088443756, 0.25411516427993774, 0.257641077041626, 0.25225743651390076, 0.1350596845149994, 0.2447117567062378, 0.152700737118721, 0.26494717597961426, 0.11080074310302734, 0.11999937146902084, 0.1634758859872818, 0.16170373558998108, 0.2210656702518463, 0.2040708065032959, 0.08604622632265091, 0.10500776022672653, 0.21774686872959137, 0.2946084439754486, 0.13127566874027252, 0.15637333691120148, 0.15512529015541077, 0.06528519093990326, 0.10328444093465805, 0.17161715030670166, 0.30824917554855347, 0.40945419669151306, 0.1886194795370102, 0.25485843420028687, 0.12259473651647568, 0.12613031268119812, 0.08695641905069351, 0.0785953477025032, 0.17036646604537964, 0.08264214545488358, 0.0777386948466301, 0.26470082998275757, 0.465838223695755, 0.2695325016975403, 0.09400486201047897, 0.06951029598712921, 0.07135611027479172, 0.3335098624229431, 0.12851308286190033, 0.08165156841278076, 0.264085054397583, 0.1031455248594284, 0.2559974491596222, 0.2549757957458496, 0.3188762366771698, 0.21089789271354675, 0.2025110125541687, 0.11786516010761261, 0.253587007522583, 0.17877063155174255, 0.20773226022720337, 0.0797085165977478, 0.1130392774939537, 0.10085704177618027, 0.2101738452911377, 0.10887888073921204, 0.11549296230077744, 0.09661261737346649, 0.28314337134361267, 0.0941006988286972, 0.21186615526676178, 0.1211748942732811, 0.2548215687274933, 0.26396411657333374, 0.1744963526725769, 0.21314126253128052, 0.14032390713691711, 0.20294681191444397, 0.07166372239589691, 0.1455298811197281, 0.10061677545309067, 0.2510994076728821, 0.1424499750137329, 0.2798907458782196, 0.23151277005672455, 0.11615455150604248, 0.1408533751964569, 0.2380993664264679, 0.28811487555503845, 0.1183651015162468, 0.1416461169719696, 0.054364196956157684, 0.16035175323486328, 0.08862077444791794, 0.1531342715024948, 0.26686540246009827, 0.2816498279571533, 0.21101073920726776, 0.2752048373222351, 0.16094346344470978, 0.16368882358074188, 0.1803349107503891, 0.14214597642421722, 0.09929697215557098, 0.45860204100608826, 0.19880233705043793, 0.141484335064888, 0.2566683888435364, 0.10188093036413193, 0.14411276578903198, 0.1413620412349701, 0.16851869225502014, 0.13026267290115356, 0.3500310182571411, 0.17772696912288666, 0.09225071966648102, 0.1212223619222641, 0.32403871417045593, 0.11948975175619125, 0.11526601761579514, 0.23915477097034454, 0.11164270341396332, 0.4071028530597687, 0.10345517098903656, 0.29114407300949097, 0.13989250361919403, 0.11098899692296982, 0.28119322657585144, 0.18200615048408508, 0.10816273838281631, 0.19460783898830414, 0.21192799508571625, 0.1102287545800209, 0.1290953904390335, 0.10951374471187592, 0.11829514056444168, 0.30437254905700684, 0.12745647132396698, 0.16058528423309326, 0.282027930021286, 0.2878117263317108, 0.2555926740169525, 0.2657393515110016, 0.12103842943906784, 0.2698630392551422, 0.15919405221939087, 0.2312617003917694, 0.16411717236042023, 0.19273750483989716, 0.16162942349910736, 0.1618623286485672, 0.1819782555103302, 0.21716366708278656, 0.13971443474292755, 0.13356928527355194, 0.22238057851791382, 0.16165272891521454, 0.13610327243804932, 0.20066975057125092, 0.1374283879995346, 0.20172853767871857, 0.1944604516029358, 0.16041725873947144, 0.22818098962306976, 0.1299200803041458, 0.13554821908473969, 0.13365182280540466, 0.15443868935108185, 0.1912367194890976, 0.1672951877117157, 0.1771521270275116, 0.1455288976430893, 0.24331530928611755, 0.17586477100849152, 0.1284209042787552, 0.1562277376651764, 0.13650809228420258, 0.12576612830162048, 0.15879328548908234, 0.1659557968378067, 0.23394827544689178, 0.250191867351532, 0.10023574531078339, 0.21503372490406036, 0.16310620307922363, 0.12740620970726013, 0.09329967200756073, 0.1500052511692047, 0.20369796454906464, 0.12866592407226562, 0.19386006891727448, 0.0862542912364006, 0.15538160502910614, 0.18140092492103577, 0.08260650187730789, 0.1894916296005249, 0.07963962852954865, 0.2984905242919922, 0.18366552889347076, 0.07818540185689926, 0.12918223440647125, 0.18987655639648438, 0.12872472405433655, 0.12623849511146545, 0.3592199385166168, 0.07463148236274719, 0.11699999868869781, 0.2572425901889801, 0.07769487798213959, 0.11339419335126877, 0.24119803309440613, 0.11769796907901764, 0.1540449857711792, 0.25848716497421265, 0.20156601071357727, 0.1830744594335556, 0.13872864842414856, 0.2402660995721817, 0.19666725397109985, 0.15035085380077362, 0.22184211015701294, 0.19193235039710999, 0.15377332270145416, 0.1577131599187851, 0.2871546447277069, 0.18801826238632202, 0.11320631206035614, 0.16402527689933777, 0.14139579236507416, 0.22417378425598145, 0.2673778831958771, 0.12398582696914673, 0.12765850126743317, 0.2140650898218155, 0.14088547229766846, 0.12208360433578491, 0.16116057336330414, 0.25142985582351685, 0.2119140475988388, 0.11937474459409714, 0.21742714941501617, 0.11655162274837494, 0.09269803017377853, 0.15004704892635345, 0.11474838852882385, 0.24359403550624847, 0.10801991075277328, 0.21820297837257385, 0.21705083549022675, 0.21653006970882416, 0.1037808433175087, 0.1662893295288086, 0.2377522736787796, 0.29055026173591614, 0.2814466059207916, 0.1062784418463707, 0.264108806848526, 0.2317637801170349, 0.2169693261384964, 0.1188364252448082, 0.15283381938934326, 0.1595187485218048, 0.1734050065279007, 0.244758740067482, 0.22300666570663452, 0.1937716156244278, 0.2034604698419571, 0.23887796700000763, 0.16688749194145203, 0.19583648443222046, 0.15240681171417236, 0.12947440147399902, 0.19702498614788055, 0.16922350227832794, 0.17695163190364838, 0.1521073579788208, 0.19487211108207703, 0.16966474056243896, 0.15943419933319092, 0.17035633325576782, 0.2300693243741989, 0.15709616243839264, 0.1545019894838333, 0.1857774555683136, 0.17130953073501587, 0.14701026678085327, 0.16989515721797943, 0.1615578532218933, 0.19005203247070312, 0.1528857797384262, 0.18124452233314514, 0.16302278637886047, 0.12980416417121887, 0.14809350669384003, 0.17871308326721191, 0.21141904592514038, 0.12293345481157303, 0.14739203453063965, 0.14989598095417023, 0.1766756772994995, 0.21787934005260468, 0.1725553572177887, 0.17845387756824493, 0.1964443176984787, 0.18508878350257874, 0.1597779095172882, 0.10611265152692795, 0.1682535707950592, 0.17736679315567017, 0.18568746745586395, 0.11111779510974884, 0.14039239287376404, 0.14986641705036163, 0.1926283985376358, 0.21149767935276031, 0.2001655399799347, 0.095531165599823, 0.18365155160427094, 0.196513369679451, 0.10021189600229263, 0.16484077274799347, 0.14562015235424042, 0.16175496578216553, 0.1417911946773529, 0.18200631439685822, 0.1265314817428589, 0.13423565030097961, 0.1428285837173462, 0.2696637809276581, 0.14856219291687012, 0.20131701231002808, 0.13911838829517365, 0.09566888958215714, 0.19608955085277557, 0.16330784559249878, 0.1291171759366989, 0.1362062692642212, 0.1643938273191452, 0.09744483232498169, 0.12700046598911285, 0.21749193966388702, 0.2023628205060959, 0.13869395852088928, 0.09299501031637192, 0.09964195638895035, 0.29341620206832886, 0.1518683284521103, 0.18319199979305267, 0.11517191678285599, 0.16188842058181763, 0.2226366251707077, 0.08087627589702606, 0.11992480605840683, 0.12664048373699188, 0.07722222805023193, 0.2588053047657013, 0.24878256022930145, 0.22144152224063873, 0.10656271129846573, 0.08903975784778595, 0.08698547631502151, 0.3242798447608948, 0.33652716875076294, 0.2752273380756378, 0.22905415296554565, 0.202159583568573, 0.18184763193130493, 0.140274316072464, 0.30263030529022217, 0.2695316970348358, 0.15002815425395966, 0.1349126696586609, 0.22808775305747986, 0.208854541182518, 0.14086057245731354, 0.23763805627822876, 0.24841730296611786, 0.11216625571250916, 0.21420544385910034, 0.16096225380897522, 0.14852383732795715, 0.15290869772434235, 0.14751537144184113, 0.14705674350261688, 0.1474844217300415, 0.15249626338481903, 0.23517441749572754, 0.19237641990184784, 0.1379786878824234, 0.11111274361610413, 0.15957379341125488, 0.13255780935287476, 0.21152235567569733, 0.19528771936893463, 0.10562164336442947, 0.15652406215667725, 0.13358831405639648, 0.13794463872909546, 0.16970109939575195, 0.1916201412677765, 0.1833290457725525, 0.19473426043987274, 0.17494405806064606, 0.13767094910144806, 0.11935897916555405, 0.2075338214635849, 0.2290961593389511, 0.18254263699054718, 0.11618554592132568, 0.11277656257152557, 0.15490005910396576, 0.1751887947320938, 0.12227107584476471, 0.1352357119321823, 0.09652160853147507, 0.22822926938533783, 0.09539125859737396, 0.19652597606182098, 0.10460123419761658, 0.13773632049560547, 0.21859051287174225, 0.15869778394699097, 0.21161659061908722, 0.08803711831569672, 0.25471681356430054, 0.14277870953083038, 0.2209940105676651, 0.10673461854457855, 0.2256675362586975, 0.32307034730911255, 0.15841205418109894, 0.08944498747587204, 0.09008429199457169, 0.0908021628856659, 0.15173183381557465, 0.2676700949668884, 0.14057914912700653, 0.13199825584888458, 0.08860863745212555, 0.13116057217121124, 0.31710174679756165, 0.17924635112285614, 0.18382327258586884, 0.19395172595977783, 0.16348077356815338, 0.17351007461547852, 0.20925995707511902, 0.1516573131084442, 0.1498536467552185, 0.23834386467933655, 0.144908145070076, 0.18785375356674194, 0.21645380556583405, 0.19815027713775635, 0.14689265191555023, 0.13836878538131714, 0.19821856915950775, 0.1020079255104065, 0.16369155049324036, 0.19503889977931976, 0.16463850438594818, 0.1642574667930603, 0.1767820566892624, 0.13637834787368774, 0.1356016844511032, 0.22305141389369965, 0.18398045003414154, 0.13556276261806488, 0.23204950988292694, 0.1910848319530487, 0.10509303957223892, 0.16181132197380066, 0.18036086857318878, 0.19594259560108185, 0.2293873429298401, 0.1673375368118286, 0.2162332832813263, 0.17993322014808655, 0.17532646656036377, 0.11553879082202911, 0.15196478366851807, 0.1652589589357376, 0.15577125549316406, 0.18141911923885345, 0.16122478246688843, 0.1394825577735901, 0.1201358214020729, 0.118483766913414, 0.2069290429353714, 0.14433081448078156, 0.21217331290245056, 0.13752126693725586, 0.135719895362854, 0.11363886296749115, 0.17054933309555054, 0.17317424714565277, 0.258888840675354, 0.15151868760585785, 0.22520136833190918, 0.1085415780544281, 0.10893652588129044, 0.1558072715997696, 0.20716294646263123, 0.10475844144821167, 0.19862042367458344, 0.1901051253080368, 0.20444820821285248, 0.2202465683221817, 0.13892243802547455, 0.1588456630706787, 0.15752552449703217, 0.18370692431926727, 0.17474554479122162, 0.17492419481277466, 0.18891437351703644, 0.12025351822376251, 0.13616476953029633, 0.23074392974376678, 0.22589769959449768, 0.24663347005844116, 0.22566430270671844, 0.18084390461444855, 0.20245765149593353, 0.19155438244342804, 0.15539716184139252, 0.21669289469718933, 0.18081650137901306, 0.17113538086414337, 0.12520284950733185, 0.17572307586669922, 0.14746564626693726, 0.16259773075580597, 0.16243113577365875, 0.22960957884788513, 0.14008213579654694, 0.16637875139713287, 0.13139517605304718, 0.17390017211437225, 0.18973016738891602, 0.2053682506084442, 0.15865300595760345, 0.19739103317260742, 0.20988276600837708, 0.22521518170833588, 0.20084355771541595, 0.13806714117527008, 0.19933903217315674, 0.1917865127325058, 0.14031636714935303, 0.140359029173851, 0.1491173952817917, 0.13931885361671448, 0.13588747382164001, 0.19044126570224762, 0.1831982284784317, 0.17090608179569244, 0.17448993027210236, 0.125758558511734, 0.20835451781749725, 0.1940147429704666, 0.2125157117843628, 0.1784738153219223, 0.16525918245315552, 0.1486048549413681, 0.12184056639671326, 0.16348594427108765, 0.1455005556344986, 0.1542632281780243, 0.1471606343984604, 0.194014310836792, 0.1176375076174736, 0.11444097757339478, 0.17063391208648682, 0.17019236087799072, 0.20232290029525757, 0.10821660608053207, 0.26925891637802124, 0.12436264008283615, 0.1907302737236023, 0.10943454504013062, 0.10872823745012283, 0.13743670284748077, 0.16240420937538147, 0.18465912342071533, 0.11747757345438004, 0.2839023470878601, 0.19378621876239777, 0.10122038424015045, 0.12910105288028717, 0.1895243525505066, 0.2334330826997757, 0.14063522219657898, 0.2841636836528778, 0.2492864578962326, 0.14174659550189972, 0.18847790360450745, 0.14131636917591095, 0.18998025357723236, 0.17471547424793243, 0.11589251458644867, 0.22238986194133759, 0.1707652062177658, 0.14621314406394958, 0.13815121352672577, 0.2129170000553131, 0.12377146631479263, 0.17602713406085968, 0.1443902999162674, 0.19435636699199677, 0.1218385398387909, 0.17603805661201477, 0.22800007462501526, 0.1818227767944336, 0.11608389765024185, 0.16151441633701324, 0.14014557003974915, 0.1555679589509964, 0.18302509188652039, 0.19623857736587524, 0.16110342741012573, 0.1639377772808075, 0.21626347303390503, 0.180887833237648, 0.13819879293441772, 0.16268527507781982, 0.1875164955854416, 0.1136612594127655, 0.21675629913806915, 0.18165411055088043, 0.11451568454504013, 0.21589308977127075, 0.20758239924907684, 0.20779885351657867, 0.14657513797283173, 0.15420430898666382, 0.16471020877361298, 0.1154521033167839, 0.21043221652507782, 0.22821728885173798, 0.15076051652431488, 0.20651374757289886, 0.14764222502708435, 0.19309601187705994, 0.19218358397483826, 0.19005343317985535, 0.1277153342962265, 0.14613553881645203, 0.14729954302310944, 0.22923456132411957, 0.18583554029464722, 0.13949373364448547, 0.15191012620925903, 0.11737364530563354, 0.11750922352075577, 0.15977083146572113, 0.14378175139427185, 0.15055058896541595, 0.1487414836883545, 0.14897382259368896, 0.13530632853507996, 0.20823360979557037, 0.12723277509212494, 0.17047585546970367, 0.11032487452030182, 0.17244163155555725, 0.14984194934368134, 0.1851372867822647, 0.22614695131778717, 0.12085205316543579, 0.12420044839382172, 0.15939080715179443, 0.2116212546825409, 0.183846116065979, 0.2280738800764084, 0.28435713052749634, 0.2205224484205246, 0.14077125489711761, 0.09965036809444427, 0.19212137162685394, 0.10035622864961624, 0.20562687516212463, 0.11589548736810684, 0.14632725715637207, 0.16781364381313324, 0.1803765594959259, 0.09823170304298401, 0.1463482826948166, 0.09676098078489304, 0.0952288880944252, 0.14056311547756195, 0.1907026618719101, 0.274995893239975, 0.18551740050315857, 0.17084293067455292, 0.11875365674495697, 0.08881271630525589, 0.21027441322803497, 0.13949091732501984, 0.10095777362585068, 0.08691716939210892, 0.1543053686618805, 0.14991511404514313, 0.25967228412628174, 0.14489836990833282, 0.2227078378200531, 0.12697316706180573, 0.15869088470935822, 0.15884160995483398, 0.08409422636032104, 0.236918643116951, 0.1637909710407257, 0.21135802567005157, 0.1924366056919098, 0.178567573428154, 0.18091705441474915, 0.09073393046855927, 0.14859676361083984, 0.0922350287437439, 0.10859525948762894, 0.11754173040390015, 0.19451594352722168, 0.23193414509296417, 0.21022172272205353, 0.19580644369125366, 0.1549249291419983, 0.18101096153259277, 0.13048066198825836, 0.09712693095207214, 0.09645365178585052, 0.17062941193580627, 0.15824738144874573, 0.13300885260105133, 0.09605371206998825, 0.18108312785625458, 0.25273558497428894, 0.15560460090637207, 0.10034390538930893, 0.15610887110233307, 0.1352277249097824, 0.26214367151260376, 0.15075737237930298, 0.19306842982769012, 0.1879860907793045, 0.17979216575622559, 0.2255101054906845, 0.1676921844482422, 0.15456388890743256, 0.129137322306633, 0.15158537030220032, 0.2934299409389496, 0.11864578723907471, 0.11743692308664322, 0.12572774291038513, 0.16574500501155853, 0.11551296710968018, 0.09988990426063538, 0.13768553733825684, 0.1569005697965622, 0.09972035884857178, 0.11214540153741837, 0.1945957988500595, 0.12436659634113312, 0.24302254617214203, 0.16517481207847595, 0.18219034373760223, 0.10445604473352432, 0.24748818576335907, 0.2340722531080246, 0.16942977905273438, 0.13550631701946259, 0.17597158253192902, 0.16100773215293884, 0.15334247052669525, 0.12405490130186081, 0.14741498231887817, 0.1435832530260086, 0.19855304062366486, 0.21033088862895966, 0.08769682794809341, 0.13524076342582703, 0.17666666209697723, 0.23665088415145874, 0.2634187936782837, 0.14605927467346191, 0.16574375331401825, 0.22449934482574463, 0.13699206709861755, 0.2565338909626007, 0.1834670901298523, 0.09389173984527588, 0.2195984274148941, 0.19894124567508698, 0.17081283032894135, 0.12646201252937317, 0.16939420998096466, 0.14114835858345032, 0.15772393345832825, 0.20499137043952942, 0.28077515959739685, 0.1402415633201599, 0.23904500901699066, 0.1549386978149414, 0.17956414818763733, 0.11107441782951355, 0.16306854784488678, 0.16618768870830536, 0.1652618646621704, 0.1765395551919937, 0.11487080156803131, 0.16593462228775024, 0.11406809091567993, 0.11376038193702698, 0.17201276123523712, 0.12977267801761627, 0.10889071971178055, 0.24980825185775757, 0.14916640520095825, 0.24069201946258545, 0.2159503847360611, 0.27161768078804016, 0.1843632459640503, 0.1365172117948532, 0.14138838648796082, 0.1519865244626999, 0.13139711320400238, 0.18013383448123932, 0.22316238284111023, 0.13665533065795898, 0.11224539577960968, 0.12459581345319748, 0.20032504200935364, 0.19617998600006104, 0.14188510179519653, 0.21571017801761627, 0.16343767940998077, 0.2525821626186371, 0.16384749114513397, 0.15583452582359314, 0.13664668798446655, 0.1691519021987915, 0.1587953418493271, 0.16393791139125824, 0.21096043288707733, 0.17028991878032684, 0.13690592348575592, 0.1789911389350891, 0.15135829150676727, 0.1366100162267685, 0.21408569812774658, 0.1727372258901596, 0.15835700929164886, 0.23392218351364136, 0.18239833414554596, 0.2543179392814636, 0.19075408577919006, 0.14495417475700378, 0.16376592218875885, 0.17596687376499176, 0.19461579620838165, 0.16592945158481598, 0.19544808566570282, 0.19673627614974976, 0.1502957046031952, 0.15673375129699707, 0.23299933969974518, 0.16153906285762787, 0.1852281242609024, 0.21246807277202606, 0.17678038775920868, 0.16455642879009247, 0.13302850723266602, 0.1257774531841278, 0.15765467286109924, 0.16892103850841522, 0.14741073548793793, 0.19983695447444916, 0.21429918706417084, 0.22598059475421906, 0.18363545835018158, 0.161624014377594, 0.16185599565505981, 0.18799687922000885, 0.2224138081073761, 0.18297730386257172, 0.13613474369049072, 0.20056377351284027, 0.19166991114616394, 0.21442674100399017, 0.17302843928337097, 0.1511947214603424, 0.16138064861297607, 0.19541572034358978, 0.18095046281814575, 0.1958080381155014, 0.2048402726650238, 0.1686021089553833, 0.14913824200630188, 0.1490159034729004, 0.1925300806760788, 0.16929440200328827, 0.1685362309217453, 0.20179949700832367, 0.16780662536621094, 0.1628282070159912, 0.16156764328479767, 0.15970171988010406, 0.20671819150447845, 0.14310267567634583, 0.18192158639431, 0.2027198225259781, 0.16586388647556305, 0.19783003628253937, 0.14201973378658295, 0.17894777655601501, 0.20598523318767548, 0.15850986540317535, 0.13970425724983215, 0.18126067519187927, 0.13842375576496124, 0.17566576600074768, 0.17090179026126862, 0.16249892115592957, 0.1599564105272293, 0.16340717673301697, 0.19027236104011536, 0.1729768067598343, 0.16425670683383942, 0.1494998037815094, 0.1263420730829239, 0.20474256575107574, 0.13938863575458527, 0.17201310396194458, 0.15290558338165283, 0.13063906133174896, 0.11978165805339813, 0.14601919054985046, 0.1163082867860794, 0.21761400997638702, 0.2096257358789444, 0.15483640134334564, 0.11174393445253372, 0.12375041842460632, 0.26610860228538513, 0.15631377696990967, 0.1077057272195816, 0.10707256942987442, 0.27210620045661926, 0.1308598816394806, 0.20820459723472595, 0.10490158945322037, 0.19236423075199127, 0.21129436790943146, 0.15791115164756775, 0.14755907654762268, 0.14678645133972168, 0.1885073482990265, 0.22128058969974518, 0.18470801413059235, 0.14912226796150208, 0.18217366933822632, 0.12682582437992096, 0.2144845873117447, 0.16088604927062988, 0.1766372174024582, 0.2704305946826935, 0.26763299107551575, 0.18851105868816376, 0.19542227685451508, 0.20160464942455292, 0.11649998277425766, 0.22451914846897125, 0.20390790700912476, 0.2398643046617508, 0.1253134310245514, 0.15015998482704163, 0.1611766517162323, 0.1878960132598877, 0.1462099552154541, 0.18057772517204285, 0.1496410369873047, 0.13485032320022583, 0.1524609625339508, 0.21446019411087036, 0.21848002076148987, 0.187808096408844, 0.15436206758022308, 0.1978193074464798, 0.1384076625108719, 0.2151339054107666, 0.21794742345809937, 0.16538919508457184, 0.17170679569244385, 0.15157991647720337, 0.17325542867183685, 0.16360826790332794, 0.1625485122203827, 0.15544748306274414, 0.1595628410577774, 0.1567530333995819, 0.16472956538200378, 0.15796488523483276, 0.18586519360542297, 0.179446741938591, 0.1974959671497345, 0.16394494473934174, 0.13502070307731628, 0.1625998467206955, 0.17030709981918335, 0.1819581538438797, 0.15886613726615906, 0.16309666633605957, 0.14862599968910217, 0.14549458026885986, 0.19957703351974487, 0.2284231334924698, 0.24049092829227448, 0.15925966203212738, 0.1535898894071579, 0.1618766337633133, 0.18167856335639954, 0.14976270496845245, 0.16360987722873688, 0.1846878081560135, 0.18585626780986786, 0.19284042716026306, 0.16870887577533722, 0.14111660420894623, 0.15453200042247772, 0.16328367590904236, 0.15414193272590637, 0.12962712347507477, 0.13046470284461975, 0.12773412466049194, 0.2339283972978592, 0.18944212794303894, 0.18862247467041016, 0.18619371950626373, 0.1934954822063446, 0.1460176557302475, 0.1943199187517166, 0.18090088665485382, 0.20160235464572906, 0.12619081139564514, 0.18547001481056213, 0.19942054152488708, 0.13902851939201355, 0.21725605428218842, 0.12781991064548492, 0.14118672907352448, 0.20557092130184174, 0.15745210647583008, 0.15026156604290009, 0.1547115296125412, 0.1396242380142212, 0.18841299414634705, 0.15426182746887207, 0.1273689866065979, 0.12573254108428955, 0.16151750087738037, 0.22752539813518524, 0.20968182384967804, 0.21717940270900726, 0.13609685003757477, 0.12183914333581924, 0.13768519461154938, 0.13837933540344238, 0.1196596547961235, 0.20135138928890228, 0.1821216344833374, 0.1812065988779068, 0.22122330963611603, 0.18157446384429932, 0.14370320737361908, 0.1325811892747879, 0.20113301277160645, 0.15470853447914124, 0.15626856684684753, 0.22887545824050903, 0.125798299908638, 0.17156893014907837, 0.15213243663311005, 0.11323702335357666, 0.18339021503925323, 0.16408048570156097, 0.15565858781337738, 0.1607017070055008, 0.13435319066047668, 0.11007408797740936, 0.10878045856952667, 0.13921914994716644, 0.1534678339958191, 0.10432016104459763, 0.19439460337162018, 0.17048215866088867, 0.13035817444324493, 0.13987378776073456, 0.12427219748497009, 0.13707147538661957, 0.19699794054031372, 0.2084837406873703, 0.18092015385627747, 0.13197597861289978, 0.18242792785167694, 0.1799330860376358, 0.19379334151744843, 0.11988517642021179, 0.09004994481801987, 0.11880020797252655, 0.14499768614768982, 0.1479826718568802, 0.1802627146244049, 0.13401061296463013, 0.1778959035873413, 0.12313293665647507, 0.17587384581565857, 0.22201694548130035, 0.08282703161239624, 0.17710943520069122, 0.25600960850715637, 0.19332340359687805, 0.1715860217809677, 0.20889690518379211, 0.1208164393901825, 0.3270954489707947, 0.261018842458725, 0.19938963651657104, 0.08886688947677612, 0.08997070044279099, 0.09093998372554779, 0.14597022533416748, 0.182718887925148, 0.24123260378837585, 0.12983326613903046, 0.09243611246347427, 0.12991765141487122, 0.09200237691402435, 0.19140644371509552, 0.13983505964279175, 0.1792317032814026, 0.23173834383487701, 0.18032579123973846, 0.19299060106277466, 0.17534953355789185, 0.20168355107307434, 0.09220336377620697, 0.19538642466068268, 0.17207477986812592, 0.13496479392051697, 0.12637750804424286, 0.12643158435821533, 0.14267100393772125, 0.14396525919437408, 0.23277270793914795, 0.19630786776542664, 0.13596506416797638, 0.2384592741727829, 0.1719260960817337, 0.17804816365242004, 0.16566920280456543, 0.24588964879512787, 0.1955677568912506, 0.17391404509544373, 0.0971967875957489, 0.17129254341125488, 0.11912008374929428, 0.0985097587108612, 0.18612417578697205, 0.13373856246471405, 0.1364622265100479, 0.23296979069709778, 0.17834316194057465, 0.14765390753746033, 0.15147143602371216, 0.11369860172271729, 0.17870555818080902, 0.1349409818649292, 0.12822647392749786, 0.09651366621255875, 0.19091756641864777, 0.1892615556716919, 0.18980132043361664, 0.2424401342868805, 0.15433841943740845, 0.178288996219635, 0.19143617153167725, 0.13785170018672943, 0.1808774322271347, 0.15154311060905457, 0.19227053225040436, 0.2188229262828827, 0.24126359820365906, 0.14154624938964844, 0.13385862112045288, 0.24206854403018951, 0.10024286061525345, 0.18820983171463013, 0.14690449833869934, 0.10127607733011246, 0.10106294602155685, 0.1729775220155716, 0.18750819563865662, 0.09967108815908432, 0.135101318359375, 0.287512868642807, 0.18280619382858276, 0.1943856030702591, 0.13376484811306, 0.1330447643995285, 0.23347796499729156, 0.284370094537735, 0.10086225718259811, 0.14686362445354462, 0.17644958198070526, 0.1640254706144333, 0.14886197447776794, 0.17472659051418304, 0.10443960875272751, 0.16270768642425537, 0.13438628613948822, 0.10365204513072968, 0.23251742124557495, 0.14365358650684357, 0.12299194186925888, 0.13768549263477325, 0.17874789237976074, 0.10175159573554993, 0.14006127417087555, 0.09931149333715439, 0.0982760637998581, 0.24754028022289276, 0.12630826234817505, 0.2337394654750824, 0.17768710851669312, 0.09405950456857681, 0.1345061957836151, 0.13526774942874908, 0.17763476073741913, 0.21554428339004517, 0.2407294511795044, 0.1642741709947586, 0.14084158837795258, 0.09252391755580902, 0.09204668551683426, 0.13558512926101685, 0.24732330441474915, 0.09067581593990326, 0.17775525152683258, 0.19251812994480133, 0.18309257924556732, 0.14875446259975433, 0.14391030371189117, 0.1319459229707718, 0.17942997813224792, 0.12375403195619583, 0.1379905641078949, 0.12363056093454361, 0.20073409378528595, 0.318838894367218, 0.08650218695402145, 0.08672372996807098, 0.12883521616458893, 0.12511083483695984, 0.12630535662174225, 0.12554749846458435, 0.08383212238550186, 0.21226553618907928, 0.20205552875995636, 0.12675249576568604, 0.08062845468521118, 0.19725778698921204, 0.07862136512994766, 0.0779716819524765, 0.0763496458530426, 0.2609158456325531, 0.200700044631958, 0.188181534409523, 0.17427140474319458, 0.12424969673156738, 0.07294419407844543, 0.1236850842833519, 0.24321743845939636, 0.19290846586227417, 0.18781882524490356, 0.20338386297225952, 0.12477800250053406, 0.12810374796390533, 0.1919010728597641, 0.13955439627170563, 0.1245383694767952, 0.11856547743082047, 0.25677159428596497, 0.11797983944416046, 0.27855971455574036, 0.11763087660074234, 0.12257089465856552, 0.24033735692501068, 0.07623548805713654, 0.1371283084154129, 0.2612869441509247, 0.13031944632530212, 0.17867213487625122, 0.11225806176662445, 0.07980746030807495, 0.07970969378948212, 0.14233730733394623, 0.2661643624305725, 0.20066021382808685, 0.07911277562379837, 0.12149181216955185, 0.07887895405292511, 0.2596859037876129, 0.12380858510732651, 0.24130846560001373, 0.2420738935470581, 0.20328457653522491, 0.11757490783929825, 0.08157467842102051, 0.08222167193889618, 0.2608028054237366, 0.12231741100549698, 0.12932166457176208, 0.16986949741840363, 0.2029668390750885, 0.12404953688383102, 0.2545498013496399, 0.23321788012981415, 0.12753915786743164, 0.12273035943508148, 0.17671382427215576, 0.1185135468840599, 0.1840631067752838, 0.24639315903186798, 0.20961825549602509, 0.16848887503147125, 0.15918107330799103, 0.13678935170173645, 0.18400250375270844, 0.1822017878293991, 0.1337966024875641, 0.12004406005144119, 0.29319751262664795, 0.1288784295320511, 0.16968142986297607, 0.0999007597565651, 0.17444130778312683, 0.1330147385597229, 0.21033991873264313, 0.13266189396381378, 0.14956218004226685, 0.24609032273292542, 0.20102743804454803, 0.19777823984622955, 0.16457979381084442, 0.16461148858070374, 0.2793079912662506, 0.13084886968135834, 0.12878216803073883, 0.16313202679157257, 0.22274139523506165, 0.14581848680973053, 0.13113313913345337, 0.10726895928382874, 0.2361268848180771, 0.24084360897541046, 0.21082265675067902, 0.17782260477542877, 0.14858879148960114, 0.1795455813407898, 0.15939898788928986, 0.1132611632347107, 0.1413496881723404, 0.1388995498418808, 0.1477055549621582, 0.11298671364784241, 0.24036110937595367, 0.16444802284240723, 0.16141611337661743, 0.14543218910694122, 0.15048418939113617, 0.15089266002178192, 0.16110235452651978, 0.15845723450183868, 0.2410394847393036, 0.1531829982995987, 0.14997896552085876, 0.1925668567419052, 0.11859660595655441, 0.2044844925403595, 0.10336961597204208, 0.21894603967666626, 0.10243331640958786, 0.1800997108221054, 0.1606685221195221, 0.16217488050460815, 0.13942492008209229, 0.23059940338134766, 0.13326884806156158, 0.17623953521251678, 0.1348423957824707, 0.1873856484889984, 0.19836516678333282, 0.2361874282360077, 0.22866912186145782, 0.22059907019138336, 0.23824894428253174, 0.17192912101745605, 0.2348707914352417, 0.12661801278591156, 0.10584253072738647, 0.1400628685951233, 0.13926361501216888, 0.22514159977436066, 0.18237444758415222, 0.20950637757778168, 0.1256963312625885, 0.16329236328601837, 0.17022357881069183, 0.15517626702785492, 0.13702808320522308, 0.1430920660495758, 0.11349956691265106, 0.22895780205726624, 0.11352606117725372, 0.18064558506011963, 0.1658366322517395, 0.16166235506534576, 0.1898559331893921, 0.18170864880084991, 0.22524259984493256, 0.15454845130443573, 0.11409247666597366, 0.19610008597373962, 0.17590342462062836, 0.22680620849132538, 0.18761947751045227, 0.15599572658538818, 0.1465013325214386, 0.18249377608299255, 0.14531539380550385, 0.18665920197963715, 0.15004658699035645, 0.14449726045131683, 0.15152607858181, 0.11393890529870987, 0.13559645414352417, 0.20725664496421814, 0.18772664666175842, 0.22153879702091217, 0.14486758410930634, 0.13820837438106537, 0.14712552726268768, 0.13688404858112335, 0.21834874153137207, 0.20770442485809326, 0.16634823381900787, 0.1525551676750183, 0.26312652230262756, 0.1350778341293335, 0.1330987960100174, 0.2598232626914978, 0.17701801657676697, 0.17330101132392883, 0.15811613202095032, 0.16699618101119995, 0.13906417787075043, 0.15346790850162506, 0.1524588018655777, 0.11582531780004501, 0.13849703967571259, 0.16766490042209625, 0.13930054008960724, 0.12953388690948486, 0.13467538356781006, 0.1723032146692276, 0.16556641459465027, 0.14699673652648926, 0.13840220868587494, 0.17322222888469696, 0.26497694849967957, 0.15475445985794067, 0.18961487710475922, 0.16207681596279144, 0.1957399696111679, 0.16459831595420837, 0.22970475256443024, 0.1567540317773819, 0.17015478014945984, 0.21748986840248108, 0.14283856749534607, 0.2099907249212265, 0.25460365414619446, 0.1472153663635254, 0.24983175098896027, 0.16814328730106354, 0.1545693725347519, 0.16288413107395172, 0.12303295731544495, 0.17842084169387817, 0.19841834902763367, 0.1262594610452652, 0.16325604915618896, 0.17422644793987274, 0.1976681500673294, 0.1705462783575058, 0.17488586902618408, 0.15946893393993378, 0.16453635692596436, 0.16826702654361725, 0.18581455945968628, 0.1490374356508255, 0.1908746212720871, 0.1881094127893448, 0.1624656319618225, 0.12960723042488098, 0.12941086292266846, 0.20687201619148254, 0.12845736742019653, 0.1644091010093689, 0.145200714468956, 0.1795971542596817, 0.17336012423038483, 0.157211035490036, 0.234624981880188, 0.17303597927093506, 0.13799606263637543, 0.17922742664813995, 0.12651456892490387, 0.19179542362689972, 0.18041230738162994, 0.1264936625957489, 0.17402808368206024, 0.16862188279628754, 0.18278183043003082, 0.16896109282970428, 0.1487133651971817, 0.18364158272743225, 0.2172229290008545, 0.14559252560138702, 0.16603511571884155, 0.13785181939601898, 0.15966655313968658, 0.1506093293428421, 0.1503438949584961, 0.2414858490228653, 0.23013262450695038, 0.1983608603477478, 0.12238138914108276, 0.16169914603233337, 0.1535443812608719, 0.16903194785118103, 0.2098221331834793, 0.22093522548675537, 0.1816885769367218, 0.18599790334701538, 0.13722744584083557, 0.1972527951002121, 0.23470871150493622, 0.14449042081832886, 0.18577352166175842, 0.1289350688457489, 0.21022824943065643, 0.18592363595962524, 0.143242746591568, 0.1839989274740219, 0.16246649622917175, 0.16988694667816162, 0.17664332687854767, 0.1954256296157837, 0.1329285055398941, 0.14600299298763275, 0.16993942856788635, 0.15546730160713196, 0.19211456179618835, 0.17272228002548218, 0.13207219541072845, 0.17529058456420898, 0.15727515518665314, 0.1440889537334442, 0.1401241570711136, 0.159836083650589, 0.21313340961933136, 0.21162822842597961, 0.1741819530725479, 0.16803383827209473, 0.12851499021053314, 0.1983201652765274, 0.174173966050148, 0.22615604102611542, 0.15200430154800415, 0.14332754909992218, 0.16060225665569305, 0.15577341616153717, 0.17567645013332367, 0.1482718139886856, 0.16704191267490387, 0.12615147233009338, 0.15882053971290588, 0.18453049659729004, 0.23785178363323212, 0.15855246782302856, 0.12403824180364609, 0.18760569393634796, 0.22018133103847504, 0.20384375751018524, 0.1885458528995514, 0.1813141405582428, 0.12412970513105392, 0.22092445194721222, 0.14772889018058777, 0.20933105051517487, 0.18719550967216492, 0.15065217018127441, 0.12628260254859924, 0.1770576387643814, 0.12683551013469696, 0.14791350066661835, 0.20070138573646545, 0.15743698179721832, 0.12505313754081726, 0.15086595714092255, 0.2077593058347702, 0.20272761583328247, 0.15302447974681854, 0.18192577362060547, 0.17222139239311218, 0.17923566699028015, 0.15743057429790497, 0.14538680016994476, 0.1542564183473587, 0.13356219232082367, 0.20017555356025696, 0.20083148777484894, 0.11821920424699783, 0.13684193789958954, 0.11730574816465378, 0.12439791113138199, 0.1898602694272995, 0.14847376942634583, 0.1820044070482254, 0.1480184644460678, 0.1713266670703888, 0.11138953268527985, 0.12958787381649017, 0.21185442805290222, 0.16963373124599457, 0.24040207266807556, 0.17789575457572937, 0.10841860622167587, 0.18332643806934357, 0.2068966031074524, 0.17239952087402344, 0.17806129157543182, 0.18105214834213257, 0.17388440668582916, 0.11013472825288773, 0.10966895520687103, 0.10900446772575378, 0.19599910080432892, 0.1319383680820465, 0.22333510220050812, 0.1065797358751297, 0.10556872189044952, 0.14238503575325012, 0.14352533221244812, 0.20631228387355804, 0.1340295821428299, 0.2089363932609558, 0.09923247992992401, 0.24888762831687927, 0.1334826946258545, 0.17587944865226746, 0.13554857671260834, 0.14916449785232544, 0.18550808727741241, 0.17301692068576813, 0.18397007882595062, 0.13585269451141357, 0.18845456838607788, 0.13607245683670044, 0.179377481341362, 0.11911547183990479, 0.16356918215751648, 0.14261138439178467, 0.17646393179893494, 0.15028513967990875, 0.14025279879570007, 0.1816571056842804, 0.1752890646457672, 0.09101416915655136, 0.2524504065513611, 0.14667905867099762, 0.1996292918920517, 0.1356675773859024, 0.17068304121494293, 0.2548094391822815, 0.12280209362506866, 0.12217427790164948, 0.1691747009754181, 0.09076621383428574, 0.09056460857391357, 0.08999563753604889, 0.0892438217997551, 0.22658655047416687, 0.2406739443540573, 0.12802033126354218, 0.25057563185691833, 0.17007288336753845, 0.12236710637807846, 0.22761157155036926, 0.16494540870189667, 0.13313448429107666, 0.25284814834594727, 0.19483985006809235, 0.20818136632442474, 0.15234783291816711, 0.12382128834724426, 0.15995930135250092, 0.1309565007686615, 0.12505517899990082, 0.12861189246177673, 0.19903776049613953, 0.21396906673908234, 0.09562739729881287, 0.16836370527744293, 0.1626535803079605, 0.09529753774404526, 0.09481070935726166, 0.2327958345413208, 0.1496395617723465, 0.17199057340621948, 0.09400910139083862, 0.15588249266147614, 0.13204607367515564, 0.15085145831108093, 0.1236780509352684, 0.22994475066661835, 0.09032103419303894, 0.09030690044164658, 0.15455953776836395, 0.13532708585262299, 0.13053275644779205, 0.10897304862737656, 0.21445536613464355, 0.18661049008369446, 0.11278475075960159, 0.16861186921596527, 0.08111224323511124, 0.08044357597827911, 0.17910903692245483, 0.18937534093856812, 0.29142722487449646, 0.34352830052375793, 0.1838802844285965, 0.20184119045734406, 0.3333260118961334, 0.17403832077980042, 0.10463542491197586, 0.08666999638080597, 0.11217492818832397, 0.152273491024971, 0.1908334493637085, 0.3059869706630707, 0.2516023516654968, 0.1196659728884697, 0.15488722920417786, 0.09833437949419022, 0.1766553372144699, 0.14977829158306122, 0.18475882709026337, 0.13281895220279694, 0.15443402528762817, 0.187116339802742, 0.11970110982656479, 0.16708393394947052, 0.15233083069324493, 0.20228226482868195, 0.12467287480831146, 0.18042895197868347, 0.19818924367427826, 0.18870098888874054, 0.14489756524562836, 0.1705097258090973, 0.16385483741760254, 0.1909637451171875, 0.17003028094768524, 0.1242026761174202, 0.21517859399318695, 0.202021062374115, 0.19232122600078583, 0.10877714306116104, 0.1773756891489029, 0.13858789205551147, 0.2684066891670227, 0.10876834392547607, 0.2092667520046234, 0.13049505650997162, 0.1792755275964737, 0.16277778148651123, 0.21086068451404572, 0.1834871470928192, 0.18959878385066986, 0.16238203644752502, 0.13653826713562012, 0.16624420881271362, 0.17843781411647797, 0.14038515090942383, 0.16155892610549927, 0.11177588999271393, 0.1849832683801651, 0.11067415028810501, 0.10970335453748703, 0.15218646824359894, 0.1464986503124237, 0.14303091168403625, 0.175723597407341, 0.1055697500705719, 0.14737828075885773, 0.12423847615718842, 0.119377002120018, 0.16252577304840088, 0.18118071556091309, 0.16295163333415985, 0.19471551477909088, 0.16964177787303925, 0.18176843225955963, 0.15372569859027863, 0.15172719955444336, 0.16526398062705994, 0.175272136926651, 0.16731961071491241, 0.22794607281684875, 0.09598564356565475, 0.1414623260498047, 0.09474456310272217, 0.2991074323654175, 0.13250109553337097, 0.13140901923179626, 0.12648916244506836, 0.19589659571647644, 0.2129974365234375, 0.25042659044265747, 0.260739803314209, 0.23977263271808624, 0.1306709349155426, 0.1691923588514328, 0.21579602360725403, 0.1261884868144989, 0.22529524564743042, 0.16744206845760345, 0.17298004031181335, 0.16100214421749115, 0.16218562424182892, 0.14770883321762085, 0.10492652654647827, 0.10533315688371658, 0.17131708562374115, 0.2173515111207962, 0.23065733909606934, 0.16274811327457428, 0.1511627584695816, 0.13034890592098236, 0.12435680627822876, 0.14355170726776123, 0.13217587769031525, 0.10613534599542618, 0.2418070286512375, 0.20170661807060242, 0.1358843594789505, 0.10510411858558655, 0.2574496567249298, 0.17880459129810333, 0.12646152079105377, 0.275749146938324, 0.14156793057918549, 0.2449227124452591, 0.13327890634536743, 0.20621755719184875, 0.18614715337753296, 0.19473308324813843, 0.2197413295507431, 0.20437385141849518, 0.17300912737846375, 0.17962166666984558, 0.16646736860275269, 0.11431802809238434, 0.18956643342971802, 0.25411877036094666, 0.1750660240650177, 0.14705447852611542, 0.2105984389781952, 0.1684647798538208, 0.14139926433563232, 0.23446205258369446, 0.1479983627796173, 0.21207980811595917, 0.12370511144399643, 0.1598970741033554, 0.16157962381839752, 0.12485756725072861, 0.13502252101898193, 0.1986190676689148, 0.1943747103214264, 0.19718101620674133, 0.2106882631778717, 0.1475813388824463, 0.146349236369133, 0.23958101868629456, 0.1664145290851593, 0.20109222829341888, 0.14947575330734253, 0.21960149705410004, 0.23814144730567932, 0.1386970728635788, 0.23803605139255524, 0.19531716406345367, 0.1429397165775299, 0.14585432410240173, 0.17940714955329895, 0.1471319943666458, 0.1581198275089264, 0.197274848818779, 0.1843613088130951, 0.1715289056301117, 0.14895963668823242, 0.19913548231124878, 0.15753605961799622, 0.1633610874414444, 0.13295820355415344, 0.13320592045783997, 0.16841575503349304, 0.16001512110233307, 0.1530606597661972, 0.17430464923381805, 0.22562982141971588, 0.13124889135360718, 0.1800796091556549, 0.17990556359291077, 0.17925041913986206, 0.18856734037399292, 0.17250268161296844, 0.1308477222919464, 0.15772883594036102, 0.22699259221553802, 0.148713618516922, 0.1545972228050232, 0.17094698548316956, 0.14426741003990173, 0.13655874133110046, 0.20513807237148285, 0.19296973943710327, 0.18413373827934265, 0.1637887954711914, 0.1580197513103485, 0.16107183694839478, 0.14325807988643646, 0.22633077204227448, 0.15996424853801727, 0.13062022626399994, 0.13103725016117096, 0.17598135769367218, 0.1790473610162735, 0.14485149085521698, 0.19027665257453918, 0.1581229567527771, 0.12749725580215454, 0.19516149163246155, 0.1554015427827835, 0.19557520747184753, 0.15487289428710938, 0.19221428036689758, 0.14879640936851501, 0.17277555167675018, 0.14501050114631653, 0.1408751755952835, 0.1222827136516571, 0.1917794942855835, 0.12040110677480698, 0.18712127208709717, 0.14653168618679047, 0.19305315613746643, 0.16687753796577454, 0.14245319366455078, 0.1403631567955017, 0.13981108367443085, 0.17065423727035522, 0.11330115050077438, 0.11265026032924652, 0.16520127654075623, 0.17008107900619507, 0.21876774728298187, 0.1818782389163971, 0.10802049934864044, 0.14130377769470215, 0.1325216442346573, 0.16209138929843903, 0.1277780681848526, 0.13583116233348846, 0.15579764544963837, 0.24060441553592682, 0.13709694147109985, 0.2318972647190094, 0.23499074578285217, 0.10167262703180313, 0.10140993446111679, 0.22617192566394806, 0.17386117577552795, 0.10108842700719833, 0.2821481227874756, 0.1300571858882904, 0.10217823833227158, 0.15929323434829712, 0.15112164616584778, 0.23197200894355774, 0.1261904388666153, 0.21751166880130768, 0.10277467221021652, 0.10253013670444489, 0.13193029165267944, 0.23807768523693085, 0.23091532289981842, 0.1825980395078659, 0.17641709744930267, 0.10375501215457916, 0.10292752087116241, 0.13529254496097565, 0.1448974460363388, 0.24806095659732819, 0.23491452634334564, 0.10217605531215668, 0.18431837856769562, 0.17974278330802917, 0.16316255927085876, 0.1597614288330078, 0.14439384639263153, 0.10251478105783463, 0.12323513627052307, 0.1695299595594406, 0.19119355082511902, 0.15653595328330994, 0.1713564693927765, 0.16290032863616943, 0.2094835788011551, 0.1435675173997879, 0.16468581557273865, 0.171672984957695, 0.13952814042568207, 0.19349071383476257, 0.20029179751873016, 0.13692763447761536, 0.10136362165212631, 0.19990599155426025, 0.25626903772354126, 0.13545973598957062, 0.18954035639762878, 0.1317015290260315, 0.28000202775001526, 0.15222898125648499, 0.23924101889133453, 0.1578100472688675, 0.2066941112279892, 0.23143553733825684, 0.13905377686023712, 0.22951748967170715, 0.10886891931295395, 0.1620524525642395, 0.1392749845981598, 0.17596657574176788, 0.17803551256656647, 0.1897679716348648, 0.12766508758068085, 0.23468485474586487, 0.17016193270683289, 0.17107592523097992, 0.19804230332374573, 0.1633981317281723, 0.1552945077419281, 0.11552548408508301, 0.13871809840202332, 0.16661731898784637, 0.21598906815052032, 0.1737658977508545, 0.13109900057315826, 0.14307884871959686, 0.14664097130298615, 0.11674590408802032, 0.12126272171735764, 0.11566589027643204, 0.13325153291225433, 0.12582144141197205, 0.20235051214694977, 0.16269855201244354, 0.1305631697177887, 0.21068556606769562, 0.14463794231414795, 0.15638303756713867, 0.10821060836315155, 0.17237310111522675, 0.19681908190250397, 0.16817399859428406, 0.20171548426151276, 0.16443873941898346, 0.22883334755897522, 0.2215227633714676, 0.16934318840503693, 0.12956354022026062, 0.1885797530412674, 0.14795523881912231, 0.26813971996307373, 0.19822858273983002, 0.20964814722537994, 0.20647753775119781, 0.15217101573944092, 0.11379537731409073, 0.15994511544704437, 0.18903674185276031, 0.19215425848960876, 0.11515305936336517, 0.17440441250801086, 0.15791483223438263, 0.16756363213062286, 0.11520637571811676, 0.19616536796092987, 0.14474362134933472, 0.16452139616012573, 0.26555389165878296, 0.11464560031890869, 0.24140684306621552, 0.1641116589307785, 0.1961556375026703, 0.13706137239933014, 0.198797345161438, 0.1798005849123001, 0.2187166064977646, 0.15370477735996246, 0.17035092413425446, 0.20393681526184082, 0.15402550995349884, 0.200162872672081, 0.1576194316148758, 0.19276192784309387, 0.17828243970870972, 0.11593499779701233, 0.16827361285686493, 0.22541871666908264, 0.17479656636714935, 0.22343619167804718, 0.11832889914512634, 0.18454498052597046, 0.1618424504995346, 0.11904522776603699, 0.1980808824300766, 0.16477367281913757, 0.1477470099925995, 0.16537773609161377, 0.17373158037662506, 0.18569457530975342, 0.11862600594758987, 0.11818163096904755, 0.16756118834018707, 0.1898023933172226, 0.1720394790172577, 0.2282702475786209, 0.16133436560630798, 0.12402917444705963, 0.13665823638439178, 0.11587055027484894, 0.21755994856357574, 0.1782851219177246, 0.17384691536426544, 0.17835381627082825, 0.2525838315486908, 0.21354293823242188, 0.17913755774497986, 0.1173877939581871, 0.14393290877342224, 0.1789337396621704, 0.16060246527194977, 0.21132691204547882, 0.14761431515216827, 0.11840923130512238, 0.1182703971862793, 0.14552336931228638, 0.15482451021671295, 0.15422089397907257, 0.17565882205963135, 0.14732074737548828, 0.17855344712734222, 0.19583651423454285, 0.1963283121585846, 0.18721042573451996, 0.19095301628112793, 0.16889351606369019, 0.13892848789691925, 0.1393236368894577, 0.11326292157173157, 0.11238888651132584, 0.18329107761383057, 0.14629273116588593, 0.16260495781898499, 0.1356046348810196, 0.12722577154636383, 0.21097950637340546, 0.14840391278266907, 0.13743332028388977, 0.13674643635749817, 0.12821108102798462, 0.13155029714107513, 0.22463233768939972, 0.14040789008140564, 0.17925481498241425, 0.1029578298330307, 0.10244067758321762, 0.18480339646339417, 0.22312313318252563, 0.2837600111961365, 0.13537725806236267, 0.18313756585121155, 0.2167043834924698, 0.19433362782001495, 0.12438572198152542, 0.23238147795200348, 0.1848192662000656, 0.2130541354417801, 0.19161847233772278, 0.13609638810157776, 0.21204513311386108, 0.2135598063468933, 0.14853201806545258, 0.17593255639076233, 0.22475218772888184, 0.11256725341081619, 0.25953951478004456, 0.18202567100524902, 0.17186623811721802, 0.1693735420703888, 0.16546162962913513, 0.21752884984016418, 0.20417705178260803, 0.11944514513015747, 0.22176361083984375, 0.1595066785812378, 0.2407459020614624, 0.12325194478034973, 0.12337933480739594, 0.18795262277126312, 0.15468716621398926, 0.12525826692581177, 0.19340617954730988, 0.1726256012916565, 0.15572626888751984, 0.18957404792308807, 0.1639038622379303, 0.1987084299325943, 0.12355419248342514, 0.1270221322774887, 0.1605658382177353, 0.12288138270378113, 0.16325651109218597, 0.1534293293952942, 0.12205911427736282, 0.1203424260020256, 0.13450253009796143, 0.1527465283870697, 0.11749542504549026, 0.11707742512226105, 0.23292775452136993, 0.1454085260629654, 0.11369866132736206, 0.17509275674819946, 0.11518654227256775, 0.18214067816734314, 0.26832354068756104, 0.20525364577770233, 0.1817268282175064, 0.10708147287368774, 0.2481815069913864, 0.2376408576965332, 0.22087815403938293, 0.19292117655277252, 0.19800235331058502, 0.17257916927337646, 0.17328542470932007, 0.12464893609285355, 0.1710933893918991, 0.1431591957807541, 0.2131085842847824, 0.2626599371433258, 0.1288181096315384, 0.16672633588314056, 0.14645032584667206, 0.17119206488132477, 0.22544093430042267, 0.11563730239868164, 0.18091605603694916, 0.2547784149646759, 0.21146409213542938, 0.13759483397006989, 0.11949765682220459, 0.12072145938873291, 0.16072732210159302, 0.22062818706035614, 0.1865307092666626, 0.2268034666776657, 0.18268533051013947, 0.15102069079875946, 0.24524840712547302, 0.1439799964427948, 0.16311034560203552, 0.1617942750453949, 0.27009573578834534, 0.20950429141521454, 0.16929493844509125, 0.16764825582504272, 0.2438775897026062, 0.12932319939136505, 0.1630302220582962, 0.20284156501293182, 0.11751268804073334, 0.16300344467163086, 0.19499096274375916, 0.17081019282341003, 0.17165398597717285, 0.2134944349527359, 0.1577208936214447, 0.19082018733024597, 0.12470666319131851, 0.17728382349014282, 0.19397114217281342, 0.15961521863937378, 0.17507462203502655, 0.12410895526409149, 0.12357740104198456, 0.1671968698501587, 0.17322123050689697, 0.12193585187196732, 0.19625408947467804, 0.14537636935710907, 0.17561541497707367, 0.11916223913431168, 0.15209504961967468, 0.15331755578517914, 0.13539330661296844, 0.11928188800811768, 0.16740958392620087, 0.1253882497549057, 0.20148509740829468, 0.18100064992904663, 0.15185467898845673, 0.22737395763397217, 0.17686063051223755, 0.1122281551361084, 0.11379501968622208, 0.23800763487815857, 0.18065260350704193, 0.24181777238845825, 0.2690433859825134, 0.15373072028160095, 0.1982060819864273, 0.1806255728006363, 0.2712814211845398, 0.17617005109786987, 0.12111165374517441, 0.14213444292545319, 0.2116270512342453, 0.08719618618488312, 0.14287661015987396, 0.13522443175315857, 0.25483280420303345, 0.2528766095638275, 0.27433672547340393, 0.12271834164857864, 0.12974773347377777, 0.12307719141244888, 0.2376198172569275, 0.16504864394664764, 0.12546002864837646, 0.23193280398845673, 0.1437135934829712, 0.13200660049915314, 0.12353833764791489, 0.20850862562656403, 0.1331987828016281, 0.1236221119761467, 0.23051999509334564, 0.11143746972084045, 0.13761429488658905, 0.12949872016906738, 0.19949117302894592, 0.1252448558807373, 0.12930065393447876, 0.1958499550819397, 0.11885574460029602, 0.21663294732570648, 0.20912007987499237, 0.16653701663017273, 0.17647263407707214, 0.16161930561065674, 0.11524955183267593, 0.18317268788814545, 0.11451491713523865, 0.2342805564403534, 0.1412835419178009, 0.12385128438472748, 0.1561548411846161, 0.1635105013847351, 0.11123541742563248, 0.1733136624097824, 0.1782669574022293, 0.13730953633785248, 0.13600824773311615, 0.12574321031570435, 0.26013612747192383, 0.10623718053102493, 0.1423502117395401, 0.1397247314453125, 0.164955273270607, 0.20493817329406738, 0.15746565163135529, 0.12883266806602478, 0.10188981145620346, 0.12556679546833038, 0.15484634041786194, 0.16840919852256775, 0.1791340410709381, 0.18938711285591125, 0.097953662276268, 0.0966421440243721, 0.14431719481945038, 0.12110638618469238, 0.2454412877559662, 0.22550275921821594, 0.24049682915210724, 0.23821182548999786, 0.12454012781381607, 0.09432496875524521, 0.10809224098920822, 0.19767795503139496, 0.1794382631778717, 0.13972558081150055, 0.09466606378555298, 0.13172130286693573, 0.18302185833454132, 0.1338970959186554, 0.09362234175205231, 0.17735470831394196, 0.17156687378883362, 0.09138958901166916, 0.1242779865860939, 0.13235415518283844, 0.1986118108034134, 0.17208106815814972, 0.2565360963344574, 0.12209434807300568, 0.18839293718338013, 0.15741507709026337, 0.2008572667837143, 0.08844254165887833, 0.18116667866706848, 0.144559845328331, 0.2379688173532486, 0.12375476211309433, 0.24916453659534454, 0.12703093886375427, 0.239567831158638, 0.12160484492778778, 0.13942411541938782, 0.18325914442539215, 0.1471511870622635, 0.17042699456214905, 0.17992497980594635, 0.1486016809940338, 0.1768975555896759, 0.17431069910526276, 0.1350431591272354, 0.1662106066942215, 0.16466864943504333, 0.2042730450630188, 0.18119879066944122, 0.09169439226388931, 0.16778607666492462, 0.0918567106127739, 0.09135104715824127, 0.14022332429885864, 0.18427221477031708, 0.24520844221115112, 0.16660350561141968, 0.14343513548374176, 0.2123958170413971, 0.09065411984920502, 0.12920233607292175, 0.16432686150074005, 0.1362616866827011, 0.13154491782188416, 0.16317875683307648, 0.26160961389541626, 0.08970089256763458, 0.10423757880926132, 0.14746622741222382, 0.15302138030529022, 0.25474753975868225, 0.18013641238212585, 0.2529703974723816, 0.13629694283008575, 0.1868392527103424, 0.25572940707206726, 0.09029459208250046, 0.09236252307891846, 0.20308461785316467, 0.24925373494625092, 0.09536854177713394, 0.12734916806221008, 0.15175943076610565, 0.09294204413890839, 0.2770073711872101, 0.2076219767332077, 0.15899643301963806, 0.13441476225852966, 0.21335278451442719, 0.09565426409244537, 0.1459169089794159, 0.1255316287279129, 0.20384018123149872, 0.09301301091909409, 0.09405315667390823, 0.17986580729484558, 0.12041369080543518, 0.19769999384880066, 0.10444986820220947, 0.21279750764369965, 0.12472953647375107, 0.1626681238412857, 0.14178426563739777, 0.12852302193641663, 0.21709278225898743, 0.16081589460372925, 0.3163679540157318, 0.08870966732501984, 0.1466953456401825, 0.13957606256008148, 0.2305675595998764, 0.23255200684070587, 0.21940557658672333, 0.09063504636287689, 0.23024965822696686, 0.10912933945655823, 0.22963321208953857, 0.09441155940294266, 0.20493486523628235, 0.2117018699645996, 0.16771915555000305, 0.15065503120422363, 0.28934648633003235, 0.15457256138324738, 0.13610996305942535, 0.1514640897512436, 0.178095743060112, 0.15288448333740234, 0.19701950252056122, 0.16757310926914215, 0.19812609255313873, 0.21948707103729248, 0.12396032363176346, 0.2647853493690491, 0.145319864153862, 0.11036047339439392, 0.25998079776763916, 0.18926185369491577, 0.11337162554264069, 0.14171260595321655, 0.1320265382528305, 0.11572979390621185, 0.21641364693641663, 0.16855184733867645, 0.18467646837234497, 0.20396700501441956, 0.18671151995658875, 0.21455034613609314, 0.1352280080318451, 0.14354240894317627, 0.21432004868984222, 0.20863549411296844, 0.13925166428089142, 0.14984075725078583, 0.11620645225048065, 0.11787933111190796, 0.1884084939956665, 0.1704101264476776, 0.14089973270893097, 0.20667482912540436, 0.2336045354604721, 0.15846970677375793, 0.21056890487670898, 0.16158951818943024, 0.13084754347801208, 0.14892099797725677]\n",
            "Val loss 0.16792757133491168\n",
            "Val auc roc 0.4999140684904177\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fca0db3f23fa4377807876ac735932eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2656.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1660\n",
            "Train Losses : [0.2123684287071228, 0.15881654620170593, 0.22025568783283234, 0.11584248393774033, 0.24780820310115814, 0.22861604392528534, 0.15817441046237946, 0.11216350644826889, 0.18476228415966034, 0.18084068596363068, 0.12840306758880615, 0.17978237569332123, 0.1638430505990982, 0.19824130833148956, 0.11119644343852997, 0.18389776349067688, 0.23528750240802765, 0.17577536404132843, 0.1756293773651123, 0.1778826266527176, 0.26621031761169434, 0.1120145246386528, 0.1866283267736435, 0.11244797706604004, 0.17210358381271362, 0.23266690969467163, 0.17127880454063416, 0.1540111005306244, 0.1662224680185318, 0.1991344690322876, 0.14743420481681824, 0.21102368831634521, 0.14217638969421387, 0.13700394332408905, 0.1309281438589096, 0.15655238926410675, 0.1789250373840332, 0.25241371989250183, 0.17945128679275513, 0.17725594341754913, 0.11689735949039459, 0.15235652029514313, 0.21260473132133484, 0.16162990033626556, 0.1170765832066536, 0.16149719059467316, 0.2047572135925293, 0.12216659635305405, 0.12152431905269623, 0.15763330459594727, 0.1733739823102951, 0.16299700736999512, 0.19623622298240662, 0.1432366669178009, 0.2107192575931549, 0.11500069499015808, 0.1422978639602661, 0.20791859924793243, 0.23443599045276642, 0.1457371860742569, 0.19646145403385162, 0.20184862613677979, 0.11516579985618591, 0.2547413408756256, 0.26067882776260376, 0.16105927526950836, 0.11617005616426468, 0.13380493223667145, 0.18470165133476257, 0.16533225774765015, 0.2150607854127884, 0.19387966394424438, 0.11681617051362991, 0.18173976242542267, 0.14465738832950592, 0.1602790653705597, 0.11900924891233444, 0.16240212321281433, 0.11634711921215057, 0.11664224416017532, 0.1457260698080063, 0.13029858469963074, 0.18123748898506165, 0.15647666156291962, 0.12511089444160461, 0.22272217273712158, 0.1807781159877777, 0.17566637694835663, 0.16921588778495789, 0.15177962183952332, 0.14453880488872528, 0.13846421241760254, 0.1576233208179474, 0.11048382520675659, 0.1537555307149887, 0.1419234275817871, 0.242200568318367, 0.10725634545087814, 0.10657516866922379, 0.10597037523984909, 0.1483684629201889, 0.13416311144828796, 0.10289555788040161, 0.14043614268302917, 0.10593539476394653, 0.12389805167913437, 0.1917230784893036, 0.15087784826755524, 0.11095880717039108, 0.15515483915805817, 0.23499733209609985, 0.19322240352630615, 0.2606615722179413, 0.17558129131793976, 0.20373280346393585, 0.18592892587184906, 0.09239677339792252, 0.27222493290901184, 0.24540852010250092, 0.20356011390686035, 0.24379967153072357, 0.18712548911571503, 0.28737673163414, 0.12489748746156693, 0.1842430979013443, 0.20923182368278503, 0.12026990950107574, 0.12593182921409607, 0.15561382472515106, 0.16623038053512573, 0.19359412789344788, 0.13673514127731323, 0.19891686737537384, 0.16780705749988556, 0.1911260038614273, 0.27477043867111206, 0.10621663182973862, 0.13368146121501923, 0.17290663719177246, 0.2324768751859665, 0.1456098109483719, 0.12175010144710541, 0.17941723763942719, 0.16454459726810455, 0.12850289046764374, 0.18773062527179718, 0.16660591959953308, 0.204875648021698, 0.10980730503797531, 0.19787682592868805, 0.26399293541908264, 0.19846583902835846, 0.21860653162002563, 0.16911698877811432, 0.11315087229013443, 0.13707879185676575, 0.1994444876909256, 0.14829693734645844, 0.16434705257415771, 0.20007716119289398, 0.1157308965921402, 0.15293458104133606, 0.11470845341682434, 0.11427691578865051, 0.16537122428417206, 0.14599937200546265, 0.14859196543693542, 0.13543084263801575, 0.2678118050098419, 0.15647704899311066, 0.16032284498214722, 0.18509820103645325, 0.2211502641439438, 0.15739981830120087, 0.14018382132053375, 0.11137041449546814, 0.1392945647239685, 0.10832684487104416, 0.1458713263273239, 0.21000437438488007, 0.19109250605106354, 0.2720802426338196, 0.10561405122280121, 0.1057749018073082, 0.17260399460792542, 0.14033780992031097, 0.16697029769420624, 0.19623897969722748, 0.16728562116622925, 0.17954565584659576, 0.15202713012695312, 0.16454312205314636, 0.10326631367206573, 0.20999205112457275, 0.13157910108566284, 0.14505261182785034, 0.24515840411186218, 0.18315428495407104, 0.27656829357147217, 0.23410795629024506, 0.12389534711837769, 0.18844030797481537, 0.12346462905406952, 0.16169632971286774, 0.2176642119884491, 0.21200516819953918, 0.10982576012611389, 0.17055675387382507, 0.22038698196411133, 0.1110466867685318, 0.14480312168598175, 0.21223284304141998, 0.138926163315773, 0.14425992965698242, 0.16789549589157104, 0.15031450986862183, 0.20824672281742096, 0.21079152822494507, 0.11299073696136475, 0.1459561437368393, 0.25808244943618774, 0.155960813164711, 0.2440740019083023, 0.18095709383487701, 0.15044689178466797, 0.15434451401233673, 0.11999614536762238, 0.2290322184562683, 0.14804388582706451, 0.23690858483314514, 0.15337805449962616, 0.14318054914474487, 0.13219007849693298, 0.11806153506040573, 0.12237517535686493, 0.2047966718673706, 0.14765970408916473, 0.2015378326177597, 0.22251936793327332, 0.17109285295009613, 0.19685354828834534, 0.2303977757692337, 0.14314985275268555, 0.17201657593250275, 0.11667370051145554, 0.11656180024147034, 0.20332875847816467, 0.1787102222442627, 0.22072453796863556, 0.21700476109981537, 0.1821262091398239, 0.14180874824523926, 0.14484386146068573, 0.14506344497203827, 0.16127710044384003, 0.15533246099948883, 0.17391875386238098, 0.13451796770095825, 0.14095538854599, 0.20304419100284576, 0.1299317181110382, 0.17020829021930695, 0.15525206923484802, 0.21273556351661682, 0.13537198305130005, 0.11160784959793091, 0.11153542995452881, 0.16867735981941223, 0.10960505902767181, 0.10903968662023544, 0.16056469082832336, 0.1979653686285019, 0.12769940495491028, 0.14016589522361755, 0.15050040185451508, 0.21798337996006012, 0.2174167037010193, 0.19771860539913177, 0.10294152796268463, 0.16478632390499115, 0.18346752226352692, 0.1414036899805069, 0.14075584709644318, 0.16349920630455017, 0.15402814745903015, 0.23302841186523438, 0.1710149645805359, 0.1942988634109497, 0.18074609339237213, 0.23084597289562225, 0.2075592279434204, 0.18177419900894165, 0.12640127539634705, 0.1429799497127533, 0.15076223015785217, 0.1772805005311966, 0.14015042781829834, 0.1029876321554184, 0.17102986574172974, 0.17246213555335999, 0.17766417562961578, 0.18209807574748993, 0.1640768200159073, 0.18458040058612823, 0.13723143935203552, 0.1814410239458084, 0.15347294509410858, 0.15484687685966492, 0.15057267248630524, 0.19170808792114258, 0.16708974540233612, 0.1015642061829567, 0.10043115168809891, 0.1437475085258484, 0.17068126797676086, 0.13500487804412842, 0.2312415987253189, 0.13232336938381195, 0.13804642856121063, 0.09738533943891525, 0.13878414034843445, 0.24751247465610504, 0.09567567706108093, 0.19798141717910767, 0.13250967860221863, 0.14652888476848602, 0.15541067719459534, 0.18595224618911743, 0.23921580612659454, 0.17156632244586945, 0.1279740184545517, 0.17313189804553986, 0.14578630030155182, 0.25474807620048523, 0.1742376685142517, 0.13164760172367096, 0.2300538569688797, 0.1889355331659317, 0.16743548214435577, 0.09684393554925919, 0.18117092549800873, 0.18238037824630737, 0.22152571380138397, 0.19343212246894836, 0.149689719080925, 0.16371563076972961, 0.14206360280513763, 0.18662653863430023, 0.09971828013658524, 0.19066894054412842, 0.10068093985319138, 0.2409847229719162, 0.16004721820354462, 0.2615818381309509, 0.1227191761136055, 0.13358110189437866, 0.10045438259840012, 0.11928766965866089, 0.27801939845085144, 0.2285870611667633, 0.10018795728683472, 0.23271560668945312, 0.14607290923595428, 0.10084430873394012, 0.13879838585853577, 0.1678042709827423, 0.18408411741256714, 0.21798941493034363, 0.13004043698310852, 0.10068776458501816, 0.15588617324829102, 0.12307986617088318, 0.13873115181922913, 0.0991029366850853, 0.28800272941589355, 0.21337947249412537, 0.15151123702526093, 0.24181295931339264, 0.09904050081968307, 0.14604198932647705, 0.09916795045137405, 0.1332651823759079, 0.21039679646492004, 0.09899883717298508, 0.13744980096817017, 0.14611642062664032, 0.13163062930107117, 0.1384095847606659, 0.23110900819301605, 0.24435736238956451, 0.13138370215892792, 0.0962754338979721, 0.23669876158237457, 0.12952245771884918, 0.12324301898479462, 0.1502428501844406, 0.17739024758338928, 0.1363871544599533, 0.12138533592224121, 0.1385478973388672, 0.14076311886310577, 0.14115186035633087, 0.13511915504932404, 0.23494426906108856, 0.25908806920051575, 0.2526414692401886, 0.21908381581306458, 0.139211043715477, 0.14360706508159637, 0.1688118875026703, 0.17817842960357666, 0.23587128520011902, 0.1406404674053192, 0.1887580007314682, 0.17779968678951263, 0.10660053044557571, 0.13837602734565735, 0.1565100997686386, 0.155964657664299, 0.11580007523298264, 0.14699961245059967, 0.17994728684425354, 0.09646253287792206, 0.15868237614631653, 0.13312701880931854, 0.17427167296409607, 0.1277187317609787, 0.09572749584913254, 0.23272617161273956, 0.09467481821775436, 0.1351555734872818, 0.11940092593431473, 0.145425483584404, 0.14563295245170593, 0.14269065856933594, 0.14614129066467285, 0.1366533786058426, 0.24017593264579773, 0.1531488001346588, 0.19891083240509033, 0.20658764243125916, 0.22026973962783813, 0.1796305775642395, 0.12347619235515594, 0.20678934454917908, 0.1717267781496048, 0.18306279182434082, 0.1266448050737381, 0.15561330318450928, 0.15326005220413208, 0.17031078040599823, 0.1363525092601776, 0.167864128947258, 0.246306374669075, 0.15563225746154785, 0.23324894905090332, 0.26106467843055725, 0.10860442370176315, 0.09529703110456467, 0.23018935322761536, 0.1428990215063095, 0.18822039663791656, 0.15346285700798035, 0.28705283999443054, 0.19987940788269043, 0.16065341234207153, 0.10227511078119278, 0.15439973771572113, 0.10251966118812561, 0.14972110092639923, 0.27827295660972595, 0.27883970737457275, 0.245267853140831, 0.14783909916877747, 0.23105570673942566, 0.10782600194215775, 0.2042357474565506, 0.18474003672599792, 0.20360441505908966, 0.24126394093036652, 0.1869838386774063, 0.13432595133781433, 0.14693322777748108, 0.2512142062187195, 0.15379102528095245, 0.11471741646528244, 0.13440854847431183, 0.1624945104122162, 0.22714371979236603, 0.1722961962223053, 0.1862688809633255, 0.1791098415851593, 0.17400050163269043, 0.11346180737018585, 0.16161182522773743, 0.13664577901363373, 0.18774282932281494, 0.16469812393188477, 0.12530362606048584, 0.15349572896957397, 0.24621975421905518, 0.13112126290798187, 0.16511008143424988, 0.233567476272583, 0.20351886749267578, 0.22677946090698242, 0.16142837703227997, 0.1846305876970291, 0.16788800060749054, 0.2283436805009842, 0.22494304180145264, 0.15300853550434113, 0.13901841640472412, 0.209244966506958, 0.17733624577522278, 0.1682184934616089, 0.16439737379550934, 0.2349078208208084, 0.16976512968540192, 0.1275106817483902, 0.16197331249713898, 0.15981630980968475, 0.17722709476947784, 0.14088815450668335, 0.17336617410182953, 0.2239234894514084, 0.15572530031204224, 0.1594357192516327, 0.17504416406154633, 0.1570594757795334, 0.20899111032485962, 0.1410306841135025, 0.17685241997241974, 0.17829766869544983, 0.17996077239513397, 0.1480410397052765, 0.1257331520318985, 0.14523497223854065, 0.23608659207820892, 0.1821463704109192, 0.15099352598190308, 0.1740543097257614, 0.1258295625448227, 0.15689241886138916, 0.18058282136917114, 0.18234999477863312, 0.19417420029640198, 0.18822535872459412, 0.1485445350408554, 0.13860388100147247, 0.16946759819984436, 0.17181047797203064, 0.12295389920473099, 0.16500037908554077, 0.16933666169643402, 0.16597864031791687, 0.18425938487052917, 0.14308886229991913, 0.14211617410182953, 0.1613398641347885, 0.11911362409591675, 0.12733978033065796, 0.19070926308631897, 0.14860685169696808, 0.19838553667068481, 0.20984509587287903, 0.11709393560886383, 0.15926575660705566, 0.23643183708190918, 0.11657080799341202, 0.13135741651058197, 0.20982880890369415, 0.11532046645879745, 0.20714128017425537, 0.1559406816959381, 0.11418065428733826, 0.1546986997127533, 0.18032637238502502, 0.13605904579162598, 0.18088774383068085, 0.11235634982585907, 0.19899021089076996, 0.17296423017978668, 0.16021934151649475, 0.19924990832805634, 0.22854866087436676, 0.26139605045318604, 0.1508754938840866, 0.1996915638446808, 0.20530520379543304, 0.2188911885023117, 0.19330179691314697, 0.17187879979610443, 0.1707647293806076, 0.21298374235630035, 0.1804685890674591, 0.11656396090984344, 0.19923026859760284, 0.16001679003238678, 0.14335733652114868, 0.1676366776227951, 0.1331741064786911, 0.1746302992105484, 0.2122998684644699, 0.18629439175128937, 0.17648807168006897, 0.1417534202337265, 0.17886947095394135, 0.20342005789279938, 0.18173278868198395, 0.12105267494916916, 0.2253943830728531, 0.12096931040287018, 0.1212194487452507, 0.12147334963083267, 0.1573592871427536, 0.14427797496318817, 0.13627690076828003, 0.17772750556468964, 0.15697821974754333, 0.15278349816799164, 0.16820479929447174, 0.1325216442346573, 0.11680340766906738, 0.1974836140871048, 0.20661908388137817, 0.1959010660648346, 0.1684885025024414, 0.22938457131385803, 0.15284420549869537, 0.163484126329422, 0.16417846083641052, 0.14222709834575653, 0.19223998486995697, 0.14683903753757477, 0.21049454808235168, 0.2113608568906784, 0.1851179003715515, 0.17769783735275269, 0.18111032247543335, 0.15887902677059174, 0.20343270897865295, 0.2568540871143341, 0.11333309859037399, 0.20118166506290436, 0.1644950807094574, 0.1493392288684845, 0.1478252410888672, 0.13750140368938446, 0.18565475940704346, 0.22804918885231018, 0.21169161796569824, 0.15852586925029755, 0.1696794033050537, 0.11706358194351196, 0.11707159131765366, 0.11727752536535263, 0.13177964091300964, 0.21246004104614258, 0.2222612202167511, 0.22264441847801208, 0.16451396048069, 0.17979547381401062, 0.11615331470966339, 0.18520252406597137, 0.19041016697883606, 0.1450066864490509, 0.2080434411764145, 0.18056713044643402, 0.1333622932434082, 0.18979448080062866, 0.16391995549201965, 0.13523688912391663, 0.20640477538108826, 0.1821652352809906, 0.12837621569633484, 0.13543960452079773, 0.19947563111782074, 0.1914559304714203, 0.21889522671699524, 0.13601154088974, 0.16883894801139832, 0.13503047823905945, 0.13215017318725586, 0.15687358379364014, 0.17545267939567566, 0.12208401411771774, 0.16766847670078278, 0.1149899885058403, 0.17903780937194824, 0.21629224717617035, 0.1848386973142624, 0.17306451499462128, 0.15523914992809296, 0.22817113995552063, 0.18338695168495178, 0.2544998228549957, 0.115012988448143, 0.11622115969657898, 0.1432587057352066, 0.16954079270362854, 0.16503773629665375, 0.16355018317699432, 0.164090096950531, 0.19776690006256104, 0.21307271718978882, 0.17651069164276123, 0.25528502464294434, 0.1544613391160965, 0.13083356618881226, 0.17046749591827393, 0.15112794935703278, 0.2119186967611313, 0.1837424784898758, 0.14311519265174866, 0.17883962392807007, 0.11594005674123764, 0.1360643208026886, 0.1446327418088913, 0.1752610206604004, 0.13414879143238068, 0.15029814839363098, 0.18060170114040375, 0.1518934965133667, 0.13264434039592743, 0.14063230156898499, 0.1754937469959259, 0.17517811059951782, 0.21882444620132446, 0.20247770845890045, 0.1878405213356018, 0.1359015852212906, 0.2209605872631073, 0.1410415768623352, 0.1900474578142166, 0.17220892012119293, 0.1426098644733429, 0.14751149713993073, 0.20943769812583923, 0.11323138326406479, 0.17396289110183716, 0.2199644297361374, 0.11311501264572144, 0.169225811958313, 0.1738108992576599, 0.18176205456256866, 0.20291335880756378, 0.1433897316455841, 0.11342843621969223, 0.13411228358745575, 0.14730706810951233, 0.13654662668704987, 0.13483759760856628, 0.1423785537481308, 0.14367450773715973, 0.20021368563175201, 0.18126948177814484, 0.11014106869697571, 0.10956452041864395, 0.14919935166835785, 0.10807190835475922, 0.2336580902338028, 0.2272050976753235, 0.2700500786304474, 0.12572374939918518, 0.2135627269744873, 0.19443275034427643, 0.1737876683473587, 0.13843432068824768, 0.13138194382190704, 0.2249988466501236, 0.17909567058086395, 0.18918077647686005, 0.17241568863391876, 0.21790502965450287, 0.13354076445102692, 0.1990702748298645, 0.14857295155525208, 0.26194506883621216, 0.16616177558898926, 0.11140661686658859, 0.21064995229244232, 0.13519668579101562, 0.20721586048603058, 0.11316011101007462, 0.19042083621025085, 0.12860149145126343, 0.1977842152118683, 0.15041567385196686, 0.14536090195178986, 0.163124680519104, 0.15666750073432922, 0.21635819971561432, 0.2026064395904541, 0.1422126442193985, 0.1470244824886322, 0.1831579953432083, 0.15338601171970367, 0.1354602873325348, 0.13777095079421997, 0.14203931391239166, 0.14589299261569977, 0.16883189976215363, 0.15010647475719452, 0.11109152436256409, 0.14652438461780548, 0.13174961507320404, 0.16285796463489532, 0.1451188176870346, 0.15822890400886536, 0.19641374051570892, 0.10665688663721085, 0.19219088554382324, 0.1686777025461197, 0.1740272045135498, 0.21023987233638763, 0.17676159739494324, 0.12793558835983276, 0.174724280834198, 0.22438718378543854, 0.22235915064811707, 0.12960630655288696, 0.14074023067951202, 0.1538340002298355, 0.10473734140396118, 0.19913142919540405, 0.13049784302711487, 0.13946780562400818, 0.10391639173030853, 0.1415223926305771, 0.19128401577472687, 0.18218651413917542, 0.10193023085594177, 0.10106611251831055, 0.229304239153862, 0.1776590347290039, 0.17036530375480652, 0.1788332611322403, 0.18805918097496033, 0.22544613480567932, 0.13416215777397156, 0.1472449004650116, 0.17096413671970367, 0.19481272995471954, 0.1784955859184265, 0.13423757255077362, 0.1420346349477768, 0.09956656396389008, 0.17973987758159637, 0.18481895327568054, 0.14955563843250275, 0.23271869122982025, 0.2415505200624466, 0.1412055641412735, 0.18851099908351898, 0.14303487539291382, 0.14742499589920044, 0.18238019943237305, 0.22432950139045715, 0.24732406437397003, 0.10004302859306335, 0.10028950124979019, 0.1002577617764473, 0.17771755158901215, 0.13692431151866913, 0.2164410650730133, 0.09954996407032013, 0.2383117824792862, 0.1490411013364792, 0.16804681718349457, 0.23049873113632202, 0.0997314304113388, 0.09966352581977844, 0.18542860448360443, 0.13683292269706726, 0.09917187690734863, 0.2210647016763687, 0.23109818994998932, 0.14162512123584747, 0.09891481697559357, 0.09859608858823776, 0.09837086498737335, 0.09776542335748672, 0.19105678796768188, 0.1352795660495758, 0.2300686091184616, 0.17594031989574432, 0.22867804765701294, 0.1319795548915863, 0.14564719796180725, 0.24914297461509705, 0.18581277132034302, 0.1917349398136139, 0.13360823690891266, 0.13251152634620667, 0.09584861248731613, 0.13993293046951294, 0.13920383155345917, 0.23756280541419983, 0.23898810148239136, 0.1359839141368866, 0.1843302696943283, 0.2255248725414276, 0.18457821011543274, 0.18001848459243774, 0.1397532820701599, 0.23074892163276672, 0.1797940731048584, 0.13406682014465332, 0.15222081542015076, 0.18165457248687744, 0.1402343213558197, 0.09850455820560455, 0.18461349606513977, 0.22871121764183044, 0.2274656593799591, 0.13818824291229248, 0.2223246991634369, 0.17647485435009003, 0.1746300905942917, 0.10069842636585236, 0.1800321340560913, 0.13745325803756714, 0.1787303388118744, 0.1341511309146881, 0.23831480741500854, 0.23538435995578766, 0.13865317404270172, 0.10267148911952972, 0.14075525104999542, 0.18102183938026428, 0.10291989147663116, 0.10268149524927139, 0.10237271338701248, 0.22291448712348938, 0.17754819989204407, 0.1778937131166458, 0.1827508509159088, 0.18174239993095398, 0.10116606950759888, 0.1749262660741806, 0.1326122134923935, 0.10071446001529694, 0.23293383419513702, 0.1728818565607071, 0.18779775500297546, 0.14382173120975494, 0.14416347444057465, 0.09969505667686462, 0.13699935376644135, 0.1277509182691574, 0.17562033236026764, 0.14114215970039368, 0.23667386174201965, 0.22507354617118835, 0.18452143669128418, 0.17798256874084473, 0.18035542964935303, 0.17839685082435608, 0.28762930631637573, 0.18074212968349457, 0.13342806696891785, 0.09991973638534546, 0.1777595430612564, 0.10042691975831985, 0.1420496702194214, 0.1828397959470749, 0.10043834149837494, 0.1780935674905777, 0.1318989396095276, 0.19063089787960052, 0.13735511898994446, 0.2332080751657486, 0.1375279277563095, 0.23428937792778015, 0.1650160551071167, 0.1268298476934433, 0.14077359437942505, 0.22464069724082947, 0.17923055589199066, 0.10061880201101303, 0.13388223946094513, 0.18799687922000885, 0.10028086602687836, 0.23129703104496002, 0.18776766955852509, 0.181779146194458, 0.28269991278648376, 0.13470889627933502, 0.10129601508378983, 0.14353355765342712, 0.18013609945774078, 0.19526703655719757, 0.1826346218585968, 0.10175008326768875, 0.17530576884746552, 0.1018422320485115, 0.17543856799602509, 0.19095127284526825, 0.16092661023139954, 0.1795996129512787, 0.1381988227367401, 0.22756020724773407, 0.2315889149904251, 0.2222110629081726, 0.14986121654510498, 0.13498029112815857, 0.1889665573835373, 0.1812896728515625, 0.1852232664823532, 0.16912049055099487, 0.10426440834999084, 0.1770467758178711, 0.18802301585674286, 0.14818473160266876, 0.13786500692367554, 0.1800992488861084, 0.22702151536941528, 0.10480998456478119, 0.14718368649482727, 0.17910094559192657, 0.16943320631980896, 0.13301105797290802, 0.22954301536083221, 0.177451491355896, 0.1704188734292984, 0.14146959781646729, 0.12966324388980865, 0.1400463581085205, 0.19856344163417816, 0.18036989867687225, 0.17919500172138214, 0.14130178093910217, 0.16911999881267548, 0.17616012692451477, 0.10480006784200668, 0.23562924563884735, 0.22084395587444305, 0.2289847433567047, 0.1416424810886383, 0.17032773792743683, 0.10590888559818268, 0.21466995775699615, 0.1445942223072052, 0.19552525877952576, 0.1403990536928177, 0.14712102711200714, 0.16690053045749664, 0.17141354084014893, 0.17917051911354065, 0.1442248672246933, 0.15550026297569275, 0.1298060119152069, 0.17154690623283386, 0.2079472839832306, 0.16894428431987762, 0.10643451660871506, 0.13732627034187317, 0.13972708582878113, 0.2706415057182312, 0.17005117237567902, 0.10625123232603073, 0.14465780556201935, 0.16029785573482513, 0.19416862726211548, 0.1498945951461792, 0.20327012240886688, 0.163688525557518, 0.10612518340349197, 0.27041956782341003, 0.10640771687030792, 0.10647541284561157, 0.1065252274274826, 0.2004990428686142, 0.1483275443315506, 0.15283188223838806, 0.1053084284067154, 0.1565660536289215, 0.19614656269550323, 0.27573153376579285, 0.18661387264728546, 0.18164195120334625, 0.22046315670013428, 0.16611987352371216, 0.1698075383901596, 0.17935214936733246, 0.22896616160869598, 0.1384037733078003, 0.19705939292907715, 0.14487044513225555, 0.17969636619091034, 0.21299059689044952, 0.23684093356132507, 0.10768499970436096, 0.10803552716970444, 0.222091406583786, 0.2655036747455597, 0.16946813464164734, 0.14261004328727722, 0.17551828920841217, 0.11073259264230728, 0.175274059176445, 0.13732805848121643, 0.22981679439544678, 0.18706069886684418, 0.1459200233221054, 0.11201831698417664, 0.11207260936498642, 0.14624571800231934, 0.13937096297740936, 0.11140302568674088, 0.26101088523864746, 0.16013608872890472, 0.17250581085681915, 0.18215642869472504, 0.1106937825679779, 0.14137256145477295, 0.2226780503988266, 0.1391078680753708, 0.2341153472661972, 0.13830910623073578, 0.14645911753177643, 0.17738379538059235, 0.11003603041172028, 0.1370321810245514, 0.26347729563713074, 0.23289255797863007, 0.14025895297527313, 0.1604161411523819, 0.13123492896556854, 0.15064069628715515, 0.17584089934825897, 0.20873184502124786, 0.13338619470596313, 0.18488596379756927, 0.16643112897872925, 0.11088458448648453, 0.18514156341552734, 0.20341703295707703, 0.11081469804048538, 0.15404678881168365, 0.12907207012176514, 0.23130494356155396, 0.17997556924819946, 0.1668415516614914, 0.15051475167274475, 0.18984030187129974, 0.13730458915233612, 0.22451043128967285, 0.11038730293512344, 0.14431358873844147, 0.2182982712984085, 0.2176038920879364, 0.1434631645679474, 0.17614084482192993, 0.11065389961004257, 0.14704245328903198, 0.1853969544172287, 0.13448497653007507, 0.19048306345939636, 0.18261387944221497, 0.14802832901477814, 0.10978811979293823, 0.17459550499916077, 0.13205668330192566, 0.18325118720531464, 0.17060410976409912, 0.14630721509456635, 0.1835695505142212, 0.22101150453090668, 0.21782657504081726, 0.1902552843093872, 0.13633424043655396, 0.18149824440479279, 0.13274012506008148, 0.17688903212547302, 0.14620192348957062, 0.1357981115579605, 0.17879031598567963, 0.1380271464586258, 0.2241431474685669, 0.10829838365316391, 0.18661613762378693, 0.14762626588344574, 0.17051512002944946, 0.10775024443864822, 0.13878197968006134, 0.22389720380306244, 0.2183743715286255, 0.14110757410526276, 0.14490145444869995, 0.14207598567008972, 0.18298229575157166, 0.17383123934268951, 0.14242318272590637, 0.1748354583978653, 0.14801561832427979, 0.2069113701581955, 0.13398295640945435, 0.10587450116872787, 0.13504765927791595, 0.22135168313980103, 0.10537393391132355, 0.12666437029838562, 0.18694056570529938, 0.1044187992811203, 0.19363412261009216, 0.13900582492351532, 0.13698643445968628, 0.10268230736255646, 0.10223377496004105, 0.1851772665977478, 0.13460980355739594, 0.13862040638923645, 0.22294023633003235, 0.21812868118286133, 0.13460272550582886, 0.1875223070383072, 0.24806661903858185, 0.18520422279834747, 0.14396989345550537, 0.2857242226600647, 0.2443128526210785, 0.1382843405008316, 0.10042190551757812, 0.1828552782535553, 0.10100512206554413, 0.10107798129320145, 0.13971780240535736, 0.1348615139722824, 0.18207070231437683, 0.14200052618980408, 0.1452033817768097, 0.18140634894371033, 0.09928031265735626, 0.1296873688697815, 0.18695761263370514, 0.12688156962394714, 0.23852033913135529, 0.23040127754211426, 0.1859433352947235, 0.18409836292266846, 0.13348063826560974, 0.239834263920784, 0.13460390269756317, 0.13615134358406067, 0.17599931359291077, 0.1367427110671997, 0.23075230419635773, 0.2386201173067093, 0.18076694011688232, 0.13299213349819183, 0.13732677698135376, 0.14354702830314636, 0.1797007918357849, 0.2287411391735077, 0.13697123527526855, 0.10054565966129303, 0.1359262317419052, 0.13181887567043304, 0.12924733757972717, 0.18804815411567688, 0.13451926410198212, 0.1303766667842865, 0.1303701102733612, 0.09891518950462341, 0.1467137336730957, 0.1831391304731369, 0.17041443288326263, 0.19891922175884247, 0.18711531162261963, 0.17904223501682281, 0.19771622121334076, 0.14568182826042175, 0.19122903048992157, 0.18827247619628906, 0.13436201214790344, 0.1383836716413498, 0.1776343137025833, 0.2379763275384903, 0.29330188035964966, 0.13576214015483856, 0.13180458545684814, 0.22225742042064667, 0.13669151067733765, 0.13496416807174683, 0.13778847455978394, 0.1884574443101883, 0.1908445954322815, 0.1363794058561325, 0.23654015362262726, 0.1339980512857437, 0.2308647632598877, 0.2302456498146057, 0.13377690315246582, 0.28241202235221863, 0.13702505826950073, 0.2194567620754242, 0.1774836927652359, 0.13931627571582794, 0.23330000042915344, 0.10444417595863342, 0.10488423705101013, 0.179346963763237, 0.13529247045516968, 0.1799621880054474, 0.17497314512729645, 0.22373007237911224, 0.10626497864723206, 0.14413213729858398, 0.1670427918434143, 0.2221076339483261, 0.26866888999938965, 0.13355721533298492, 0.1438298374414444, 0.13770563900470734, 0.22466197609901428, 0.10858740657567978, 0.18321216106414795, 0.14752373099327087, 0.13931523263454437, 0.21916308999061584, 0.10907502472400665, 0.10905645042657852, 0.18550164997577667, 0.2281043976545334, 0.1902974545955658, 0.21562887728214264, 0.13740263879299164, 0.1834174394607544, 0.14490535855293274, 0.17621207237243652, 0.1762867122888565, 0.10959474742412567, 0.17839792370796204, 0.17152608931064606, 0.17505504190921783, 0.17639243602752686, 0.21537789702415466, 0.21635982394218445, 0.11013045161962509, 0.1423359215259552, 0.11035140603780746, 0.2614542543888092, 0.21855707466602325, 0.22215262055397034, 0.1813460737466812, 0.17086607217788696, 0.21453098952770233, 0.14669115841388702, 0.14540411531925201, 0.15511581301689148, 0.17727085947990417, 0.14265386760234833, 0.14441914856433868, 0.17734549939632416, 0.1376248598098755, 0.17898690700531006, 0.17590564489364624, 0.2172645777463913, 0.17143262922763824, 0.17368541657924652, 0.145554319024086, 0.17556814849376678, 0.20755167305469513, 0.14875608682632446, 0.21279124915599823, 0.17157427966594696, 0.17707781493663788, 0.1829090714454651, 0.1724359393119812, 0.147910937666893, 0.17501626908779144, 0.2192329615354538, 0.18305255472660065, 0.17018969357013702, 0.17501717805862427, 0.24542225897312164, 0.20228837430477142, 0.120231494307518, 0.1783747524023056, 0.21194402873516083, 0.16529002785682678, 0.1433333307504654, 0.1803363412618637, 0.14518290758132935, 0.14810334146022797, 0.14544357359409332, 0.14781299233436584, 0.14170166850090027, 0.12301687896251678, 0.15347625315189362, 0.14193928241729736, 0.24041172862052917, 0.12173491716384888, 0.1779250204563141, 0.17927494645118713, 0.14122822880744934, 0.20120655000209808, 0.12084055691957474, 0.17708350718021393, 0.2428971827030182, 0.16604584455490112, 0.20837968587875366, 0.14305654168128967, 0.1503940373659134, 0.12147064507007599, 0.17521731555461884, 0.20827646553516388, 0.14433340728282928, 0.15281376242637634, 0.18156325817108154, 0.1625937819480896, 0.17255717515945435, 0.1571691632270813, 0.16799990832805634, 0.14473943412303925, 0.12081677466630936, 0.1874603033065796, 0.15029534697532654, 0.14590445160865784, 0.11975884437561035, 0.18268980085849762, 0.2459242343902588, 0.21095147728919983, 0.21817606687545776, 0.1491735875606537, 0.17281076312065125, 0.16399917006492615, 0.14761199057102203, 0.1665898561477661, 0.11944896727800369, 0.21225060522556305, 0.21436269581317902, 0.15355098247528076, 0.16910380125045776, 0.2439332902431488, 0.15081390738487244, 0.18314146995544434, 0.21323874592781067, 0.12129504233598709, 0.14247821271419525, 0.14188237488269806, 0.1762528419494629, 0.14989911019802094, 0.17400668561458588, 0.12133000791072845, 0.176491379737854, 0.17959807813167572, 0.20676420629024506, 0.12088409811258316, 0.1709987074136734, 0.14367476105690002, 0.15327712893486023, 0.12018463760614395, 0.21245752274990082, 0.15994004905223846, 0.11938843131065369, 0.14342467486858368, 0.18918290734291077, 0.13890331983566284, 0.15242524445056915, 0.1452275663614273, 0.1800583451986313, 0.1754496544599533, 0.11589086055755615, 0.1445399671792984, 0.21845997869968414, 0.18185341358184814, 0.21442626416683197, 0.11415936797857285, 0.11396273225545883, 0.1559915989637375, 0.21779251098632812, 0.1810249388217926, 0.13345302641391754, 0.13440723717212677, 0.13748379051685333, 0.1455618292093277, 0.1798209398984909, 0.1855870634317398, 0.14240191876888275, 0.261175274848938, 0.14045409858226776, 0.1375635862350464, 0.16347090899944305, 0.22592954337596893, 0.1621735841035843, 0.26091304421424866, 0.22236965596675873, 0.2193422019481659, 0.13736742734909058, 0.21159295737743378, 0.1478971540927887, 0.11399184167385101, 0.15248939394950867, 0.23062969744205475, 0.218052938580513, 0.19001492857933044, 0.14953868091106415, 0.11594739556312561, 0.11617077887058258, 0.14746572077274323, 0.14498589932918549, 0.11552485078573227, 0.11522453278303146, 0.11470536887645721, 0.11403638869524002, 0.14510656893253326, 0.1401650309562683, 0.14558985829353333, 0.1800985038280487, 0.21964913606643677, 0.13869479298591614, 0.22058480978012085, 0.13818290829658508, 0.22392261028289795, 0.14227403700351715, 0.1804846227169037, 0.10868221521377563, 0.14024005830287933, 0.17526869475841522, 0.1445777714252472, 0.18565700948238373, 0.2182074338197708, 0.14119014143943787, 0.10695493966341019, 0.2687090337276459, 0.22841957211494446, 0.22645960748195648, 0.23400166630744934, 0.1377793252468109, 0.137002095580101, 0.17691348493099213, 0.18519283831119537, 0.18218578398227692, 0.172845721244812, 0.1391465961933136, 0.16424933075904846, 0.11033277213573456, 0.17558668553829193, 0.14431729912757874, 0.22898492217063904, 0.1105361208319664, 0.11043401062488556, 0.1353556215763092, 0.22836270928382874, 0.17880144715309143, 0.22129465639591217, 0.17428208887577057, 0.17270390689373016, 0.1726195067167282, 0.14377866685390472, 0.17474059760570526, 0.14462722837924957, 0.14254797995090485, 0.17663778364658356, 0.17470325529575348, 0.11051442474126816, 0.11031851172447205, 0.1371375173330307, 0.16842305660247803, 0.13731588423252106, 0.1471991240978241, 0.22169126570224762, 0.186984583735466, 0.14622776210308075, 0.10805938392877579, 0.14405979216098785, 0.17962238192558289, 0.20902319252490997, 0.17931653559207916, 0.10678587853908539, 0.21681493520736694, 0.1887873411178589, 0.1917126178741455, 0.10649365186691284, 0.17677809298038483, 0.10637494176626205, 0.18134631216526031, 0.105826236307621, 0.14487627148628235, 0.182149276137352, 0.17860904335975647, 0.18674299120903015, 0.10428605228662491, 0.13580486178398132, 0.1448868364095688, 0.13822343945503235, 0.21584895253181458, 0.10241066664457321, 0.17899322509765625, 0.13417302072048187, 0.18308420479297638, 0.17699559032917023, 0.18084795773029327, 0.13531051576137543, 0.14471282064914703, 0.10020971298217773, 0.18215885758399963, 0.18068359792232513, 0.2849876880645752, 0.13363173604011536, 0.13056181371212006, 0.17745178937911987, 0.09929826855659485, 0.1354018896818161, 0.09901148080825806, 0.1780984252691269, 0.23572546243667603, 0.17975963652133942, 0.13795793056488037, 0.1376054286956787, 0.12910476326942444, 0.18868078291416168, 0.135050430893898, 0.23551984131336212, 0.13691338896751404, 0.24208202958106995, 0.23792171478271484, 0.19036853313446045, 0.17912136018276215, 0.1411024034023285, 0.22009702026844025, 0.09901432693004608, 0.2271879017353058, 0.1729007512331009, 0.12967181205749512, 0.18109048902988434, 0.18712955713272095, 0.13436411321163177, 0.1782681941986084, 0.1367320567369461, 0.171787291765213, 0.14816156029701233, 0.1351001262664795, 0.1374022215604782, 0.13918763399124146, 0.17829234898090363, 0.13218408823013306, 0.1875721663236618, 0.13483116030693054, 0.14131726324558258, 0.13818734884262085, 0.23923459649085999, 0.17542065680027008, 0.18180574476718903, 0.13721247017383575, 0.1717396229505539, 0.1804291307926178, 0.16979831457138062, 0.13886672258377075, 0.14048393070697784, 0.18137741088867188, 0.1885785162448883, 0.23105791211128235, 0.14196564257144928, 0.22560864686965942, 0.19217321276664734, 0.12716196477413177, 0.14005738496780396, 0.13972093164920807, 0.10042823106050491, 0.22658060491085052, 0.1334814578294754, 0.13748718798160553, 0.1923184096813202, 0.12912437319755554, 0.13930125534534454, 0.14359188079833984, 0.2404753565788269, 0.22915863990783691, 0.1397935152053833, 0.12699204683303833, 0.17802786827087402, 0.141640767455101, 0.18197108805179596, 0.133714959025383, 0.09929300844669342, 0.1706971675157547, 0.1820286065340042, 0.13537202775478363, 0.13137970864772797, 0.2217450886964798, 0.22852036356925964, 0.17590893805027008, 0.09849776327610016, 0.16975371539592743, 0.18059691786766052, 0.13586294651031494, 0.13890181481838226, 0.17392149567604065, 0.22127963602542877, 0.09868235886096954, 0.135060116648674, 0.14344066381454468, 0.17418311536312103, 0.22733460366725922, 0.1769273430109024, 0.13996434211730957, 0.23301962018013, 0.13099555671215057, 0.13049837946891785, 0.09892579913139343, 0.16869860887527466, 0.14040403068065643, 0.23668646812438965, 0.14077934622764587, 0.13390235602855682, 0.1805305778980255, 0.223788321018219, 0.19026684761047363, 0.2293844223022461, 0.23017995059490204, 0.09964083880186081, 0.1398128867149353, 0.10003762692213058, 0.12514804303646088, 0.09995832294225693, 0.18603657186031342, 0.1386043131351471, 0.12570250034332275, 0.18137754499912262, 0.09888510406017303, 0.14079037308692932, 0.1799406260251999, 0.12781356275081635, 0.13194194436073303, 0.09694831073284149, 0.18771778047084808, 0.13017752766609192, 0.13925591111183167, 0.13969045877456665, 0.13324910402297974, 0.2433152198791504, 0.29875901341438293, 0.09358376264572144, 0.17941826581954956, 0.29844391345977783, 0.13272692263126373, 0.13879749178886414, 0.13543958961963654, 0.23397120833396912, 0.13658928871154785, 0.09501254558563232, 0.13768483698368073, 0.29504892230033875, 0.13348960876464844, 0.18415464460849762, 0.17878565192222595, 0.09600882232189178, 0.14160747826099396, 0.09588845819234848, 0.13245372474193573, 0.14109136164188385, 0.23657138645648956, 0.18663860857486725, 0.29468342661857605, 0.14043660461902618, 0.17008830606937408, 0.187246635556221, 0.1795208752155304, 0.1492544710636139, 0.290426641702652, 0.136161208152771, 0.1288549154996872, 0.22432725131511688, 0.18462711572647095, 0.2853236496448517, 0.12947797775268555, 0.10045706480741501, 0.2218140959739685, 0.22297325730323792, 0.10211309790611267, 0.102415531873703, 0.18517965078353882, 0.2208268791437149, 0.13307181000709534, 0.1288413256406784, 0.18056485056877136, 0.139699786901474, 0.1488916426897049, 0.20995020866394043, 0.17432241141796112, 0.10434658080339432, 0.17447195947170258, 0.1689910590648651, 0.18116062879562378, 0.22847908735275269, 0.2329033464193344, 0.1831117421388626, 0.17260073125362396, 0.19543282687664032, 0.13588905334472656, 0.17704926431179047, 0.12008796632289886, 0.15270133316516876, 0.10726067423820496, 0.18129856884479523, 0.13390889763832092, 0.14196409285068512, 0.1624690294265747, 0.10699445009231567, 0.16216379404067993, 0.16931965947151184, 0.10595747083425522, 0.10611574351787567, 0.22680655121803284, 0.2721986770629883, 0.15865281224250793, 0.1321966052055359, 0.14943964779376984, 0.21964652836322784, 0.14590243995189667, 0.13238301873207092, 0.15334461629390717, 0.1881863921880722, 0.15733611583709717, 0.10583236813545227, 0.15648303925991058, 0.1359945386648178, 0.17339134216308594, 0.19108779728412628, 0.11813008040189743, 0.10461046546697617, 0.15870463848114014, 0.10352394729852676, 0.14968787133693695, 0.20232386887073517, 0.22495737671852112, 0.24044257402420044, 0.1018415242433548, 0.27927646040916443, 0.21595968306064606, 0.22320979833602905, 0.23062415421009064, 0.1485041379928589, 0.23175814747810364, 0.10491018742322922, 0.1847507655620575, 0.19365660846233368, 0.1464797854423523, 0.17689861357212067, 0.13515004515647888, 0.17491629719734192, 0.10683482140302658, 0.1069529801607132, 0.2466673105955124, 0.13587690889835358, 0.21911995112895966, 0.19084596633911133, 0.1421249806880951, 0.10688741505146027, 0.13650506734848022, 0.2156800627708435, 0.21500548720359802, 0.1305997371673584, 0.14107054471969604, 0.18891102075576782, 0.10700064152479172, 0.22217024862766266, 0.16360092163085938, 0.22601202130317688, 0.10729287564754486, 0.17801202833652496, 0.21592111885547638, 0.1799902319908142, 0.1868017017841339, 0.17732368409633636, 0.1734219491481781, 0.17480416595935822, 0.2134334295988083, 0.18364453315734863, 0.1420704424381256, 0.14639216661453247, 0.1349322348833084, 0.10999704897403717, 0.1765376180410385, 0.15383726358413696, 0.17235136032104492, 0.2104824036359787, 0.22521427273750305, 0.1359168440103531, 0.1487404853105545, 0.17892833054065704, 0.11009540408849716, 0.1863061785697937, 0.17454227805137634, 0.16950350999832153, 0.18378372490406036, 0.16610431671142578, 0.17503850162029266, 0.14386284351348877, 0.16919493675231934, 0.14168760180473328, 0.11031416803598404, 0.17922990024089813, 0.13901783525943756, 0.14291159808635712, 0.14606045186519623, 0.1436070054769516, 0.18298427760601044, 0.13297420740127563, 0.12994158267974854, 0.10756880789995193, 0.14021189510822296, 0.17070510983467102, 0.17628049850463867, 0.17183294892311096, 0.14185425639152527, 0.22458262741565704, 0.17066314816474915, 0.21223200857639313, 0.1772962361574173, 0.13745202124118805, 0.17105799913406372, 0.13892988860607147, 0.10518873482942581, 0.17414581775665283, 0.10492409765720367, 0.2196439951658249, 0.19482704997062683, 0.17716923356056213, 0.14923147857189178, 0.27372369170188904, 0.1863223910331726, 0.1050209179520607, 0.17845511436462402, 0.20827598869800568, 0.16654051840305328, 0.14585331082344055, 0.21299225091934204, 0.21547526121139526, 0.14038975536823273, 0.14641663432121277, 0.18900066614151, 0.14685159921646118, 0.21324706077575684, 0.14362813532352448, 0.22364643216133118, 0.18143780529499054, 0.21410368382930756, 0.17448139190673828, 0.16024433076381683, 0.21589146554470062, 0.2234528660774231, 0.14034080505371094, 0.16305607557296753, 0.1394875943660736, 0.1115821972489357, 0.16715896129608154, 0.19343039393424988, 0.1775190532207489, 0.1776433140039444, 0.1344873011112213, 0.12320013344287872, 0.1124732568860054, 0.14156080782413483, 0.167546808719635, 0.14755424857139587, 0.18621213734149933, 0.21860283613204956, 0.2147594690322876, 0.16723982989788055, 0.1496390402317047, 0.17352908849716187, 0.16805091500282288, 0.15057380497455597, 0.14275769889354706, 0.16469015181064606, 0.1393941193819046, 0.18437610566616058, 0.20043331384658813, 0.11161775887012482, 0.14951655268669128, 0.20098328590393066, 0.15715768933296204, 0.17221827805042267, 0.1525861620903015, 0.13470487296581268, 0.21455641090869904, 0.1460522711277008, 0.18784606456756592, 0.11006081849336624, 0.14512000977993011, 0.18411746621131897, 0.14802077412605286, 0.13808797299861908, 0.10882314294576645, 0.21949659287929535, 0.10846154391765594, 0.10801710188388824, 0.18025438487529755, 0.10703637450933456, 0.18154312670230865, 0.1060754582285881, 0.23819755017757416, 0.13817989826202393, 0.18072491884231567, 0.133103147149086, 0.1504676192998886, 0.2747756540775299, 0.18871720135211945, 0.18661655485630035, 0.13991929590702057, 0.10387485474348068, 0.1333448588848114, 0.15320627391338348, 0.17108531296253204, 0.14483065903186798, 0.1402156502008438, 0.18187659978866577, 0.2401456981897354, 0.13915111124515533, 0.17288917303085327, 0.23861446976661682, 0.18201015889644623, 0.22251750528812408, 0.18148308992385864, 0.1839888095855713, 0.17908158898353577, 0.1379440724849701, 0.1857098937034607, 0.13925695419311523, 0.14140072464942932, 0.21760466694831848, 0.18665741384029388, 0.10428911447525024, 0.14758706092834473, 0.1361391246318817, 0.10413821041584015, 0.18508385121822357, 0.2753213346004486, 0.17852576076984406, 0.13432560861110687, 0.12971335649490356, 0.10388081520795822, 0.1935826539993286, 0.17651236057281494, 0.17203906178474426, 0.17317277193069458, 0.17926663160324097, 0.23398487269878387, 0.10386551171541214, 0.14909079670906067, 0.17166350781917572, 0.1666199117898941, 0.13585758209228516, 0.10377271473407745, 0.18217143416404724, 0.21711580455303192, 0.10346987843513489, 0.17680363357067108, 0.1740153580904007, 0.1864214986562729, 0.18474450707435608, 0.2280217856168747, 0.13354191184043884, 0.15356004238128662, 0.2212677299976349, 0.17619824409484863, 0.14505688846111298, 0.1725068837404251, 0.10413488745689392, 0.1823754608631134, 0.13924452662467957, 0.13900145888328552, 0.17214128375053406, 0.16999544203281403, 0.12325312942266464, 0.17922310531139374, 0.17554011940956116, 0.17794808745384216, 0.1691495180130005, 0.14852719008922577, 0.21625764667987823, 0.15072448551654816, 0.17597976326942444, 0.18465128540992737, 0.1889113336801529, 0.19171331822872162, 0.12780573964118958, 0.182016983628273, 0.13168863952159882, 0.14014612138271332, 0.18657943606376648, 0.13417403399944305, 0.13813108205795288, 0.14612266421318054, 0.1902914047241211, 0.14449641108512878, 0.13823729753494263, 0.13650253415107727, 0.16726861894130707, 0.17498765885829926, 0.2231660783290863, 0.17688441276550293, 0.1381291151046753, 0.13437506556510925, 0.18238919973373413, 0.13871103525161743, 0.1286175549030304, 0.1698642522096634, 0.2175614982843399, 0.1366806924343109, 0.10141131281852722, 0.13287179172039032, 0.1694803237915039, 0.1009502187371254, 0.10054781287908554, 0.1782059222459793, 0.23455500602722168, 0.22756512463092804, 0.23832714557647705, 0.1805352419614792, 0.18754351139068604, 0.18866537511348724, 0.21590304374694824, 0.14946305751800537, 0.10126958042383194, 0.1936219036579132, 0.13479486107826233, 0.14387215673923492, 0.18476401269435883, 0.13738420605659485, 0.1649838089942932, 0.22255343198776245, 0.1836097091436386, 0.13251186907291412, 0.16769945621490479, 0.10205502063035965, 0.13607807457447052, 0.1017342135310173, 0.10142926871776581, 0.17640309035778046, 0.14535380899906158, 0.20175716280937195, 0.1887432485818863, 0.09996102005243301, 0.13145698606967926, 0.1424054652452469, 0.1742195039987564, 0.12821151316165924, 0.19537070393562317, 0.17642559111118317, 0.17462094128131866, 0.09744099527597427, 0.16013401746749878, 0.1430676430463791, 0.17128382623195648, 0.14777280390262604, 0.18125195801258087, 0.17433974146842957, 0.13165238499641418, 0.1852668672800064, 0.1694522202014923, 0.16639700531959534, 0.14052055776119232, 0.18335753679275513, 0.11901163309812546, 0.14661775529384613, 0.2326940894126892, 0.192186638712883, 0.1790289282798767, 0.19370852410793304, 0.17636631429195404, 0.1708153933286667, 0.18139810860157013, 0.19109560549259186, 0.18652211129665375, 0.18945370614528656, 0.13849404454231262, 0.13258527219295502, 0.13418616354465485, 0.2372797280550003, 0.1281847357749939, 0.18921014666557312, 0.13790059089660645, 0.14124399423599243, 0.137599915266037, 0.23619790375232697, 0.18094268441200256, 0.1445576250553131, 0.14275690913200378, 0.25110968947410583, 0.1314813494682312, 0.1365925520658493, 0.09713905304670334, 0.24395902454853058, 0.12508176267147064, 0.21056212484836578, 0.170135498046875, 0.17763110995292664, 0.23945891857147217, 0.09719487279653549, 0.18403224647045135, 0.1769840121269226, 0.13289237022399902, 0.14400577545166016, 0.09764700382947922, 0.18070705235004425, 0.19554995000362396, 0.09721267968416214, 0.18977820873260498, 0.13400398194789886, 0.18042795360088348, 0.18074771761894226, 0.17474377155303955, 0.13385073840618134, 0.1432277113199234, 0.0961296558380127, 0.13497091829776764, 0.2211705446243286, 0.24190086126327515, 0.17347832024097443, 0.1276913583278656, 0.22819069027900696, 0.18495962023735046, 0.18898603320121765, 0.1297953873872757, 0.1709904670715332, 0.13568012416362762, 0.13853473961353302, 0.29092612862586975, 0.14989140629768372, 0.22571918368339539, 0.14398673176765442, 0.09794045239686966, 0.14009396731853485, 0.17529642581939697, 0.13488051295280457, 0.1305357664823532, 0.17957185208797455, 0.1799032837152481, 0.16373741626739502, 0.13347630202770233, 0.1846321076154709, 0.2880871295928955, 0.19339917600154877, 0.23196464776992798, 0.1440063863992691, 0.18913470208644867, 0.1393798142671585, 0.1359362006187439, 0.18556343019008636, 0.1389894038438797, 0.18971171975135803, 0.13928496837615967, 0.13653618097305298, 0.19427460432052612, 0.10042153298854828, 0.19523297250270844, 0.12873004376888275, 0.10011664032936096, 0.22640308737754822, 0.099749356508255, 0.13995307683944702, 0.1858530193567276, 0.14448176324367523, 0.13218165934085846, 0.1308736354112625, 0.13057444989681244, 0.09782692044973373, 0.1354118436574936, 0.18059353530406952, 0.17292609810829163, 0.09606673568487167, 0.18120482563972473, 0.13631412386894226, 0.1308029741048813, 0.17515656352043152, 0.09404489398002625, 0.1348138004541397, 0.17188748717308044, 0.18817108869552612, 0.177826926112175, 0.18152667582035065, 0.17818209528923035, 0.13190539181232452, 0.0916929841041565, 0.17369450628757477, 0.23844242095947266, 0.18209604918956757, 0.19046837091445923, 0.09127654135227203, 0.24243392050266266, 0.24599651992321014, 0.13067452609539032, 0.18485847115516663, 0.091964490711689, 0.1770699918270111, 0.14134474098682404, 0.13173535466194153, 0.13486826419830322, 0.18496794998645782, 0.13296732306480408, 0.0917929857969284, 0.0914703905582428, 0.3043215274810791, 0.17270764708518982, 0.20367828011512756, 0.1802522987127304, 0.09153227508068085, 0.17573904991149902, 0.1791001707315445, 0.12488366663455963, 0.0914895087480545, 0.19855958223342896, 0.19131170213222504, 0.12414524704217911, 0.1323995441198349, 0.18497921526432037, 0.1337549388408661, 0.1794721782207489, 0.12899985909461975, 0.1418256163597107, 0.30667588114738464, 0.13159999251365662, 0.09055726230144501, 0.23718003928661346, 0.17846639454364777, 0.13471680879592896, 0.09085331857204437, 0.13221392035484314, 0.12814004719257355, 0.2423001080751419, 0.12360544502735138, 0.2454858124256134, 0.1299063116312027, 0.19398286938667297, 0.12495555728673935, 0.1304711550474167, 0.13208051025867462, 0.13106748461723328, 0.18009747564792633, 0.2456679493188858, 0.1353953778743744, 0.17751362919807434, 0.18301339447498322, 0.1796693205833435, 0.09078352898359299, 0.1753344088792801, 0.12284747511148453, 0.30530086159706116, 0.09096713364124298, 0.194994255900383, 0.13603544235229492, 0.09146434813737869, 0.17453904449939728, 0.1837441325187683, 0.1352911740541458, 0.18719790875911713, 0.18522559106349945, 0.24190519750118256, 0.13176760077476501, 0.12819190323352814, 0.09182027727365494, 0.13152702152729034, 0.1783570945262909, 0.0915052741765976, 0.1781422644853592, 0.13504905998706818, 0.18001925945281982, 0.18027585744857788, 0.1317080557346344, 0.24208538234233856, 0.18129810690879822, 0.18592001497745514, 0.14069750905036926, 0.09083367884159088, 0.1873464584350586, 0.1878969818353653, 0.23907147347927094, 0.2417663335800171, 0.18131721019744873, 0.17453797161579132, 0.13094928860664368, 0.1376497447490692, 0.17568707466125488, 0.13426750898361206, 0.25089961290359497, 0.09298155456781387, 0.18150345981121063, 0.12340741604566574, 0.19185709953308105, 0.14669503271579742, 0.19404391944408417, 0.13261383771896362, 0.09347989410161972, 0.29891306161880493, 0.1285138726234436, 0.09365272521972656, 0.13562774658203125, 0.09345397353172302, 0.12176035344600677, 0.12490113824605942, 0.13665075600147247, 0.2351023405790329, 0.23144957423210144, 0.1749463826417923, 0.13717302680015564, 0.13018405437469482, 0.1859784722328186, 0.18683476746082306, 0.24623489379882812, 0.13323013484477997, 0.23120513558387756, 0.1977788656949997, 0.13224045932292938, 0.24430204927921295, 0.24558737874031067, 0.14404572546482086, 0.13206475973129272, 0.13650134205818176, 0.1810503602027893, 0.19148531556129456, 0.18041245639324188, 0.18583470582962036, 0.13959704339504242, 0.142663836479187, 0.13724729418754578, 0.1906987726688385, 0.23158875107765198, 0.23767857253551483, 0.18618455529212952, 0.1321946531534195, 0.23958441615104675, 0.19354048371315002, 0.1943032294511795, 0.09852543473243713, 0.17707479000091553, 0.18365958333015442, 0.23305518925189972, 0.2262895107269287, 0.1000748947262764, 0.14078862965106964, 0.13544777035713196, 0.14192801713943481, 0.14728116989135742, 0.18397845327854156, 0.17522041499614716, 0.14355170726776123, 0.13163162767887115, 0.19243468344211578, 0.2336857169866562, 0.1417434960603714, 0.17167726159095764, 0.10067716985940933, 0.17687919735908508, 0.23460254073143005, 0.18133682012557983, 0.10087168216705322, 0.10082336515188217, 0.17666636407375336, 0.2324957400560379, 0.18282556533813477, 0.1843697875738144, 0.22826848924160004, 0.13652221858501434, 0.1387440413236618, 0.1799563616514206, 0.10159574449062347, 0.22949190437793732, 0.1400861293077469, 0.13527268171310425, 0.17201389372348785, 0.10158062726259232, 0.1848406344652176, 0.10133304446935654, 0.17159080505371094, 0.13407926261425018, 0.18231965601444244, 0.23023153841495514, 0.1371075063943863, 0.13247893750667572, 0.14323408901691437, 0.10028304159641266, 0.173234224319458, 0.23293352127075195, 0.23436091840267181, 0.23382815718650818, 0.1387614607810974, 0.13222108781337738, 0.23291178047657013, 0.18481357395648956, 0.13209499418735504, 0.24045565724372864, 0.17475952208042145, 0.1443302184343338, 0.13610149919986725, 0.2369219958782196, 0.1308690458536148, 0.10234735161066055, 0.22404450178146362, 0.10250801593065262, 0.10253766924142838, 0.132270947098732, 0.18962541222572327, 0.22877246141433716, 0.1411924809217453, 0.17381682991981506, 0.18544118106365204, 0.10220082104206085, 0.2783842086791992, 0.13688801229000092, 0.17997199296951294, 0.135163813829422, 0.1026545837521553, 0.14529718458652496, 0.10227382183074951, 0.14531974494457245, 0.23724912106990814, 0.10167816281318665, 0.13819319009780884, 0.16860584914684296, 0.13826890289783478, 0.14174239337444305, 0.10034671425819397, 0.09994155913591385, 0.17926815152168274, 0.133354052901268, 0.2859770655632019, 0.13038355112075806, 0.2352912276983261, 0.14048191905021667, 0.1358073353767395, 0.23634351789951324, 0.22863341867923737, 0.13841849565505981, 0.14372935891151428, 0.1706831157207489, 0.18123817443847656, 0.1749960482120514, 0.13921944797039032, 0.09909220784902573, 0.2851407527923584, 0.22538304328918457, 0.13761521875858307, 0.1409352570772171, 0.17619910836219788, 0.17735715210437775, 0.1436309516429901, 0.1784151941537857, 0.17842724919319153, 0.22097060084342957, 0.2808786630630493, 0.17286574840545654, 0.18216684460639954, 0.19115763902664185, 0.10290119051933289, 0.1392870992422104, 0.14322836697101593, 0.13683122396469116, 0.17118002474308014, 0.18356673419475555, 0.18973341584205627, 0.23073288798332214, 0.14176975190639496, 0.17941579222679138, 0.273665189743042, 0.1453419029712677, 0.22943711280822754, 0.18489980697631836, 0.1058581992983818, 0.17958813905715942, 0.2253008484840393, 0.10668417811393738, 0.17765729129314423, 0.14597240090370178, 0.10720349848270416, 0.10709547996520996, 0.14138886332511902, 0.26861560344696045, 0.21487243473529816, 0.13442599773406982, 0.14465057849884033, 0.1680101603269577, 0.18119964003562927, 0.17422711849212646, 0.2218119502067566, 0.21231889724731445, 0.17387142777442932, 0.14919757843017578, 0.14146316051483154, 0.16460268199443817, 0.21822765469551086, 0.16746658086776733, 0.19464075565338135, 0.16536496579647064, 0.10999488830566406, 0.1394774168729782, 0.13747285306453705, 0.13834883272647858, 0.13727666437625885, 0.1441969871520996, 0.1373763531446457, 0.13600653409957886, 0.16405649483203888, 0.169321209192276, 0.14752957224845886, 0.2014007568359375, 0.14232270419597626, 0.14848512411117554, 0.18470391631126404, 0.1787422150373459, 0.22348642349243164, 0.16460269689559937, 0.16982659697532654, 0.1439376026391983, 0.17366202175617218, 0.12635278701782227, 0.2259826958179474, 0.1771474927663803, 0.13395561277866364, 0.19464772939682007, 0.1991010159254074, 0.2289418876171112, 0.1281842142343521, 0.1562335342168808, 0.1297280341386795, 0.20862175524234772, 0.13278532028198242, 0.20210768282413483, 0.13014021515846252, 0.1793585866689682, 0.10970976948738098, 0.19837461411952972, 0.21604882180690765, 0.19595688581466675, 0.14590588212013245, 0.15300309658050537, 0.19440560042858124, 0.26254981756210327, 0.1955014169216156, 0.11064723134040833, 0.13692311942577362, 0.15615223348140717, 0.14877626299858093, 0.14036762714385986, 0.190858855843544, 0.12255758792161942, 0.19301334023475647, 0.1643170863389969, 0.1451730877161026, 0.1559775024652481, 0.12959903478622437, 0.20994114875793457, 0.11075694113969803, 0.15139295160770416, 0.21622134745121002, 0.14019566774368286, 0.10985547304153442, 0.1896236687898636, 0.11005087196826935, 0.1093970537185669, 0.1905737668275833]\n",
            "Val loss 0.1670366127527397\n",
            "Val auc roc 0.5001880878496451\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9478b6bb9566476d917e2c64df504ac1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2656.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.1657\n",
            "Train Losses : [0.17100685834884644, 0.12454754114151001, 0.21149340271949768, 0.19855737686157227, 0.13387040793895721, 0.13134603202342987, 0.20389527082443237, 0.16340702772140503, 0.1306556910276413, 0.2376227229833603, 0.13369709253311157, 0.1918020248413086, 0.17272718250751495, 0.14669975638389587, 0.1646191030740738, 0.14441286027431488, 0.19310946762561798, 0.10701818019151688, 0.10693895816802979, 0.19784098863601685, 0.13586430251598358, 0.1863773912191391, 0.1847783625125885, 0.16240130364894867, 0.12553612887859344, 0.18110713362693787, 0.18688790500164032, 0.13592693209648132, 0.1827576458454132, 0.2223159670829773, 0.1796189844608307, 0.13477423787117004, 0.2724253237247467, 0.1646159440279007, 0.20068588852882385, 0.17712780833244324, 0.12600882351398468, 0.10654210299253464, 0.1230950877070427, 0.1934736669063568, 0.19823144376277924, 0.13426995277404785, 0.15689662098884583, 0.2692073583602905, 0.22449907660484314, 0.2108832448720932, 0.1781248152256012, 0.19294172525405884, 0.16407857835292816, 0.16130810976028442, 0.2655431628227234, 0.10922907292842865, 0.127940371632576, 0.13403601944446564, 0.18168188631534576, 0.10998568683862686, 0.19415223598480225, 0.13798628747463226, 0.18239633738994598, 0.21149136126041412, 0.10967879742383957, 0.1655113250017166, 0.13294075429439545, 0.2046227902173996, 0.1970001459121704, 0.17164571583271027, 0.18949885666370392, 0.1321077048778534, 0.17230351269245148, 0.1454181671142578, 0.13337458670139313, 0.1094675362110138, 0.21827015280723572, 0.14116977155208588, 0.17284607887268066, 0.10913579165935516, 0.14414064586162567, 0.1682852804660797, 0.18156489729881287, 0.13290905952453613, 0.15480561554431915, 0.1505609154701233, 0.15992823243141174, 0.1406720131635666, 0.2180386781692505, 0.1975812464952469, 0.13894937932491302, 0.13591182231903076, 0.13304133713245392, 0.17753630876541138, 0.18263989686965942, 0.10587367415428162, 0.13963095843791962, 0.23044434189796448, 0.10496511310338974, 0.20048941671848297, 0.17518962919712067, 0.2736749053001404, 0.22205790877342224, 0.19622892141342163, 0.16675883531570435, 0.2220817506313324, 0.1686796247959137, 0.12508895993232727, 0.10690358281135559, 0.21628887951374054, 0.16695329546928406, 0.2243558019399643, 0.1808827817440033, 0.12381349503993988, 0.21641051769256592, 0.1488819271326065, 0.1586717665195465, 0.1772063672542572, 0.1507415920495987, 0.17849573493003845, 0.14117403328418732, 0.1099252700805664, 0.13298174738883972, 0.1376873403787613, 0.198710635304451, 0.1270599514245987, 0.17799623310565948, 0.21698839962482452, 0.14396242797374725, 0.16879650950431824, 0.20411927998065948, 0.14528131484985352, 0.18078544735908508, 0.20218905806541443, 0.22320163249969482, 0.14850987493991852, 0.18877345323562622, 0.17349717020988464, 0.14970915019512177, 0.14550575613975525, 0.16965064406394958, 0.2165096551179886, 0.23687152564525604, 0.11011074483394623, 0.2069309949874878, 0.1506652534008026, 0.14822867512702942, 0.16299450397491455, 0.1453818827867508, 0.2613331973552704, 0.16162212193012238, 0.14084748923778534, 0.2302720546722412, 0.12913832068443298, 0.11142367124557495, 0.1566457450389862, 0.15811751782894135, 0.1736707091331482, 0.1813633143901825, 0.17855949699878693, 0.11136528849601746, 0.22312510013580322, 0.13649582862854004, 0.20279665291309357, 0.14812301099300385, 0.11121974885463715, 0.11140844225883484, 0.1780172735452652, 0.22723837196826935, 0.18801672756671906, 0.11091573536396027, 0.12926635146141052, 0.1431061178445816, 0.13362820446491241, 0.17893488705158234, 0.13395565748214722, 0.13747087121009827, 0.10946257412433624, 0.15528318285942078, 0.1320708692073822, 0.1837012767791748, 0.22373074293136597, 0.1385747790336609, 0.16830210387706757, 0.15093058347702026, 0.16586001217365265, 0.26783934235572815, 0.13691113889217377, 0.14247740805149078, 0.17423436045646667, 0.23743543028831482, 0.17819777131080627, 0.1237267404794693, 0.22839219868183136, 0.20489105582237244, 0.23282186686992645, 0.13800691068172455, 0.13391812145709991, 0.13020266592502594, 0.23556528985500336, 0.1537061631679535, 0.1360587626695633, 0.21217650175094604, 0.13114666938781738, 0.11032117903232574, 0.16850046813488007, 0.13760234415531158, 0.1379069983959198, 0.17763619124889374, 0.2060445100069046, 0.12834987044334412, 0.1387680619955063, 0.19990244507789612, 0.16236716508865356, 0.16949085891246796, 0.18125797808170319, 0.1285228580236435, 0.17055979371070862, 0.18184633553028107, 0.1482376903295517, 0.18594390153884888, 0.2137008160352707, 0.13824684917926788, 0.1874084174633026, 0.1293729543685913, 0.1658284217119217, 0.13844893872737885, 0.18805554509162903, 0.1501072198152542, 0.13604618608951569, 0.15897120535373688, 0.19083243608474731, 0.26287299394607544, 0.18697401881217957, 0.26196879148483276, 0.18270044028759003, 0.19744296371936798, 0.11230811476707458, 0.1432199627161026, 0.19717441499233246, 0.1804487556219101, 0.1636134386062622, 0.15069392323493958, 0.1626855432987213, 0.2282845824956894, 0.11356980353593826, 0.13948026299476624, 0.1134209856390953, 0.1494046300649643, 0.19928951561450958, 0.20688237249851227, 0.13545231521129608, 0.14139136672019958, 0.2061845064163208, 0.1889350861310959, 0.14278879761695862, 0.1308141052722931, 0.16432665288448334, 0.14266102015972137, 0.14097952842712402, 0.1826373040676117, 0.19791197776794434, 0.18239854276180267, 0.18240530788898468, 0.16378313302993774, 0.11190789937973022, 0.19773297011852264, 0.19213268160820007, 0.14108134806156158, 0.22584804892539978, 0.22148600220680237, 0.19969485700130463, 0.15995843708515167, 0.11218225955963135, 0.20550185441970825, 0.13672548532485962, 0.1642601191997528, 0.14171159267425537, 0.11246883124113083, 0.15532991290092468, 0.15837855637073517, 0.16279147565364838, 0.14222921431064606, 0.14671571552753448, 0.1115252822637558, 0.13573837280273438, 0.14633774757385254, 0.18232040107250214, 0.1582542210817337, 0.10973289608955383, 0.1417790800333023, 0.18933862447738647, 0.17135633528232574, 0.2241659313440323, 0.19012989103794098, 0.16977940499782562, 0.18899160623550415, 0.15437176823616028, 0.1615506261587143, 0.14269757270812988, 0.1570289582014084, 0.21587903797626495, 0.12483569979667664, 0.19099202752113342, 0.13965679705142975, 0.13686127960681915, 0.17093296349048615, 0.16805967688560486, 0.2024051994085312, 0.14862751960754395, 0.150602787733078, 0.13152937591075897, 0.177956223487854, 0.13639022409915924, 0.10750734806060791, 0.24150599539279938, 0.10719053447246552, 0.18940593302249908, 0.18790195882320404, 0.17042285203933716, 0.1278984248638153, 0.14117269217967987, 0.1064690425992012, 0.1456601768732071, 0.1323617845773697, 0.17772553861141205, 0.16662558913230896, 0.1811843365430832, 0.12860482931137085, 0.1652103066444397, 0.19696736335754395, 0.20798183977603912, 0.18959063291549683, 0.20017077028751373, 0.1349383443593979, 0.21602469682693481, 0.2741564214229584, 0.13628074526786804, 0.21196235716342926, 0.23322561383247375, 0.13511651754379272, 0.23915179073810577, 0.1059553250670433, 0.19603003561496735, 0.18826697766780853, 0.14283186197280884, 0.17394167184829712, 0.10715191811323166, 0.14958281815052032, 0.15190242230892181, 0.224223330616951, 0.15667890012264252, 0.15825675427913666, 0.19703270494937897, 0.19589698314666748, 0.17961692810058594, 0.17553137242794037, 0.18325720727443695, 0.15714304149150848, 0.1072491854429245, 0.14647865295410156, 0.16474896669387817, 0.1719808727502823, 0.18885686993598938, 0.10667839646339417, 0.22846731543540955, 0.19945171475410461, 0.19079093635082245, 0.10655760765075684, 0.14018237590789795, 0.16633382439613342, 0.13554450869560242, 0.18076196312904358, 0.10598201304674149, 0.2705351412296295, 0.14728058874607086, 0.179270938038826, 0.17441600561141968, 0.20774154365062714, 0.13863474130630493, 0.13755705952644348, 0.236053928732872, 0.13709138333797455, 0.18770556151866913, 0.10670509934425354, 0.14430919289588928, 0.16820789873600006, 0.13189797103405, 0.18595685064792633, 0.13365881145000458, 0.19404911994934082, 0.17969104647636414, 0.15147919952869415, 0.23910164833068848, 0.14387482404708862, 0.13199996948242188, 0.13116756081581116, 0.1353188008069992, 0.15392106771469116, 0.17466050386428833, 0.17312966287136078, 0.27209264039993286, 0.2719723880290985, 0.23047593235969543, 0.22333867847919464, 0.10680749267339706, 0.1277356892824173, 0.172621488571167, 0.1468350887298584, 0.13710978627204895, 0.21976996958255768, 0.17115120589733124, 0.13815832138061523, 0.13311120867729187, 0.14698414504528046, 0.19199365377426147, 0.15095236897468567, 0.17080309987068176, 0.10854730755090714, 0.17508229613304138, 0.18739436566829681, 0.13201311230659485, 0.19243597984313965, 0.15408855676651, 0.15313133597373962, 0.10853797942399979, 0.10764575749635696, 0.1400739997625351, 0.1322556883096695, 0.17799755930900574, 0.15410278737545013, 0.19737163186073303, 0.1741323322057724, 0.16527298092842102, 0.13335852324962616, 0.16776007413864136, 0.12173598259687424, 0.10504864156246185, 0.13255544006824493, 0.1873355656862259, 0.22206620872020721, 0.14773845672607422, 0.1886131763458252, 0.18044158816337585, 0.12056370079517365, 0.14202472567558289, 0.2766275703907013, 0.22941671311855316, 0.18054243922233582, 0.13536031544208527, 0.21218296885490417, 0.2279772162437439, 0.10540845990180969, 0.14159566164016724, 0.18410082161426544, 0.17309080064296722, 0.22269941866397858, 0.16381867229938507, 0.17912070453166962, 0.14514772593975067, 0.2041057050228119, 0.12852613627910614, 0.13957011699676514, 0.21654929220676422, 0.15065394341945648, 0.13742013275623322, 0.15419988334178925, 0.12343736737966537, 0.13583169877529144, 0.19780203700065613, 0.22157467901706696, 0.16640137135982513, 0.13576975464820862, 0.10695745050907135, 0.11811842769384384, 0.15362849831581116, 0.17311732470989227, 0.1336597502231598, 0.14017175137996674, 0.13000844419002533, 0.12262243777513504, 0.1641528606414795, 0.2396564781665802, 0.15213757753372192, 0.10599162429571152, 0.27298927307128906, 0.13569073379039764, 0.21124635636806488, 0.1926753669977188, 0.1617830991744995, 0.15196871757507324, 0.1742386519908905, 0.12533500790596008, 0.14779585599899292, 0.22776944935321808, 0.10539864748716354, 0.10578444600105286, 0.21064980328083038, 0.18786607682704926, 0.21633492410182953, 0.20840641856193542, 0.10544456541538239, 0.15789571404457092, 0.16184663772583008, 0.2137252539396286, 0.1411503702402115, 0.13568179309368134, 0.1629154533147812, 0.18765926361083984, 0.14602038264274597, 0.23873542249202728, 0.15642856061458588, 0.10554017871618271, 0.13864640891551971, 0.13210025429725647, 0.10522590577602386, 0.1803106814622879, 0.1855207085609436, 0.16876854002475739, 0.1543654501438141, 0.13019050657749176, 0.11893780529499054, 0.13432815670967102, 0.1697467714548111, 0.16170799732208252, 0.12154245376586914, 0.12400335818529129, 0.1547161489725113, 0.1389283835887909, 0.10186092555522919, 0.2804085314273834, 0.14452454447746277, 0.17784349620342255, 0.1845400184392929, 0.10123217105865479, 0.14721712470054626, 0.10111430287361145, 0.12160136550664902, 0.17230316996574402, 0.17017047107219696, 0.17645487189292908, 0.2012084722518921, 0.17185179889202118, 0.17393244802951813, 0.09931645542383194, 0.13666440546512604, 0.16958561539649963, 0.2473144233226776, 0.15203213691711426, 0.23429657518863678, 0.13234132528305054, 0.1433723419904709, 0.0985574945807457, 0.20019623637199402, 0.15425057709217072, 0.17339642345905304, 0.1831728219985962, 0.1914801001548767, 0.18011260032653809, 0.2462807595729828, 0.20354607701301575, 0.2878354787826538, 0.17693890631198883, 0.13716168701648712, 0.09992853552103043, 0.16753610968589783, 0.09978277236223221, 0.16268783807754517, 0.10005224496126175, 0.14337854087352753, 0.18887284398078918, 0.12223939597606659, 0.13603469729423523, 0.11860892176628113, 0.13935525715351105, 0.11691521108150482, 0.14303715527057648, 0.18785244226455688, 0.28816723823547363, 0.1405188888311386, 0.15754027664661407, 0.1271451860666275, 0.16830891370773315, 0.17188383638858795, 0.1758643388748169, 0.09792764484882355, 0.09818831831216812, 0.18303699791431427, 0.17301593720912933, 0.12932609021663666, 0.11235730350017548, 0.09707312285900116, 0.15466220676898956, 0.22963759303092957, 0.1643454134464264, 0.13785934448242188, 0.1364128291606903, 0.1654016673564911, 0.1572258174419403, 0.29353049397468567, 0.24688202142715454, 0.12322738766670227, 0.24448667466640472, 0.20722632110118866, 0.17222875356674194, 0.14746923744678497, 0.09791513532400131, 0.1686292588710785, 0.19430719316005707, 0.09788874536752701, 0.22652123868465424, 0.2288190871477127, 0.1848626434803009, 0.17660340666770935, 0.223898246884346, 0.16449680924415588, 0.28624141216278076, 0.1516418755054474, 0.14038757979869843, 0.10060075670480728, 0.16449448466300964, 0.136998251080513, 0.18860100209712982, 0.1861737221479416, 0.14520934224128723, 0.13299879431724548, 0.17186897993087769, 0.19600197672843933, 0.15957863628864288, 0.2318807691335678, 0.14332596957683563, 0.22995950281620026, 0.13059601187705994, 0.14531978964805603, 0.1696922779083252, 0.12936265766620636, 0.2780973017215729, 0.18904085457324982, 0.22109024226665497, 0.2534514367580414, 0.10457301884889603, 0.20711460709571838, 0.22517411410808563, 0.13949060440063477, 0.13467204570770264, 0.16135959327220917, 0.1329471915960312, 0.15222766995429993, 0.10614871233701706, 0.15299199521541595, 0.13013097643852234, 0.13653600215911865, 0.1514071673154831, 0.1831650286912918, 0.12236204743385315, 0.14221766591072083, 0.14668746292591095, 0.15897688269615173, 0.18454842269420624, 0.14462769031524658, 0.10465263575315475, 0.18585138022899628, 0.20701226592063904, 0.13851360976696014, 0.2767251431941986, 0.10363287478685379, 0.276512086391449, 0.10498354583978653, 0.1482493281364441, 0.14558464288711548, 0.2491694986820221, 0.1798601597547531, 0.19047079980373383, 0.10492698848247528, 0.10380223393440247, 0.1709466129541397, 0.1613566279411316, 0.13522019982337952, 0.22551509737968445, 0.1649651676416397, 0.20279638469219208, 0.2049635350704193, 0.19863924384117126, 0.25162115693092346, 0.10335130244493484, 0.1036926731467247, 0.21345937252044678, 0.18807661533355713, 0.19923341274261475, 0.17022106051445007, 0.10371606796979904, 0.20188157260417938, 0.24242113530635834, 0.16724742949008942, 0.18406085669994354, 0.12636321783065796, 0.22010184824466705, 0.16307589411735535, 0.19149048626422882, 0.16704091429710388, 0.11750932037830353, 0.10494621843099594, 0.2039288878440857, 0.19294485449790955, 0.10508963465690613, 0.10547255724668503, 0.13833680748939514, 0.10474739968776703, 0.20317073166370392, 0.15843874216079712, 0.14596524834632874, 0.2017783522605896, 0.14133039116859436, 0.2762888967990875, 0.18052279949188232, 0.10340696573257446, 0.2529563307762146, 0.18435978889465332, 0.14984095096588135, 0.19397710263729095, 0.1435532569885254, 0.20220139622688293, 0.2244568020105362, 0.1441573053598404, 0.18026024103164673, 0.22225093841552734, 0.1434076875448227, 0.10362682491540909, 0.22559216618537903, 0.18750795722007751, 0.17569781839847565, 0.1509476900100708, 0.14655324816703796, 0.14014782011508942, 0.15737564861774445, 0.16894309222698212, 0.13828103244304657, 0.1493818163871765, 0.17785844206809998, 0.13358771800994873, 0.14927570521831512, 0.15914949774742126, 0.14673636853694916, 0.1348663866519928, 0.16324664652347565, 0.10283525288105011, 0.2059432417154312, 0.1786600649356842, 0.1024538055062294, 0.17282606661319733, 0.15019050240516663, 0.10195077210664749, 0.14895933866500854, 0.10178913176059723, 0.14004266262054443, 0.18866711854934692, 0.1743571013212204, 0.1697586327791214, 0.12889134883880615, 0.22824357450008392, 0.16500023007392883, 0.1853351891040802, 0.17727085947990417, 0.18137268722057343, 0.1538652926683426, 0.10011664777994156, 0.23275747895240784, 0.09978867322206497, 0.2216476947069168, 0.13582155108451843, 0.22364801168441772, 0.2204841524362564, 0.17927275598049164, 0.24500425159931183, 0.182501882314682, 0.1481897085905075, 0.1864486038684845, 0.12784969806671143, 0.13468851149082184, 0.10121217370033264, 0.1894170641899109, 0.23516951501369476, 0.15640169382095337, 0.16101613640785217, 0.21301883459091187, 0.15066708624362946, 0.19054970145225525, 0.15850496292114258, 0.23266412317752838, 0.22964027523994446, 0.1025739461183548, 0.18301264941692352, 0.1624872237443924, 0.2242158204317093, 0.2203657329082489, 0.19909198582172394, 0.18037112057209015, 0.18923848867416382, 0.17147940397262573, 0.1366063505411148, 0.23714163899421692, 0.13136041164398193, 0.10519824922084808, 0.1340828239917755, 0.17520584166049957, 0.14865291118621826, 0.1054321825504303, 0.1674782633781433, 0.27178066968917847, 0.1862795650959015, 0.13854026794433594, 0.1449369639158249, 0.2112502008676529, 0.22151190042495728, 0.18757390975952148, 0.1875961422920227, 0.15119950473308563, 0.10682503134012222, 0.1587652862071991, 0.15184995532035828, 0.1465318351984024, 0.13366827368736267, 0.10653391480445862, 0.16483022272586823, 0.1335686445236206, 0.2038154900074005, 0.1919848769903183, 0.10644061118364334, 0.12977322936058044, 0.19150277972221375, 0.18019160628318787, 0.1272629201412201, 0.13384877145290375, 0.13290567696094513, 0.2337932139635086, 0.15409056842327118, 0.1424132138490677, 0.13183188438415527, 0.18178460001945496, 0.132517471909523, 0.13780681788921356, 0.10462029278278351, 0.16919425129890442, 0.1690005511045456, 0.27502694725990295, 0.1040206030011177, 0.1945992410182953, 0.1387210339307785, 0.10361164808273315, 0.10353384912014008, 0.22040976583957672, 0.1716824173927307, 0.22871051728725433, 0.14722001552581787, 0.12977749109268188, 0.16972151398658752, 0.16530051827430725, 0.168315589427948, 0.10311872512102127, 0.14073581993579865, 0.17952600121498108, 0.19534435868263245, 0.23851807415485382, 0.2775007486343384, 0.18368540704250336, 0.1627795547246933, 0.16717155277729034, 0.13176420331001282, 0.22681207954883575, 0.21903228759765625, 0.14109303057193756, 0.19401012361049652, 0.1809229701757431, 0.17236560583114624, 0.225416362285614, 0.1905139684677124, 0.2711508572101593, 0.1842392534017563, 0.19201137125492096, 0.1354377120733261, 0.13837483525276184, 0.14936895668506622, 0.10753183811903, 0.17976634204387665, 0.14754252135753632, 0.1485816091299057, 0.2109977900981903, 0.19862912595272064, 0.10795627534389496, 0.17068831622600555, 0.14368516206741333, 0.12665559351444244, 0.16368336975574493, 0.12827801704406738, 0.16083167493343353, 0.2435140162706375, 0.20712581276893616, 0.10717043280601501, 0.15475675463676453, 0.19118855893611908, 0.15484844148159027, 0.179148867726326, 0.12962108850479126, 0.17191985249519348, 0.1321650743484497, 0.13052257895469666, 0.18253189325332642, 0.1512276977300644, 0.18301500380039215, 0.11984609067440033, 0.17417840659618378, 0.14623937010765076, 0.10622503608465195, 0.13638928532600403, 0.1414831131696701, 0.13213852047920227, 0.22608697414398193, 0.24781948328018188, 0.12688827514648438, 0.14205187559127808, 0.15769515931606293, 0.13338036835193634, 0.24031813442707062, 0.10453898459672928, 0.1768147498369217, 0.12597423791885376, 0.12602686882019043, 0.19489631056785583, 0.10432818531990051, 0.10383538156747818, 0.1372297704219818, 0.1493249386548996, 0.1884477138519287, 0.17407244443893433, 0.1432199627161026, 0.14053045213222504, 0.18116894364356995, 0.24494361877441406, 0.217933788895607, 0.1408500224351883, 0.14858520030975342, 0.16540876030921936, 0.22321084141731262, 0.15595628321170807, 0.19098563492298126, 0.2791315019130707, 0.12550948560237885, 0.27736082673072815, 0.14366596937179565, 0.16507959365844727, 0.10394945740699768, 0.18361002206802368, 0.16483373939990997, 0.1439337283372879, 0.2077772170305252, 0.10427173227071762, 0.2346978634595871, 0.23338733613491058, 0.14791250228881836, 0.21702633798122406, 0.18175360560417175, 0.10536646097898483, 0.22138690948486328, 0.16483455896377563, 0.12113387137651443, 0.12345218658447266, 0.10585907846689224, 0.13362149894237518, 0.22294734418392181, 0.21670843660831451, 0.18486054241657257, 0.14062811434268951, 0.17317737638950348, 0.19137057662010193, 0.19544117152690887, 0.1062372624874115, 0.10629671066999435, 0.1875067502260208, 0.17769628763198853, 0.13859154284000397, 0.16841602325439453, 0.12695986032485962, 0.17321093380451202, 0.17985033988952637, 0.1296403408050537, 0.105766661465168, 0.17058509588241577, 0.19646236300468445, 0.15675055980682373, 0.1729290783405304, 0.13240157067775726, 0.20425647497177124, 0.27224990725517273, 0.13405048847198486, 0.12396695464849472, 0.10557998716831207, 0.17804385721683502, 0.23742975294589996, 0.12368858605623245, 0.10559333115816116, 0.16771306097507477, 0.16793151199817657, 0.14732825756072998, 0.17706456780433655, 0.19875110685825348, 0.11835088580846786, 0.2242758721113205, 0.19718921184539795, 0.10564463585615158, 0.1770155280828476, 0.19913296401500702, 0.13097240030765533, 0.23194710910320282, 0.1798563450574875, 0.16545818746089935, 0.14693303406238556, 0.14955094456672668, 0.18057969212532043, 0.16694515943527222, 0.15059013664722443, 0.2121080458164215, 0.2055746614933014, 0.16643019020557404, 0.16707675158977509, 0.14531494677066803, 0.16294142603874207, 0.18442808091640472, 0.10568676888942719, 0.10566987842321396, 0.132609024643898, 0.1688820719718933, 0.1056043803691864, 0.135675847530365, 0.20847482979297638, 0.16034038364887238, 0.16550099849700928, 0.27389222383499146, 0.12710998952388763, 0.12912113964557648, 0.16374516487121582, 0.23063133656978607, 0.10498584061861038, 0.10524094849824905, 0.12932772934436798, 0.13159331679344177, 0.1488155722618103, 0.24395529925823212, 0.22229404747486115, 0.1506965309381485, 0.23773695528507233, 0.12556596100330353, 0.10504693537950516, 0.14713893830776215, 0.1299259066581726, 0.1944206953048706, 0.12053500860929489, 0.18495512008666992, 0.1272512972354889, 0.23359374701976776, 0.14830419421195984, 0.1711745262145996, 0.1890445053577423, 0.1419319212436676, 0.2744860053062439, 0.157854825258255, 0.2377730756998062, 0.142963707447052, 0.19332395493984222, 0.131491020321846, 0.10500649362802505, 0.10520496219396591, 0.20963047444820404, 0.20989607274532318, 0.15232287347316742, 0.18354904651641846, 0.1415742039680481, 0.19496725499629974, 0.10538382083177567, 0.1589333713054657, 0.18825893104076385, 0.15143050253391266, 0.1334395408630371, 0.2261987030506134, 0.15092602372169495, 0.22081877291202545, 0.14519518613815308, 0.22027486562728882, 0.27284935116767883, 0.14552900195121765, 0.14637963473796844, 0.19044525921344757, 0.10592983663082123, 0.1632508784532547, 0.10603956878185272, 0.16384345293045044, 0.14453917741775513, 0.15866199135780334, 0.15615254640579224, 0.14943109452724457, 0.12454941868782043, 0.1766384392976761, 0.10546889901161194, 0.22001956403255463, 0.10527454316616058, 0.2113513946533203, 0.17153207957744598, 0.1726163923740387, 0.21212662756443024, 0.2397966831922531, 0.15210652351379395, 0.1944587230682373, 0.13673663139343262, 0.10512237250804901, 0.14083625376224518, 0.10512369126081467, 0.16381147503852844, 0.1317392736673355, 0.1304454505443573, 0.18249501287937164, 0.14502446353435516, 0.18419165909290314, 0.14049775898456573, 0.1040014773607254, 0.1293945461511612, 0.2293202131986618, 0.1454591602087021, 0.10349740833044052, 0.24866969883441925, 0.1535782516002655, 0.1259273737668991, 0.10285847634077072, 0.13167229294776917, 0.134928360581398, 0.17268899083137512, 0.1240338459610939, 0.17985986173152924, 0.18167419731616974, 0.19520434737205505, 0.19479887187480927, 0.12566138803958893, 0.20754340291023254, 0.1786467581987381, 0.17523612082004547, 0.18509504199028015, 0.1010686531662941, 0.12359747290611267, 0.2817023694515228, 0.1957748383283615, 0.19748851656913757, 0.2234908789396286, 0.21709737181663513, 0.1018759086728096, 0.1465057134628296, 0.19530293345451355, 0.10191371291875839, 0.10196767002344131, 0.2316688448190689, 0.27924612164497375, 0.18521709740161896, 0.15897826850414276, 0.16898506879806519, 0.13480260968208313, 0.1734134703874588, 0.19281169772148132, 0.10311803966760635, 0.18097664415836334, 0.14058665931224823, 0.10335680097341537, 0.17988888919353485, 0.17235398292541504, 0.25372427701950073, 0.1265975832939148, 0.1442040055990219, 0.12762291729450226, 0.17506009340286255, 0.10300193727016449, 0.13187719881534576, 0.1885446310043335, 0.10279729962348938, 0.16608354449272156, 0.17640870809555054, 0.13483186066150665, 0.13821546733379364, 0.16925735771656036, 0.12725397944450378, 0.20667223632335663, 0.10183493047952652, 0.10158083587884903, 0.18221889436244965, 0.17524424195289612, 0.18683300912380219, 0.17695394158363342, 0.1870432198047638, 0.185120090842247, 0.18727603554725647, 0.14491480588912964, 0.10088363289833069, 0.28199639916419983, 0.1883728802204132, 0.10099239647388458, 0.13446500897407532, 0.10069277882575989, 0.18934662640094757, 0.13831903040409088, 0.18908371031284332, 0.13476258516311646, 0.12916141748428345, 0.10010489076375961, 0.22024448215961456, 0.09989271312952042, 0.16784296929836273, 0.23424851894378662, 0.24922919273376465, 0.19288946688175201, 0.2522135078907013, 0.18691599369049072, 0.2477889209985733, 0.13393042981624603, 0.2248144894838333, 0.13481929898262024, 0.1683868020772934, 0.13660842180252075, 0.22384637594223022, 0.23445521295070648, 0.17057982087135315, 0.1381351500749588, 0.101960688829422, 0.13977111876010895, 0.19427061080932617, 0.160757377743721, 0.13986097276210785, 0.23205360770225525, 0.17156675457954407, 0.1887209415435791, 0.21573121845722198, 0.13645967841148376, 0.1401096135377884, 0.14194592833518982, 0.1697983741760254, 0.14148202538490295, 0.1652195006608963, 0.19499485194683075, 0.14533400535583496, 0.10310576111078262, 0.17551614344120026, 0.18850210309028625, 0.19614310562610626, 0.14461438357830048, 0.1341281235218048, 0.19854967296123505, 0.22393076121807098, 0.17624378204345703, 0.22796832025051117, 0.23721469938755035, 0.17910055816173553, 0.1601741760969162, 0.14916932582855225, 0.15211570262908936, 0.18426184356212616, 0.1386406570672989, 0.10370568931102753, 0.2303316742181778, 0.14926625788211823, 0.10389050096273422, 0.10372746735811234, 0.10345805436372757, 0.13978686928749084, 0.10326722264289856, 0.13729307055473328, 0.13147008419036865, 0.14086589217185974, 0.13982674479484558, 0.10188259929418564, 0.16877539455890656, 0.10136087983846664, 0.10124845802783966, 0.21734033524990082, 0.1004992425441742, 0.1394692361354828, 0.16824232041835785, 0.15429125726222992, 0.19502636790275574, 0.22663898766040802, 0.13236960768699646, 0.09955344349145889, 0.1835973709821701, 0.18125830590724945, 0.1318543255329132, 0.23576773703098297, 0.14181417226791382, 0.17658233642578125, 0.188752681016922, 0.13684111833572388, 0.17764031887054443, 0.09832241386175156, 0.19826866686344147, 0.18464715778827667, 0.14569205045700073, 0.14092136919498444, 0.14432816207408905, 0.17827415466308594, 0.0977027490735054, 0.2520175874233246, 0.18939048051834106, 0.28934159874916077, 0.1364501714706421, 0.1770201027393341, 0.186521515250206, 0.13076730072498322, 0.13952815532684326, 0.19831600785255432, 0.13789285719394684, 0.14720407128334045, 0.16520202159881592, 0.09809684753417969, 0.22817009687423706, 0.12304345518350601, 0.18042200803756714, 0.2436983585357666, 0.17776258289813995, 0.14189358055591583, 0.16589590907096863, 0.2509158253669739, 0.18377019464969635, 0.13642235100269318, 0.16923536360263824, 0.28648319840431213, 0.16379690170288086, 0.2381480485200882, 0.23191538453102112, 0.14681310951709747, 0.09986687451601028, 0.17668941617012024, 0.12921877205371857, 0.17807060480117798, 0.14615575969219208, 0.13557836413383484, 0.2467847615480423, 0.1008056253194809, 0.171222522854805, 0.177016481757164, 0.1232643723487854, 0.14669010043144226, 0.1518373042345047, 0.14565445482730865, 0.18217799067497253, 0.22338217496871948, 0.22311711311340332, 0.1514042168855667, 0.12747523188591003, 0.17678819596767426, 0.18263930082321167, 0.19091889262199402, 0.1319870948791504, 0.24573759734630585, 0.22583137452602386, 0.2314101755619049, 0.13981294631958008, 0.171225443482399, 0.12390893697738647, 0.18292967975139618, 0.18187394738197327, 0.17813387513160706, 0.1489875465631485, 0.1023816168308258, 0.13545091450214386, 0.10216102749109268, 0.13145634531974792, 0.2788211703300476, 0.1709951013326645, 0.21500414609909058, 0.15305277705192566, 0.10241274535655975, 0.23804828524589539, 0.13102629780769348, 0.17907655239105225, 0.14992548525333405, 0.10249015688896179, 0.27797797322273254, 0.1791730672121048, 0.18208886682987213, 0.19117143750190735, 0.1869664341211319, 0.18236981332302094, 0.10332535207271576, 0.10321692377328873, 0.14264503121376038, 0.14003363251686096, 0.2459537535905838, 0.10293060541152954, 0.17384245991706848, 0.13751369714736938, 0.13656672835350037, 0.14378878474235535, 0.2209458202123642, 0.14654983580112457, 0.14035597443580627, 0.14276088774204254, 0.1424885392189026, 0.1423020213842392, 0.10191330313682556, 0.14208367466926575, 0.10178159922361374, 0.13699330389499664, 0.14401929080486298, 0.16740231215953827, 0.22854089736938477, 0.17804162204265594, 0.17677345871925354, 0.10036255419254303, 0.1464003473520279, 0.1945214420557022, 0.1737031489610672, 0.2287321239709854, 0.17861998081207275, 0.17432831227779388, 0.24547100067138672, 0.12847216427326202, 0.17629939317703247, 0.15173695981502533, 0.16750836372375488, 0.10037598013877869, 0.14862680435180664, 0.2829365134239197, 0.22782312333583832, 0.2046501636505127, 0.13528846204280853, 0.1779043972492218, 0.2365483045578003, 0.23313145339488983, 0.17682546377182007, 0.13938207924365997, 0.1014467105269432, 0.18496955931186676, 0.18530139327049255, 0.13339531421661377, 0.12885203957557678, 0.21769261360168457, 0.13409137725830078, 0.17759506404399872, 0.10197488218545914, 0.13275523483753204, 0.2284022867679596, 0.27909234166145325, 0.16777969896793365, 0.10223942995071411, 0.17570702731609344, 0.1734396070241928, 0.13235588371753693, 0.10252127051353455, 0.14188756048679352, 0.10248477756977081, 0.1320551335811615, 0.13393042981624603, 0.12814919650554657, 0.1399131417274475, 0.18147888779640198, 0.1393050104379654, 0.17555250227451324, 0.1988859474658966, 0.12906622886657715, 0.10133020579814911, 0.17671164870262146, 0.14084425568580627, 0.1598374843597412, 0.10086271911859512, 0.10076243430376053, 0.12870252132415771, 0.10054551064968109, 0.10003796964883804, 0.17121806740760803, 0.17902183532714844, 0.17544950544834137, 0.14166097342967987, 0.13704144954681396, 0.16930948197841644, 0.17867664992809296, 0.17467010021209717, 0.286659300327301, 0.09862376749515533, 0.1302865892648697, 0.18403907120227814, 0.23529750108718872, 0.13053590059280396, 0.14728021621704102, 0.09889759868383408, 0.18241529166698456, 0.1815929114818573, 0.17746594548225403, 0.17799116671085358, 0.15090270340442657, 0.185904398560524, 0.17854805290699005, 0.1743459552526474, 0.16160660982131958, 0.24508404731750488, 0.13272564113140106, 0.22404851019382477, 0.09876684844493866, 0.2459339052438736, 0.13892556726932526, 0.16046664118766785, 0.21705500781536102, 0.1678381860256195, 0.18692991137504578, 0.19485069811344147, 0.2315119206905365, 0.13133707642555237, 0.13928541541099548, 0.1400463581085205, 0.19413720071315765, 0.18671244382858276, 0.17222097516059875, 0.09998851269483566, 0.10005485266447067, 0.19245481491088867, 0.19525295495986938, 0.17821449041366577, 0.13216900825500488, 0.23365317285060883, 0.1382347047328949, 0.1356942057609558, 0.13050884008407593, 0.24528256058692932, 0.09991420805454254, 0.13456718623638153, 0.16849227249622345, 0.09980016201734543, 0.23328609764575958, 0.13640400767326355, 0.2332690954208374, 0.12688763439655304, 0.18080957233905792, 0.17983457446098328, 0.18504826724529266, 0.1826067566871643, 0.23314563930034637, 0.09982828050851822, 0.17614290118217468, 0.2833786606788635, 0.22461958229541779, 0.1906871497631073, 0.14207713305950165, 0.10050619393587112, 0.13392335176467896, 0.1397164911031723, 0.10082859545946121, 0.1843998283147812, 0.22875165939331055, 0.10070675611495972, 0.1759021133184433, 0.1802828311920166, 0.16108562052249908, 0.18385736644268036, 0.1731502264738083, 0.21595746278762817, 0.14131027460098267, 0.14695696532726288, 0.1010342389345169, 0.14507974684238434, 0.14115256071090698, 0.14211277663707733, 0.1496836394071579, 0.24215707182884216, 0.23027990758419037, 0.2404259741306305, 0.14095908403396606, 0.18918678164482117, 0.10086595267057419, 0.2246706783771515, 0.14228351414203644, 0.23892880976200104, 0.14567574858665466, 0.23162506520748138, 0.22699964046478271, 0.13722120225429535, 0.18605937063694, 0.140726700425148, 0.19536192715168, 0.18201926350593567, 0.18175554275512695, 0.12831543385982513, 0.13813991844654083, 0.18413332104682922, 0.17183785140514374, 0.10208766907453537, 0.10194603353738785, 0.17199085652828217, 0.22872498631477356, 0.1400386244058609, 0.10204025357961655, 0.18125738203525543, 0.14383873343467712, 0.1875552088022232, 0.12936408817768097, 0.2799263596534729, 0.14196446537971497, 0.13599102199077606, 0.18609102070331573, 0.14640702307224274, 0.17557965219020844, 0.1277802437543869, 0.14256219565868378, 0.1862136274576187, 0.14486554265022278, 0.10146776586771011, 0.10139910876750946, 0.13095714151859283, 0.130387082695961, 0.10096754878759384, 0.1937159150838852, 0.14159159362316132, 0.22327229380607605, 0.12601718306541443, 0.12968090176582336, 0.23419290781021118, 0.2285076528787613, 0.10008466988801956, 0.18847286701202393, 0.13793323934078217, 0.10007824748754501, 0.2267797589302063, 0.24164721369743347, 0.1343550682067871, 0.1345738023519516, 0.1705622375011444, 0.2400275468826294, 0.2345467358827591, 0.18743504583835602, 0.1768280416727066, 0.12814611196517944, 0.22170811891555786, 0.18019746243953705, 0.1743275374174118, 0.13386985659599304, 0.10099168121814728, 0.14202626049518585, 0.13732627034187317, 0.1860351413488388, 0.13433165848255157, 0.1329556554555893, 0.2173909693956375, 0.13943934440612793, 0.19103820621967316, 0.17114028334617615, 0.2246285080909729, 0.1396706998348236, 0.1370803266763687, 0.13336411118507385, 0.10107827186584473, 0.19192315638065338, 0.19862379133701324, 0.10067477822303772, 0.2368333786725998, 0.10058854520320892, 0.13634240627288818, 0.1642809510231018, 0.14217332005500793, 0.10053626447916031, 0.16755962371826172, 0.18786868453025818, 0.18195506930351257, 0.10003862529993057, 0.24030724167823792, 0.14038757979869843, 0.21965360641479492, 0.14752165973186493, 0.12931418418884277, 0.18339942395687103, 0.09979163110256195, 0.135949045419693, 0.18294347822666168, 0.0995703786611557, 0.17337144911289215, 0.24130839109420776, 0.19077716767787933, 0.23379375040531158, 0.09953689575195312, 0.25046011805534363, 0.20394212007522583, 0.22199758887290955, 0.0997004359960556, 0.13744914531707764, 0.1345532089471817, 0.1303434818983078, 0.1808023750782013, 0.13579687476158142, 0.2491283416748047, 0.12250864505767822, 0.09981057792901993, 0.12977808713912964, 0.22786103188991547, 0.1317729651927948, 0.09963985532522202, 0.13543614745140076, 0.185347780585289, 0.17743493616580963, 0.09962382167577744, 0.13307783007621765, 0.18127816915512085, 0.14608892798423767, 0.18813496828079224, 0.09889021515846252, 0.2182188481092453, 0.13814064860343933, 0.09875938296318054, 0.14835277199745178, 0.1485862135887146, 0.18850940465927124, 0.1751699298620224, 0.13624627888202667, 0.1385861039161682, 0.17499476671218872, 0.09807231277227402, 0.13232484459877014, 0.13148245215415955, 0.12869438529014587, 0.15284083783626556, 0.17533667385578156, 0.1796492338180542, 0.22360993921756744, 0.12738516926765442, 0.0969783142209053, 0.17786133289337158, 0.14069920778274536, 0.29080453515052795, 0.23645995557308197, 0.13433144986629486, 0.13287945091724396, 0.18785208463668823, 0.22436372935771942, 0.16419973969459534, 0.2452361136674881, 0.18598629534244537, 0.1487724334001541, 0.17962433397769928, 0.22650770843029022, 0.13135874271392822, 0.18277780711650848, 0.09786397963762283, 0.13248437643051147, 0.1333894431591034, 0.13079719245433807, 0.09802156686782837, 0.17920979857444763, 0.18234889209270477, 0.1777801364660263, 0.18379998207092285, 0.09767866879701614, 0.20020858943462372, 0.12759333848953247, 0.18046259880065918, 0.23214949667453766, 0.13955436646938324, 0.13442732393741608, 0.12545087933540344, 0.14132241904735565, 0.1313597708940506, 0.22875246405601501, 0.1300005167722702, 0.1376996785402298, 0.12609313428401947, 0.23090113699436188, 0.1687748283147812, 0.09745581448078156, 0.2479620724916458, 0.2500341832637787, 0.13678835332393646, 0.09727908670902252, 0.17711779475212097, 0.17731855809688568, 0.23241235315799713, 0.14770664274692535, 0.13235220313072205, 0.23745201528072357, 0.13501055538654327, 0.1764802634716034, 0.13224823772907257, 0.17952226102352142, 0.18457230925559998, 0.13955867290496826, 0.13124848902225494, 0.23678472638130188, 0.175216943025589, 0.18080037832260132, 0.13289834558963776, 0.18978655338287354, 0.19194407761096954, 0.09794215857982635, 0.13430295884609222, 0.13476942479610443, 0.0979347974061966, 0.135189950466156, 0.13270612061023712, 0.17333658039569855, 0.13924254477024078, 0.13439828157424927, 0.09739778190851212, 0.1830185502767563, 0.18444663286209106, 0.21562665700912476, 0.1879434883594513, 0.17806220054626465, 0.18625685572624207, 0.1388137936592102, 0.18589887022972107, 0.1351134330034256, 0.17634999752044678, 0.13862057030200958, 0.22991114854812622, 0.1851527988910675, 0.09705056250095367, 0.13643908500671387, 0.09694443643093109, 0.23998630046844482, 0.14104770123958588, 0.18575240671634674, 0.1816086769104004, 0.17704372107982635, 0.23148955404758453, 0.2268209606409073, 0.14480529725551605, 0.23327216506004333, 0.1793121099472046, 0.18684756755828857, 0.13528989255428314, 0.17618347704410553, 0.2419384866952896, 0.2885145843029022, 0.13653501868247986, 0.16848427057266235, 0.1362038105726242, 0.13622838258743286, 0.20227161049842834, 0.22892586886882782, 0.2199527770280838, 0.18310825526714325, 0.09882622212171555, 0.13254761695861816, 0.18397945165634155, 0.2852258086204529, 0.23259688913822174, 0.19223083555698395, 0.18436160683631897, 0.19513779878616333, 0.17133377492427826, 0.15474599599838257, 0.1775277554988861, 0.1351587474346161, 0.1374502331018448, 0.1345604658126831, 0.14934580028057098, 0.1479518860578537, 0.1792925000190735, 0.15194977819919586, 0.1486513316631317, 0.17865683138370514, 0.175509512424469, 0.10034525394439697, 0.2824985086917877, 0.18665258586406708, 0.10052913427352905, 0.1470695286989212, 0.17939519882202148, 0.13858114182949066, 0.18370410799980164, 0.1304110288619995, 0.1481371521949768, 0.18527507781982422, 0.1700025200843811, 0.22117747366428375, 0.17617923021316528, 0.17966791987419128, 0.17590923607349396, 0.23346662521362305, 0.13270607590675354, 0.131479874253273, 0.2222946137189865, 0.14781345427036285, 0.1007797122001648, 0.23424431681632996, 0.17940446734428406, 0.13366243243217468, 0.1814437210559845, 0.14113956689834595, 0.10080215334892273, 0.20343993604183197, 0.1418077051639557, 0.1394207626581192, 0.172328919172287, 0.17235980927944183, 0.1288784295320511, 0.18631410598754883, 0.14338886737823486, 0.18906481564044952, 0.2249213308095932, 0.13456425070762634, 0.17458990216255188, 0.15108297765254974, 0.17983730137348175, 0.14205504953861237, 0.17511232197284698, 0.18406705558300018, 0.12830516695976257, 0.14117027819156647, 0.14173860847949982, 0.17815500497817993, 0.1374262422323227, 0.22703436017036438, 0.22512532770633698, 0.14050044119358063, 0.2192193865776062, 0.18183496594429016, 0.1462610363960266, 0.1260710209608078, 0.13882039487361908, 0.13463568687438965, 0.17931948602199554, 0.22700805962085724, 0.10057345032691956, 0.18261048197746277, 0.23627397418022156, 0.281820148229599, 0.10060715675354004, 0.18171127140522003, 0.16950233280658722, 0.24342846870422363, 0.2311791479587555, 0.23615004122257233, 0.23315896093845367, 0.18390977382659912, 0.18278315663337708, 0.13584376871585846, 0.10195311158895493, 0.14860667288303375, 0.12934109568595886, 0.23105879127979279, 0.18201878666877747, 0.1818266659975052, 0.14306990802288055, 0.18306174874305725, 0.2233375608921051, 0.19424045085906982, 0.1415393203496933, 0.27765992283821106, 0.14603431522846222, 0.21824543178081512, 0.14675824344158173, 0.16969354450702667, 0.2764401435852051, 0.13170574605464935, 0.13107621669769287, 0.18498016893863678, 0.16945640742778778, 0.10366051644086838, 0.10390631854534149, 0.13684751093387604, 0.18165192008018494, 0.18816228210926056, 0.18195946514606476, 0.17234252393245697, 0.13531962037086487, 0.17054224014282227, 0.17019613087177277, 0.22219237685203552, 0.1462271809577942, 0.2208191454410553, 0.14111720025539398, 0.15264347195625305, 0.20793819427490234, 0.12780793011188507, 0.17252367734909058, 0.22328272461891174, 0.17318320274353027, 0.10419566929340363, 0.23925137519836426, 0.13647140562534332, 0.22040678560733795, 0.16682513058185577, 0.1808597892522812, 0.10474754869937897, 0.12837082147598267, 0.10462506115436554, 0.10502255707979202, 0.21392306685447693, 0.13689163327217102, 0.10452300310134888, 0.18325094878673553, 0.10437367856502533, 0.16360336542129517, 0.1411682665348053, 0.1278749704360962, 0.1322314590215683, 0.10406624525785446, 0.18129444122314453, 0.17578774690628052, 0.17102313041687012, 0.2748444378376007, 0.14357009530067444, 0.17570066452026367, 0.1383749544620514, 0.17157995700836182, 0.13097962737083435, 0.1668592095375061, 0.1037670448422432, 0.21672430634498596, 0.18706142902374268, 0.13908059895038605, 0.1737351417541504, 0.10392477363348007, 0.19151891767978668, 0.24459823966026306, 0.22618184983730316, 0.14991800487041473, 0.12108772993087769, 0.17865391075611115, 0.1339172124862671, 0.1835155338048935, 0.2271801233291626, 0.1413152813911438, 0.17898564040660858, 0.13325820863246918, 0.14358831942081451, 0.1779944896697998, 0.17967048287391663, 0.2156391590833664, 0.16621306538581848, 0.14374861121177673, 0.18423806130886078, 0.10392789542675018, 0.23126757144927979, 0.14064297080039978, 0.17649994790554047, 0.18164727091789246, 0.1405111402273178, 0.1872873455286026, 0.1517099291086197, 0.14571069180965424, 0.2745298743247986, 0.17691823840141296, 0.19084426760673523, 0.10419749468564987, 0.10448205471038818, 0.18294672667980194, 0.2268495112657547, 0.10416888445615768, 0.10401622951030731, 0.22212497889995575, 0.13700222969055176, 0.14585500955581665, 0.17381471395492554, 0.14173489809036255, 0.14123202860355377, 0.1425713747739792, 0.1348339170217514, 0.13431121408939362, 0.18316778540611267, 0.13737082481384277, 0.18235895037651062, 0.17768332362174988, 0.13892251253128052, 0.18129615485668182, 0.1035623773932457, 0.24223285913467407, 0.14783459901809692, 0.13806378841400146, 0.13280439376831055, 0.1852545142173767, 0.18623344600200653, 0.1809311956167221, 0.12885400652885437, 0.1756415218114853, 0.13913877308368683, 0.180168017745018, 0.18220621347427368, 0.22648437321186066, 0.1230066642165184, 0.17628316581249237, 0.13684508204460144, 0.17168456315994263, 0.13301227986812592, 0.16747026145458221, 0.1799790859222412, 0.17401067912578583, 0.2208048552274704, 0.10302731394767761, 0.16240711510181427, 0.2764134705066681, 0.134750097990036, 0.18568378686904907, 0.10323262959718704, 0.17717698216438293, 0.2270490825176239, 0.17956651747226715, 0.2342139631509781, 0.13950109481811523, 0.10343393683433533, 0.17968952655792236, 0.13028743863105774, 0.18965303897857666, 0.17446845769882202, 0.13432087004184723, 0.21369792520999908, 0.10356337577104568, 0.1818673014640808, 0.13967101275920868, 0.18896406888961792, 0.2266656458377838, 0.189469113945961, 0.275066614151001, 0.17473545670509338, 0.10397542268037796, 0.10392842441797256, 0.13635003566741943, 0.1038818210363388, 0.10383933782577515, 0.23514264822006226, 0.14655640721321106, 0.136098250746727, 0.10378411412239075, 0.19725023210048676, 0.13287915289402008, 0.14173021912574768, 0.10349856317043304, 0.10351133346557617, 0.17220865190029144, 0.15443049371242523, 0.10316108912229538, 0.18021494150161743, 0.1349807232618332, 0.13624249398708344, 0.13690337538719177, 0.1289750635623932, 0.1660335808992386, 0.17957761883735657, 0.1465412676334381, 0.13846419751644135, 0.17597587406635284, 0.19018450379371643, 0.10233272612094879, 0.27851492166519165, 0.27808547019958496, 0.17936575412750244, 0.2778218984603882, 0.13659745454788208, 0.12841545045375824, 0.1994047909975052, 0.17415370047092438, 0.13347117602825165, 0.1794615089893341, 0.17998282611370087, 0.18115408718585968, 0.2222878485918045, 0.1951957494020462, 0.2011394202709198, 0.1809684783220291, 0.17419038712978363, 0.1375579535961151, 0.10327048599720001, 0.22877465188503265, 0.1859968602657318, 0.1032763347029686, 0.22643153369426727, 0.17431893944740295, 0.135269895195961, 0.18669220805168152, 0.12367147207260132, 0.1936001032590866, 0.2287057340145111, 0.1817048192024231, 0.13271179795265198, 0.17307327687740326, 0.21937167644500732, 0.10358478873968124, 0.15233509242534637, 0.22211404144763947, 0.13187859952449799, 0.17939460277557373, 0.16385620832443237, 0.13748176395893097, 0.13766108453273773, 0.13169382512569427, 0.14499253034591675, 0.2252693623304367, 0.21532069146633148, 0.12568290531635284, 0.17854879796504974, 0.1394193321466446, 0.14225630462169647, 0.10391350090503693, 0.10389655083417892, 0.13648931682109833, 0.14754578471183777, 0.10374047607183456, 0.2246614545583725, 0.14308138191699982, 0.2179814875125885, 0.17337611317634583, 0.18609513342380524, 0.22764146327972412, 0.2211545705795288, 0.2283966988325119, 0.2291865199804306, 0.10360562801361084, 0.1347518116235733, 0.1372525840997696, 0.10392813384532928, 0.17836324870586395, 0.14092420041561127, 0.14959511160850525, 0.18030071258544922, 0.2105056196451187, 0.17155936360359192, 0.15014497935771942, 0.1339290738105774, 0.1701631397008896, 0.13356474041938782, 0.13770009577274323, 0.2150297611951828, 0.13487683236598969, 0.13939791917800903, 0.180153951048851, 0.18502196669578552, 0.14741918444633484, 0.1447756290435791, 0.18030264973640442, 0.1404692828655243, 0.2237309217453003, 0.17507125437259674, 0.17733190953731537, 0.1754883974790573, 0.14423933625221252, 0.13832814991474152, 0.1392386257648468, 0.22505511343479156, 0.18238964676856995, 0.14881184697151184, 0.1484062522649765, 0.16958065330982208, 0.10334007441997528, 0.17869557440280914, 0.1743905395269394, 0.16992253065109253, 0.22444380819797516, 0.14106805622577667, 0.14039115607738495, 0.12976422905921936, 0.14109531044960022, 0.17030397057533264, 0.13713791966438293, 0.1285507082939148, 0.16830532252788544, 0.13558395206928253, 0.205226331949234, 0.16780129075050354, 0.12771722674369812, 0.13957479596138, 0.10318094491958618, 0.17591850459575653, 0.15525373816490173, 0.1306823194026947, 0.2343171387910843, 0.18425875902175903, 0.10279814153909683, 0.12961694598197937, 0.17391128838062286, 0.22801412642002106, 0.15359774231910706, 0.14134283363819122, 0.1988767683506012, 0.13858675956726074, 0.23098888993263245, 0.1802244335412979, 0.22979368269443512, 0.2771385908126831, 0.1781829297542572, 0.15033209323883057, 0.13214342296123505, 0.10291433334350586, 0.18735423684120178, 0.1471206545829773, 0.13547025620937347, 0.13987472653388977, 0.15875597298145294, 0.10283545404672623, 0.22298291325569153, 0.17466029524803162, 0.18348684906959534, 0.13964518904685974, 0.1029425859451294, 0.14247682690620422, 0.18545706570148468, 0.12793593108654022, 0.17353840172290802, 0.21511657536029816, 0.1806921362876892, 0.18623952567577362, 0.1375943124294281, 0.19918331503868103, 0.18783225119113922, 0.14360859990119934, 0.18873384594917297, 0.13523146510124207, 0.10267581790685654, 0.13728204369544983, 0.17567570507526398, 0.13881775736808777, 0.23104561865329742, 0.18172244727611542, 0.18075262010097504, 0.1025855764746666, 0.1950630396604538, 0.16268430650234222, 0.10251498222351074, 0.1390114724636078, 0.16419291496276855, 0.21909502148628235, 0.10248290747404099, 0.16929158568382263, 0.174505814909935, 0.13468921184539795, 0.18080635368824005, 0.18499773740768433, 0.13731761276721954, 0.1310264766216278, 0.18332728743553162, 0.2781903147697449, 0.17055580019950867, 0.10242592543363571, 0.16598621010780334, 0.18337368965148926, 0.1371258795261383, 0.13768668472766876, 0.13777878880500793, 0.10246353596448898, 0.1900482177734375, 0.19097910821437836, 0.23486806452274323, 0.10238508880138397, 0.10237600654363632, 0.17489227652549744, 0.22768357396125793, 0.10238837450742722, 0.19076775014400482, 0.22547030448913574, 0.17552849650382996, 0.23916758596897125, 0.18059740960597992, 0.2778424322605133, 0.16419517993927002, 0.14081445336341858, 0.1376647800207138, 0.178002268075943, 0.1820688545703888, 0.10256437212228775, 0.2292570322751999, 0.23591715097427368, 0.2770574688911438, 0.1383609026670456, 0.18635360896587372, 0.10290567576885223, 0.14015990495681763, 0.27653729915618896, 0.2765207886695862, 0.1759834736585617, 0.13642039895057678, 0.13898296654224396, 0.22543662786483765, 0.14635108411312103, 0.16015826165676117, 0.18860313296318054, 0.10332532227039337, 0.21743443608283997, 0.14218290150165558, 0.19187255203723907, 0.13318932056427002, 0.1893054097890854, 0.22484257817268372, 0.10360881686210632, 0.1503039300441742, 0.18845167756080627, 0.1384744793176651, 0.1432257741689682, 0.15375995635986328, 0.14117999374866486, 0.14547090232372284, 0.14135295152664185, 0.17418110370635986, 0.22692811489105225, 0.19767163693904877, 0.12503653764724731, 0.2330450713634491, 0.17573833465576172, 0.17400026321411133, 0.225617453455925, 0.13392002880573273, 0.1753678023815155, 0.16703984141349792, 0.14841362833976746, 0.2376147359609604, 0.17670704424381256, 0.1395060122013092, 0.18356570601463318, 0.14603377878665924, 0.1864510476589203, 0.15410801768302917, 0.13131269812583923, 0.22941191494464874, 0.16742850840091705, 0.1816466897726059, 0.17536312341690063, 0.27481192350387573, 0.13264532387256622, 0.223057821393013, 0.23554028570652008, 0.17793726921081543, 0.14915959537029266, 0.14289027452468872, 0.22160610556602478, 0.1747792512178421, 0.14540649950504303, 0.2149093896150589, 0.1432899385690689, 0.2053869068622589, 0.14697469770908356, 0.13383318483829498, 0.13699062168598175, 0.135808065533638, 0.14103473722934723, 0.1890518069267273, 0.134044349193573, 0.12936891615390778, 0.2176627516746521, 0.2118559181690216, 0.10425793379545212, 0.18633201718330383, 0.14216028153896332, 0.14174529910087585, 0.10439124703407288, 0.10415524989366531, 0.17993967235088348, 0.13492879271507263, 0.14005933701992035, 0.22740726172924042, 0.14837560057640076, 0.18243569135665894, 0.23502570390701294, 0.14274072647094727, 0.1440783590078354, 0.10421334952116013, 0.14154310524463654, 0.14260484278202057, 0.1395658701658249, 0.17155253887176514, 0.17350274324417114, 0.13177140057086945, 0.14093393087387085, 0.10392361134290695, 0.18292225897312164, 0.22646531462669373, 0.21925881505012512, 0.10399579256772995, 0.17129932343959808, 0.17209048569202423, 0.10380187630653381, 0.1285334825515747, 0.23723113536834717, 0.1762038618326187, 0.19246794283390045, 0.10378575325012207, 0.18165883421897888, 0.18478082120418549, 0.17864181101322174, 0.19510971009731293, 0.22968874871730804, 0.10376940667629242, 0.1842687726020813, 0.18562303483486176, 0.1398189216852188, 0.22832132875919342, 0.22375982999801636, 0.13033069670200348, 0.16890661418437958, 0.164279967546463, 0.14207452535629272, 0.18419969081878662, 0.22231259942054749, 0.13650570809841156, 0.10385110974311829, 0.21762506663799286, 0.1649714708328247, 0.14264552295207977, 0.14114245772361755, 0.13278253376483917, 0.27446505427360535, 0.10402494668960571, 0.18078310787677765, 0.10388929396867752, 0.14261414110660553, 0.14145861566066742, 0.1831997036933899, 0.2214524745941162, 0.10395924746990204, 0.23139292001724243, 0.1705285757780075, 0.1038735955953598, 0.18342842161655426, 0.13226640224456787, 0.1430945247411728, 0.13721086084842682, 0.17533421516418457, 0.14541785418987274, 0.10382316261529922, 0.13858191668987274, 0.1453939974308014, 0.2266007661819458, 0.1038171574473381, 0.2326338142156601, 0.16539640724658966, 0.22227616608142853, 0.2079504281282425, 0.18878856301307678, 0.21694201231002808, 0.23734554648399353, 0.17921574413776398, 0.18766260147094727, 0.21266791224479675, 0.17248934507369995, 0.22517846524715424, 0.10417640954256058, 0.23083697259426117, 0.18073402345180511, 0.10399599373340607, 0.22724877297878265, 0.13141708076000214, 0.17882710695266724, 0.23106789588928223, 0.10404376685619354, 0.2044275850057602, 0.21681806445121765, 0.1405283808708191, 0.17866449058055878, 0.14047278463840485, 0.14546313881874084, 0.14781782031059265, 0.22720783948898315, 0.10419762134552002, 0.12645642459392548, 0.16957397758960724, 0.17783582210540771, 0.23317275941371918, 0.14423507452011108, 0.1398177295923233, 0.1676027774810791, 0.17708179354667664, 0.19688309729099274, 0.21613523364067078, 0.2190343141555786, 0.19124317169189453, 0.16510659456253052, 0.1774355173110962, 0.1733691543340683, 0.14051420986652374, 0.12771958112716675, 0.16906613111495972, 0.1689411997795105, 0.10446934401988983, 0.18225236237049103, 0.1385386884212494, 0.19665539264678955, 0.18104831874370575, 0.1712832897901535, 0.10432551056146622, 0.17152681946754456, 0.14819660782814026, 0.13023686408996582, 0.18282823264598846, 0.1797809600830078, 0.18337088823318481, 0.27355891466140747, 0.16855359077453613, 0.1297142058610916, 0.10437748581171036, 0.1479087471961975, 0.17201542854309082, 0.1274196207523346, 0.27362728118896484, 0.1429629623889923, 0.1850186437368393, 0.13474656641483307, 0.14226241409778595, 0.10436014831066132, 0.18576981127262115, 0.1376163214445114, 0.10429196059703827, 0.14133378863334656, 0.1819397509098053, 0.13453568518161774, 0.10450661927461624, 0.10426662862300873, 0.12930206954479218, 0.2338416427373886, 0.13185718655586243, 0.14277784526348114, 0.16791999340057373, 0.18160469830036163, 0.18945762515068054, 0.1420639008283615, 0.23453044891357422, 0.1778860092163086, 0.2267153263092041, 0.13765232264995575, 0.10423024743795395, 0.27372366189956665, 0.22990107536315918, 0.242191344499588, 0.17546875774860382, 0.13919493556022644, 0.1425938904285431, 0.13931336998939514, 0.16652914881706238, 0.12959140539169312, 0.13788533210754395, 0.17996183037757874, 0.1269591748714447, 0.10425076633691788, 0.14758159220218658, 0.18080635368824005, 0.14745208621025085, 0.13066035509109497, 0.14080001413822174, 0.13196657598018646, 0.21613693237304688, 0.2737024426460266, 0.19010494649410248, 0.19561944901943207, 0.10442105680704117, 0.1908835917711258, 0.19333958625793457, 0.27432122826576233, 0.1875910609960556, 0.27378562092781067, 0.13934223353862762, 0.10438991338014603, 0.19865207374095917, 0.1409352719783783, 0.229747012257576, 0.19058503210544586, 0.2244032323360443, 0.14311985671520233, 0.14231808483600616, 0.13654927909374237, 0.16262052953243256, 0.10428202152252197, 0.18406333029270172, 0.13359534740447998, 0.1766502559185028, 0.18018874526023865, 0.227603018283844, 0.10429000854492188]\n",
            "Val loss 0.166866207077303\n",
            "Val auc roc 0.5\n",
            "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch     3: reducing learning rate of group 1 to 1.0000e-04.\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "801cde13-8c49-4051-bed3-788d02026c15"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "542e109d-4fc0-4287-c011-ab9609716f6e"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4836f3d-d63b-43f5-febe-eff860fac60c"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "3fb61671-3459-4cde-9406-42449dbc105e"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Image_Only_Informative]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ea744f5-fe8e-42fb-e54a-f499c35db8d0"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-08-05 20:34:53.866700'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}