{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pie9t7l91U2t"
   },
   "source": [
    "# Data Import from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "gh1JATeBylTD",
    "outputId": "8f24ffb6-e717-4768-83cb-77d64e1b3fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ieee-bigmm-images'...\n",
      "remote: Enumerating objects: 30, done.\u001b[K\n",
      "remote: Counting objects:   3% (1/30)\u001b[K\r",
      "remote: Counting objects:   6% (2/30)\u001b[K\r",
      "remote: Counting objects:  10% (3/30)\u001b[K\r",
      "remote: Counting objects:  13% (4/30)\u001b[K\r",
      "remote: Counting objects:  16% (5/30)\u001b[K\r",
      "remote: Counting objects:  20% (6/30)\u001b[K\r",
      "remote: Counting objects:  23% (7/30)\u001b[K\r",
      "remote: Counting objects:  26% (8/30)\u001b[K\r",
      "remote: Counting objects:  30% (9/30)\u001b[K\r",
      "remote: Counting objects:  33% (10/30)\u001b[K\r",
      "remote: Counting objects:  36% (11/30)\u001b[K\r",
      "remote: Counting objects:  40% (12/30)\u001b[K\r",
      "remote: Counting objects:  43% (13/30)\u001b[K\r",
      "remote: Counting objects:  46% (14/30)\u001b[K\r",
      "remote: Counting objects:  50% (15/30)\u001b[K\r",
      "remote: Counting objects:  53% (16/30)\u001b[K\r",
      "remote: Counting objects:  56% (17/30)\u001b[K\r",
      "remote: Counting objects:  60% (18/30)\u001b[K\r",
      "remote: Counting objects:  63% (19/30)\u001b[K\r",
      "remote: Counting objects:  66% (20/30)\u001b[K\r",
      "remote: Counting objects:  70% (21/30)\u001b[K\r",
      "remote: Counting objects:  73% (22/30)\u001b[K\r",
      "remote: Counting objects:  76% (23/30)\u001b[K\r",
      "remote: Counting objects:  80% (24/30)\u001b[K\r",
      "remote: Counting objects:  83% (25/30)\u001b[K\r",
      "remote: Counting objects:  86% (26/30)\u001b[K\r",
      "remote: Counting objects:  90% (27/30)\u001b[K\r",
      "remote: Counting objects:  93% (28/30)\u001b[K\r",
      "remote: Counting objects:  96% (29/30)\u001b[K\r",
      "remote: Counting objects: 100% (30/30)\u001b[K\r",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 7172 (delta 11), reused 9 (delta 3), pack-reused 7142\u001b[K\n",
      "Receiving objects: 100% (7172/7172), 592.03 MiB | 44.69 MiB/s, done.\n",
      "Resolving deltas: 100% (14/14), done.\n",
      "Checking out files: 100% (8550/8550), done.\n"
     ]
    }
   ],
   "source": [
    "# %cd ..\n",
    "# %pwd\n",
    "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
    "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hno1BI3eIQb7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b9M7H8jCyzjC",
    "outputId": "4a05d97e-af49-454d-fdb0-b8be8d92c1ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaUvnWy2y97N"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !unzip ieee-bigmm-images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WkUI93xgzRFm",
    "outputId": "edd26250-8aaf-4890-a2e0-f687db31359d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ieee-bigmm-images\n"
     ]
    }
   ],
   "source": [
    "%cd ieee-bigmm-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CYp3BrmFb4EY",
    "outputId": "c8067b71-1804-419c-b9c3-b371f40a6358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
      " * branch            master     -> FETCH_HEAD\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "h-J3t5rG0EwK",
    "outputId": "cc98dd6f-6849-4a8a-8f4d-733d4bf0d386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_datav5.csv   final_test3_unpreprocessed.csv  test_tweet_2.csv\n",
      "clean_datav6.csv   README.md                       \u001b[0m\u001b[01;34mtrain_images\u001b[0m/\n",
      "final_dataset.csv  test_data_cleaned.csv\n",
      "final_test2.csv    \u001b[01;34mtest_images\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "17uVz_YI1dty"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "id": "2dghuwTb1t2n",
    "outputId": "cd691f08-5de5-4e63-9096-8a6054982ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\r",
      "\u001b[K     |██▋                             | 10kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 20kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 30kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 40kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 51kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 61kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 71kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 81kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 92kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 102kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 112kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 122kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 133kB 4.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.24)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.5.1+cu101)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.24 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.24)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->pytorch_pretrained_bert) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->pytorch_pretrained_bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.24->boto3->pytorch_pretrained_bert) (1.15.0)\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.5.1+cu101 in /usr/local/lib/python3.6/dist-packages (1.5.1+cu101)\n",
      "Requirement already satisfied: torchvision==0.6.1+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.1+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "!pip install pytorch_pretrained_bert\n",
    "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
    "# !pip3 install torchvision\n",
    "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1MWr-9J1AAk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pytorch_pretrained_bert.modeling import BertModel\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from pytorch_pretrained_bert import BertAdam\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import tqdm\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "199f2bGeBK_H",
    "outputId": "cd8584af-6922-4413-cabf-aa78d44a7aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ftb6j_3C1uSa",
    "outputId": "47cc4cd7-9a23-4ed5-d16c-182074030a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "print(device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "colab_type": "code",
    "id": "Phuvcx_b2LNM",
    "outputId": "d056d622-ede0-4114-a1c0-645fbe6483a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>missing_text</th>\n",
       "      <th>Text_Only_Informative</th>\n",
       "      <th>Image_Only_Informative</th>\n",
       "      <th>Directed_Hate</th>\n",
       "      <th>Generalized_Hate</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Allegation</th>\n",
       "      <th>Justification</th>\n",
       "      <th>Refutation</th>\n",
       "      <th>Support</th>\n",
       "      <th>Oppose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1052237153789390853</td>\n",
       "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1052207832081129472</td>\n",
       "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1052183746344960000</td>\n",
       "      <td>Mother Nature’s #MeToo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1052156864840908800</td>\n",
       "      <td>ption - no:2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1052095305133510656</td>\n",
       "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
       "0           0             0               0  ...         0.0     1.0     0.0\n",
       "1           1             1               1  ...         0.0     1.0     0.0\n",
       "2           2             2               2  ...         0.0     0.0     0.0\n",
       "3           3             3               3  ...         0.0     0.0     1.0\n",
       "4           4             4               4  ...         0.0     1.0     0.0\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./clean_datav6.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "1SOPiJUN2PoF",
    "outputId": "d8c98837-b8c7-4f57-a840-048c8dae82b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tara Actress planned to sue Alok Nath in #MeTo...\n",
       "1    Yesterday was good for my soul and made me exc...\n",
       "2    Aabhaasam actress Divya hurls #MeToo charges a...\n",
       "3                                        ption - no:2 \n",
       "4    After the exit of Anu Malik due to the #MeToo ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
    "train_df = train_df.reset_index()\n",
    "val_df = val_df.reset_index()\n",
    "train_df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0gsQ0q72XPY"
   },
   "outputs": [],
   "source": [
    "img_transformations = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "#             transforms.Resize((224, 244)),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
    "                std=[0.12221994, 0.12145835, 0.14380469],\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JFomlns02fvZ",
    "outputId": "f7e29921-6552-47ca-8043-a75f2bbe8d7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [00:10<00:00, 37587681.51B/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2ScheMbt2_6w",
    "outputId": "7969bbb8-784a-4cca-a979-c200459ffd90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 884621.07B/s]\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(\n",
    "            'bert-base-uncased', do_lower_case=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "SZacy6uP3F-Z",
    "outputId": "7c70583c-ba5c-4d64-8750-7a3e47ecef4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2047,\n",
       " 2695,\n",
       " 4968,\n",
       " 4808,\n",
       " 7073,\n",
       " 3236,\n",
       " 2033,\n",
       " 1062,\n",
       " 13213,\n",
       " 13213,\n",
       " 2595,\n",
       " 2620,\n",
       " 16703,\n",
       " 2581,\n",
       " 2475,\n",
       " 1030,\n",
       " 22038,\n",
       " 20348]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8zRJVGDJmA8U",
    "outputId": "94d6f355-08c6-4d85-ee9e-112139072496"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 100, 101, 102, 103]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxbHMxJEbdRu"
   },
   "outputs": [],
   "source": [
    "# help(bert)\n",
    "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
    "\n",
    "# class BertModel(BertPreTrainedModel)\n",
    "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
    "#  |  \n",
    "#  |  Params:\n",
    "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
    "#  |  \n",
    "#  |  Inputs:\n",
    "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
    "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
    "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
    "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
    "#  |          a `sentence B` token (see BERT paper for more details).\n",
    "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
    "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
    "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
    "#  |          a batch has varying length sentences.\n",
    "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
    "#  |  \n",
    "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
    "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
    "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
    "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
    "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
    "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
    "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
    "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
    "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
    "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJ-TvFY8oB6I"
   },
   "outputs": [],
   "source": [
    "# help(bert.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CabXmZJl3KVB"
   },
   "outputs": [],
   "source": [
    "class TextNImageDataset(Dataset):\n",
    "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
    "        self.data = data\n",
    "        self.image_path = (image_path)\n",
    "        self.label_name = label_name\n",
    "        self.transforms = transforms\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
    "        self.vocab = vocab\n",
    "        df2 = self.data[self.data[label_name]==minority_class]\n",
    "        df2 = df2.copy().reset_index(drop=True)\n",
    "        df3 = df2.copy().reset_index(drop=True)\n",
    "        # print(df2)\n",
    "        print(f\"Old data length : {len(self.data)}\")\n",
    "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
    "        for i in range(len(df2)):\n",
    "            text = df2['text'][i]\n",
    "            text = text.split(' ')\n",
    "            random.shuffle(text)\n",
    "            text2 = ' '.join(text)\n",
    "            df2['text'][i]=text2\n",
    "            random.shuffle(text)\n",
    "            text3 = ' '.join(text)\n",
    "            df3['text'][i]=text3\n",
    "        self.data = self.data.append(df2, ignore_index=True)\n",
    "        self.data = self.data.append(df3, ignore_index=True)\n",
    "        self.data = self.data.reset_index(drop=True)\n",
    "        print(f\"New data length : {len(self.data)}\")\n",
    "\n",
    "    def __getitem__(self,  index):\n",
    "        text = self.data['text'][index]\n",
    "        text = str(text)\n",
    "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
    "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
    "        tweet_id = self.data['tweet_id'][index]\n",
    "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
    "        image = None\n",
    "        try:\n",
    "            image = Image.open(\n",
    "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
    "            ).convert(\"RGB\")\n",
    "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
    "#             image.show()\n",
    "            image = self.transforms(image)\n",
    "        except:\n",
    "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return text, label, image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        model = torchvision.models.resnet152(pretrained=True)\n",
    "        modules = list(model.children())[:-2]\n",
    "        # we are removing the last adaptive average pooling layer and the \n",
    "        # the classification layer\n",
    "        self.model = nn.Sequential(*modules)\n",
    "        if(torch.cuda.is_available()):\n",
    "            self.model = self.model.cuda()\n",
    "        # self.model = self.model.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = (self.model(x))\n",
    "        # print('Model output', out.size())\n",
    "\n",
    "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
    "        # to be obtained after pooling\n",
    "        # print('Pooling output', out.size())\n",
    "\n",
    "        out = torch.flatten(out, start_dim=2)\n",
    "        # print('Flattening output', out.size())\n",
    "\n",
    "        out = out.transpose(1, 2).contiguous()\n",
    "        # print('Transpose output', out.size())\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class Vocab(object):\n",
    "    def __init__(self, emptyInit=False):\n",
    "        if emptyInit:\n",
    "            self.stoi={}#string to index dictionary\n",
    "            self.itos=[]#index to string dictionary\n",
    "            self.vocab_size=0\n",
    "        else:\n",
    "            self.stoi={\n",
    "                w:i\n",
    "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
    "            }\n",
    "            self.itos = [w for w in self.stoi]\n",
    "            self.vocab_size = len(self.itos)\n",
    "    \n",
    "    def add(self, words):\n",
    "        counter = len(self.itos)\n",
    "        for w in words:\n",
    "            if w in self.stoi:\n",
    "                continue\n",
    "            self.stoi[w]=counter\n",
    "            counter+=1\n",
    "            self.itos.append(w)\n",
    "        self.vocab_size = len(self.itos)\n",
    "\n",
    "class ImageEmbeddingsForBert(nn.Module):\n",
    "    def __init__(self, embeddings, vocabObject):\n",
    "        super(ImageEmbeddingsForBert, self).__init__()\n",
    "        self.vocab = vocabObject\n",
    "#       the embeddins received as input are the \n",
    "#       all the embeddings provided by the bert model from pytorch\n",
    "        self.img_embeddings = nn.Linear(2048, 768)\n",
    "#       above is linear layer is used to convert the flattened images \n",
    "#       logits obtained after pooling from Image encoder which have 2048\n",
    "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
    "        \n",
    "        self.position_embeddings = embeddings.position_embeddings\n",
    "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
    "        self.word_embeddings = embeddings.word_embeddings\n",
    "        self.LayerNorm = embeddings.LayerNorm\n",
    "        self.dropout = embeddings.dropout\n",
    "        \n",
    "    def forward(self, batch_input_imgs, token_type_ids):\n",
    "        batch_size = batch_input_imgs.size(0)\n",
    "        seq_length = 7 + 2\n",
    "#         since we are assuming that from each image we will obtain\n",
    "#         7 image embeddings of 768 dimensions each\n",
    "        \n",
    "        cls_id = torch.LongTensor([101])\n",
    "        if torch.cuda.is_available():\n",
    "            cls_id = cls_id.cuda()\n",
    "            self.word_embeddings = self.word_embeddings.cuda()\n",
    "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            cls_id = cls_id.cuda()\n",
    "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
    "        \n",
    "        sep_id = torch.LongTensor([102])\n",
    "        if torch.cuda.is_available():\n",
    "            sep_id = sep_id.cuda()\n",
    "            self.img_embeddings = self.img_embeddings.cuda()\n",
    "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
    "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
    "        \n",
    "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
    "        \n",
    "        token_embeddings = torch.cat(\n",
    "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
    "        \n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
    "        if torch.cuda.is_available():\n",
    "            position_ids = position_ids.cuda()\n",
    "            self.position_embeddings = self.position_embeddings.cuda()\n",
    "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
    "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
    "        \n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        \n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "        \n",
    "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
    "        if torch.cuda.is_available():\n",
    "            embeddings = embeddings.cuda()\n",
    "            self.LayerNorm=self.LayerNorm.cuda()\n",
    "            self.dropout=self.dropout.cuda()\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class MultiModalBertEncoder(nn.Module):\n",
    "    def __init__(self, no_of_classes, tokenizer):\n",
    "        super(MultiModalBertEncoder, self).__init__()\n",
    "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.embeddings = bert.embeddings\n",
    "        self.vocab=Vocab()\n",
    "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.encoder = bert.encoder\n",
    "        self.pooler = bert.pooler\n",
    "        self.clf = nn.Linear(768, no_of_classes)\n",
    "        \n",
    "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
    "        batch_size = input_text.size(0)\n",
    "# input text is a tensor of encoded texts!\n",
    "        temp = torch.ones(batch_size, 7+2).long()\n",
    "        if torch.cuda.is_available():\n",
    "            temp = temp.cuda()\n",
    "            self.encoder = self.encoder.cuda()\n",
    "            self.pooler = self.pooler.cuda()\n",
    "        attention_mask = torch.cat(\n",
    "            [\n",
    "                temp, text_attention_mask\n",
    "            ],\n",
    "            dim=1\n",
    "        )\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
    "        extended_attention_mask = extended_attention_mask.to(\n",
    "            dtype=next(self.parameters()).dtype\n",
    "        )\n",
    "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
    "        \n",
    "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
    "        if(torch.cuda.is_available()):\n",
    "            image_token_type_ids= image_token_type_ids.cuda()\n",
    "        \n",
    "        image = self.image_encoder(input_image)\n",
    "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
    "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
    "#         print('Image embeddings: ', image_embedding_out.size())\n",
    "        \n",
    "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
    "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
    "#         print(input_text, text_embedding_out)\n",
    "        \n",
    "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
    "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
    "    \n",
    "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
    "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
    "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
    "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
    "        final = self.pooler(encoded_layers[-1])\n",
    "        # print('FINAL POOLED LAYERS', final, final.size())\n",
    "#         print('encoded layers', encoded_layers)\n",
    "        return final\n",
    "        # how to extract CLS layer\n",
    "        \n",
    "\n",
    "class MultiModalBertClf(nn.Module):\n",
    "    def __init__(self, no_of_classes, tokenizer):\n",
    "        super(MultiModalBertClf, self).__init__()\n",
    "        self.no_of_classes = no_of_classes\n",
    "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
    "        # self.layer1 = nn.Linear(768, 512)\n",
    "        # self.layer2 = nn.Linear(512, 256)\n",
    "        self.batch_norm = nn.BatchNorm1d(768)\n",
    "        self.clf = nn.Linear(768, self.no_of_classes)\n",
    "    \n",
    "    def forward(self, text, text_attention_mask, text_segment, image):\n",
    "        if(torch.cuda.is_available()):\n",
    "            text = text.cuda()\n",
    "            text_attention_mask=text_attention_mask.cuda()\n",
    "            text_segment=text_segment.cuda()\n",
    "            image = image.cuda()\n",
    "            self.clf = self.clf.cuda()\n",
    "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
    "        # x = F.relu(self.layer1(x))\n",
    "        # x = F.relu(self.layer2(x))\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.clf(x)\n",
    "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
    "        return x \n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    # read the focal loss paper\n",
    "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
    "            \n",
    "        pt = torch.exp(-BCE_loss)\n",
    "#       # pt = p if y = 1\n",
    "#       # pt = 1 - p if y = else\n",
    "#       p is the predicted value, y is the target label\n",
    "        # pt is used to indicate if the prediction matches the target or not\n",
    "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
    "        # so focal loss basically downweights the loss generated in a proper classification\n",
    "        # but does not change downweight the loss in a miss classification\n",
    "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        return F_loss\n",
    "        \n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, logits = True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
    "        if(logits):\n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "        y_pred = y_pred.view(-1)\n",
    "        y_true = y_true.view(-1)\n",
    "\n",
    "        intersection = (y_pred*y_true).sum()\n",
    "        pred_sum = (y_pred*y_pred).sum()\n",
    "        true_sum = (y_true*y_true).sum()\n",
    "\n",
    "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kS4hVKn3OBA"
   },
   "outputs": [],
   "source": [
    "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
    "    lengths = [len(row[0]) for row in batch]\n",
    "    batch_size = len(batch)\n",
    "    max_sent_len = max(lengths)\n",
    "    if(max_sent_len>128-7-2):\n",
    "        max_sent_len=128-7-2\n",
    "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
    "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
    "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
    "    \n",
    "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
    "    \n",
    "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
    "    if task_type=='multilabel':\n",
    "        label_tensors = torch.stack([row[1] for row in batch])\n",
    "#     note there is a difference between stack and cat, refer link below if needed\n",
    "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
    "    \n",
    "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
    "        text_tokens = row[0]\n",
    "        if(length>128-7-2):\n",
    "            length = 128-7-2\n",
    "        text_tensors[i, :length] = text_tokens\n",
    "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
    "        text_attention_mask[i, :length]=1\n",
    "    \n",
    "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
    "\n",
    "\n",
    "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
    "    total_steps = (\n",
    "        train_data_len\n",
    "        / batch_size\n",
    "        / gradient_accumulation_steps\n",
    "        * max_epochs\n",
    "    )\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
    "    ]\n",
    "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
    "    optimizer = BertAdam(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=lr,\n",
    "#         warmup=args.warmup,\n",
    "        t_total=total_steps,\n",
    "    )\n",
    "#     optimizer = optim.Adam(\n",
    "#         optimizer_grouped_parameters,\n",
    "#         lr=lr,\n",
    "# #         warmup=args.warmup,\n",
    "#         t_total=total_steps,\n",
    "#     )\n",
    "    return optimizer\n",
    "\n",
    "def model_forward(i_epoch, model, criterion, batch):\n",
    "    txt, tgt, segment, mask, img= batch\n",
    "\n",
    "#         for param in model.enc.img_encoder.parameters():\n",
    "#             param.requires_grad = not freeze_img\n",
    "#         for param in model.enc.encoder.parameters():\n",
    "#             param.requires_grad = not freeze_txt\n",
    "    if(torch.cuda.is_available()):\n",
    "        txt, img = txt.cuda(), img.cuda()\n",
    "        mask, segment = mask.cuda(), segment.cuda()\n",
    "    out = model(txt, mask, segment, img)\n",
    "    if(torch.cuda.is_available()):\n",
    "        tgt = tgt.cuda()\n",
    "    # print()\n",
    "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
    "    return loss, out, tgt\n",
    "\n",
    "\n",
    "def store_preds_to_disk(tgts, preds, savedir):\n",
    "    str_time = str(datetime.datetime.now())\n",
    "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
    "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
    "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
    "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
    "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
    "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
    "\n",
    "\n",
    "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
    "    with torch.no_grad():\n",
    "        losses, preds, tgts = [], [], []\n",
    "        for batch in data:\n",
    "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
    "            losses.append(loss.item())\n",
    "            if no_of_classes==1:\n",
    "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
    "                # for i in range(pred.shape[0]):\n",
    "                #     if pred[i][0]>0.5:\n",
    "                #         pred[i][0]=1\n",
    "                #     else:\n",
    "                #         pred[i][0]=0\n",
    "            else:\n",
    "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
    "                \n",
    "            preds.append(pred)\n",
    "            tgt = tgt.cpu().detach().numpy()\n",
    "            tgts.append(tgt)\n",
    "\n",
    "    metrics = {\"loss\": np.mean(losses)}\n",
    "    tgts = [l for sl in tgts for l in sl]\n",
    "    preds = [l for sl in preds for l in sl]\n",
    "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
    "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
    "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
    "\n",
    "    if store_preds:\n",
    "        store_preds_to_disk(tgts, preds, './')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLA_xWa87RDR"
   },
   "outputs": [],
   "source": [
    "class SubmissionDataset(Dataset):\n",
    "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
    "        self.data = data\n",
    "        self.image_path = (image_path)\n",
    "        self.transforms = transforms\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
    "        self.vocab = vocab\n",
    "    def __getitem__(self,  index):\n",
    "        text = self.data['text'][index]\n",
    "        text = str(text)\n",
    "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
    "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
    "        tweet_id = self.data['TweetId'][index]\n",
    "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
    "        image = None\n",
    "        try:\n",
    "            image = Image.open(\n",
    "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
    "            ).convert(\"RGB\")\n",
    "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
    "#             image.show()\n",
    "            image = self.transforms(image)\n",
    "        except:\n",
    "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return text, image, tweet_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
    "    lengths = [len(row[0]) for row in batch]\n",
    "    batch_size = len(batch)\n",
    "    max_sent_len = max(lengths)\n",
    "    if(max_sent_len>128-7-2):\n",
    "        max_sent_len=128-7-2\n",
    "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
    "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
    "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
    "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
    "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
    "    \n",
    "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
    "    # if task_type=='multilabel':\n",
    "        # label_tensors = torch.stack([row[1] for row in batch])\n",
    "#     note there is a difference between stack and cat, refer link below if needed\n",
    "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
    "    \n",
    "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
    "        text_tokens = row[0]\n",
    "        if(length>128-7-2):\n",
    "            length = 128-7-2\n",
    "        text_tensors[i, :length] = text_tokens\n",
    "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
    "        text_attention_mask[i, :length]=1\n",
    "        tweet_id_tensors[i, 0]=row[2]\n",
    "    \n",
    "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qroLei1K7M2h"
   },
   "outputs": [],
   "source": [
    "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
    "    \n",
    "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
    "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
    "\n",
    "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
    "        print('Loaded previous model state successfully!')\n",
    "    except:\n",
    "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if no_of_classes==1:\n",
    "        print('using '+str(chosen_criteria)+' loss')\n",
    "        criterion = chosen_criteria\n",
    "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \"max\", \n",
    "        patience=patience, \n",
    "        verbose=True, \n",
    "#         factor=args.lr_factor\n",
    "    )\n",
    "    if(torch.cuda.is_available()):\n",
    "        model=model.cuda()\n",
    "\n",
    "\n",
    "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
    "\n",
    "    print(\"Training..\")\n",
    "    for i_epoch in range(start_epoch, max_epochs):\n",
    "        train_losses = []\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
    "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
    "            # if gradient_accumulation_steps > 1:\n",
    "            #     loss = loss / gradient_accumulation_steps\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            global_step += 1\n",
    "            if global_step % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
    "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
    "        print('Train Losses :', train_losses)\n",
    "        print(\"Val loss\", metrics['loss'])\n",
    "        # print(metrics['acc'])\n",
    "        # print(metrics['classification_report'])\n",
    "        print('Val auc roc', metrics['roc_auc_score'])\n",
    "        tuning_metric = ( metrics['roc_auc_score'])\n",
    "        scheduler.step(tuning_metric)\n",
    "        is_improvement = tuning_metric > best_metric\n",
    "        if is_improvement:\n",
    "            best_metric = tuning_metric\n",
    "            n_no_improve = 0\n",
    "        else:\n",
    "            n_no_improve += 1\n",
    "        \n",
    "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
    "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
    "        # if n_no_improve >= patience:\n",
    "        #     print(\"No improvement. Breaking out of loop.\")\n",
    "        #     break\n",
    "\n",
    "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
    "#     model.eval()\n",
    "# #     for test_name, test_loader in test_loaders.items():\n",
    "#     test_metrics = model_eval(\n",
    "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
    "#     )\n",
    "#     print(f\"Test - \", test_metrics['loss'])\n",
    "#     print(test_metrics['acc'])\n",
    "#     print(test_metrics['classification_report'])\n",
    "#     print(test_metrics['roc_auc_score'])\n",
    "\n",
    "#     torch.save(model.state_dict(), './modelv1.pth')\n",
    "    return model\n",
    "    # return model, test_metrics\n",
    "\n",
    "\n",
    "def model_forward_predict(i_epoch, model, criterion, batch):\n",
    "    txt, segment, mask, img, tweet_id= batch\n",
    "\n",
    "#         for param in model.enc.img_encoder.parameters():\n",
    "#             param.requires_grad = not freeze_img\n",
    "#         for param in model.enc.encoder.parameters():\n",
    "#             param.requires_grad = not freeze_txt\n",
    "    if(torch.cuda.is_available()):\n",
    "        txt, img = txt.cuda(), img.cuda()\n",
    "        mask, segment = mask.cuda(), segment.cuda()\n",
    "    out = model(txt, mask, segment, img)\n",
    "    # if(torch.cuda.is_available()):\n",
    "    #     tgt = tgt.cuda()\n",
    "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
    "    return out, tweet_id\n",
    "\n",
    "\n",
    "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
    "    with torch.no_grad():\n",
    "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
    "        for batch in dataloader:\n",
    "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
    "            # losses.append(loss.item())\n",
    "            if no_of_classes==1:\n",
    "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
    "                # for i in range(pred.shape[0]):\n",
    "                #     if pred[i][0]>0.5:\n",
    "                #         pred[i][0]=1\n",
    "                #     else:\n",
    "                #         pred[i][0]=0\n",
    "            else:\n",
    "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
    "            # for i in range(4):\n",
    "            #     if(pred[i])\n",
    "            \n",
    "            # print('preddhd', pred)\n",
    "            # if pred > 0.5:\n",
    "            #     preds.append(1)\n",
    "            # else:\n",
    "            #     preds.append(0)\n",
    "\n",
    "            preds.append(pred)\n",
    "            # tgt = tgt.cpu().detach().numpy()\n",
    "            # tgts.append(tgt)\n",
    "            tweet_id = tweet_id.cpu().detach().numpy()\n",
    "            tweet_ids.append(tweet_id)\n",
    "\n",
    "    # metrics = {\"loss\": np.mean(losses)}\n",
    "    # tgts = [l for sl in tgts for l in sl]\n",
    "    preds = [l for sl in preds for l in sl]\n",
    "    # for i in len(preds):\n",
    "    #     if preds[i]>0.5:\n",
    "    #         preds[i]=1\n",
    "    #     else:\n",
    "    #         preds[i]=0\n",
    "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
    "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
    "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
    "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
    "\n",
    "    # if store_preds:\n",
    "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
    "\n",
    "    return preds, tweet_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UEETPiGryzOA",
    "outputId": "1fcf054a-a361-40a6-ee23-82c1ce0a7ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FocalLoss()\n"
     ]
    }
   ],
   "source": [
    "col_name = \"Generalized_Hate\"\n",
    "train_epochs = 3\n",
    "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
    "chosen_criteria = losses[0]()\n",
    "no_of_classes = 1\n",
    "print(str(chosen_criteria))\n",
    "minority_class = 1 # or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-kABURr7vsf"
   },
   "outputs": [],
   "source": [
    "vocab = Vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 947,
     "referenced_widgets": [
      "0fc44352e7ce49dcac07d32d769a2757",
      "6f410fe5dc3c491087ff79820c5047ec",
      "66aefddebbc5464eb20b1186a85cd915",
      "7dda0fcd285549998d1383defc3c7da6",
      "75c6d95c06c1469a9ea8d252e5af90d3",
      "b2f1af333fce4ae189d1111042af3ec9",
      "ee2a4fc50c2b4e31a45eae9f23084488",
      "f86098877c054be48eaa3ca7819ae253",
      "42685acc56dd458fba57903118d99291",
      "ede6503080f6442f845b9c7da032772a",
      "91e2b49f13a04c65be7cf88ea854ab7e",
      "2d1ea967679845029275603085b344b5",
      "226eb4e8e9e64853aa756bd58173aa98",
      "fb6576223354419c8981443ecaaa8504",
      "e51594b3bc9c45c5ae20f900459313e6",
      "b6ef73e7b9cd4ceabae23089bb9cf4bc",
      "505af5263980412989e2c4ee4433d090",
      "98b8d90b702346f3ab8d4ba6a52d6a3e",
      "097895f8a2b6495692d9a27e03e696db",
      "f16e401def4e45a4be19dd71fb9e9e7e",
      "cd6a768ff18d440db94fdc8562622a4b",
      "b2a324457fc142e39e9dd06345420eaf",
      "d8f8b217793e4bdbbe2c08d1a3885fb5",
      "17b1763c24bd4b929d4ada36269967cb",
      "a184b03dc83542a68b2648d6035b0125",
      "1ae6400435da44a893ee89e1b9ef70a8",
      "f78aa42748ba4c8dade0b3e71dfb8247",
      "5fe3aeaaac264d50a65386f98aef26c9",
      "a24c30054906424a9d7a5938e8f452d2",
      "72c0bf2895f846e0bb19ff49ab56e1cc",
      "3e731da642324e9ba2f195350cbd3580",
      "bc3255c243024a79a202505513a82efb"
     ]
    },
    "colab_type": "code",
    "id": "W-5z7hFf4D3q",
    "outputId": "b1bb4376-9bcc-4d24-c1ec-f69aa731cd1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old data length : 6382\n",
      "minority class is 1. Duplicating minority class data!\n",
      "New data length : 6726\n",
      "Old data length : 1596\n",
      "minority class is 1. Duplicating minority class data!\n",
      "New data length : 1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc44352e7ce49dcac07d32d769a2757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fresh! Previous model state dict load unsuccessful\n",
      "using FocalLoss() loss\n",
      "Training..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42685acc56dd458fba57903118d99291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1681.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0523\n",
      "Train Losses : [0.1614096462726593, 0.5211608409881592, 0.9041175842285156, 0.579133927822113, 3.7603759765625, 0.861186146736145, 0.6353676319122314, 0.334367036819458, 0.11321140825748444, 0.25997933745384216, 0.03614106774330139, 0.423667848110199, 0.42516714334487915, 0.38009384274482727, 0.2888776957988739, 0.14868265390396118, 1.1847217082977295, 0.17736360430717468, 0.08993417769670486, 0.7127869129180908, 0.0192116666585207, 0.021388791501522064, 0.018085945397615433, 0.05513111501932144, 0.04749316722154617, 0.009639042429625988, 0.0096581457182765, 0.0070877098478376865, 0.13257870078086853, 0.02068125456571579, 0.005940916948020458, 0.035893671214580536, 0.14243529736995697, 0.0050811911933124065, 0.008620534092187881, 0.0035447299014776945, 0.002433835994452238, 0.003934228792786598, 0.0019646291621029377, 0.003336656140163541, 0.0048245335929095745, 0.0020445706322789192, 0.002190508646890521, 0.4941481947898865, 0.0025868003722280264, 0.11465296894311905, 0.0012291115708649158, 0.0010359713342040777, 0.0013440578477457166, 0.0030039194971323013, 0.1754174679517746, 0.0011031880276277661, 0.1149536669254303, 0.6145060062408447, 0.08462787419557571, 0.0019877536687999964, 0.003496416611596942, 0.007341464981436729, 0.0067578088492155075, 0.5678597688674927, 0.00729644438251853, 0.011738049797713757, 0.09843258559703827, 0.011068486608564854, 0.010816041380167007, 0.014238015748560429, 0.018245935440063477, 0.02803877554833889, 0.013742880895733833, 0.015269358642399311, 0.01756463386118412, 0.015762967988848686, 0.22583380341529846, 0.01121552474796772, 0.00884011760354042, 0.009788908064365387, 0.01003451831638813, 0.007923904806375504, 0.16052797436714172, 0.006992512382566929, 0.07796767354011536, 0.008348971605300903, 0.005193791817873716, 0.004717318341135979, 0.0049306051805615425, 0.46736598014831543, 0.0055884309113025665, 0.0059949602000415325, 0.005822272505611181, 0.005984866991639137, 0.007561855483800173, 0.032782647758722305, 0.007137968670576811, 0.2581879794597626, 0.1052694022655487, 0.08862248808145523, 0.27642977237701416, 0.006257724482566118, 0.10503838211297989, 0.007529247552156448, 0.00818905420601368, 0.09826963394880295, 0.008414859883487225, 0.008443992584943771, 0.0077254376374185085, 0.0073542785830795765, 0.12021058797836304, 0.007151889149099588, 0.006895041558891535, 0.006556874141097069, 0.16861680150032043, 0.007350803352892399, 0.006297880318015814, 0.006164907943457365, 0.006255291868001223, 0.10619108378887177, 0.10730166733264923, 0.00554811442270875, 0.1021411195397377, 0.4458787441253662, 0.0726427286863327, 0.009534848853945732, 0.008125952444970608, 0.013415326364338398, 0.01566329598426819, 0.01640944555401802, 0.011241787113249302, 0.007744661532342434, 0.13528646528720856, 0.1780799776315689, 0.21080438792705536, 0.21877644956111908, 0.007766345981508493, 0.013545614667236805, 0.0079380813986063, 0.011809613555669785, 0.010051052086055279, 0.14196576178073883, 0.008577394299209118, 0.007858507335186005, 0.008606447838246822, 0.008121147751808167, 0.007280869409441948, 0.007083436474204063, 0.08523410558700562, 0.005876441951841116, 0.00480084540322423, 0.0059795319102704525, 0.0052301618270576, 0.2475235015153885, 0.004208611324429512, 0.5601899027824402, 0.004812728147953749, 0.004803874064236879, 0.06632456183433533, 0.06342374533414841, 0.3087141215801239, 0.006795706693083048, 0.08790834993124008, 0.1827297955751419, 0.01365507859736681, 0.011015599593520164, 0.012369816191494465, 0.048133138567209244, 0.014064213261008263, 0.015286915935575962, 0.14130190014839172, 0.01589011587202549, 0.013485854491591454, 0.18756188452243805, 0.01452338695526123, 0.01303541287779808, 0.013775442726910114, 0.0729527398943901, 0.011577448807656765, 0.013907591812312603, 0.054758649319410324, 0.009724246338009834, 0.011303320527076721, 0.00982069130986929, 0.009045838378369808, 0.008269225247204304, 0.008621476590633392, 0.0077413455583155155, 0.24254313111305237, 0.006387890316545963, 0.0061075021512806416, 0.5214596390724182, 0.15759623050689697, 0.006644194945693016, 0.5339478850364685, 0.14919549226760864, 0.11753964424133301, 0.008948522619903088, 0.010750779882073402, 0.01039830595254898, 0.012042385526001453, 0.15472066402435303, 0.10571123659610748, 0.01299136783927679, 0.013343196362257004, 0.29243242740631104, 0.01732724905014038, 0.01532986294478178, 0.08871573209762573, 0.01620449870824814, 0.09688802808523178, 0.018056783825159073, 0.12945611774921417, 0.1454450637102127, 0.015980735421180725, 0.016331573948264122, 0.052410341799259186, 0.015458683483302593, 0.0142005430534482, 0.01427631825208664, 0.013239347375929356, 0.08364003151655197, 0.015136873349547386, 0.07126016914844513, 0.011058859527111053, 0.012612777762115002, 0.011718043126165867, 0.00974978320300579, 0.12258049100637436, 0.15653681755065918, 0.007695301435887814, 0.007364820223301649, 0.0076857940293848515, 0.006714072544127703, 0.007745520211756229, 0.006365709938108921, 0.006344122346490622, 0.0060815829783678055, 0.005851848050951958, 0.007256675511598587, 0.20278608798980713, 0.1463967263698578, 0.12360119819641113, 0.004554361570626497, 0.005510034970939159, 0.0054502650164067745, 0.005763700231909752, 0.28510892391204834, 0.006164672784507275, 0.08183478564023972, 0.0069786314852535725, 0.19617947936058044, 0.007063410244882107, 0.008085939101874828, 0.06712307035923004, 0.010348583571612835, 0.010529548861086369, 0.008207793347537518, 0.00912133976817131, 0.047415174543857574, 0.1193709522485733, 0.010197418741881847, 0.015655310824513435, 0.009471231140196323, 0.009348179213702679, 0.008294526487588882, 0.007820099592208862, 0.08721768856048584, 0.008222869597375393, 0.039879683405160904, 0.04433562606573105, 0.007662628777325153, 0.009145259857177734, 0.009452352300286293, 0.03455545753240585, 0.012000583112239838, 0.009032201021909714, 0.07725659757852554, 0.010454725474119186, 0.009418853558599949, 0.1976679116487503, 0.005454604979604483, 0.11422908306121826, 0.23538999259471893, 0.008843977004289627, 0.009965438395738602, 0.01318243145942688, 0.012121995911002159, 0.010783215053379536, 0.00814470462501049, 0.06657499819993973, 0.29785576462745667, 0.009146887809038162, 0.008488141931593418, 0.0071021150797605515, 0.007443069946020842, 0.006756877992302179, 0.00820969045162201, 0.006178268231451511, 0.00984513945877552, 0.005823695100843906, 0.00631226459518075, 0.0054694488644599915, 0.5266212821006775, 0.09728510677814484, 0.21943002939224243, 0.004853555932641029, 0.005712929181754589, 0.1407468318939209, 0.11657273024320602, 0.006681847386062145, 0.006690762005746365, 0.006948096211999655, 0.007718927692621946, 0.007271348964422941, 0.007742465008050203, 0.006516850087791681, 0.006951279938220978, 0.22873146831989288, 0.00694514624774456, 0.006743014324456453, 0.0076631647534668446, 0.006153218913823366, 0.007031439337879419, 0.007060317788273096, 0.27619555592536926, 0.006259257439523935, 0.007608567830175161, 0.006977348122745752, 0.3344728648662567, 0.13431107997894287, 0.008783461526036263, 0.008392696268856525, 0.009907593950629234, 0.009947692975401878, 0.07105953246355057, 0.011129453778266907, 0.01141299307346344, 0.09053704142570496, 0.009944837540388107, 0.11812292784452438, 0.010167967528104782, 0.01058784406632185, 0.009853852912783623, 0.011156943626701832, 0.009854323230683804, 0.1026771068572998, 0.12157795578241348, 0.009379303082823753, 0.008854355663061142, 0.11679872125387192, 0.3657747209072113, 0.008785923011600971, 0.011775814928114414, 0.009360022842884064, 0.010229166597127914, 0.13546466827392578, 0.1904536783695221, 0.011092470027506351, 0.011440976522862911, 0.011020471341907978, 0.05505664646625519, 0.009700040332973003, 0.009954826906323433, 0.009454917162656784, 0.009593259543180466, 0.009924648329615593, 0.00886634923517704, 0.07785976678133011, 0.008707846514880657, 0.007777195889502764, 0.007956543006002903, 0.007614676374942064, 0.08443321287631989, 0.06962320953607559, 0.03976210206747055, 0.08817002922296524, 0.1784680038690567, 0.007131855469197035, 0.0063883052207529545, 0.006588072516024113, 0.007889357395470142, 0.14505136013031006, 0.007325251121073961, 0.06190237030386925, 0.007857154123485088, 0.09316828101873398, 0.006969389505684376, 0.008245828561484814, 0.006786797661334276, 0.00698329322040081, 0.006274592597037554, 0.007002946455031633, 0.007474930956959724, 0.005324406083673239, 0.0055166264064610004, 0.005465987138450146, 0.006388378795236349, 0.00461722444742918, 0.00518780155107379, 0.004402765538543463, 0.005455294623970985, 0.004028798546642065, 0.00476217782124877, 0.12287144362926483, 0.11265696585178375, 0.15817978978157043, 0.12007718533277512, 0.0042901658453047276, 0.004707448650151491, 0.003926648758351803, 0.00476519949734211, 0.004258995875716209, 0.004262230824679136, 0.004809695295989513, 0.004802298732101917, 0.004632363561540842, 0.00454930542036891, 0.005289722699671984, 0.00455621350556612, 0.005596126429736614, 0.0042707654647529125, 0.1325332075357437, 0.11961124837398529, 0.0043605295941233635, 0.00442562997341156, 0.054471567273139954, 0.004493050742894411, 0.23898333311080933, 0.004233722109347582, 0.005372949875891209, 0.004550443962216377, 0.004138672724366188, 0.004687661305069923, 0.005253493785858154, 0.07174249738454819, 0.00534477736800909, 0.05599718913435936, 0.004140101373195648, 0.004847452975809574, 0.004831169731914997, 0.004438392352312803, 0.004961299244314432, 0.0042618634179234505, 0.00540826003998518, 0.004387779626995325, 0.004766739904880524, 0.004494498949497938, 0.0037102855276316404, 0.1091851070523262, 0.0037941685877740383, 0.0036432477645576, 0.004310416057705879, 0.09687115997076035, 0.004780352581292391, 0.003842375474050641, 0.004143512342125177, 0.003755536861717701, 0.0040941364131867886, 0.46838998794555664, 0.08313411474227905, 0.00407381821423769, 0.10007966309785843, 0.004698145668953657, 0.0073934816755354404, 0.005191287957131863, 0.0069082933478057384, 0.006680584512650967, 0.006581457797437906, 0.007871536538004875, 0.005875975824892521, 0.36984890699386597, 0.2493506669998169, 0.008186553604900837, 0.0077442205511033535, 0.10238827019929886, 0.008490115404129028, 0.11851227283477783, 0.010386505164206028, 0.009825031273066998, 0.011886774562299252, 0.008702988736331463, 0.010547913610935211, 0.009622016921639442, 0.047883205115795135, 0.11205039918422699, 0.13330648839473724, 0.008401417173445225, 0.010889695025980473, 0.11586835235357285, 0.009671268984675407, 0.29285553097724915, 0.010789569467306137, 0.010640636086463928, 0.00850297324359417, 0.008583207614719868, 0.07663824409246445, 0.009001794271171093, 0.008149830624461174, 0.009538349695503712, 0.007985683158040047, 0.008470290340483189, 0.00878765620291233, 0.06596540659666061, 0.11640758067369461, 0.006488312501460314, 0.006515285931527615, 0.006646724417805672, 0.005601946264505386, 0.007934829220175743, 0.006763793062418699, 0.006609742529690266, 0.005656430963426828, 0.004796436056494713, 0.004507938865572214, 0.005590401589870453, 0.00453973188996315, 0.08420421928167343, 0.003964618779718876, 0.2756989300251007, 0.12198696285486221, 0.09196226298809052, 0.004653592593967915, 0.08808174729347229, 0.004505993332713842, 0.4869958758354187, 0.005493042524904013, 0.005815740209072828, 0.00581083120778203, 0.04984287917613983, 0.0064957402646541595, 0.14494049549102783, 0.08097920566797256, 0.008114964701235294, 0.01051003485918045, 0.008375183679163456, 0.18388162553310394, 0.009643346071243286, 0.009880139492452145, 0.00939691998064518, 0.1091216430068016, 0.08895683288574219, 0.010034223087131977, 0.19121584296226501, 0.010701121762394905, 0.00954691506922245, 0.009718011133372784, 0.009605889208614826, 0.009740789420902729, 0.009310348890721798, 0.008807429112493992, 0.008533354848623276, 0.008645749650895596, 0.008034327998757362, 0.00771627202630043, 0.007305107545107603, 0.007435062434524298, 0.00715238880366087, 0.006661263294517994, 0.005789452698081732, 0.00608572643250227, 0.10539179295301437, 0.005339168943464756, 0.00495030777528882, 0.11123200505971909, 0.005135036073625088, 0.005076844245195389, 0.00472735520452261, 0.0046675666235387325, 0.004532727412879467, 0.423554927110672, 0.0043357182294130325, 0.0048196520656347275, 0.0050209383480250835, 0.0050438703037798405, 0.005073327571153641, 0.0982302576303482, 0.005401573143899441, 0.005917377304285765, 0.006659237667918205, 0.005593385547399521, 0.005717292428016663, 0.005952752195298672, 0.005392853636294603, 0.005367868114262819, 0.0053612045012414455, 0.005792350508272648, 0.0054116821847856045, 0.32376208901405334, 0.1635132133960724, 0.005721311084926128, 0.005922607611864805, 0.006601190660148859, 0.006362138781696558, 0.007143066730350256, 0.21754956245422363, 0.007433549501001835, 0.12890735268592834, 0.007359578274190426, 0.007169296965003014, 0.007268661633133888, 0.007645543664693832, 0.08400233834981918, 0.00756631838157773, 0.007568544242531061, 0.3520050346851349, 0.007872638292610645, 0.008208075538277626, 0.0911119133234024, 0.008809770457446575, 0.010576233267784119, 0.10829789191484451, 0.0093685956671834, 0.009436598047614098, 0.12028761208057404, 0.10590004920959473, 0.0873645767569542, 0.01013423316180706, 0.010937580838799477, 0.00977871473878622, 0.11589918285608292, 0.010176362469792366, 0.009636916220188141, 0.010086260735988617, 0.009641267359256744, 0.010258279740810394, 0.08985334634780884, 0.009095801040530205, 0.00895675364881754, 0.14456282556056976, 0.008499659597873688, 0.008777511306107044, 0.008558716624975204, 0.00779599929228425, 0.007622051984071732, 0.09788773953914642, 0.1060708612203598, 0.007211199030280113, 0.007456338498741388, 0.007305586244910955, 0.006648761685937643, 0.0065823933109641075, 0.006443750113248825, 0.006215162109583616, 0.00606128666549921, 0.005796973593533039, 0.14146079123020172, 0.005517370533198118, 0.0055862548761069775, 0.005101213697344065, 0.10791918635368347, 0.00503307580947876, 0.004899099934846163, 0.00495292479172349, 0.0047124167904257774, 0.12326919287443161, 0.12532258033752441, 0.004718386102467775, 0.004731867928057909, 0.004687251523137093, 0.005032808985561132, 0.0047190431505441666, 0.004707116633653641, 0.004552663769572973, 0.004689868539571762, 0.39147111773490906, 0.004898167215287685, 0.12334899604320526, 0.005646933801472187, 0.005448166746646166, 0.05529806390404701, 0.0060334717854857445, 0.0061298212967813015, 0.006635761354118586, 0.006661541294306517, 0.13097846508026123, 0.007092867512255907, 0.007585965096950531, 0.007197816390544176, 0.006676144432276487, 0.006802072282880545, 0.006637537851929665, 0.006534690968692303, 0.006267036776989698, 0.006432501599192619, 0.006388074718415737, 0.0060581183061003685, 0.005713609047234058, 0.0988028272986412, 0.005481984931975603, 0.005188980605453253, 0.0052852146327495575, 0.005316652823239565, 0.12532353401184082, 0.004911941941827536, 0.0048737251199781895, 0.004719754680991173, 0.004708792082965374, 0.0047636618837714195, 0.00439222389832139, 0.00440463051199913, 0.004309315234422684, 0.004192035179585218, 0.004011543933302164, 0.10017893463373184, 0.0037771323695778847, 0.004009775817394257, 0.0038738511502742767, 0.0037318363320082426, 0.13523241877555847, 0.14634810388088226, 0.0037363755982369184, 0.003776528872549534, 0.13494321703910828, 0.0038552640471607447, 0.004052972421050072, 0.0040429155342280865, 0.004238619469106197, 0.004010091535747051, 0.15802690386772156, 0.004201884381473064, 0.17407505214214325, 0.004712620284408331, 0.004355881363153458, 0.004588898736983538, 0.08586739003658295, 0.0046072653494775295, 0.004762257914990187, 0.10099446028470993, 0.004883957095444202, 0.12520480155944824, 0.1392793506383896, 0.005195640027523041, 0.005647472571581602, 0.15941274166107178, 0.005956513807177544, 0.07318077981472015, 0.0060392203740775585, 0.0968102365732193, 0.17210909724235535, 0.006764073856174946, 0.006930378265678883, 0.1085822731256485, 0.14530085027217865, 0.007636284921318293, 0.007834874093532562, 0.007950198836624622, 0.008083165623247623, 0.007920716889202595, 0.007793933153152466, 0.007685238495469093, 0.12384968250989914, 0.007694676518440247, 0.11603017151355743, 0.007557673379778862, 0.007530433125793934, 0.00744523573666811, 0.0072947172448039055, 0.007349062245339155, 0.09671758860349655, 0.0070136357098817825, 0.1278074085712433, 0.006879312917590141, 0.0070555368438363075, 0.006706614512950182, 0.006841348484158516, 0.00649957824498415, 0.4180760681629181, 0.006740150973200798, 0.006865516770631075, 0.11731322854757309, 0.007468604017049074, 0.00783147756010294, 0.007737788371741772, 0.10197128355503082, 0.10431376099586487, 0.00801969226449728, 0.08332693576812744, 0.00836244411766529, 0.008450030349195004, 0.008274328894913197, 0.11890562623739243, 0.12733891606330872, 0.008459617383778095, 0.008352531120181084, 0.008301058784127235, 0.008322360925376415, 0.00818475428968668, 0.09129112958908081, 0.008076627738773823, 0.007808692287653685, 0.10336069017648697, 0.007550288923084736, 0.007430455181747675, 0.007371200248599052, 0.007332107052206993, 0.006882626563310623, 0.09850863367319107, 0.006666307803243399, 0.006638758350163698, 0.006518968380987644, 0.006385848857462406, 0.0062080007046461105, 0.00600414676591754, 0.09607484936714172, 0.005563617683947086, 0.005693853832781315, 0.005600268021225929, 0.0899251326918602, 0.005170978605747223, 0.0050000692717731, 0.004965175874531269, 0.005101677030324936, 0.005049566272646189, 0.07795597612857819, 0.004659194033592939, 0.004598536528646946, 0.004716863390058279, 0.004489659331738949, 0.10620231926441193, 0.1220724880695343, 0.004469523672014475, 0.1511279046535492, 0.00465016346424818, 0.004823388997465372, 0.004629283212125301, 0.004732178989797831, 0.08885864913463593, 0.004881194327026606, 0.005032025743275881, 0.09627079218626022, 0.43320852518081665, 0.12705522775650024, 0.005849834065884352, 0.006599635351449251, 0.006805608980357647, 0.3661029040813446, 0.008219365030527115, 0.008705470710992813, 0.09478301554918289, 0.01054320577532053, 0.010676180012524128, 0.010849019512534142, 0.011281665414571762, 0.011436262167990208, 0.08597241342067719, 0.08151191473007202, 0.012379299849271774, 0.012679441832005978, 0.012275672517716885, 0.012164438143372536, 0.012113390490412712, 0.08771633356809616, 0.011292572133243084, 0.10562865436077118, 0.16689589619636536, 0.010839942842721939, 0.012387379072606564, 0.01077070739120245, 0.010182846337556839, 0.010521086864173412, 0.009519575163722038, 0.009909261018037796, 0.008891759440302849, 0.008350927382707596, 0.007963106036186218, 0.00781329907476902, 0.008349167183041573, 0.006893814075738192, 0.11929945647716522, 0.09619881212711334, 0.006390773691236973, 0.006645123474299908, 0.08109474927186966, 0.005802780389785767, 0.0057294717989861965, 0.005630031693726778, 0.005869012791663408, 0.005463641602545977, 0.005116697400808334, 0.005051268730312586, 0.11074545234441757, 0.12275604903697968, 0.0993967279791832, 0.005039417650550604, 0.004908216651529074, 0.1203276589512825, 0.005227054003626108, 0.00532331969588995, 0.005223655607551336, 0.12155795842409134, 0.005350362043827772, 0.0052049532532691956, 0.005639160983264446, 0.0053682574070990086, 0.005145044066011906, 0.11316042393445969, 0.00554819218814373, 0.005643410142511129, 0.005517257377505302, 0.1708943247795105, 0.0052715265192091465, 0.09556226432323456, 0.13789227604866028, 0.12023643404245377, 0.15746988356113434, 0.0061452556401491165, 0.006115025840699673, 0.09318611770868301, 0.0064103733748197556, 0.007241363171488047, 0.006851756479591131, 0.007581131998449564, 0.007017189171165228, 0.006836974527686834, 0.07877232879400253, 0.0068089705891907215, 0.0913519412279129, 0.13779529929161072, 0.007575655356049538, 0.1288844794034958, 0.007362989708781242, 0.007065019570291042, 0.11347797513008118, 0.00776141881942749, 0.007253527175635099, 0.007819967344403267, 0.09419688582420349, 0.11153309047222137, 0.007567849010229111, 0.007379905786365271, 0.08115668594837189, 0.007182194851338863, 0.007941017858684063, 0.007435259874910116, 0.007663425989449024, 0.11260927468538284, 0.007094474509358406, 0.006889429409056902, 0.006788560654968023, 0.0072021689265966415, 0.1278424859046936, 0.15267202258110046, 0.07589421421289444, 0.006881482433527708, 0.10408315807580948, 0.0077374582178890705, 0.12574681639671326, 0.09715433418750763, 0.00804714486002922, 0.007765510119497776, 0.008461167104542255, 0.007326596882194281, 0.11850275099277496, 0.007803607732057571, 0.007706336211413145, 0.00758842658251524, 0.008593510836362839, 0.007103348150849342, 0.007319550029933453, 0.0070596071891486645, 0.006596195511519909, 0.006766849663108587, 0.006623920053243637, 0.006130734924226999, 0.0062981476075947285, 0.005958233959972858, 0.11926934123039246, 0.005794764030724764, 0.09804628044366837, 0.12480507045984268, 0.17262403666973114, 0.005671551916748285, 0.2959642708301544, 0.006400830578058958, 0.006100120022892952, 0.006508557125926018, 0.06550218909978867, 0.007025843020528555, 0.007307067047804594, 0.11948461085557938, 0.007944978773593903, 0.007865700870752335, 0.08057289570569992, 0.008897418156266212, 0.00838411133736372, 0.008027409203350544, 0.008119485341012478, 0.008047778159379959, 0.008003851398825645, 0.1328675001859665, 0.008279037661850452, 0.007960428483784199, 0.008155753836035728, 0.00788445957005024, 0.14205798506736755, 0.00750377681106329, 0.21253328025341034, 0.007134879007935524, 0.0067854817025363445, 0.00701923156157136, 0.007688403595238924, 0.07586202025413513, 0.006782170385122299, 0.09280416369438171, 0.3121313154697418, 0.006888972129672766, 0.006941730622202158, 0.007046402897685766, 0.008087465539574623, 0.09070409089326859, 0.007980150170624256, 0.008101971819996834, 0.007926709949970245, 0.008016256615519524, 0.3804643452167511, 0.00836857594549656, 0.008959856815636158, 0.008687731809914112, 0.009245180524885654, 0.009111561812460423, 0.07002217322587967, 0.010263299569487572, 0.009582571685314178, 0.009534179233014584, 0.009540637955069542, 0.13669703900814056, 0.010052450001239777, 0.009074204601347446, 0.00947320181876421, 0.12334132194519043, 0.008406128734350204, 0.008635670877993107, 0.008309691213071346, 0.008157015778124332, 0.007970446720719337, 0.007510820869356394, 0.007473735138773918, 0.0073321801610291, 0.007914993911981583, 0.006719341967254877, 0.006151949055492878, 0.1274200826883316, 0.005780115257948637, 0.11315108835697174, 0.005687391385436058, 0.00628607627004385, 0.006153847556561232, 0.005434880498796701, 0.005146851297467947, 0.005508361384272575, 0.004879838787019253, 0.004761901684105396, 0.005197673570364714, 0.0048903049901127815, 0.22587069869041443, 0.004455261398106813, 0.004405561368912458, 0.105173759162426, 0.1216920018196106, 0.004319644067436457, 0.004615262150764465, 0.004528821911662817, 0.14208252727985382, 0.0042783175595104694, 0.004676560405641794, 0.3769032061100006, 0.005124323070049286, 0.09603587538003922, 0.005468565970659256, 0.005919189658015966, 0.0830560103058815, 0.006315312348306179, 0.006861768197268248, 0.00695278262719512, 0.007225836627185345, 0.007201855070888996, 0.0075070965103805065, 0.0073742992244660854, 0.007733166683465242, 0.0070993322879076, 0.1290581375360489, 0.007229287177324295, 0.007150203920900822, 0.006885884795337915, 0.006772548425942659, 0.08551694452762604, 0.49891629815101624, 0.007517606485635042, 0.007465752307325602, 0.007607140578329563, 0.007809492293745279, 0.007912062108516693, 0.10418778657913208, 0.00838317908346653, 0.008268981240689754, 0.008247964084148407, 0.008372316136956215, 0.09436062723398209, 0.008361410349607468, 0.1268392652273178, 0.008168577216565609, 0.13130487501621246, 0.008623326197266579, 0.13559961318969727, 0.07749559730291367, 0.008352061733603477, 0.008190413936972618, 0.008505134843289852, 0.11482340842485428, 0.008281503804028034, 0.008302402682602406, 0.008411034941673279, 0.008213991299271584, 0.008087255991995335, 0.007568405009806156, 0.007469947915524244, 0.007380260620266199, 0.007597077637910843, 0.006791241466999054, 0.3478570282459259, 0.006917108781635761, 0.006976416800171137, 0.006999066099524498, 0.007074510678648949, 0.007318106014281511, 0.007119409274309874, 0.007130669429898262, 0.007098171394318342, 0.0068695941008627415, 0.006645521614700556, 0.11448047310113907, 0.00645486218854785, 0.10043895244598389, 0.006425743922591209, 0.0072816647589206696, 0.2997703552246094, 0.0066266474314033985, 0.11676880717277527, 0.007273529656231403, 0.007667145226150751, 0.007885267958045006, 0.007917559705674648, 0.008346949703991413, 0.008050444535911083, 0.29569554328918457, 0.00865504052489996, 0.009694589301943779, 0.009222143329679966, 0.12053921073675156, 0.009625893086194992, 0.011209143325686455, 0.010335377417504787, 0.010068271309137344, 0.30506080389022827, 0.01059379056096077, 0.012131057679653168, 0.011606166139245033, 0.012214967980980873, 0.01144478376954794, 0.011913617141544819, 0.12237690389156342, 0.011884687468409538, 0.2639925181865692, 0.012002392672002316, 0.01287336740642786, 0.2907966077327728, 0.012755035422742367, 0.014044693671166897, 0.09018591791391373, 0.09407317638397217, 0.014878885820508003, 0.11042667925357819, 0.015920614823698997, 0.11038368940353394, 0.015628712251782417, 0.015623611398041248, 0.01619001291692257, 0.01620221883058548, 0.015591672621667385, 0.014175773598253727, 0.014427974820137024, 0.01416848786175251, 0.01274498738348484, 0.060161419212818146, 0.012085926719009876, 0.012418046593666077, 0.01207018829882145, 0.010237691923975945, 0.010296445339918137, 0.00922013632953167, 0.008759327232837677, 0.008630719035863876, 0.00804092176258564, 0.07563841342926025, 0.007620826363563538, 0.0070795645006000996, 0.0069892508909106255, 0.006866514682769775, 0.006050752941519022, 0.006239157170057297, 0.006000805180519819, 0.005452195648103952, 0.005547382403165102, 0.0052659702487289906, 0.0809994786977768, 0.32456156611442566, 0.12083350121974945, 0.30860456824302673, 0.006132686976343393, 0.12633202970027924, 0.006658805534243584, 0.007020739372819662, 0.008199941366910934, 0.008509211242198944, 0.07807771116495132, 0.009483207017183304, 0.010526980273425579, 0.00972386822104454, 0.00922087486833334, 0.010351466946303844, 0.01027410663664341, 0.01058032177388668, 0.009424724616110325, 0.009027722291648388, 0.009854997508227825, 0.008810371160507202, 0.00876045785844326, 0.008701636455953121, 0.13266929984092712, 0.007969451136887074, 0.00755287054926157, 0.008260129019618034, 0.1583227813243866, 0.007471525110304356, 0.08779314160346985, 0.09924806654453278, 0.0070869592018425465, 0.14774246513843536, 0.21850503981113434, 0.00783614069223404, 0.008386766538023949, 0.09921301901340485, 0.007179642096161842, 0.007111209444701672, 0.008066820912063122, 0.09322734922170639, 0.06758477538824081, 0.007368736434727907, 0.006980821955949068, 0.09644801169633865, 0.008168158121407032, 0.37210598587989807, 0.007797591388225555, 0.22320738434791565, 0.41185760498046875, 0.10734575241804123, 0.010628965683281422, 0.011344212107360363, 0.011247540824115276, 0.14436335861682892, 0.10498155653476715, 0.012911618687212467, 0.01470546331256628, 0.014789250679314137, 0.013525711372494698, 0.014279531314969063, 0.015031210146844387, 0.06887546926736832, 0.013387876562774181, 0.1430286318063736, 0.013315683230757713, 0.014870104379951954, 0.013223265297710896, 0.1144232377409935, 0.09992604702711105, 0.0988723486661911, 0.01142097171396017, 0.01221654936671257, 0.011240478605031967, 0.11297624558210373, 0.010854286141693592, 0.011474952101707458, 0.010179027915000916, 0.10007348656654358, 0.3694680333137512, 0.010314079001545906, 0.09842327982187271, 0.011096793226897717, 0.011085394769906998, 0.15557371079921722, 0.01023692637681961, 0.13023096323013306, 0.010756457224488258, 0.010958551429212093, 0.010677780024707317, 0.01030601467937231, 0.011002336628735065, 0.010098195634782314, 0.009666960686445236, 0.009901254437863827, 0.08159521967172623, 0.11221486330032349, 0.009289301931858063, 0.009165523573756218, 0.008951079100370407, 0.15077683329582214, 0.12299089878797531, 0.008186684921383858, 0.0080712316557765, 0.007779187522828579, 0.007873582653701305, 0.0073943850584328175, 0.00738737965002656, 0.007436838932335377, 0.006907562725245953, 0.006696757860481739, 0.0068489862605929375, 0.006191633641719818, 0.0065193185582757, 0.0058614714071154594, 0.005723111797124147, 0.1490195393562317, 0.11323748528957367, 0.10091131180524826, 0.005342827178537846, 0.005240653641521931, 0.005207827780395746, 0.13124287128448486, 0.005206678528338671, 0.0053658862598240376, 0.005346239544451237, 0.005208384245634079, 0.0053094131872057915, 0.0051266346126794815, 0.005015320610255003, 0.005302947014570236, 0.004941859748214483, 0.12679366767406464, 0.00496235117316246, 0.004696889780461788, 0.00478907348588109, 0.004792453721165657, 0.13194207847118378, 0.00454864464700222, 0.004505614284425974, 0.004707731306552887, 0.004555791616439819, 0.13939552009105682, 0.00437508849427104, 0.004572375677525997, 0.004388249013572931, 0.00434942077845335, 0.004362523090094328, 0.004394227638840675, 0.004269394092261791, 0.004184017423540354, 0.004146198742091656, 0.16277022659778595, 0.004092753864824772, 0.004023616202175617, 0.003972076345235109, 0.0039789373986423016, 0.1222451776266098, 0.0039339265786111355, 0.38356196880340576, 0.10821641981601715, 0.0045667667873203754, 0.004824270959943533, 0.005140392575412989, 0.005360874813050032, 0.005547499284148216, 0.0056457240134477615, 0.11694315075874329, 0.006062494125217199, 0.006249543745070696, 0.006207589525729418, 0.09862593561410904, 0.11287079006433487, 0.006547089666128159, 0.10170728713274002, 0.10887216031551361, 0.006944485008716583, 0.007121078670024872, 0.007147648837417364, 0.007378648966550827, 0.007319889031350613, 0.11283092945814133, 0.007552092429250479, 0.42580655217170715, 0.0076455362141132355, 0.008004060946404934, 0.008385439403355122, 0.008489595726132393, 0.008715800940990448, 0.008891051635146141, 0.008732296526432037, 0.008761275559663773, 0.00898649450391531, 0.008645443245768547, 0.0889551192522049, 0.10931447148323059, 0.008508801460266113, 0.08815622329711914, 0.008570094592869282, 0.11803615838289261, 0.008345578797161579, 0.09183043986558914, 0.008246243000030518, 0.12034933269023895, 0.08851882815361023, 0.008703764528036118, 0.008338927291333675, 0.008344176225364208, 0.008312013931572437, 0.008369876071810722, 0.008076637051999569, 0.11960753053426743, 0.008016097359359264, 0.0077822767198085785, 0.007715970743447542, 0.007537903729826212, 0.0076149143278598785, 0.0072733866982162, 0.007153755519539118, 0.10706627368927002, 0.00671418895944953, 0.006941291503608227, 0.0063523282296955585, 0.006571531295776367, 0.11584634333848953, 0.005937391426414251, 0.10536494106054306, 0.005846211686730385, 0.005909633357077837, 0.1072741374373436, 0.0056190346367657185, 0.005652968771755695, 0.005699777975678444, 0.005443400237709284, 0.09043549001216888, 0.11842789500951767, 0.0055002449080348015, 0.08123087137937546, 0.005726310424506664, 0.15199120342731476, 0.005590541288256645, 0.005754171404987574, 0.11474785208702087, 0.005954270716756582, 0.11575928330421448, 0.006072704680263996, 0.006086050998419523, 0.10565692186355591, 0.08449890464544296, 0.006491571199148893, 0.006551478989422321, 0.006537273526191711, 0.006630470044910908, 0.11822662502527237, 0.0069200340658426285, 0.006678406149148941, 0.006800828035920858, 0.006550473161041737, 0.006483134347945452, 0.10417698323726654, 0.006679276470094919, 0.006419253535568714, 0.006384097505360842, 0.1190810278058052, 0.006278271786868572, 0.12955284118652344, 0.006375172175467014, 0.006180230062454939, 0.006354381330311298, 0.006150767207145691, 0.006270417477935553, 0.005935814697295427, 0.005897492170333862, 0.005760500207543373, 0.005595675203949213, 0.005522321444004774, 0.005378726404160261, 0.005169575102627277, 0.005262333899736404, 0.0049711233004927635, 0.00489262118935585, 0.10581576824188232, 0.004638819023966789, 0.08071291446685791, 0.0045479666441679, 0.004507324192672968, 0.10863203555345535, 0.3728516101837158, 0.09787878394126892, 0.005016747862100601, 0.005314646288752556, 0.005546842701733112, 0.005859429482370615, 0.005959853995591402, 0.006541774608194828, 0.09649795293807983, 0.006601715460419655, 0.006528337020426989, 0.11438768357038498, 0.006774968467652798, 0.10349481552839279, 0.006981655023992062, 0.4257005751132965, 0.007463154848664999, 0.12763084471225739, 0.008706042543053627, 0.08849149197340012, 0.00908723846077919, 0.009532442316412926, 0.08240006864070892, 0.010060252621769905, 0.010392332449555397, 0.010323505848646164, 0.080699622631073, 0.1030566543340683, 0.010695169679820538, 0.010808817110955715, 0.0107411565259099, 0.11367356032133102, 0.01092306338250637, 0.010861190035939217, 0.10066217184066772, 0.010658404789865017, 0.010243812575936317, 0.010631203651428223, 0.300567090511322, 0.010301077738404274, 0.010586819611489773, 0.01066637597978115, 0.010322640649974346, 0.10476507991552353, 0.010784497484564781, 0.11628495901823044, 0.010289323516190052, 0.010125107131898403, 0.010055724531412125, 0.10755491256713867, 0.07576359063386917, 0.009895149618387222, 0.009887072257697582, 0.009587871842086315, 0.00979097094386816, 0.009710871614515781, 0.009380016475915909, 0.009285248816013336, 0.009040670469403267, 0.0083928806707263, 0.08434095233678818, 0.10071687400341034, 0.007994266226887703, 0.10258705168962479, 0.007780593354254961, 0.007754229009151459, 0.0075849490240216255, 0.007024907507002354, 0.007022692821919918, 0.006980441510677338, 0.006919135805219412, 0.006391914561390877, 0.006336313672363758, 0.14119388163089752, 0.09001105278730392, 0.13251502811908722, 0.005932378116995096, 0.07088728249073029, 0.12966102361679077, 0.07936247438192368, 0.006237794179469347, 0.006166489329189062, 0.4195578098297119, 0.006867865100502968, 0.007084987126290798, 0.007360504940152168, 0.007843264378607273, 0.008000405505299568, 0.007925285957753658, 0.14236648380756378, 0.008387574926018715, 0.00846244115382433, 0.09138192236423492, 0.008378914557397366, 0.009068216197192669, 0.1770360767841339, 0.1062140241265297, 0.00851503200829029, 0.008538609370589256, 0.008553195744752884, 0.008640775457024574, 0.13423098623752594, 0.008484626188874245, 0.008388467133045197, 0.008498826064169407, 0.008163615129888058, 0.008613189682364464, 0.09933134913444519, 0.12822513282299042, 0.0077186585403978825, 0.0075607760809361935, 0.2742942273616791, 0.1418442577123642, 0.13691750168800354, 0.008795921690762043, 0.009065155871212482, 0.12156250327825546, 0.00898938812315464, 0.009199419990181923, 0.09062595665454865, 0.00953484047204256, 0.07378373295068741, 0.3601541221141815, 0.07934892177581787, 0.010915699414908886, 0.011914958246052265, 0.01167244277894497, 0.012200123630464077, 0.10629846155643463, 0.01229873951524496, 0.0129502909258008, 0.01248921174556017, 0.11764679849147797, 0.012203040532767773, 0.01205240935087204, 0.08990275114774704, 0.012149440124630928, 0.01196508388966322, 0.012014525011181831, 0.011334910988807678, 0.01118374988436699, 0.011049647815525532, 0.010869861580431461, 0.010262559168040752, 0.009565256536006927, 0.009590682573616505, 0.08146283775568008, 0.009076453745365143, 0.00838371179997921, 0.00807713158428669, 0.15534710884094238, 0.00772093003615737, 0.007461695000529289, 0.007192359305918217, 0.006992623209953308, 0.006789304316043854, 0.0065310122445225716, 0.006362584885209799, 0.006159404292702675, 0.0061625586822628975, 0.005903513636440039, 0.005566904321312904, 0.005579857155680656, 0.0908307135105133, 0.005335260182619095, 0.005057201720774174, 0.0051309592090547085, 0.005211003124713898, 0.004698806907981634, 0.004499967209994793, 0.10973098129034042, 0.11389639973640442, 0.004379413090646267, 0.126986563205719, 0.004344065673649311, 0.13773463666439056, 0.004425277467817068, 0.12118155509233475, 0.3933151066303253, 0.004913127049803734, 0.005427548196166754, 0.005564581602811813, 0.00635181600227952, 0.07849803566932678, 0.09293602406978607, 0.09923752397298813, 0.006953877862542868, 0.00717761367559433, 0.007683428470045328, 0.007371063809841871, 0.007532161194831133, 0.007878977805376053]\n",
      "Val loss 0.04510608136282256\n",
      "Val auc roc 0.5214881763622887\n",
      "Saved model state dict for epoch 0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505af5263980412989e2c4ee4433d090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1681.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0450\n",
      "Train Losses : [0.007995503954589367, 0.1498439908027649, 0.007954559288918972, 0.007742165122181177, 0.008103927597403526, 0.007798227947205305, 0.007596411742269993, 0.007616179529577494, 0.11966881155967712, 0.09608539938926697, 0.007682380266487598, 0.007646429352462292, 0.007410629186779261, 0.10431505739688873, 0.007113841827958822, 0.007014927454292774, 0.007191759534180164, 0.006682554725557566, 0.006732387002557516, 0.006975262891501188, 0.12973617017269135, 0.11721605807542801, 0.006523815914988518, 0.006187338847666979, 0.006330163683742285, 0.0060661835595965385, 0.006234013941138983, 0.0061948285438120365, 0.08459391444921494, 0.005741193890571594, 0.005957288667559624, 0.005501895677298307, 0.005433680023998022, 0.00535656837746501, 0.06716158241033554, 0.005414661951363087, 0.005284441635012627, 0.005095381755381823, 0.004946532659232616, 0.005025154445320368, 0.004962488077580929, 0.004710594657808542, 0.0045699384063482285, 0.004863685928285122, 0.004569693468511105, 0.0044122058898210526, 0.0042701722122728825, 0.004231568425893784, 0.004207330290228128, 0.003924843855202198, 0.004266845993697643, 0.16821424663066864, 0.003692955942824483, 0.0037977618630975485, 0.0037774809170514345, 0.0036074514500796795, 0.003685681615024805, 0.003546625142917037, 0.0034666943829506636, 0.14710071682929993, 0.13210895657539368, 0.003506714478135109, 0.0035694867838174105, 0.003701280802488327, 0.003736772108823061, 0.12303666025400162, 0.003471990581601858, 0.09818548709154129, 0.0038596447557210922, 0.1456584930419922, 0.00393318198621273, 0.0040808250196278095, 0.004108209162950516, 0.003980867564678192, 0.004091929644346237, 0.8274490237236023, 0.004739661235362291, 0.11178366094827652, 0.005481864791363478, 0.006198698654770851, 0.006763670593500137, 0.0069532496854662895, 0.3732215464115143, 0.15181702375411987, 0.008951030671596527, 0.009956362657248974, 0.010524466633796692, 0.010771218687295914, 0.011445931158959866, 0.011521827429533005, 0.012055579572916031, 0.01194121316075325, 0.01210117619484663, 0.012583080679178238, 0.012385210022330284, 0.012808446772396564, 0.2940433919429779, 0.012079277075827122, 0.13645607233047485, 0.01232095342129469, 0.01342069823294878, 0.013200869783759117, 0.1057627871632576, 0.013531333766877651, 0.012566212564706802, 0.01238787081092596, 0.012170309200882912, 0.012502062134444714, 0.012004584074020386, 0.011442534625530243, 0.08593296259641647, 0.011156301945447922, 0.010628785006701946, 0.01024360116571188, 0.010462656617164612, 0.010158326476812363, 0.00937502458691597, 0.008980272337794304, 0.009111250750720501, 0.008524525910615921, 0.008405820466578007, 0.007991023361682892, 0.0074822562746703625, 0.1172211766242981, 0.006938230711966753, 0.07860536128282547, 0.0072580259293317795, 0.006747876759618521, 0.006679000798612833, 0.006493547931313515, 0.006206244230270386, 0.09340076893568039, 0.006040066480636597, 0.005809942726045847, 0.27352815866470337, 0.0060286917723715305, 0.0058129215613007545, 0.005928270518779755, 0.1298733651638031, 0.006462670862674713, 0.12950889766216278, 0.09149602800607681, 0.0067114983685314655, 0.00679825060069561, 0.007348054088652134, 0.10132654011249542, 0.007289537228643894, 0.006999965291470289, 0.006849117577075958, 0.10960306227207184, 0.0724194124341011, 0.11733701825141907, 0.0073097520507872105, 0.007508484646677971, 0.1268652379512787, 0.13235856592655182, 0.007635483518242836, 0.00769715616479516, 0.007928626611828804, 0.007982906885445118, 0.007865376770496368, 0.007694812957197428, 0.007638013921678066, 0.14625012874603271, 0.007860440760850906, 0.007300710771232843, 0.007569257635623217, 0.00736519880592823, 0.10538208484649658, 0.8409646153450012, 0.008174252696335316, 0.11567163467407227, 0.008957929909229279, 0.00956482533365488, 0.09646089375019073, 0.010410225950181484, 0.10399161279201508, 0.33236390352249146, 0.012068006210029125, 0.012740671634674072, 0.1055680513381958, 0.13671515882015228, 0.014176515862345695, 0.11444413661956787, 0.15427535772323608, 0.3088555932044983, 0.1281662881374359, 0.31335505843162537, 0.0177449993789196, 0.02036021277308464, 0.02041015215218067, 0.021122820675373077, 0.02129449136555195, 0.08943381160497665, 0.022224316373467445, 0.021788211539387703, 0.11040850728750229, 0.10188283026218414, 0.02119474858045578, 0.02188861183822155, 0.020815016701817513, 0.020922761410474777, 0.019833428785204887, 0.01914174295961857, 0.01845324970781803, 0.01777716539800167, 0.017029795795679092, 0.016212278977036476, 0.01577766053378582, 0.1088443249464035, 0.014294270426034927, 0.013708269223570824, 0.012912229634821415, 0.012457897886633873, 0.0995444506406784, 0.012015299871563911, 0.08498510718345642, 0.010511254891753197, 0.010259494185447693, 0.14050424098968506, 0.10192324966192245, 0.009266453795135021, 0.009303375147283077, 0.10121060162782669, 0.00881809089332819, 0.008516889996826649, 0.15109938383102417, 0.008297336287796497, 0.007998081855475903, 0.10994965583086014, 0.007840101607143879, 0.007615696173161268, 0.00761359091848135, 0.007499088533222675, 0.09832698851823807, 0.1411706954240799, 0.007138599641621113, 0.006994318682700396, 0.0068925837986171246, 0.006842371076345444, 0.006800268776714802, 0.0065573896281421185, 0.09654729068279266, 0.006529300473630428, 0.006330673582851887, 0.006220204755663872, 0.006264217663556337, 0.006017378531396389, 0.3658718466758728, 0.006123226135969162, 0.12362485378980637, 0.10847524553537369, 0.006737002171576023, 0.13576848804950714, 0.007114770356565714, 0.10655063390731812, 0.00749169709160924, 0.10438218712806702, 0.007711786311119795, 0.007717510219663382, 0.007879426702857018, 0.007959963753819466, 0.11687082052230835, 0.007958016358315945, 0.008062681183218956, 0.008032877929508686, 0.008167266845703125, 0.007978690788149834, 0.007874706760048866, 0.12901006639003754, 0.0077319880947470665, 0.007621509954333305, 0.007556675933301449, 0.00750366784632206, 0.11447390168905258, 0.007415685802698135, 0.007162752561271191, 0.12207107245922089, 0.10495110601186752, 0.0070583210326731205, 0.39393728971481323, 0.007296507712453604, 0.007590985856950283, 0.007762429770082235, 0.007910140790045261, 0.12345536053180695, 0.10913337767124176, 0.00853181816637516, 0.008406758308410645, 0.008636564016342163, 0.008507933467626572, 0.00854841060936451, 0.008616761304438114, 0.008471335284411907, 0.008407189510762691, 0.00833819154649973, 0.008143104612827301, 0.008024735376238823, 0.1043977290391922, 0.007814610376954079, 0.007761034648865461, 0.007635892368853092, 0.007475049234926701, 0.007297389209270477, 0.007135608233511448, 0.006958212703466415, 0.006845382042229176, 0.006669982802122831, 0.0064009507186710835, 0.0063008335418999195, 0.006167363375425339, 0.10465613752603531, 0.005820389371365309, 0.005734867416322231, 0.091554656624794, 0.005544901359826326, 0.0055603329092264175, 0.00539025804027915, 0.005355485714972019, 0.005288921762257814, 0.0051932567730546, 0.005111840553581715, 0.0048913415521383286, 0.0048020947724580765, 0.004767839331179857, 0.15160928666591644, 0.004577982239425182, 0.004506836179643869, 0.004465017002075911, 0.004591363947838545, 0.10588876157999039, 0.004414704628288746, 0.14741380512714386, 0.12293118238449097, 0.11255834996700287, 0.00446957116946578, 0.004604846239089966, 0.0046829949133098125, 0.004763903561979532, 0.0047056726180016994, 0.14356689155101776, 0.004771033767610788, 0.12671564519405365, 0.004871965851634741, 0.0050728581845760345, 0.004963344428688288, 0.10015536099672318, 0.10833021998405457, 0.005115580279380083, 0.37574461102485657, 0.10087990760803223, 0.005973676219582558, 0.006146247498691082, 0.10940621048212051, 0.006728550419211388, 0.006945767439901829, 0.007324795704334974, 0.007318742107599974, 0.09112641215324402, 0.007578062359243631, 0.11777275055646896, 0.3467652499675751, 0.008247250691056252, 0.008979537524282932, 0.00902553927153349, 0.3508031964302063, 0.010089296847581863, 0.010426472872495651, 0.01093755941838026, 0.011218017898499966, 0.011526488699018955, 0.011816561222076416, 0.12356987595558167, 0.1061728298664093, 0.10362529009580612, 0.08989735692739487, 0.10317026823759079, 0.012752767652273178, 0.012962735258042812, 0.012903227470815182, 0.012953372672200203, 0.012878937646746635, 0.012785756029188633, 0.012498032301664352, 0.08906643092632294, 0.01218627393245697, 0.01203539501875639, 0.01183506939560175, 0.011754819191992283, 0.011453078128397465, 0.010846194811165333, 0.08983270823955536, 0.010351831093430519, 0.010128243826329708, 0.00995563343167305, 0.6857125759124756, 0.010095816105604172, 0.09836847335100174, 0.3057006001472473, 0.11533305794000626, 0.09212352335453033, 0.013090199790894985, 0.013817450031638145, 0.014144480228424072, 0.014703205786645412, 0.0148975420743227, 0.015457953326404095, 0.0156922098249197, 0.015515414997935295, 0.015280312858521938, 0.014919445849955082, 0.014922677539288998, 0.014645795337855816, 0.014225293882191181, 0.01383640430867672, 0.013553043827414513, 0.1315978616476059, 0.013070745393633842, 0.012636678293347359, 0.012287464924156666, 0.011758973821997643, 0.01143648661673069, 0.011059263721108437, 0.010902796871960163, 0.01033020205795765, 0.32214173674583435, 0.08403836935758591, 0.010467606596648693, 0.010278619825839996, 0.08356671780347824, 0.01005687564611435, 0.010173708200454712, 0.009959658607840538, 0.009751766920089722, 0.009621690027415752, 0.009578392840921879, 0.009400084614753723, 0.009187662042677402, 0.008910201489925385, 0.008852844126522541, 0.008694136515259743, 0.00831338856369257, 0.008100349456071854, 0.008023970760405064, 0.007720602210611105, 0.007597710471600294, 0.007211601827293634, 0.0071272533386945724, 0.00685030547901988, 0.12302561849355698, 0.0064885178580880165, 0.00648548873141408, 0.006261502858251333, 0.14159585535526276, 0.006126654800027609, 0.005966921802610159, 0.128761887550354, 0.0057863094843924046, 0.005724162794649601, 0.005683321505784988, 0.005726736504584551, 0.005587381776422262, 0.005456764250993729, 0.10831217467784882, 0.0053268903866410255, 0.005265461280941963, 0.005207948852330446, 0.09644674509763718, 0.3447868227958679, 0.005350770894438028, 0.005588719621300697, 0.005625592544674873, 0.005906638223677874, 0.0058944798074662685, 0.09979035705327988, 0.11010581254959106, 0.006168629974126816, 0.08936794847249985, 0.006669365800917149, 0.11803728342056274, 0.00674132676795125, 0.006811115425080061, 0.006849629804491997, 0.006861774250864983, 0.369262158870697, 0.09311438351869583, 0.007438702043145895, 0.007863758131861687, 0.007981473580002785, 0.00815556850284338, 0.008203360252082348, 0.00867170188575983, 0.00833616591989994, 0.008419402875006199, 0.008371776901185513, 0.28554534912109375, 0.008467601612210274, 0.008675379678606987, 0.00907227024435997, 0.009227695874869823, 0.0973653644323349, 0.0919143408536911, 0.009381357580423355, 0.00950073916465044, 0.009728070348501205, 0.009262006729841232, 0.009391474537551403, 0.009235826320946217, 0.009336783550679684, 0.2479921579360962, 0.010012423619627953, 0.06934364140033722, 0.009877395816147327, 0.12314771115779877, 0.009603839367628098, 0.11027592420578003, 0.00965680368244648, 0.010108563117682934, 0.010193629190325737, 0.011075024493038654, 0.142900750041008, 0.009706743061542511, 0.010428979992866516, 0.009399883449077606, 0.009368936531245708, 0.010250527411699295, 0.0095912404358387, 0.00980850774794817, 0.10787181556224823, 0.14224031567573547, 0.0091626001521945, 0.009056775830686092, 0.009159627370536327, 0.008919664658606052, 0.008178972639143467, 0.007919388823211193, 0.13836616277694702, 0.008398696780204773, 0.007592827547341585, 0.00745713897049427, 0.00746077299118042, 0.007348707411438227, 0.007224468048661947, 0.007174930535256863, 0.006918472703546286, 0.16203123331069946, 0.11258193850517273, 0.006498924922198057, 0.1068795919418335, 0.006501390598714352, 0.006614499259740114, 0.12512335181236267, 0.006537958513945341, 0.006610718090087175, 0.006355553399771452, 0.006291786674410105, 0.0062330421060323715, 0.006113134790211916, 0.006191762629896402, 0.006025201641023159, 0.006277582608163357, 0.4057023227214813, 0.006152821704745293, 0.006116775330156088, 0.006189973559230566, 0.006326662376523018, 0.0064012655057013035, 0.006423661019653082, 0.1257694959640503, 0.006457348354160786, 0.4030829668045044, 0.006765101104974747, 0.00710604153573513, 0.007465641014277935, 0.11023835837841034, 0.3502407371997833, 0.008093505166471004, 0.1314135193824768, 0.3499150276184082, 0.12450151145458221, 0.010429730638861656, 0.12903374433517456, 0.011708589270710945, 0.012113719247281551, 0.012601206079125404, 0.012938913889229298, 0.013286211527884007, 0.013591928407549858, 0.013877717778086662, 0.013790071941912174, 0.013534323312342167, 0.108271025121212, 0.013457246124744415, 0.0893712192773819, 0.013318115845322609, 0.1255807727575302, 0.013114722445607185, 0.013055103830993176, 0.11536618322134018, 0.01274881698191166, 0.01264421921223402, 0.012395982630550861, 0.012242559343576431, 0.011872010305523872, 0.10369563102722168, 0.0899539589881897, 0.08096194267272949, 0.011084417812526226, 0.01105616707354784, 0.010739232413470745, 0.010640457272529602, 0.010382290929555893, 0.010161321610212326, 0.010011361911892891, 0.009642486460506916, 0.009577522985637188, 0.009249093942344189, 0.308809369802475, 0.008954322896897793, 0.009022544138133526, 0.009001736529171467, 0.00896559190005064, 0.08622489869594574, 0.00893382541835308, 0.008794219233095646, 0.09849753230810165, 0.008874787017703056, 0.1270393282175064, 0.00858540739864111, 0.008684944361448288, 0.10524563491344452, 0.0953669622540474, 0.008509218692779541, 0.09863585978746414, 0.008595507591962814, 0.09272248297929764, 0.09910516440868378, 0.008501353673636913, 0.00856001302599907, 0.11855580657720566, 0.00858068186789751, 0.14940428733825684, 0.008718649856746197, 0.00858450960367918, 0.008668913505971432, 0.38137194514274597, 0.10612235963344574, 0.008910395205020905, 0.12195409834384918, 0.009454717859625816, 0.00977091770619154, 0.009835751727223396, 0.009817462414503098, 0.01000355277210474, 0.009850588627159595, 0.009798242710530758, 0.009921377524733543, 0.3100144863128662, 0.09386254847049713, 0.010204779915511608, 0.11516672372817993, 0.010501958429813385, 0.01072560716420412, 0.010679950006306171, 0.11175244301557541, 0.010881278663873672, 0.08666913956403732, 0.1235608160495758, 0.010827424935996532, 0.12408265471458435, 0.2971805930137634, 0.011259165592491627, 0.12250827997922897, 0.011813242919743061, 0.11410738527774811, 0.012240689247846603, 0.012592846527695656, 0.012434064410626888, 0.012423442676663399, 0.012376368045806885, 0.012340658344328403, 0.01244591735303402, 0.012031766586005688, 0.01197030022740364, 0.01172184944152832, 0.011542176827788353, 0.011224479414522648, 0.011034635826945305, 0.1023385301232338, 0.11387292295694351, 0.0104916887357831, 0.11330699920654297, 0.010107375681400299, 0.009956506080925465, 0.009767163544893265, 0.009678168222308159, 0.11571475863456726, 0.09631676971912384, 0.009239541366696358, 0.10619881004095078, 0.009016606956720352, 0.008961748331785202, 0.008794615045189857, 0.008854263462126255, 0.12457138299942017, 0.11454667150974274, 0.00845104455947876, 0.008319495245814323, 0.1151573583483696, 0.008218346163630486, 0.11216840147972107, 0.008149892091751099, 0.09834462404251099, 0.008072685450315475, 0.3265736401081085, 0.008238626644015312, 0.11740045249462128, 0.09972778707742691, 0.12180420011281967, 0.0090860640630126, 0.009189831092953682, 0.11388968676328659, 0.009458089247345924, 0.009563402272760868, 0.00976883340626955, 0.00979856587946415, 0.10201931744813919, 0.09283827245235443, 0.009928293526172638, 0.08752717077732086, 0.009856944903731346, 0.009909592568874359, 0.009691452607512474, 0.009561126120388508, 0.09315638989210129, 0.00943470187485218, 0.009446954354643822, 0.00932090450078249, 0.009241650812327862, 0.009284830652177334, 0.008996293880045414, 0.008703748695552349, 0.00871343445032835, 0.008373340591788292, 0.008334795013070107, 0.00804575439542532, 0.007917569018900394, 0.007697208784520626, 0.007490943651646376, 0.12593233585357666, 0.4013247787952423, 0.007315508089959621, 0.1218964159488678, 0.1180155947804451, 0.007695620879530907, 0.007826017215847969, 0.1099206954240799, 0.008040323853492737, 0.008081026375293732, 0.008145147934556007, 0.008260208182036877, 0.008158722892403603, 0.11596880853176117, 0.008134005591273308, 0.088826023042202, 0.008152938447892666, 0.10361366719007492, 0.008139119483530521, 0.008116239681839943, 0.008062474429607391, 0.008104882203042507, 0.007999926805496216, 0.00792430154979229, 0.12440111488103867, 0.007726637646555901, 0.007739532273262739, 0.007548487279564142, 0.007429695222526789, 0.007373774889856577, 0.007220009341835976, 0.007135962136089802, 0.10003674775362015, 0.006897576618939638, 0.006808343809098005, 0.10707465559244156, 0.11159158498048782, 0.006643963512033224, 0.006627932656556368, 0.0067068529315292835, 0.3610715866088867, 0.11205483973026276, 0.0068785762414336205, 0.007203259039670229, 0.14986968040466309, 0.007500023581087589, 0.007504808716475964, 0.11893704533576965, 0.007835564203560352, 0.007867253385484219, 0.10673428326845169, 0.007985004223883152, 0.10154817253351212, 0.008123123086988926, 0.008217970840632915, 0.00824464950710535, 0.008172646164894104, 0.008253073319792747, 0.008108507841825485, 0.12138395011425018, 0.008050055243074894, 0.008010742254555225, 0.12088873237371445, 0.008041854947805405, 0.007852761074900627, 0.007846222259104252, 0.007713797967880964, 0.10950647294521332, 0.007502370979636908, 0.007459418848156929, 0.007366790436208248, 0.007360349874943495, 0.007245364133268595, 0.007031884044408798, 0.006984936539083719, 0.006854433100670576, 0.0066753593273460865, 0.00653138617053628, 0.0064136371947824955, 0.006330365780740976, 0.006206303369253874, 0.11378630995750427, 0.12881425023078918, 0.005906807724386454, 0.005919113289564848, 0.005848478060215712, 0.005734483245760202, 0.005698913708329201, 0.10768664628267288, 0.005616124719381332, 0.005510059650987387, 0.0054703387431800365, 0.005479208193719387, 0.005351608153432608, 0.7594086527824402, 0.005725979804992676, 0.005886918865144253, 0.0061417920514941216, 0.006371333729475737, 0.10811644047498703, 0.0916442945599556, 0.00706863310188055, 0.007213627453893423, 0.10383548587560654, 0.08815402537584305, 0.007792145479470491, 0.007893785834312439, 0.008048811927437782, 0.008193221874535084, 0.008201814256608486, 0.008196672424674034, 0.008236482739448547, 0.00818420760333538, 0.008140834048390388, 0.115925632417202, 0.00805658008903265, 0.007982401177287102, 0.007942150346934795, 0.007837331853806973, 0.007798583246767521, 0.007690077647566795, 0.12774044275283813, 0.3288736343383789, 0.007696453016251326, 0.007913864217698574, 0.007916484028100967, 0.007981848903000355, 0.00801272876560688, 0.008047043345868587, 0.008192266337573528, 0.008028503507375717, 0.007933690212666988, 0.11455108225345612, 0.007919988594949245, 0.007842643186450005, 0.007796675898134708, 0.0076529704965651035, 0.11027632653713226, 0.0075584701262414455, 0.007509356364607811, 0.007549521513283253, 0.11954811215400696, 0.007296436000615358, 0.007198372855782509, 0.10480999946594238, 0.007133384235203266, 0.007063458673655987, 0.10463077574968338, 0.007022588048130274, 0.007014421746134758, 0.006915856618434191, 0.006855606101453304, 0.006745903752744198, 0.00666655320674181, 0.00658043660223484, 0.0065011559054255486, 0.006372187752276659, 0.11013568937778473, 0.006240502931177616, 0.00613374263048172, 0.09326916188001633, 0.006061358377337456, 0.12236019223928452, 0.006022003013640642, 0.006056088488548994, 0.006035604514181614, 0.005933762528002262, 0.005886241793632507, 0.0058393594808876514, 0.14783893525600433, 0.00570895429700613, 0.1378292292356491, 0.005706785712391138, 0.0056686438620090485, 0.005761542823165655, 0.12015096843242645, 0.005608039442449808, 0.0056382413022220135, 0.11343728005886078, 0.005702340044081211, 0.00561367766931653, 0.005671711638569832, 0.005631878972053528, 0.11639194190502167, 0.005604555830359459, 0.00562688522040844, 0.005595669150352478, 0.005566844251006842, 0.005512349307537079, 0.005457173101603985, 0.005410139914602041, 0.12749511003494263, 0.005389093887060881, 0.005345908924937248, 0.005277405958622694, 0.005247341934591532, 0.005143813788890839, 0.005157488863915205, 0.005054196808487177, 0.005019271746277809, 0.11543349176645279, 0.1093885526061058, 0.004950110334903002, 0.13313031196594238, 0.00491749495267868, 0.00492051150649786, 0.00493569066748023, 0.004942977335304022, 0.004941170569509268, 0.13299895823001862, 0.004920359700918198, 0.004948818124830723, 0.00496830977499485, 0.004884057212620974, 0.10923046618700027, 0.11251159012317657, 0.004949439316987991, 0.0049956683069467545, 0.004958860110491514, 0.004990342538803816, 0.004964711610227823, 0.004953146446496248, 0.0049729435704648495, 0.004872418008744717, 0.10745570808649063, 0.004900957457721233, 0.004839765839278698, 0.004819558467715979, 0.0047910925932228565, 0.10560745745897293, 0.004767326638102531, 0.004742360673844814, 0.11381867527961731, 0.004807346034795046, 0.004736086819320917, 0.13572019338607788, 0.004844683222472668, 0.0048120454885065556, 0.004784074146300554, 0.004832652863115072, 0.004730497021228075, 0.0047251577489078045, 0.004719475284218788, 0.004647504072636366, 0.004639278631657362, 0.004610663279891014, 0.004513436928391457, 0.00454871216788888, 0.11802158504724503, 0.004420270677655935, 0.004381253849714994, 0.004339231178164482, 0.4276362359523773, 0.004502314142882824, 0.004584603477269411, 0.004702666308730841, 0.004790845327079296, 0.004865637514740229, 0.13878676295280457, 0.005033663008362055, 0.005080346018075943, 0.005146595649421215, 0.005196765530854464, 0.00530236354097724, 0.005301603116095066, 0.0052525969222188, 0.005230075214058161, 0.37742993235588074, 0.005509632173925638, 0.0055827065370976925, 0.005754102021455765, 0.08586375415325165, 0.005888700485229492, 0.006033533718436956, 0.0061178989708423615, 0.006191362161189318, 0.38859036564826965, 0.006457475479692221, 0.006668077781796455, 0.09515003114938736, 0.007018342614173889, 0.007205381989479065, 0.12623269855976105, 0.0074888188391923904, 0.007689475081861019, 0.007865579798817635, 0.007828625850379467, 0.007810195442289114, 0.007881347090005875, 0.09871314465999603, 0.007916155271232128, 0.09010246396064758, 0.007980357855558395, 0.007956833578646183, 0.007870872505009174, 0.007827513851225376, 0.007738585118204355, 0.007767693605273962, 0.007630825508385897, 0.007585830055177212, 0.08919621258974075, 0.007326627615839243, 0.007251291535794735, 0.007153112906962633, 0.007113979663699865, 0.0069383010268211365, 0.006831018719822168, 0.006730434484779835, 0.0066956100054085255, 0.006535928696393967, 0.006502795033156872, 0.006295612081885338, 0.0061868466436862946, 0.006041231565177441, 0.005970446392893791, 0.005848366301506758, 0.1072082668542862, 0.005623054690659046, 0.0055664717219769955, 0.005512349773198366, 0.10539685934782028, 0.005412082187831402, 0.124116450548172, 0.005319113843142986, 0.10226468741893768, 0.11068854480981827, 0.0052667828276753426, 0.00534216919913888, 0.0053979759104549885, 0.11163558810949326, 0.005383188370615244, 0.10996920615434647, 0.005577783100306988, 0.005542710889130831, 0.00566531578078866, 0.005492899566888809, 0.005475749261677265, 0.005535895936191082, 0.10976774990558624, 0.005431824829429388, 0.005413175560534, 0.005429400596767664, 0.00547627080231905, 0.00540626747533679, 0.13735274970531464, 0.005410478916019201, 0.005283397622406483, 0.40518155694007874, 0.005544466432183981, 0.11230964213609695, 0.005794092081487179, 0.005945070181041956, 0.10657467693090439, 0.0063881478272378445, 0.11888077855110168, 0.11882974207401276, 0.12097513675689697, 0.006825905758887529, 0.006983425933867693, 0.007105608936399221, 0.007282140664756298, 0.007310173939913511, 0.0073139844462275505, 0.3359135687351227, 0.0076277232728898525, 0.007835867814719677, 0.008052862249314785, 0.00815772544592619, 0.11814585328102112, 0.008404232561588287, 0.00852081086486578, 0.008561260998249054, 0.1278640627861023, 0.00872705690562725, 0.008623164147138596, 0.008754980750381947, 0.00859777256846428, 0.09294283390045166, 0.10361740738153458, 0.10310951620340347, 0.10320935398340225, 0.008845866657793522, 0.10738261789083481, 0.008736963383853436, 0.008760334923863411, 0.008824166841804981, 0.008969863876700401, 0.0087227588519454, 0.008673299103975296, 0.00857543759047985, 0.008447587490081787, 0.008389843627810478, 0.008236240595579147, 0.008106815628707409, 0.10697466880083084, 0.007941264659166336, 0.007906798273324966, 0.0076971338130533695, 0.007612616755068302, 0.007485590875148773, 0.11650019139051437, 0.11571204662322998, 0.0071731675416231155, 0.007117867935448885, 0.007081226445734501, 0.006988026667386293, 0.006904230453073978, 0.12480225414037704, 0.3459504246711731, 0.006890829652547836, 0.10237050801515579, 0.007158244028687477, 0.10938414931297302, 0.007438953034579754, 0.10514827072620392, 0.00765911815688014, 0.007753301877528429, 0.10211891680955887, 0.007905567064881325, 0.10914253443479538, 0.008014915511012077, 0.008077393285930157, 0.1096700057387352, 0.008138155564665794, 0.008299686014652252, 0.11577275395393372, 0.008242042735219002, 0.008330052718520164, 0.008217078633606434, 0.10854703933000565, 0.008176815696060658, 0.008248845115303993, 0.0081208860501647, 0.008052761666476727, 0.00800937321037054, 0.007892206311225891, 0.007930676452815533, 0.0077000767923891544, 0.1297694742679596, 0.10692272335290909, 0.0075246901251375675, 0.007478606887161732, 0.007439960725605488, 0.10869491100311279, 0.11019916087388992, 0.007335882168263197, 0.007250694092363119, 0.10027830302715302, 0.0072020357474684715, 0.11404299736022949, 0.0071847643703222275, 0.007231573574244976, 0.007211507298052311, 0.007062859367579222, 0.007022805046290159, 0.006959822028875351, 0.10233119875192642, 0.10637027025222778, 0.006882273592054844, 0.006845760624855757, 0.00676399189978838, 0.006754619535058737, 0.09709247201681137, 0.006631067022681236, 0.006599729880690575, 0.006588753312826157, 0.006533506792038679, 0.11107522994279861, 0.12041090428829193, 0.006499056238681078, 0.10250163823366165, 0.006422347389161587, 0.00639107683673501, 0.10532015562057495, 0.006497692782431841, 0.006447439547628164, 0.13777241110801697, 0.006432661786675453, 0.09884654730558395, 0.08684669435024261, 0.12238927185535431, 0.006585089489817619, 0.006619427818804979, 0.006678661331534386, 0.006701882928609848, 0.006707780063152313, 0.0067250970751047134, 0.11608561873435974, 0.0066429972648620605, 0.1353183388710022, 0.0066247982904314995, 0.006624006666243076, 0.006629586219787598, 0.006613563280552626, 0.10785610228776932, 0.006601415108889341, 0.11283457279205322, 0.006679601036012173, 0.11142473667860031, 0.12049144506454468, 0.006654657889157534, 0.006657714489847422, 0.0066687013022601604, 0.1005445197224617, 0.36107686161994934, 0.00691970344632864, 0.007221123203635216, 0.0073326025158166885, 0.007471556309610605, 0.007612574379891157, 0.007670674938708544, 0.007769105955958366, 0.007783346809446812, 0.007820023223757744, 0.007771494798362255, 0.30349424481391907, 0.007941138930618763, 0.10839147120714188, 0.008264612406492233, 0.008415833115577698, 0.09739208966493607, 0.00868276134133339, 0.008870545774698257, 0.008797858841717243, 0.008870493620634079, 0.008952386677265167, 0.008772711269557476, 0.0973215326666832, 0.008845105767250061, 0.1075286939740181, 0.008704702369868755, 0.00873479712754488, 0.1022757813334465, 0.11811734735965729, 0.10588587075471878, 0.008646499365568161, 0.008749270811676979, 0.008626582100987434, 0.008641943335533142, 0.008564833551645279, 0.008508270606398582, 0.008521975949406624, 0.09813258796930313, 0.09853699058294296, 0.1054794192314148, 0.008225490339100361, 0.008228015154600143, 0.008156840689480305, 0.008094831369817257, 0.11309836804866791, 0.13264763355255127, 0.007977832108736038, 0.008037671446800232, 0.007942939177155495, 0.007890438660979271, 0.008019770495593548, 0.00772115821018815, 0.007672681473195553, 0.00755662564188242, 0.0074350470677018166, 0.11615277081727982, 0.00726447906345129, 0.007180626504123211, 0.007072265259921551, 0.006972037255764008, 0.006819503381848335, 0.10566199570894241, 0.006639955099672079, 0.006590280681848526, 0.006468630861490965, 0.006509690545499325, 0.006402585655450821, 0.006224445998668671, 0.006102565675973892, 0.10472259670495987, 0.006002694834023714, 0.005926613230258226, 0.10219860076904297, 0.005796997342258692, 0.08598040044307709, 0.005750882439315319, 0.11232046782970428, 0.3805294930934906, 0.005903394892811775, 0.006071560084819794, 0.0062324730679392815, 0.006335472222417593, 0.12235615402460098, 0.006561540067195892, 0.006612235214561224, 0.006759675685316324, 0.006755548994988203, 0.10934232175350189, 0.006816775072365999, 0.0069226608611643314, 0.006842911243438721, 0.00697669293731451, 0.00687519833445549, 0.006831261329352856, 0.00679783197119832, 0.11174364387989044, 0.00673968531191349, 0.006692515220493078, 0.006760552991181612, 0.3828343451023102, 0.007021856494247913, 0.006947904359549284, 0.006941415835171938, 0.0071880873292684555, 0.0974087044596672, 0.11544077843427658, 0.007385735400021076, 0.10910146683454514, 0.007371094543486834, 0.09406507760286331, 0.10960224270820618, 0.0076336669735610485, 0.007697178982198238, 0.00781332328915596, 0.10574221611022949, 0.008002882823348045, 0.007845534011721611, 0.007807905785739422, 0.007897742092609406, 0.12348367273807526, 0.007824075408279896, 0.0077853999100625515, 0.007723184302449226, 0.007671548053622246, 0.007594242691993713, 0.0075375172309577465, 0.007424515206366777, 0.007444293703883886, 0.007411649450659752, 0.10595419257879257, 0.007091693580150604, 0.00701536238193512, 0.09978151321411133, 0.11157981306314468, 0.006873127073049545, 0.006813966669142246, 0.006816999055445194, 0.00680070323869586, 0.3603643476963043, 0.09646455198526382, 0.006996885407716036, 0.09899027645587921, 0.007295094430446625, 0.12482061982154846, 0.07644965499639511, 0.00768011249601841, 0.00792674534022808, 0.007921808399260044, 0.00794127956032753, 0.008084794506430626, 0.008115381933748722, 0.09784216433763504, 0.008028635755181313, 0.10155594348907471, 0.008138059638440609, 0.008175785653293133, 0.007984685711562634, 0.10802403092384338, 0.114008828997612, 0.0864553451538086, 0.008059239946305752, 0.008097099140286446, 0.008003337308764458, 0.007951945066452026, 0.007881575264036655, 0.13011014461517334, 0.007867991924285889, 0.0077745807357132435, 0.007728772237896919, 0.007904517464339733, 0.007618685718625784, 0.11318954080343246, 0.3030993640422821, 0.00770231056958437, 0.0076964134350419044, 0.007838658057153225, 0.007913943380117416, 0.3581160306930542, 0.11604639142751694, 0.10643643885850906, 0.008623317815363407, 0.008910966105759144, 0.009091518819332123, 0.009294532239437103, 0.29145389795303345, 0.3097638189792633, 0.09544006735086441, 0.10492991656064987, 0.10241112858057022, 0.011712498962879181, 0.012245726771652699, 0.012807103805243969, 0.012789702974259853, 0.013407685793936253, 0.013554723002016544, 0.013193478807806969, 0.01372016966342926, 0.013388781808316708, 0.10961850732564926, 0.013441418297588825, 0.012978702783584595, 0.01286659762263298, 0.013105109333992004, 0.013171661645174026, 0.013398759998381138, 0.01250704750418663, 0.012014055624604225, 0.0124165378510952, 0.011831160634756088, 0.01157685462385416, 0.011100079864263535, 0.16310642659664154, 0.010838717222213745, 0.010593906044960022, 0.010140729136765003, 0.010571242310106754, 0.0100871492177248, 0.00956052541732788, 0.10216592997312546, 0.009250043891370296, 0.009186769835650921, 0.009052468463778496, 0.008710772730410099, 0.008517731912434101, 0.008261576294898987, 0.008179370313882828, 0.008167642168700695, 0.007820128463208675, 0.007606203202158213, 0.007660147733986378, 0.007282736245542765, 0.007441958412528038, 0.10764846950769424, 0.006979778409004211, 0.006786455865949392, 0.00693907355889678, 0.006516963243484497, 0.0064313593320548534, 0.12860015034675598, 0.09188521653413773, 0.00621290085837245, 0.3962757885456085, 0.00630046846345067, 0.006452613975852728, 0.0068307360634207726, 0.09025606513023376, 0.00667441263794899, 0.11376495659351349, 0.00694914348423481, 0.007101522758603096, 0.006990017369389534, 0.1242804080247879, 0.00701119052246213, 0.1325027197599411, 0.007333160378038883, 0.09467638283967972, 0.007174008525907993, 0.007282140664756298, 0.007255012635141611, 0.08698353171348572, 0.007297937758266926, 0.1163926050066948, 0.00744473934173584, 0.09497568011283875, 0.00738582294434309, 0.007353771012276411, 0.00738513981923461, 0.007406005170196295, 0.10972681641578674, 0.0075455172918736935, 0.007428936194628477, 0.007207019254565239, 0.0072949850000441074, 0.00723192747682333, 0.007089975290000439, 0.007006172556430101, 0.11288151144981384, 0.0069222236052155495, 0.006961687467992306, 0.006749565247446299, 0.13012127578258514, 0.1116829589009285, 0.3565179407596588, 0.006951575167477131, 0.10672922432422638, 0.007369719445705414, 0.0073584746569395065, 0.007502288091927767, 0.007515313103795052, 0.12831085920333862, 0.10808534920215607, 0.007958384230732918, 0.00799537543207407, 0.007979899644851685, 0.09455333650112152, 0.008096928708255291, 0.00822316762059927, 0.008038182742893696, 0.10989297181367874, 0.00817240308970213, 0.008308939635753632, 0.008021465502679348, 0.14620409905910492, 0.00788869708776474, 0.008238670416176319, 0.00787076074630022, 0.007908094674348831, 0.11416402459144592, 0.3163518011569977, 0.1206694021821022, 0.008125074207782745, 0.008457856252789497, 0.1332249790430069, 0.10183683782815933, 0.11168299615383148, 0.008685605600476265, 0.008991613984107971, 0.009070392698049545, 0.009032816626131535, 0.009164045564830303, 0.009148609824478626, 0.3096894323825836, 0.0877595767378807, 0.08599848300218582, 0.00949857197701931, 0.009649715386331081, 0.010035467334091663, 0.009858272969722748, 0.10866378992795944, 0.010121784172952175, 0.010082203894853592, 0.010230361483991146, 0.010020202957093716, 0.0896914154291153, 0.009850527159869671, 0.009822261519730091, 0.009858714416623116, 0.09576604515314102, 0.009789138101041317, 0.009695641696453094, 0.009459990076720715, 0.10475597530603409, 0.009445314295589924, 0.00920209288597107, 0.34077054262161255, 0.3053317964076996, 0.009796577505767345, 0.010430007241666317, 0.1192127913236618, 0.1078292578458786, 0.10902915149927139, 0.11585623770952225, 0.11581385135650635, 0.10931696742773056, 0.10901819914579391, 0.14243942499160767, 0.012162163853645325, 0.123455710709095, 0.012331976555287838, 0.012612300924956799, 0.10075962543487549, 0.01265830546617508, 0.09341126680374146, 0.11522730439901352, 0.08855204284191132, 0.012997942976653576, 0.012839826755225658, 0.012992197647690773, 0.012816530652344227, 0.08220922201871872, 0.012622158974409103, 0.012729678303003311, 0.31012067198753357, 0.012577854096889496, 0.012960181571543217, 0.012758906930685043, 0.01280423253774643, 0.01276372093707323, 0.09652228653430939, 0.012615554966032505, 0.08304867893457413, 0.012831881642341614, 0.012425826862454414, 0.012429330497980118, 0.012437865138053894, 0.12298445403575897, 0.012361826375126839, 0.11949360370635986, 0.01163255050778389, 0.011649726890027523, 0.11410631239414215, 0.09725979715585709, 0.011390219442546368, 0.01119288895279169, 0.11406911909580231, 0.01098775863647461, 0.010853086598217487, 0.1224755048751831, 0.01066950336098671, 0.09695286303758621, 0.01036776416003704, 0.01025810744613409, 0.010322357527911663, 0.010228238999843597, 0.13507677614688873, 0.09898093342781067, 0.08387380093336105, 0.009801285341382027, 0.009810131043195724, 0.009616699069738388, 0.009516332298517227, 0.009537849575281143, 0.35674750804901123, 0.009359522722661495, 0.009541387669742107, 0.009542168118059635, 0.009626145474612713, 0.009609490633010864, 0.009487943723797798, 0.009715675376355648, 0.3633996248245239, 0.1281258910894394, 0.009933891706168652, 0.00988894235342741, 0.010109339840710163, 0.09133601933717728, 0.10830378532409668]\n",
      "Val loss 0.04589309896433155\n",
      "Val auc roc 0.5107954953016283\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch     2: reducing learning rate of group 1 to 1.0000e-04.\n",
      "Saved model state dict for epoch 1 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a184b03dc83542a68b2648d6035b0125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1681.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0435\n",
      "Train Losses : [0.010195760987699032, 0.010301380418241024, 0.010300647467374802, 0.11641989648342133, 0.09066574275493622, 0.12494415789842606, 0.010254677385091782, 0.010366558097302914, 0.010158388875424862, 0.010254722088575363, 0.010379976592957973, 0.010257565416395664, 0.010185942985117435, 0.010146244429051876, 0.010155965574085712, 0.010300586000084877, 0.11719623953104019, 0.010124598629772663, 0.010107087902724743, 0.010164710693061352, 0.09415747970342636, 0.010079330764710903, 0.010072702541947365, 0.010050907731056213, 0.10413040220737457, 0.010209186933934689, 0.010030820965766907, 0.010069156996905804, 0.10822216421365738, 0.009979994967579842, 0.307402104139328, 0.10790234059095383, 0.010018503293395042, 0.1271345615386963, 0.01001745741814375, 0.010286904871463776, 0.12917032837867737, 0.010068467818200588, 0.009995917789638042, 0.010234544984996319, 0.010014896281063557, 0.010013503953814507, 0.010015172883868217, 0.009977546520531178, 0.009951363317668438, 0.12386363744735718, 0.0998559445142746, 0.010115968994796276, 0.00991472601890564, 0.009979852475225925, 0.009924961254000664, 0.14061486721038818, 0.00996058527380228, 0.010211048647761345, 0.009907814674079418, 0.0100026186555624, 0.009943310171365738, 0.009797141887247562, 0.12167633324861526, 0.09728091955184937, 0.009861287660896778, 0.009848845191299915, 0.10037560015916824, 0.009760555811226368, 0.09577351808547974, 0.009845450520515442, 0.32413461804389954, 0.009719893336296082, 0.009828967042267323, 0.009789006784558296, 0.009825312532484531, 0.009889788925647736, 0.12989091873168945, 0.10439112037420273, 0.009909502230584621, 0.009794948622584343, 0.009816095232963562, 0.10036949068307877, 0.009809748269617558, 0.009899391792714596, 0.08910447359085083, 0.12634152173995972, 0.009839314967393875, 0.10866259038448334, 0.009743851609528065, 0.10230989009141922, 0.33473363518714905, 0.009913251735270023, 0.009770739823579788, 0.12327837944030762, 0.010013862513005733, 0.11533977091312408, 0.009965774603188038, 0.010131693445146084, 0.09115220606327057, 0.00994386337697506, 0.009848874062299728, 0.009953468106687069, 0.10382119566202164, 0.010197700932621956, 0.009791617281734943, 0.009815209545195103, 0.00991442147642374, 0.009800543077290058, 0.009821389801800251, 0.009889992885291576, 0.009832378476858139, 0.009837357327342033, 0.009756755083799362, 0.09802829474210739, 0.009730934165418148, 0.09589282423257828, 0.09515466541051865, 0.00981857068836689, 0.009817329235374928, 0.009673858992755413, 0.009893445298075676, 0.12868733704090118, 0.009707219898700714, 0.009793076664209366, 0.11612687259912491, 0.009806903079152107, 0.009575709700584412, 0.009949852712452412, 0.009708267636597157, 0.009532904252409935, 0.009594802744686604, 0.009588519111275673, 0.11189258843660355, 0.09920328855514526, 0.009509132243692875, 0.11104558408260345, 0.009812851436436176, 0.3183510899543762, 0.08158504962921143, 0.009610486216843128, 0.0992414578795433, 0.009607662446796894, 0.09891406446695328, 0.009504320099949837, 0.009520144201815128, 0.009614595212042332, 0.11493856459856033, 0.11881256848573685, 0.009617139585316181, 0.009570089168846607, 0.00964380707591772, 0.10782857239246368, 0.009667337872087955, 0.009632603265345097, 0.09950484335422516, 0.30651557445526123, 0.00952963437885046, 0.00953766517341137, 0.10522262006998062, 0.1212095096707344, 0.009674795903265476, 0.00975485797971487, 0.009721456095576286, 0.009731498546898365, 0.08049840480089188, 0.009635797701776028, 0.009733314625918865, 0.10331667214632034, 0.009636481292545795, 0.09592010080814362, 0.00978777650743723, 0.0097623560577631, 0.009592786431312561, 0.009592873975634575, 0.00970571581274271, 0.009626868180930614, 0.00986297708004713, 0.009675877168774605, 0.009629672393202782, 0.009784112684428692, 0.00963517464697361, 0.009546403773128986, 0.009618633426725864, 0.09969978779554367, 0.009466578252613544, 0.009489267133176327, 0.009541108272969723, 0.32890698313713074, 0.11402136832475662, 0.09820760041475296, 0.11278107762336731, 0.009643247351050377, 0.00947372242808342, 0.009609907865524292, 0.11473598331212997, 0.009605428203940392, 0.009541801176965237, 0.00962124578654766, 0.00954230036586523, 0.009460561908781528, 0.009483122266829014, 0.009502595290541649, 0.00946558266878128, 0.009527412243187428, 0.009449562057852745, 0.009447090327739716, 0.09659215062856674, 0.11301717907190323, 0.009478929452598095, 0.009616044349968433, 0.09992609173059464, 0.10542771965265274, 0.10396348685026169, 0.009406193159520626, 0.009412214159965515, 0.009484019130468369, 0.009398121386766434, 0.00934859924018383, 0.009417455643415451, 0.009349147789180279, 0.11403302848339081, 0.009319751523435116, 0.009284419938921928, 0.10228614509105682, 0.10600374639034271, 0.009303047321736813, 0.009278862737119198, 0.009336878545582294, 0.009358801878988743, 0.009345649741590023, 0.3659861385822296, 0.12247589230537415, 0.009263018146157265, 0.009369554929435253, 0.13359057903289795, 0.00926247239112854, 0.009271947667002678, 0.009283955208957195, 0.009314504452049732, 0.009538089856505394, 0.11504729837179184, 0.10060541331768036, 0.009415141306817532, 0.009238013066351414, 0.12512367963790894, 0.10350503772497177, 0.009337265975773335, 0.009363443590700626, 0.009281309321522713, 0.009376974776387215, 0.11966806650161743, 0.00923815555870533, 0.009440876543521881, 0.009223975241184235, 0.009312473237514496, 0.10329980403184891, 0.009308687411248684, 0.11537931859493256, 0.009282426908612251, 0.00917097833007574, 0.1007487028837204, 0.09639662504196167, 0.009332886897027493, 0.009151896461844444, 0.009161502122879028, 0.3327455222606659, 0.009287468157708645, 0.00924935657531023, 0.009196581318974495, 0.009181643836200237, 0.009210641495883465, 0.36771339178085327, 0.00928327813744545, 0.10978143662214279, 0.009221561253070831, 0.33874329924583435, 0.10037840902805328, 0.009402673691511154, 0.34869349002838135, 0.009364335797727108, 0.00945836678147316, 0.00942776445299387, 0.00941393617540598, 0.009567849338054657, 0.11906641721725464, 0.1169043630361557, 0.009556843899190426, 0.00949515774846077, 0.009648637846112251, 0.009549849666655064, 0.009571918286383152, 0.09726305305957794, 0.009763884358108044, 0.009626501239836216, 0.009766032919287682, 0.009754541330039501, 0.1139260083436966, 0.009625901468098164, 0.009773408994078636, 0.009490635246038437, 0.009546758607029915, 0.009536967612802982, 0.009597237221896648, 0.009531772695481777, 0.009540888480842113, 0.009523454122245312, 0.009717234410345554, 0.009487001225352287, 0.00943924579769373, 0.11986548453569412, 0.10628309845924377, 0.009386546909809113, 0.009435615502297878, 0.009405100718140602, 0.009554005227982998, 0.009350801818072796, 0.00941030029207468, 0.009300168603658676, 0.09654921293258667, 0.11767978221178055, 0.009406994096934795, 0.009344014339148998, 0.009471125900745392, 0.009295028634369373, 0.00931800901889801, 0.009247560054063797, 0.00935094803571701, 0.009213482029736042, 0.0092476736754179, 0.009346877224743366, 0.009181879460811615, 0.11322510242462158, 0.009330961853265762, 0.11298353970050812, 0.009143813513219357, 0.009121152572333813, 0.10938004404306412, 0.00954845454543829, 0.0091154919937253, 0.11125476658344269, 0.009089603088796139, 0.009111950173974037, 0.009314578026533127, 0.009194140322506428, 0.009077814407646656, 0.009059101343154907, 0.009064349345862865, 0.10959562659263611, 0.009061044082045555, 0.008986066095530987, 0.009085964411497116, 0.00901862233877182, 0.00898087490350008, 0.009009122848510742, 0.009015713818371296, 0.008970250375568867, 0.008936476893723011, 0.10518907010555267, 0.009023700840771198, 0.008970465511083603, 0.10373592376708984, 0.08840843290090561, 0.008874555118381977, 0.008943556807935238, 0.008986392058432102, 0.3146381974220276, 0.10275615006685257, 0.008920229971408844, 0.10662311315536499, 0.009035020135343075, 0.10259445756673813, 0.1285131871700287, 0.00908692181110382, 0.00889301486313343, 0.00887266080826521, 0.008963096886873245, 0.09535850584506989, 0.008961907587945461, 0.008875521831214428, 0.008923493325710297, 0.008933410048484802, 0.008943632245063782, 0.09169062227010727, 0.008972948417067528, 0.008860994130373001, 0.008859402500092983, 0.00889855157583952, 0.008856653235852718, 0.11606783419847488, 0.009052928537130356, 0.009028013795614243, 0.008903454057872295, 0.13781212270259857, 0.008936719037592411, 0.008871291764080524, 0.009047354571521282, 0.008842526003718376, 0.008996263146400452, 0.008838874287903309, 0.008875884115695953, 0.09112805873155594, 0.008762432262301445, 0.11664173007011414, 0.008789528161287308, 0.11492805927991867, 0.10249324887990952, 0.008798986673355103, 0.10828129947185516, 0.11044031381607056, 0.008731297217309475, 0.30811288952827454, 0.00875808298587799, 0.12578856945037842, 0.008839806541800499, 0.00875924527645111, 0.1060001328587532, 0.008835706859827042, 0.008840348571538925, 0.009159363806247711, 0.008790956810116768, 0.10789471864700317, 0.10202160477638245, 0.008755289949476719, 0.11289472132921219, 0.008791753090918064, 0.00877614039927721, 0.008776159025728703, 0.008800913579761982, 0.008857185952365398, 0.008842350915074348, 0.008849353529512882, 0.008843962103128433, 0.10871268063783646, 0.008849501609802246, 0.008898122236132622, 0.008771829307079315, 0.11191758513450623, 0.008750366978347301, 0.008769860491156578, 0.008700648322701454, 0.008782589808106422, 0.008722888305783272, 0.008725259453058243, 0.008888443000614643, 0.008714794181287289, 0.008687552995979786, 0.12047252058982849, 0.008705339394509792, 0.008610613644123077, 0.11431462317705154, 0.008618454448878765, 0.008640661835670471, 0.008697576820850372, 0.008604592643678188, 0.008595721796154976, 0.008569976314902306, 0.10662738978862762, 0.00852886401116848, 0.008521399460732937, 0.008695685304701328, 0.008495978079736233, 0.10104456543922424, 0.008615287952125072, 0.008519155904650688, 0.008559715002775192, 0.1162167638540268, 0.00848910491913557, 0.008616183884441853, 0.008437077514827251, 0.008482267148792744, 0.008538713678717613, 0.008703089319169521, 0.00846052635461092, 0.008410405367612839, 0.12344981729984283, 0.008385335095226765, 0.008435961790382862, 0.10418206453323364, 0.008477575145661831, 0.00838723499327898, 0.008510256186127663, 0.008473066613078117, 0.0084890341386199, 0.008408295921981335, 0.00831520464271307, 0.12891359627246857, 0.11195391416549683, 0.10393795371055603, 0.11619836837053299, 0.09271642565727234, 0.008257437497377396, 0.008409681729972363, 0.008375070989131927, 0.008284948766231537, 0.12090562283992767, 0.008407236076891422, 0.008243824355304241, 0.008282487280666828, 0.10812794417142868, 0.008285507559776306, 0.008327918127179146, 0.00824749656021595, 0.00837379228323698, 0.008337095379829407, 0.008281359449028969, 0.00823661033064127, 0.008197706192731857, 0.008446059189736843, 0.008342303335666656, 0.008282298222184181, 0.008321496658027172, 0.10042714327573776, 0.00814651045948267, 0.008246645331382751, 0.008182681165635586, 0.008150226436555386, 0.10430809110403061, 0.008187680505216122, 0.008155926130712032, 0.11222703754901886, 0.008094103075563908, 0.11002589762210846, 0.008076194673776627, 0.10669036209583282, 0.11487317085266113, 0.008092219941318035, 0.008113455027341843, 0.00806059967726469, 0.7251124978065491, 0.4057389795780182, 0.008277695626020432, 0.00813201442360878, 0.008276586420834064, 0.13809794187545776, 0.008256139233708382, 0.008300619199872017, 0.008367822505533695, 0.008275405503809452, 0.1004423126578331, 0.00828513503074646, 0.008299008011817932, 0.008481084369122982, 0.10973864793777466, 0.11857500672340393, 0.132625013589859, 0.008368113078176975, 0.008307240903377533, 0.008403153158724308, 0.00835493765771389, 0.11258862167596817, 0.09711560606956482, 0.008473418653011322, 0.3097204864025116, 0.10992801934480667, 0.008588403463363647, 0.00837754923850298, 0.11538877338171005, 0.3376621901988983, 0.008649453520774841, 0.11418411880731583, 0.008532785810530186, 0.008533267304301262, 0.008521158248186111, 0.008518544025719166, 0.008543908596038818, 0.11481842398643494, 0.008633849211037159, 0.008672986179590225, 0.008548383601009846, 0.008581987582147121, 0.008745482191443443, 0.10258171707391739, 0.008570030331611633, 0.008814445696771145, 0.11377167701721191, 0.008552550338208675, 0.008562762290239334, 0.008563408628106117, 0.008517499081790447, 0.008542772382497787, 0.008501698262989521, 0.00851906556636095, 0.1376529037952423, 0.008483420126140118, 0.008524668402969837, 0.008561682887375355, 0.11558269709348679, 0.008558085188269615, 0.13000164926052094, 0.3055139482021332, 0.008511453866958618, 0.008602127432823181, 0.008649827912449837, 0.00851843785494566, 0.008635615929961205, 0.11992095410823822, 0.008592979051172733, 0.008491558022797108, 0.008560586720705032, 0.008528309874236584, 0.008515611290931702, 0.12423545867204666, 0.00858120433986187, 0.008680574595928192, 0.008462992496788502, 0.10827171802520752, 0.00846319179981947, 0.008523721247911453, 0.00859724823385477, 0.00848871935158968, 0.008513987995684147, 0.008463879115879536, 0.008559353649616241, 0.008477925322949886, 0.00847440492361784, 0.008528882637619972, 0.008407284505665302, 0.008467575535178185, 0.008548448793590069, 0.008365409448742867, 0.00842959899455309, 0.008382913656532764, 0.008408596739172935, 0.3170998692512512, 0.09529560804367065, 0.008331122808158398, 0.10806205123662949, 0.008454139344394207, 0.008476918563246727, 0.00833871215581894, 0.09451039880514145, 0.11587722599506378, 0.008412538096308708, 0.12469169497489929, 0.008634570054709911, 0.10246838629245758, 0.12272071093320847, 0.008538281545042992, 0.008522288873791695, 0.008364297449588776, 0.008358586579561234, 0.10455695539712906, 0.008456260897219181, 0.008348741568624973, 0.36389702558517456, 0.008484168909490108, 0.008361561223864555, 0.008543496020138264, 0.10596133768558502, 0.008500926196575165, 0.3725832998752594, 0.008514528162777424, 0.008410732261836529, 0.3181711435317993, 0.10709984600543976, 0.008549666032195091, 0.008678757585585117, 0.008511939086019993, 0.008756965398788452, 0.008662277832627296, 0.008648088201880455, 0.008706171065568924, 0.008715248666703701, 0.008558038622140884, 0.008749407716095448, 0.008585743606090546, 0.00852238480001688, 0.008532880805432796, 0.09814172238111496, 0.008794044144451618, 0.086667500436306, 0.008539984934031963, 0.008563932962715626, 0.008760597556829453, 0.00852056872099638, 0.008533233776688576, 0.008507663384079933, 0.10493141412734985, 0.008557681925594807, 0.008519073016941547, 0.3669137954711914, 0.008659430779516697, 0.008526054210960865, 0.11608458310365677, 0.11322490125894547, 0.008634028024971485, 0.10622748732566833, 0.00864523183554411, 0.008558998815715313, 0.10483289510011673, 0.008591565303504467, 0.008665812201797962, 0.00855659507215023, 0.008517338894307613, 0.008543184027075768, 0.008629899471998215, 0.11409609019756317, 0.008566213771700859, 0.008557120338082314, 0.00853594671934843, 0.008538657799363136, 0.008516751229763031, 0.00860591046512127, 0.008572769351303577, 0.008645541034638882, 0.09509501606225967, 0.008503341116011143, 0.008580946363508701, 0.00866367295384407, 0.008518455550074577, 0.00853267777711153, 0.008563882671296597, 0.008637643419206142, 0.008423485793173313, 0.008425469510257244, 0.008562498725950718, 0.008394772186875343, 0.008399657905101776, 0.008453195914626122, 0.008458967320621014, 0.10041613131761551, 0.12401580065488815, 0.11304333060979843, 0.008337827399373055, 0.008616072125732899, 0.008389666676521301, 0.008394732140004635, 0.008430112153291702, 0.09520255029201508, 0.008336758241057396, 0.008340353146195412, 0.008383119478821754, 0.10875917971134186, 0.008371291682124138, 0.1243077889084816, 0.09968147426843643, 0.09418006986379623, 0.00832521915435791, 0.008274269290268421, 0.1075664833188057, 0.09925104677677155, 0.008286994881927967, 0.008305695839226246, 0.1127190813422203, 0.008294947445392609, 0.00834425538778305, 0.008364450186491013, 0.13583441078662872, 0.00836581364274025, 0.10162144899368286, 0.008265027776360512, 0.09124500304460526, 0.008270016871392727, 0.10739582031965256, 0.008419353514909744, 0.008337097242474556, 0.00828638020902872, 0.0848856195807457, 0.008388211019337177, 0.008427049033343792, 0.0835825577378273, 0.008404871448874474, 0.008415235206484795, 0.00833640992641449, 0.11150045692920685, 0.09764457494020462, 0.008249986916780472, 0.008338474668562412, 0.008566135540604591, 0.008480796590447426, 0.008347053080797195, 0.008265470154583454, 0.008287436328828335, 0.008336466737091541, 0.0083473464474082, 0.008261834271252155, 0.00821699295192957, 0.1146518662571907, 0.008231334388256073, 0.00820204708725214, 0.08636264503002167, 0.00828272383660078, 0.008171114139258862, 0.008166415616869926, 0.008262141607701778, 0.008308252319693565, 0.008240933530032635, 0.008145023137331009, 0.008282906375825405, 0.00813352968543768, 0.12404265999794006, 0.09917502105236053, 0.008177073672413826, 0.11579082161188126, 0.008361839689314365, 0.1219368427991867, 0.008172545582056046, 0.008178074844181538, 0.008151231333613396, 0.008208937011659145, 0.008131150156259537, 0.008187145926058292, 0.008073994889855385, 0.008095367811620235, 0.09544291347265244, 0.008119974285364151, 0.11457884311676025, 0.008040964603424072, 0.12438501417636871, 0.1107516959309578, 0.008164296858012676, 0.09875061362981796, 0.008036441169679165, 0.3324589431285858, 0.008066046051681042, 0.008088208734989166, 0.008251971565186977, 0.008076796308159828, 0.09090696275234222, 0.008148732595145702, 0.008229851722717285, 0.008083581924438477, 0.0083079282194376, 0.1152006983757019, 0.008069552481174469, 0.008265871554613113, 0.008156180381774902, 0.11528141051530838, 0.09467960894107819, 0.008196999318897724, 0.00820991676300764, 0.08690013736486435, 0.008209321647882462, 0.00810398068279028, 0.008134589530527592, 0.00812353752553463, 0.008252311497926712, 0.008112741634249687, 0.008088884875178337, 0.00810777023434639, 0.1024603396654129, 0.00803713034838438, 0.008091343566775322, 0.008079771883785725, 0.09828726202249527, 0.105173759162426, 0.09830448776483536, 0.008029824122786522, 0.08612421154975891, 0.008096901699900627, 0.11679603159427643, 0.08456556499004364, 0.11949744820594788, 0.008024009875953197, 0.008139243349432945, 0.008063462562859058, 0.11310403794050217, 0.008051039651036263, 0.08694034814834595, 0.0852140560746193, 0.008114634081721306, 0.09250083565711975, 0.008130503818392754, 0.12546369433403015, 0.10553569346666336, 0.008112926967442036, 0.008163358084857464, 0.008073253557085991, 0.008086767978966236, 0.008054090663790703, 0.008053582161664963, 0.008059147745370865, 0.008143573999404907, 0.008025838062167168, 0.33420222997665405, 0.008033117279410362, 0.09808049350976944, 0.008067701011896133, 0.008115529082715511, 0.008071930147707462, 0.1289348006248474, 0.00810330081731081, 0.008059161715209484, 0.10666204988956451, 0.008204014971852303, 0.09164732694625854, 0.00807710736989975, 0.008161908946931362, 0.3388161361217499, 0.11123645305633545, 0.008073912002146244, 0.008086667396128178, 0.008084907196462154, 0.008091372437775135, 0.008107387460768223, 0.008067518472671509, 0.10617184638977051, 0.008138434030115604, 0.008127783425152302, 0.008146307431161404, 0.07804585248231888, 0.008105667307972908, 0.008118757046759129, 0.10226333886384964, 0.12064923346042633, 0.008149337954819202, 0.008119523525238037, 0.008176922798156738, 0.008106987923383713, 0.008163678459823132, 0.008171488530933857, 0.008103011175990105, 0.13651081919670105, 0.008079553954303265, 0.00807178858667612, 0.008098920807242393, 0.008166207000613213, 0.10899001359939575, 0.008080982603132725, 0.008070915937423706, 0.008100630715489388, 0.008127687498927116, 0.11833478510379791, 0.10086984187364578, 0.00819825753569603, 0.008061576634645462, 0.008099761791527271, 0.008145333267748356, 0.008003300055861473, 0.330810010433197, 0.008052706718444824, 0.008044812828302383, 0.008026838302612305, 0.00807234738022089, 0.00813279952853918, 0.08955426514148712, 0.008152363821864128, 0.00802722480148077, 0.008029132150113583, 0.008032361976802349, 0.008030756376683712, 0.008057099767029285, 0.007998674176633358, 0.007992097176611423, 0.008025010116398335, 0.008088815957307816, 0.008169188164174557, 0.008147149346768856, 0.10169058293104172, 0.11525336652994156, 0.008019417524337769, 0.008179033175110817, 0.00806925818324089, 0.11419998854398727, 0.007954518310725689, 0.1273352950811386, 0.008036882616579533, 0.00799571257084608, 0.12140350788831711, 0.007985474541783333, 0.008036845363676548, 0.11834406852722168, 0.007968975231051445, 0.12281230092048645, 0.13513436913490295, 0.007990403100848198, 0.007978199049830437, 0.088842011988163, 0.007995988242328167, 0.007979781366884708, 0.008076110854744911, 0.008019732311367989, 0.00806859228760004, 0.00795857422053814, 0.007941730320453644, 0.007928344421088696, 0.007913012057542801, 0.12439223378896713, 0.007925487123429775, 0.11182384192943573, 0.008015239611268044, 0.3491049110889435, 0.007963207550346851, 0.11007077991962433, 0.007984152995049953, 0.1172138974070549, 0.007920915260910988, 0.008072501048445702, 0.007927724160254002, 0.10739479213953018, 0.007936160080134869, 0.008049451746046543, 0.008032238110899925, 0.007964463904500008, 0.008030936121940613, 0.00794973410665989, 0.008027478121221066, 0.008069612085819244, 0.008054686710238457, 0.007962331175804138, 0.007914325222373009, 0.007990553043782711, 0.10025078058242798, 0.007964870892465115, 0.11244460940361023, 0.00789062399417162, 0.007985329255461693, 0.008062673732638359, 0.10728473216295242, 0.008023856207728386, 0.007903244346380234, 0.007909689098596573, 0.007938922382891178, 0.007901960983872414, 0.00801959540694952, 0.0967736691236496, 0.007978776469826698, 0.00808005128055811, 0.007981772534549236, 0.007921039126813412, 0.007867339067161083, 0.007889124564826488, 0.007995313964784145, 0.008011299185454845, 0.007963022217154503, 0.1171293705701828, 0.007900075055658817, 0.007933114655315876, 0.1347951591014862, 0.09546997398138046, 0.007917249575257301, 0.007848934270441532, 0.0980779379606247, 0.007883675396442413, 0.007800371386110783, 0.00785020086914301, 0.00782993994653225, 0.33512961864471436, 0.007785007823258638, 0.007796601392328739, 0.11658155173063278, 0.007911193184554577, 0.0078004030510783195, 0.007891347631812096, 0.007896993309259415, 0.007937446236610413, 0.007940614596009254, 0.007800833787769079, 0.008006960153579712, 0.007820984348654747, 0.11774461716413498, 0.007868850603699684, 0.007873444817960262, 0.007788051385432482, 0.007830340415239334, 0.10325366258621216, 0.10049108415842056, 0.12705405056476593, 0.007773947902023792, 0.09829942137002945, 0.007835877127945423, 0.007835072465240955, 0.007810773327946663, 0.007804032415151596, 0.007842088118195534, 0.007790467236191034, 0.007787107490003109, 0.0077590313740074635, 0.351060688495636, 0.007777869235724211, 0.007774874102324247, 0.0077970256097614765, 0.007763792760670185, 0.007914064452052116, 0.007907063700258732, 0.007885642349720001, 0.00795160885900259, 0.00782281905412674, 0.007793549448251724, 0.007787320297211409, 0.007831988856196404, 0.007851501926779747, 0.007769211661070585, 0.09744323790073395, 0.007886378094553947, 0.007757218088954687, 0.10804108530282974, 0.007859903387725353, 0.14344730973243713, 0.007783597335219383, 0.007740661036223173, 0.007832955569028854, 0.00779335992410779, 0.007880561985075474, 0.007830706425011158, 0.09594201296567917, 0.007754248101264238, 0.007759724743664265, 0.09481734037399292, 0.00779576413333416, 0.007721956353634596, 0.1153179481625557, 0.007847613655030727, 0.09598976373672485, 0.007981857284903526, 0.007707430049777031, 0.007748664356768131, 0.007729552686214447, 0.10587138682603836, 0.09240687638521194, 0.007833859883248806, 0.10724356770515442, 0.007980887778103352, 0.0077180517837405205, 0.116627536714077, 0.11530817300081253, 0.007781906984746456, 0.0077892206609249115, 0.0077247461304068565, 0.00778904790058732, 0.33278897404670715, 0.007735226769000292, 0.1135004460811615, 0.007776964921504259, 0.007875277660787106, 0.007726676296442747, 0.007739354390650988, 0.10217928141355515, 0.00773363932967186, 0.11828918009996414, 0.007737239357084036, 0.007802776992321014, 0.11437022686004639, 0.12069600075483322, 0.007838437333703041, 0.007808549329638481, 0.08674564212560654, 0.007726193871349096, 0.007782818749547005, 0.10972161591053009, 0.00786401517689228, 0.007932327687740326, 0.10305976867675781, 0.007947366684675217, 0.007715567015111446, 0.007853611372411251, 0.007736211642622948, 0.007788398303091526, 0.007925539277493954, 0.007741170935332775, 0.007915533147752285, 0.007826189510524273, 0.0077291387133300304, 0.007733022794127464, 0.00780886597931385, 0.0077119674533605576, 0.09396784752607346, 0.00776364840567112, 0.10160984843969345, 0.007747829891741276, 0.007812974974513054, 0.13281001150608063, 0.007704364135861397, 0.10583700984716415, 0.007733144331723452, 0.10621897131204605, 0.007694670930504799, 0.007709873840212822, 0.00766792381182313, 0.11951564252376556, 0.007739900611341, 0.007690976373851299, 0.007662719581276178, 0.125342458486557, 0.00781584344804287, 0.0077839200384914875, 0.1158345490694046, 0.00783352367579937, 0.12129625678062439, 0.007814322598278522, 0.007658679038286209, 0.0077539170160889626, 0.00772497896105051, 0.13766267895698547, 0.007673960644751787, 0.13307969272136688, 0.112945556640625, 0.1012721061706543, 0.007650081533938646, 0.12065151333808899, 0.11804290115833282, 0.007660291623324156, 0.007651254069060087, 0.3526141047477722, 0.007654118351638317, 0.007680018898099661, 0.09550748020410538, 0.007813850417733192, 0.007673668209463358, 0.007748423609882593, 0.007731237448751926, 0.007679390721023083, 0.00771602988243103, 0.007673227693885565, 0.007729964796453714, 0.3825048804283142, 0.12312593311071396, 0.08652288466691971, 0.007710914593189955, 0.11908897012472153, 0.10394740104675293, 0.00781802274286747, 0.11805035173892975, 0.007734602317214012, 0.007729560602456331, 0.007817002944648266, 0.007740087807178497, 0.007871558889746666, 0.007740848232060671, 0.007859955541789532, 0.007721223868429661, 0.12047159671783447, 0.00782198365777731, 0.11609520018100739, 0.007728298660367727, 0.10400182008743286, 0.007711921352893114, 0.007874554954469204, 0.12107882648706436, 0.007724391296505928, 0.007875361479818821, 0.007935313507914543, 0.0077515109442174435, 0.09774404019117355, 0.007817615754902363, 0.07725488394498825, 0.007750491611659527, 0.007780688814818859, 0.11596935987472534, 0.007730625569820404, 0.007792022544890642, 0.007726960349828005, 0.12212784588336945, 0.007722698152065277, 0.007731744088232517, 0.09561062604188919, 0.007820652797818184, 0.007757531479001045, 0.007931623607873917, 0.0076951016671955585, 0.007733317092061043, 0.007695777807384729, 0.007704311981797218, 0.007700602523982525, 0.00784860085695982, 0.007891727611422539, 0.007761653512716293, 0.0076712933368980885, 0.007823511958122253, 0.007731250952929258, 0.007813329808413982, 0.11093741655349731, 0.007743119727820158, 0.007681833114475012, 0.007951481267809868, 0.007736135274171829, 0.007741570472717285, 0.00766789959743619, 0.0077787344343960285, 0.0077738710679113865, 0.11358115822076797, 0.13508276641368866, 0.007661642041057348, 0.007783150300383568, 0.007801539730280638, 0.007661330513656139, 0.007842430844902992, 0.007654460612684488, 0.007659118622541428, 0.3080217242240906, 0.007644223514944315, 0.0076856957748532295, 0.10904540121555328, 0.0076668341644108295, 0.007683136034756899, 0.0076351407915353775, 0.0076191299594938755, 0.0076391855254769325, 0.12103938311338425, 0.10813727974891663, 0.007615205831825733, 0.0076450263150036335, 0.0078011155128479, 0.10117435455322266, 0.007621064782142639, 0.10482560098171234, 0.007762398105114698, 0.1271606683731079, 0.12469463050365448, 0.007686622906476259, 0.007811787072569132, 0.007703516632318497, 0.007701411377638578, 0.11628832668066025, 0.0077453237026929855, 0.1181061714887619, 0.10481234639883041, 0.3471693694591522, 0.007657231763005257, 0.007792409043759108, 0.007711443584412336, 0.08970628678798676, 0.007747279945760965, 0.007657250855118036, 0.0076920026913285255, 0.12007885426282883, 0.1188877671957016, 0.007729510776698589, 0.11848150193691254, 0.007679733447730541, 0.09336164593696594, 0.14360874891281128, 0.007669432554394007, 0.0077089280821383, 0.10145571827888489, 0.007714034989476204, 0.3516952693462372, 0.007696093525737524, 0.007752608973532915, 0.007817148230969906, 0.0077178324572741985, 0.007886846549808979, 0.12395881116390228, 0.00779134314507246, 0.12430667132139206, 0.10765723139047623, 0.007781293708831072, 0.0077090878039598465, 0.007702102418988943, 0.00772620877251029, 0.0996718779206276, 0.11489196866750717, 0.007767218630760908, 0.007740072440356016, 0.007726472336798906, 0.11146371811628342, 0.12491125613451004, 0.09829280525445938, 0.007782856933772564, 0.11334404349327087, 0.09936463087797165, 0.082743801176548, 0.007748821750283241, 0.007798574864864349, 0.007782937493175268, 0.0077167535200715065, 0.09969959408044815, 0.007870425470173359, 0.12171495705842972, 0.39536893367767334, 0.00775410421192646, 0.007858329452574253, 0.10539058595895767, 0.007737569510936737, 0.32219037413597107, 0.007740309461951256, 0.007773743476718664, 0.007753023877739906, 0.007781770545989275, 0.007757237646728754, 0.007867909036576748, 0.00777185894548893, 0.0077962614595890045, 0.007737322710454464, 0.007916118018329144, 0.007862457074224949, 0.09803829342126846, 0.00783111434429884, 0.007864920422434807, 0.00776308961212635, 0.1186150461435318, 0.007740729488432407, 0.10669061541557312, 0.007969105616211891, 0.007763240486383438, 0.007775884121656418, 0.007739232387393713, 0.007751891389489174, 0.007748844102025032, 0.09162256121635437, 0.09284168481826782, 0.3474692702293396, 0.007826211862266064, 0.007817092351615429, 0.007827794179320335, 0.09981141984462738, 0.00792550016194582, 0.0077971769496798515, 0.007903989404439926, 0.007755560800433159, 0.11817146092653275, 0.007784578017890453, 0.007794402539730072, 0.007760182023048401, 0.007788033224642277, 0.007835149765014648, 0.007754384074360132, 0.007829475216567516, 0.007909872569143772, 0.00793825089931488, 0.007816690020263195, 0.1230916902422905, 0.007765290327370167, 0.007894747890532017, 0.007753812242299318, 0.10717733204364777, 0.10502610355615616, 0.00789527129381895, 0.0077811358496546745, 0.007865618914365768, 0.12181191891431808, 0.007790233939886093, 0.007742955349385738, 0.007872123271226883, 0.007738969754427671, 0.007784207351505756, 0.007755504455417395, 0.09099068492650986, 0.00785181112587452, 0.007787015289068222, 0.10903462767601013, 0.007853347808122635, 0.12130719423294067, 0.007818266749382019, 0.007839007303118706, 0.007786772213876247, 0.00771609041839838, 0.09861743450164795, 0.0077326553873717785, 0.007752879988402128, 0.007727057673037052, 0.007806474342942238, 0.31023189425468445, 0.007902439683675766, 0.32831916213035583, 0.35899055004119873, 0.0077191004529595375, 0.007861748337745667, 0.10570807009935379, 0.08869391679763794, 0.007841852493584156, 0.007918912917375565, 0.34709104895591736, 0.007794960401952267, 0.007789438124746084, 0.00778054678812623, 0.007771874777972698, 0.007944351062178612, 0.007788361515849829, 0.0078937578946352, 0.007787069771438837, 0.00784949492663145, 0.007856756448745728, 0.007967368699610233, 0.007862736470997334, 0.007875964976847172, 0.0077875228598713875, 0.00776884239166975, 0.007777931168675423, 0.007895815186202526, 0.007846139371395111, 0.12038315832614899, 0.007788261864334345, 0.007797726895660162, 0.007986183278262615, 0.11984524130821228, 0.007871084846556187, 0.0077660223469138145, 0.007827439345419407, 0.007853689603507519, 0.08880868554115295, 0.007906115613877773, 0.007768495474010706, 0.007818265818059444, 0.007897713221609592, 0.007845509797334671, 0.12266574800014496, 0.007790285162627697, 0.10994866490364075, 0.0077692801132798195, 0.11166613548994064, 0.008031504228711128, 0.11017908900976181, 0.1010827049612999, 0.007832827046513557, 0.00784874614328146, 0.007834542542696, 0.008007390424609184, 0.007900571450591087, 0.00782142486423254, 0.007924528792500496, 0.10915196686983109, 0.007839856669306755, 0.007816510275006294, 0.0077721900306642056, 0.007869808934628963, 0.00773892505094409, 0.0077550471760332584, 0.10653568059206009, 0.007787007372826338, 0.007803851272910833, 0.00781787745654583, 0.007778380531817675, 0.007795254234224558, 0.11074218899011612, 0.007853998802602291, 0.007743450812995434, 0.007818304002285004, 0.007781943306326866, 0.007892828434705734, 0.0077514927834272385, 0.10424036532640457, 0.007820289582014084, 0.00782960094511509, 0.0077522373758256435, 0.007743302267044783, 0.007849982008337975, 0.007723478600382805, 0.007804956287145615, 0.007797924801707268, 0.379692405462265, 0.11317557841539383, 0.007746709510684013, 0.007832487113773823, 0.10409283638000488, 0.0077472273260355, 0.007919961586594582, 0.007804834749549627, 0.11963369697332382, 0.094239242374897, 0.12560278177261353, 0.007783226668834686, 0.007799481973052025, 0.30559706687927246, 0.007914561778306961, 0.007781364023685455, 0.007733744569122791, 0.007803141605108976, 0.10148487240076065, 0.15268293023109436, 0.0077634756453335285, 0.007738384883850813, 0.09270443767309189, 0.0077751390635967255, 0.00775592727586627, 0.128019317984581, 0.12728986144065857, 0.00784284807741642, 0.10078694671392441, 0.10853924602270126, 0.007825500331819057, 0.00788292195647955, 0.007778503932058811, 0.3559017479419708, 0.007760181091725826, 0.007835444062948227, 0.007848645560443401, 0.10836414247751236, 0.1145445927977562, 0.007860327139496803, 0.00776364840567112, 0.007778937462717295, 0.10380355268716812, 0.007759520318359137, 0.007787550333887339, 0.10559000819921494, 0.007780418731272221, 0.007804167922586203, 0.0077756354585289955, 0.09177549928426743, 0.007937619462609291, 0.007843316532671452, 0.007783394772559404, 0.007788859307765961, 0.1255629062652588, 0.10386007279157639, 0.007771833334118128, 0.007819130085408688, 0.007967195473611355, 0.007768615148961544, 0.007845372892916203, 0.12245900183916092, 0.007818811573088169, 0.007776264101266861, 0.0077730026096105576, 0.12774315476417542, 0.13972900807857513, 0.007795331999659538, 0.09513538330793381, 0.00789638515561819, 0.007757764309644699, 0.007750761695206165, 0.007910003885626793, 0.007948960177600384, 0.10936174541711807, 0.007751621305942535, 0.007757598999887705, 0.10163020342588425, 0.007752338424324989, 0.007767551112920046, 0.007749080657958984, 0.007763550616800785, 0.11407119780778885, 0.12201598286628723, 0.007763550616800785, 0.007861437276005745, 0.007770484779030085, 0.007794469129294157, 0.007791449781507254, 0.007915636524558067, 0.3929111957550049, 0.007823211140930653, 0.008008984848856926, 0.00778532586991787, 0.007755072321742773, 0.007762912195175886, 0.007892444729804993, 0.11481521278619766, 0.007746769580990076, 0.00785562302917242, 0.00774681381881237, 0.0077952113933861256, 0.007826357148587704, 0.007830392569303513, 0.007839031517505646, 0.1051526740193367, 0.007841996848583221, 0.007952314801514149, 0.007739870809018612, 0.007820113562047482, 0.007833951152861118, 0.007890143431723118, 0.007784064393490553, 0.007768782787024975, 0.007812432013452053, 0.007909957319498062, 0.007882434874773026, 0.007758444640785456, 0.00796719454228878, 0.007741075940430164, 0.0077620744705200195, 0.33163759112358093, 0.3613763451576233, 0.007796066347509623, 0.0077989655546844006, 0.10415585339069366, 0.10315648466348648, 0.007793927565217018, 0.007916552945971489, 0.007971439510583878, 0.12973150610923767, 0.007752313744276762, 0.00786561705172062, 0.09174871444702148, 0.007878599688410759, 0.007908795960247517, 0.12412559241056442, 0.007886943407356739, 0.12653054296970367, 0.10455559939146042, 0.11891307681798935, 0.1204589456319809, 0.007776307873427868, 0.007802506443113089, 0.007778268773108721, 0.3243725895881653, 0.11586344242095947, 0.007914070971310139, 0.0077589768916368484, 0.0999579206109047, 0.0919228047132492, 0.12222890555858612, 0.007789394818246365, 0.007791096344590187, 0.007904446683824062]\n",
      "Val loss 0.04433948241147675\n",
      "Val auc roc 0.5208880281184994\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch     3: reducing learning rate of group 1 to 1.0000e-05.\n",
      "Saved model state dict for epoch 2 \n"
     ]
    }
   ],
   "source": [
    "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yFm0nuBLjo-E",
    "outputId": "f56c5b4b-545d-446e-8c8e-66183f78debe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous model state successfully!\n"
     ]
    }
   ],
   "source": [
    "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
    "try:\n",
    "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
    "    print('Loaded previous model state successfully!')\n",
    "except:\n",
    "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yXL1gy1tRZW"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xc5diJj175Yp"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tMm6SH297H5w"
   },
   "outputs": [],
   "source": [
    "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
    "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
    "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2Y9PDREj1A1A",
    "outputId": "357c2392-bc11-45e1-f848-c50db680606f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_submission_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ez1sufJ7oqR"
   },
   "outputs": [],
   "source": [
    "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aDOclNQGRFWN"
   },
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "    predictions[i]=(predictions[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnJHqglG5s0h"
   },
   "outputs": [],
   "source": [
    "predictions = np.array(predictions).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_zKcQfDh7NCP",
    "outputId": "437c1435-63d2-418e-e4de-ff1e629b5b9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1995, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tids = []\n",
    "for i in range(len(tweet_ids)):\n",
    "    tids+=[[str(tweet_ids[i][0])]]\n",
    "tids_arr = np.array(tids)\n",
    "tids_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QGf7qcW897U"
   },
   "outputs": [],
   "source": [
    "# TweetIds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5OWDbQnT4yfi"
   },
   "outputs": [],
   "source": [
    "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uo4r_mE56ujc"
   },
   "outputs": [],
   "source": [
    "# for i in range(tweet_ids.shape[0]):\n",
    "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ItQ8IOaG62RN"
   },
   "outputs": [],
   "source": [
    "# type(tweet_ids[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Id5X5Pmb1geu"
   },
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "fvHbyBTW5A2R",
    "outputId": "7923ecbb-7f8e-4f8c-d336-447f315eae5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Generalized_Hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TweetId, Generalized_Hate]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df[submit_df[col_name]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQemOi-I6K0m"
   },
   "outputs": [],
   "source": [
    "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "SQt3drOM94rP",
    "outputId": "ec32c9b8-06be-4aa3-b409-dac1a64be2f3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2020-07-28 11:14:53.792686'"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mSTypu-_r5r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled10(1) account dos.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "097895f8a2b6495692d9a27e03e696db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2a324457fc142e39e9dd06345420eaf",
      "max": 1681,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd6a768ff18d440db94fdc8562622a4b",
      "value": 1681
     }
    },
    "0fc44352e7ce49dcac07d32d769a2757": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66aefddebbc5464eb20b1186a85cd915",
       "IPY_MODEL_7dda0fcd285549998d1383defc3c7da6"
      ],
      "layout": "IPY_MODEL_6f410fe5dc3c491087ff79820c5047ec"
     }
    },
    "17b1763c24bd4b929d4ada36269967cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ae6400435da44a893ee89e1b9ef70a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "226eb4e8e9e64853aa756bd58173aa98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2d1ea967679845029275603085b344b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6ef73e7b9cd4ceabae23089bb9cf4bc",
      "placeholder": "​",
      "style": "IPY_MODEL_e51594b3bc9c45c5ae20f900459313e6",
      "value": " 1681/1681 [15:01&lt;00:00,  1.86it/s]"
     }
    },
    "3e731da642324e9ba2f195350cbd3580": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42685acc56dd458fba57903118d99291": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_91e2b49f13a04c65be7cf88ea854ab7e",
       "IPY_MODEL_2d1ea967679845029275603085b344b5"
      ],
      "layout": "IPY_MODEL_ede6503080f6442f845b9c7da032772a"
     }
    },
    "505af5263980412989e2c4ee4433d090": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_097895f8a2b6495692d9a27e03e696db",
       "IPY_MODEL_f16e401def4e45a4be19dd71fb9e9e7e"
      ],
      "layout": "IPY_MODEL_98b8d90b702346f3ab8d4ba6a52d6a3e"
     }
    },
    "5fe3aeaaac264d50a65386f98aef26c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc3255c243024a79a202505513a82efb",
      "placeholder": "​",
      "style": "IPY_MODEL_3e731da642324e9ba2f195350cbd3580",
      "value": " 1681/1681 [15:28&lt;00:00,  1.81it/s]"
     }
    },
    "66aefddebbc5464eb20b1186a85cd915": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2f1af333fce4ae189d1111042af3ec9",
      "max": 241530880,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_75c6d95c06c1469a9ea8d252e5af90d3",
      "value": 241530880
     }
    },
    "6f410fe5dc3c491087ff79820c5047ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72c0bf2895f846e0bb19ff49ab56e1cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c6d95c06c1469a9ea8d252e5af90d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7dda0fcd285549998d1383defc3c7da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f86098877c054be48eaa3ca7819ae253",
      "placeholder": "​",
      "style": "IPY_MODEL_ee2a4fc50c2b4e31a45eae9f23084488",
      "value": " 230M/230M [00:03&lt;00:00, 75.1MB/s]"
     }
    },
    "91e2b49f13a04c65be7cf88ea854ab7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb6576223354419c8981443ecaaa8504",
      "max": 1681,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_226eb4e8e9e64853aa756bd58173aa98",
      "value": 1681
     }
    },
    "98b8d90b702346f3ab8d4ba6a52d6a3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a184b03dc83542a68b2648d6035b0125": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f78aa42748ba4c8dade0b3e71dfb8247",
       "IPY_MODEL_5fe3aeaaac264d50a65386f98aef26c9"
      ],
      "layout": "IPY_MODEL_1ae6400435da44a893ee89e1b9ef70a8"
     }
    },
    "a24c30054906424a9d7a5938e8f452d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b2a324457fc142e39e9dd06345420eaf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2f1af333fce4ae189d1111042af3ec9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6ef73e7b9cd4ceabae23089bb9cf4bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc3255c243024a79a202505513a82efb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd6a768ff18d440db94fdc8562622a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d8f8b217793e4bdbbe2c08d1a3885fb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e51594b3bc9c45c5ae20f900459313e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ede6503080f6442f845b9c7da032772a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee2a4fc50c2b4e31a45eae9f23084488": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f16e401def4e45a4be19dd71fb9e9e7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17b1763c24bd4b929d4ada36269967cb",
      "placeholder": "​",
      "style": "IPY_MODEL_d8f8b217793e4bdbbe2c08d1a3885fb5",
      "value": " 1681/1681 [15:26&lt;00:00,  1.81it/s]"
     }
    },
    "f78aa42748ba4c8dade0b3e71dfb8247": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72c0bf2895f846e0bb19ff49ab56e1cc",
      "max": 1681,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a24c30054906424a9d7a5938e8f452d2",
      "value": 1681
     }
    },
    "f86098877c054be48eaa3ca7819ae253": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb6576223354419c8981443ecaaa8504": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
