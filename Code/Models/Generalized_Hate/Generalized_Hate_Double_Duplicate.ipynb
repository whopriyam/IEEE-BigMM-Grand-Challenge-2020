{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generalized_Hate_Double_Duplicate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d401a7b56ed4939893179e16b4f6d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0ac1a821b69640d6b5c717f99d8325be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f1a8fed9402b4fc0a287e766e83fda65",
              "IPY_MODEL_a782f3772c544b45b06074f7ffdd7820"
            ]
          }
        },
        "0ac1a821b69640d6b5c717f99d8325be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1a8fed9402b4fc0a287e766e83fda65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_234a90eccde249ffbb0a2eebfbc47e95",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b747defa2b24be9a751d40ffc100697"
          }
        },
        "a782f3772c544b45b06074f7ffdd7820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4188c0756c4f46d1aff972de1e697792",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:11&lt;00:00, 21.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9ccf8a74f0547778444d41084a993e4"
          }
        },
        "234a90eccde249ffbb0a2eebfbc47e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b747defa2b24be9a751d40ffc100697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4188c0756c4f46d1aff972de1e697792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9ccf8a74f0547778444d41084a993e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4bf642263614a25a9c70a446b86001a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_781079382af44162a9a9c8de6775c33e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_631e0e9b25a74ff5880b2ce90772cc1b",
              "IPY_MODEL_4b0bedff92374db6ac7ba577be59668a"
            ]
          }
        },
        "781079382af44162a9a9c8de6775c33e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "631e0e9b25a74ff5880b2ce90772cc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34c2fc235b844e359e674783102bbbed",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1677,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1677,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8ed679a1f3e4bdd904616efa49401ad"
          }
        },
        "4b0bedff92374db6ac7ba577be59668a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4c444c501fb46f4899f369f1916f265",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1677/1677 [30:43&lt;00:00,  1.10s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14a527aae4624431ae5d4b11497d6ce4"
          }
        },
        "34c2fc235b844e359e674783102bbbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8ed679a1f3e4bdd904616efa49401ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4c444c501fb46f4899f369f1916f265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14a527aae4624431ae5d4b11497d6ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "856c5666bdb24e4387dc29857403fb47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d1bb0af02e14abb8b6812e872f33474",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b2544c912794572a71e15ff2b3bce75",
              "IPY_MODEL_319df79ba5614ccd820314b4984eb7bb"
            ]
          }
        },
        "7d1bb0af02e14abb8b6812e872f33474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b2544c912794572a71e15ff2b3bce75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_043603f5b7584fa382a7547c0ecf611d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1677,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1677,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f7d517cf5d84b858995adecb2b0943f"
          }
        },
        "319df79ba5614ccd820314b4984eb7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7f1bec0b96349ad8c9cdb75b2973b7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1677/1677 [31:01&lt;00:00,  1.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8642fe3db2ca40279eb09c318db05816"
          }
        },
        "043603f5b7584fa382a7547c0ecf611d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f7d517cf5d84b858995adecb2b0943f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7f1bec0b96349ad8c9cdb75b2973b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8642fe3db2ca40279eb09c318db05816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f1eb6a6f9fb46ccb1f5ceda3b053840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db3a253ae9c74a649f149ca0057b07ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b01cc7d734984ac6972dc8a06444a7d7",
              "IPY_MODEL_9f305762a36544a3bfa777276cf8c592"
            ]
          }
        },
        "db3a253ae9c74a649f149ca0057b07ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b01cc7d734984ac6972dc8a06444a7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e17c3fff296d4a9dbbd35e42329bf94c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1677,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1677,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84883e78979742ff899dfdaf90eb5477"
          }
        },
        "9f305762a36544a3bfa777276cf8c592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d52ac8c76814f6894b5f54bc24902d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1677/1677 [31:03&lt;00:00,  1.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0da3068774842ed8df0a3ae0c7cc360"
          }
        },
        "e17c3fff296d4a9dbbd35e42329bf94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84883e78979742ff899dfdaf90eb5477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d52ac8c76814f6894b5f54bc24902d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0da3068774842ed8df0a3ae0c7cc360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie9t7l91U2t",
        "colab_type": "text"
      },
      "source": [
        "# Data Import from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh1JATeBylTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f16dc8cf-09e0-4aaa-e7df-43dd339e0dd4"
      },
      "source": [
        "# %cd ..\n",
        "# %pwd\n",
        "# !cp '/content/drive/My Drive/IEEE BigMM/ieee-bigmm-images.zip' './'\n",
        "!git clone 'https://github.com/sohamtiwari3120/ieee-bigmm-images.git'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ieee-bigmm-images'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 7175 (delta 12), reused 8 (delta 3), pack-reused 7142\u001b[K\n",
            "Receiving objects: 100% (7175/7175), 592.44 MiB | 33.53 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (8551/8551), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hno1BI3eIQb7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9M7H8jCyzjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba131d0b-3be3-40c4-d0d3-452aa00b6c2e"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mieee-bigmm-images\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaUvnWy2y97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !unzip ieee-bigmm-images.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUI93xgzRFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e198c39-ffa9-42df-ac9d-84a283dc378a"
      },
      "source": [
        "%cd ieee-bigmm-images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ieee-bigmm-images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp3BrmFb4EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4f2c0638-b69b-494e-b18a-0e39a69e419b"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/sohamtiwari3120/ieee-bigmm-images\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J3t5rG0EwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "03d56872-ad7c-4e4d-861f-054661e9b5df"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_datav5.csv                README.md\n",
            "clean_datav6.csv                test_data_cleaned.csv\n",
            "Data_without-invalid_cells.csv  \u001b[0m\u001b[01;34mtest_images\u001b[0m/\n",
            "final_dataset.csv               test_tweet_2.csv\n",
            "final_test2.csv                 \u001b[01;34mtrain_images\u001b[0m/\n",
            "final_test3_unpreprocessed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17uVz_YI1dty",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dghuwTb1t2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "2f26619e-2b19-4878-e9c1-1f5aeec2a5e2"
      },
      "source": [
        "# %%capture\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "! pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install imbalanced-learn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1MWr-9J1AAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import tqdm\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199f2bGeBK_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "452d0636-dfbc-4cbf-8ee9-b9493874e794"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb6j_3C1uSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e94d7a9-bb9e-4c7b-a950-4d44a2d5b7b2"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phuvcx_b2LNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "65758838-e2be-4758-8cf1-4491b7e98d58"
      },
      "source": [
        "df = pd.read_csv('./clean_datav6.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>missing_text</th>\n",
              "      <th>Text_Only_Informative</th>\n",
              "      <th>Image_Only_Informative</th>\n",
              "      <th>Directed_Hate</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "      <th>Sarcasm</th>\n",
              "      <th>Allegation</th>\n",
              "      <th>Justification</th>\n",
              "      <th>Refutation</th>\n",
              "      <th>Support</th>\n",
              "      <th>Oppose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1052237153789390853</td>\n",
              "      <td>New post (Domestic Violence Awareness Hasn't C...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1052207832081129472</td>\n",
              "      <td>Domestic Violence Awareness Hasn’t Caught Up W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1052183746344960000</td>\n",
              "      <td>Mother Nature’s #MeToo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1052156864840908800</td>\n",
              "      <td>ption - no:2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1052095305133510656</td>\n",
              "      <td>It is 'high time' #MeToo named and shamed men ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  Refutation Support  Oppose\n",
              "0           0             0               0  ...         0.0     1.0     0.0\n",
              "1           1             1               1  ...         0.0     1.0     0.0\n",
              "2           2             2               2  ...         0.0     0.0     0.0\n",
              "3           3             3               3  ...         0.0     0.0     1.0\n",
              "4           4             4               4  ...         0.0     1.0     0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SOPiJUN2PoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7a9d5ffc-73f4-4413-f117-ce8057618b9a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, train_size=0.8, shuffle = True )\n",
        "train_df = train_df.reset_index()\n",
        "val_df = val_df.reset_index()\n",
        "train_df['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                        ption - no:2 \n",
              "1    Bryan Singer is now denying accusations about ...\n",
              "2    #BIGNEWS: Today I got know that #ArjunSarja ha...\n",
              "3                                        ption - no:2 \n",
              "4    One Year of #MeToo: How the Movement Eludes Go...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gsQ0q72XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_transformations = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "#             transforms.Resize((224, 244)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFomlns02fvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d369527d-d9a8-4866-a878-b33f84f668c2"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:08<00:00, 50253356.66B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScheMbt2_6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71923219-78ba-48db-9d81-4753d2db7447"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "            'bert-base-uncased', do_lower_case=True\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 1913971.05B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZacy6uP3F-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "388b1c73-62ad-4ad5-ca99-6c706cb749b3"
      },
      "source": [
        "(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize('new post domestic violence awareness caught me zzzzzx83272@xxxx')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2047,\n",
              " 2695,\n",
              " 4968,\n",
              " 4808,\n",
              " 7073,\n",
              " 3236,\n",
              " 2033,\n",
              " 1062,\n",
              " 13213,\n",
              " 13213,\n",
              " 2595,\n",
              " 2620,\n",
              " 16703,\n",
              " 2581,\n",
              " 2475,\n",
              " 1030,\n",
              " 22038,\n",
              " 20348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRJVGDJmA8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae8816ee-781a-4cb0-daad-2c97a46be8ae"
      },
      "source": [
        "bert_tokenizer.convert_tokens_to_ids([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 100, 101, 102, 103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbHMxJEbdRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert)\n",
        "# Help on BertModel in module pytorch_pretrained_bert.modeling object:\n",
        "\n",
        "# class BertModel(BertPreTrainedModel)\n",
        "#  |  BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "#  |  \n",
        "#  |  Params:\n",
        "#  |      config: a BertConfig class instance with the configuration to build a new model\n",
        "#  |  \n",
        "#  |  Inputs:\n",
        "#  |      `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "#  |          with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "#  |          `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "#  |      `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "#  |          types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "#  |          a `sentence B` token (see BERT paper for more details).\n",
        "#  |      `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "#  |          selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "#  |          input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "#  |          a batch has varying length sentences.\n",
        "#  |      `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "#  |  \n",
        "#  |  Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "#  |      `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "#  |          - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "#  |              of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "#  |              encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "#  |          - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "#  |              to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
        "#  |      `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "#  |          classifier pretrained on top of the hidden state associated to the first character of the\n",
        "#  |          input (`CLS`) to train on the Next-Sentence task (see BERT's paper). \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ-TvFY8oB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(bert.encoder)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabXmZJl3KVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNImageDataset(Dataset):\n",
        "    def __init__(self, data, image_path, label_name, transforms, tokenizer, vocab, minority_class):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.label_name = label_name\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "        df2 = self.data[self.data[label_name]==minority_class]\n",
        "        df2 = df2.copy().reset_index(drop=True)\n",
        "        df3 = df2.copy().reset_index(drop=True)\n",
        "        # print(df2)\n",
        "        print(f\"Old data length : {len(self.data)}\")\n",
        "        print(f'minority class is {minority_class}. Duplicating minority class data!')\n",
        "        for i in range(len(df2)):\n",
        "            text = df2['text'][i]\n",
        "            text = text.split(' ')\n",
        "            random.shuffle(text)\n",
        "            text2 = ' '.join(text)\n",
        "            df2['text'][i]=text2\n",
        "            random.shuffle(text)\n",
        "            text3 = ' '.join(text)\n",
        "            df3['text'][i]=text3\n",
        "        self.data = self.data.append(df2, ignore_index=True)\n",
        "        self.data = self.data.append(df3, ignore_index=True)\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(f\"New data length : {len(self.data)}\")\n",
        "\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['tweet_id'][index]\n",
        "        label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, label, image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        model = torchvision.models.resnet152(pretrained=True)\n",
        "        modules = list(model.children())[:-2]\n",
        "        # we are removing the last adaptive average pooling layer and the \n",
        "        # the classification layer\n",
        "        self.model = nn.Sequential(*modules)\n",
        "        if(torch.cuda.is_available()):\n",
        "            self.model = self.model.cuda()\n",
        "        # self.model = self.model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = (self.model(x))\n",
        "        # print('Model output', out.size())\n",
        "\n",
        "        out = nn.AdaptiveAvgPool2d((7, 1))(out)#specifying the H and W of the image\n",
        "        # to be obtained after pooling\n",
        "        # print('Pooling output', out.size())\n",
        "\n",
        "        out = torch.flatten(out, start_dim=2)\n",
        "        # print('Flattening output', out.size())\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        # print('Transpose output', out.size())\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    def __init__(self, emptyInit=False):\n",
        "        if emptyInit:\n",
        "            self.stoi={}#string to index dictionary\n",
        "            self.itos=[]#index to string dictionary\n",
        "            self.vocab_size=0\n",
        "        else:\n",
        "            self.stoi={\n",
        "                w:i\n",
        "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "            }\n",
        "            self.itos = [w for w in self.stoi]\n",
        "            self.vocab_size = len(self.itos)\n",
        "    \n",
        "    def add(self, words):\n",
        "        counter = len(self.itos)\n",
        "        for w in words:\n",
        "            if w in self.stoi:\n",
        "                continue\n",
        "            self.stoi[w]=counter\n",
        "            counter+=1\n",
        "            self.itos.append(w)\n",
        "        self.vocab_size = len(self.itos)\n",
        "\n",
        "class ImageEmbeddingsForBert(nn.Module):\n",
        "    def __init__(self, embeddings, vocabObject):\n",
        "        super(ImageEmbeddingsForBert, self).__init__()\n",
        "        self.vocab = vocabObject\n",
        "#       the embeddins received as input are the \n",
        "#       all the embeddings provided by the bert model from pytorch\n",
        "        self.img_embeddings = nn.Linear(2048, 768)\n",
        "#       above is linear layer is used to convert the flattened images \n",
        "#       logits obtained after pooling from Image encoder which have 2048\n",
        "#       dimensions to a 768 dimensions which is the size of bert's hidden layer\n",
        "        \n",
        "        self.position_embeddings = embeddings.position_embeddings\n",
        "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
        "        self.word_embeddings = embeddings.word_embeddings\n",
        "        self.LayerNorm = embeddings.LayerNorm\n",
        "        self.dropout = embeddings.dropout\n",
        "        \n",
        "    def forward(self, batch_input_imgs, token_type_ids):\n",
        "        batch_size = batch_input_imgs.size(0)\n",
        "        seq_length = 7 + 2\n",
        "#         since we are assuming that from each image we will obtain\n",
        "#         7 image embeddings of 768 dimensions each\n",
        "        \n",
        "        cls_id = torch.LongTensor([101])\n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "            self.word_embeddings = self.word_embeddings.cuda()\n",
        "        cls_id = cls_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            cls_id = cls_id.cuda()\n",
        "        cls_token_embeddings = self.word_embeddings(cls_id)\n",
        "        \n",
        "        sep_id = torch.LongTensor([102])\n",
        "        if torch.cuda.is_available():\n",
        "            sep_id = sep_id.cuda()\n",
        "            self.img_embeddings = self.img_embeddings.cuda()\n",
        "        sep_id = sep_id.unsqueeze(0).expand(batch_size, 1)\n",
        "        sep_token_embeddings = self.word_embeddings(sep_id)\n",
        "        \n",
        "        batch_image_embeddings_768 = self.img_embeddings(batch_input_imgs)\n",
        "        \n",
        "        token_embeddings = torch.cat(\n",
        "        [cls_token_embeddings, batch_image_embeddings_768, sep_token_embeddings], dim=1)\n",
        "        \n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "        if torch.cuda.is_available():\n",
        "            position_ids = position_ids.cuda()\n",
        "            self.position_embeddings = self.position_embeddings.cuda()\n",
        "            self.token_type_embeddings= self.token_type_embeddings.cuda()\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_length)\n",
        "        \n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = token_embeddings+position_embeddings+token_type_embeddings\n",
        "        if torch.cuda.is_available():\n",
        "            embeddings = embeddings.cuda()\n",
        "            self.LayerNorm=self.LayerNorm.cuda()\n",
        "            self.dropout=self.dropout.cuda()\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiModalBertEncoder(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertEncoder, self).__init__()\n",
        "        bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings = bert.embeddings\n",
        "        self.vocab=Vocab()\n",
        "        self.image_embeddings = ImageEmbeddingsForBert(self.embeddings, self.vocab)\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.encoder = bert.encoder\n",
        "        self.pooler = bert.pooler\n",
        "        self.clf = nn.Linear(768, no_of_classes)\n",
        "        \n",
        "    def forward(self, input_text, text_attention_mask, text_segment, input_image):\n",
        "        batch_size = input_text.size(0)\n",
        "# input text is a tensor of encoded texts!\n",
        "        temp = torch.ones(batch_size, 7+2).long()\n",
        "        if torch.cuda.is_available():\n",
        "            temp = temp.cuda()\n",
        "            self.encoder = self.encoder.cuda()\n",
        "            self.pooler = self.pooler.cuda()\n",
        "        attention_mask = torch.cat(\n",
        "            [\n",
        "                temp, text_attention_mask\n",
        "            ],\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "#         print(attention_mask.shape, extended_attention_mask.shape)\n",
        "        extended_attention_mask = extended_attention_mask.to(\n",
        "            dtype=next(self.parameters()).dtype\n",
        "        )\n",
        "        # extended_attention_mask = (1.0 - extended_attention_mask)*-10000.0\n",
        "        \n",
        "        image_token_type_ids = torch.LongTensor(batch_size, 7+2).fill_(0)\n",
        "        if(torch.cuda.is_available()):\n",
        "            image_token_type_ids= image_token_type_ids.cuda()\n",
        "        \n",
        "        image = self.image_encoder(input_image)\n",
        "#         above image returned is of the formc nC x nH x nW and is a tensor\n",
        "        image_embedding_out = self.image_embeddings(image, image_token_type_ids)\n",
        "#         print('Image embeddings: ', image_embedding_out.size())\n",
        "        \n",
        "        text_embedding_out = self.embeddings(input_text, text_segment)\n",
        "#         print('Text embeddings: ', text_embedding_out.size(), text_embedding_out)\n",
        "#         print(input_text, text_embedding_out)\n",
        "        \n",
        "        encoder_input = torch.cat([image_embedding_out, text_embedding_out], dim=1)\n",
        "#         the encoder input is of the form CLS (7 image embeddings) SEP text_embeddings\n",
        "    \n",
        "        encoded_layers = self.encoder(encoder_input, extended_attention_mask, output_all_encoded_layers=False)\n",
        "        # above function returns the hidden states off all the layers L in the bert model. in case of bert base, L = 12;\n",
        "        # if output all encoded layers is false, then only returns the hidden state of the last self attention layer\n",
        "        # print('ENCODED_LAYERS',encoded_layers[-1],'enc layers2', encoded_layers[-1][:][0])\n",
        "        final = self.pooler(encoded_layers[-1])\n",
        "        # print('FINAL POOLED LAYERS', final, final.size())\n",
        "#         print('encoded layers', encoded_layers)\n",
        "        return final\n",
        "        # how to extract CLS layer\n",
        "        \n",
        "\n",
        "class MultiModalBertClf(nn.Module):\n",
        "    def __init__(self, no_of_classes, tokenizer):\n",
        "        super(MultiModalBertClf, self).__init__()\n",
        "        self.no_of_classes = no_of_classes\n",
        "        self.enc = MultiModalBertEncoder(self.no_of_classes, tokenizer)\n",
        "        # self.layer1 = nn.Linear(768, 512)\n",
        "        # self.layer2 = nn.Linear(512, 256)\n",
        "        self.batch_norm = nn.BatchNorm1d(768)\n",
        "        self.clf = nn.Linear(768, self.no_of_classes)\n",
        "    \n",
        "    def forward(self, text, text_attention_mask, text_segment, image):\n",
        "        if(torch.cuda.is_available()):\n",
        "            text = text.cuda()\n",
        "            text_attention_mask=text_attention_mask.cuda()\n",
        "            text_segment=text_segment.cuda()\n",
        "            image = image.cuda()\n",
        "            self.clf = self.clf.cuda()\n",
        "        x = self.enc(text, text_attention_mask, text_segment, image)\n",
        "        # x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layer2(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.clf(x)\n",
        "        # print('Sigmoid output: ',torch.sigmoid(x))\n",
        "        return x \n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    # read the focal loss paper\n",
        "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.reduce = reduce\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(y_pred.squeeze(-1), y_true.squeeze(-1), reduce = None)#this automatically  takes sigmoid of logits\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(y_pred, y_true, reduce = None)\n",
        "            \n",
        "        pt = torch.exp(-BCE_loss)\n",
        "#       # pt = p if y = 1\n",
        "#       # pt = 1 - p if y = else\n",
        "#       p is the predicted value, y is the target label\n",
        "        # pt is used to indicate if the prediction matches the target or not\n",
        "        # if pt->1, then proper classification, else if pt->0, then misclassification\n",
        "        # so focal loss basically downweights the loss generated in a proper classification\n",
        "        # but does not change downweight the loss in a miss classification\n",
        "        F_loss =self.alpha * ((1-pt)**self.gamma) * BCE_loss\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        return F_loss\n",
        "        \n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, logits = True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, logits=True, smooth=1):\n",
        "        if(logits):\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "\n",
        "        intersection = (y_pred*y_true).sum()\n",
        "        pred_sum = (y_pred*y_pred).sum()\n",
        "        true_sum = (y_true*y_true).sum()\n",
        "\n",
        "        return 1 - (2 * intersection + smooth) / (pred_sum + true_sum+smooth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kS4hVKn3OBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_function_for_dataloader(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    \n",
        "    batch_image_tensors = torch.stack([row[2] for row in batch])\n",
        "    \n",
        "    label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    if task_type=='multilabel':\n",
        "        label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "    \n",
        "    return text_tensors, label_tensors, text_segment, text_attention_mask, batch_image_tensors\n",
        "\n",
        "\n",
        "def get_optimizer(model, train_data_len, batch_size = 4, gradient_accumulation_steps=1, max_epochs=3, lr=0.001):\n",
        "    total_steps = (\n",
        "        train_data_len\n",
        "        / batch_size\n",
        "        / gradient_accumulation_steps\n",
        "        * max_epochs\n",
        "    )\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
        "    ]\n",
        "    # print('OPTIMIZER PARAMS', optimizer_grouped_parameters)\n",
        "    optimizer = BertAdam(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=lr,\n",
        "#         warmup=args.warmup,\n",
        "        t_total=total_steps,\n",
        "    )\n",
        "#     optimizer = optim.Adam(\n",
        "#         optimizer_grouped_parameters,\n",
        "#         lr=lr,\n",
        "# #         warmup=args.warmup,\n",
        "#         t_total=total_steps,\n",
        "#     )\n",
        "    return optimizer\n",
        "\n",
        "def model_forward(i_epoch, model, criterion, batch):\n",
        "    txt, tgt, segment, mask, img= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    if(torch.cuda.is_available()):\n",
        "        tgt = tgt.cuda()\n",
        "    # print()\n",
        "    loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return loss, out, tgt\n",
        "\n",
        "\n",
        "def store_preds_to_disk(tgts, preds, savedir):\n",
        "    str_time = str(datetime.datetime.now())\n",
        "    with open(os.path.join(savedir, \"./test_labels_pred_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in preds]))\n",
        "    with open(os.path.join(savedir, \"./test_labels_actual_\"+str_time+\"_.txt\"), \"w\") as fw:\n",
        "        fw.write(\"\\n\".join([str(x) for x in tgts]))\n",
        "#     with open(os.path.join(savedir, \"test_labels.txt\"), \"w\") as fw:\n",
        "#         fw.write(\" \".join([str(l) for l in alabels]))\n",
        "\n",
        "\n",
        "def model_eval(i_epoch, data, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts = [], [], []\n",
        "        for batch in data:\n",
        "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
        "            losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "                \n",
        "            preds.append(pred)\n",
        "            tgt = tgt.cpu().detach().numpy()\n",
        "            tgts.append(tgt)\n",
        "\n",
        "    metrics = {\"loss\": np.mean(losses)}\n",
        "    tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    if store_preds:\n",
        "        store_preds_to_disk(tgts, preds, './')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLA_xWa87RDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SubmissionDataset(Dataset):\n",
        "    def __init__(self, data, image_path, transforms, tokenizer, vocab):\n",
        "        self.data = data\n",
        "        self.image_path = (image_path)\n",
        "        self.transforms = transforms\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sent_len = 128 - 7 - 2 #since there will be [CLS] <7 image embeddings> [SEP] <the text embeddings>\n",
        "        self.vocab = vocab\n",
        "    def __getitem__(self,  index):\n",
        "        text = self.data['text'][index]\n",
        "        text = str(text)\n",
        "        text = self.tokenizer.tokenize(text)[:self.max_sent_len]\n",
        "        text = torch.LongTensor(self.tokenizer.convert_tokens_to_ids(text))\n",
        "        tweet_id = self.data['TweetId'][index]\n",
        "#         label = torch.LongTensor([self.data[self.label_name][index]])\n",
        "        image = None\n",
        "        try:\n",
        "            image = Image.open(\n",
        "                self.image_path+\"/\"+str(tweet_id)+\".jpg\"\n",
        "            ).convert(\"RGB\")\n",
        "#             print(self.image_path+\"/\"+str(tweet_id)+\".jpg\"+\" opened!\")\n",
        "#             image.show()\n",
        "            image = self.transforms(image)\n",
        "        except:\n",
        "            image = Image.fromarray(128*np.ones((256, 256, 3), dtype=np.uint8))\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return text, image, tweet_id\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def collate_function_for_submission(batch, task_type='singlelabel'):\n",
        "    lengths = [len(row[0]) for row in batch]\n",
        "    batch_size = len(batch)\n",
        "    max_sent_len = max(lengths)\n",
        "    if(max_sent_len>128-7-2):\n",
        "        max_sent_len=128-7-2\n",
        "    text_tensors = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_attention_mask = torch.zeros(batch_size, max_sent_len).long()\n",
        "    text_segment = torch.zeros(batch_size, max_sent_len).long()\n",
        "    batch_image_tensors = torch.stack([row[1] for row in batch])\n",
        "    tweet_id_tensors = torch.zeros(batch_size, 1).long()\n",
        "    \n",
        "    # label_tensors = torch.cat([row[1] for row in batch]).long()\n",
        "    # if task_type=='multilabel':\n",
        "        # label_tensors = torch.stack([row[1] for row in batch])\n",
        "#     note there is a difference between stack and cat, refer link below if needed\n",
        "# https://stackoverflow.com/questions/54307225/whats-the-difference-between-torch-stack-and-torch-cat-functions\n",
        "    \n",
        "    for i, (row, length) in enumerate(zip(batch, lengths)):\n",
        "        text_tokens = row[0]\n",
        "        if(length>128-7-2):\n",
        "            length = 128-7-2\n",
        "        text_tensors[i, :length] = text_tokens\n",
        "        text_segment[i, :length] = 1#since images will constitute segment 0\n",
        "        text_attention_mask[i, :length]=1\n",
        "        tweet_id_tensors[i, 0]=row[2]\n",
        "    \n",
        "    return text_tensors, text_segment, text_attention_mask, batch_image_tensors, tweet_id_tensors"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroLei1K7M2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(label_name, no_of_classes, max_epochs, train_df, val_df, img_transformations, bert_tokenizer, vocab, gradient_accumulation_steps=1, patience=0):\n",
        "    \n",
        "    train_dataset = TextNImageDataset(train_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    val_dataset = TextNImageDataset(val_df, './train_images', label_name, img_transformations, bert_tokenizer, vocab, minority_class)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function_for_dataloader, drop_last=True)\n",
        "\n",
        "    model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "        print('Loaded previous model state successfully!')\n",
        "    except:\n",
        "        print('Starting fresh! Previous model state dict load unsuccessful')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if no_of_classes==1:\n",
        "        print('using '+str(chosen_criteria)+' loss')\n",
        "        criterion = chosen_criteria\n",
        "    optimizer = get_optimizer(model, train_dataset.__len__(), max_epochs=max_epochs, gradient_accumulation_steps=gradient_accumulation_steps)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", \n",
        "        patience=patience, \n",
        "        verbose=True, \n",
        "#         factor=args.lr_factor\n",
        "    )\n",
        "    if(torch.cuda.is_available()):\n",
        "        model=model.cuda()\n",
        "\n",
        "\n",
        "    start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
        "\n",
        "    print(\"Training..\")\n",
        "    for i_epoch in range(start_epoch, max_epochs):\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in tqdm.notebook.tqdm(train_loader, total=len(train_loader)):\n",
        "            loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
        "            # if gradient_accumulation_steps > 1:\n",
        "            #     loss = loss / gradient_accumulation_steps\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            global_step += 1\n",
        "            if global_step % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        metrics = model_eval(i_epoch, val_loader, model, criterion, no_of_classes, True)\n",
        "        print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
        "        print('Train Losses :', train_losses)\n",
        "        print(\"Val loss\", metrics['loss'])\n",
        "        # print(metrics['acc'])\n",
        "        # print(metrics['classification_report'])\n",
        "        print('Val auc roc', metrics['roc_auc_score'])\n",
        "        tuning_metric = ( metrics['roc_auc_score'])\n",
        "        scheduler.step(tuning_metric)\n",
        "        is_improvement = tuning_metric > best_metric\n",
        "        if is_improvement:\n",
        "            best_metric = tuning_metric\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "        \n",
        "        torch.save(model.state_dict(), './model_state_dict.pth')\n",
        "        print(f'Saved model state dict for epoch {i_epoch} ')\n",
        "        # if n_no_improve >= patience:\n",
        "        #     print(\"No improvement. Breaking out of loop.\")\n",
        "        #     break\n",
        "\n",
        "#     load_checkpoint(model, os.path.join(args.savedir, \"model_best.pt\"))\n",
        "#     model.eval()\n",
        "# #     for test_name, test_loader in test_loaders.items():\n",
        "#     test_metrics = model_eval(\n",
        "#         np.inf, val_loader, model, criterion, no_of_classes, store_preds=True\n",
        "#     )\n",
        "#     print(f\"Test - \", test_metrics['loss'])\n",
        "#     print(test_metrics['acc'])\n",
        "#     print(test_metrics['classification_report'])\n",
        "#     print(test_metrics['roc_auc_score'])\n",
        "\n",
        "#     torch.save(model.state_dict(), './modelv1.pth')\n",
        "    return model\n",
        "    # return model, test_metrics\n",
        "\n",
        "\n",
        "def model_forward_predict(i_epoch, model, criterion, batch):\n",
        "    txt, segment, mask, img, tweet_id= batch\n",
        "\n",
        "#         for param in model.enc.img_encoder.parameters():\n",
        "#             param.requires_grad = not freeze_img\n",
        "#         for param in model.enc.encoder.parameters():\n",
        "#             param.requires_grad = not freeze_txt\n",
        "    if(torch.cuda.is_available()):\n",
        "        txt, img = txt.cuda(), img.cuda()\n",
        "        mask, segment = mask.cuda(), segment.cuda()\n",
        "    out = model(txt, mask, segment, img)\n",
        "    # if(torch.cuda.is_available()):\n",
        "    #     tgt = tgt.cuda()\n",
        "    # loss = criterion(out*1.0, tgt.unsqueeze(1)*1.0)\n",
        "    return out, tweet_id\n",
        "\n",
        "\n",
        "def model_predict(dataloader, model, criterion, no_of_classes, store_preds=False):\n",
        "    with torch.no_grad():\n",
        "        losses, preds, tgts, tweet_ids = [], [], [], []\n",
        "        for batch in dataloader:\n",
        "            out, tweet_id = model_forward_predict(1, model, criterion, batch)\n",
        "            # losses.append(loss.item())\n",
        "            if no_of_classes==1:\n",
        "                pred = torch.sigmoid(out).cpu().detach().numpy()\n",
        "                # for i in range(pred.shape[0]):\n",
        "                #     if pred[i][0]>0.5:\n",
        "                #         pred[i][0]=1\n",
        "                #     else:\n",
        "                #         pred[i][0]=0\n",
        "            else:\n",
        "                pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "            # for i in range(4):\n",
        "            #     if(pred[i])\n",
        "            \n",
        "            # print('preddhd', pred)\n",
        "            # if pred > 0.5:\n",
        "            #     preds.append(1)\n",
        "            # else:\n",
        "            #     preds.append(0)\n",
        "\n",
        "            preds.append(pred)\n",
        "            # tgt = tgt.cpu().detach().numpy()\n",
        "            # tgts.append(tgt)\n",
        "            tweet_id = tweet_id.cpu().detach().numpy()\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "    # metrics = {\"loss\": np.mean(losses)}\n",
        "    # tgts = [l for sl in tgts for l in sl]\n",
        "    preds = [l for sl in preds for l in sl]\n",
        "    # for i in len(preds):\n",
        "    #     if preds[i]>0.5:\n",
        "    #         preds[i]=1\n",
        "    #     else:\n",
        "    #         preds[i]=0\n",
        "    tweet_ids = [l for sl in tweet_ids for l in sl]\n",
        "    # metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
        "    # metrics['classification_report'] = classification_report(tgts, preds)\n",
        "    # metrics['roc_auc_score'] = roc_auc_score(tgts, preds)\n",
        "\n",
        "    # if store_preds:\n",
        "    #     store_preds_to_disk(tweet_ids, preds, './')\n",
        "\n",
        "    return preds, tweet_ids"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEETPiGryzOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe2b78a9-68b1-42b2-813d-3d6a65bc6698"
      },
      "source": [
        "col_name = \"Generalized_Hate\"\n",
        "train_epochs = 3\n",
        "losses = [FocalLoss, DiceLoss, nn.BCEWithLogitsLoss]\n",
        "chosen_criteria = losses[0]()\n",
        "no_of_classes = 1\n",
        "print(str(chosen_criteria))\n",
        "minority_class = 1 # or 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FocalLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kABURr7vsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocab()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5z7hFf4D3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862,
          "referenced_widgets": [
            "2d401a7b56ed4939893179e16b4f6d0f",
            "0ac1a821b69640d6b5c717f99d8325be",
            "f1a8fed9402b4fc0a287e766e83fda65",
            "a782f3772c544b45b06074f7ffdd7820",
            "234a90eccde249ffbb0a2eebfbc47e95",
            "4b747defa2b24be9a751d40ffc100697",
            "4188c0756c4f46d1aff972de1e697792",
            "c9ccf8a74f0547778444d41084a993e4",
            "e4bf642263614a25a9c70a446b86001a",
            "781079382af44162a9a9c8de6775c33e",
            "631e0e9b25a74ff5880b2ce90772cc1b",
            "4b0bedff92374db6ac7ba577be59668a",
            "34c2fc235b844e359e674783102bbbed",
            "b8ed679a1f3e4bdd904616efa49401ad",
            "c4c444c501fb46f4899f369f1916f265",
            "14a527aae4624431ae5d4b11497d6ce4",
            "856c5666bdb24e4387dc29857403fb47",
            "7d1bb0af02e14abb8b6812e872f33474",
            "9b2544c912794572a71e15ff2b3bce75",
            "319df79ba5614ccd820314b4984eb7bb",
            "043603f5b7584fa382a7547c0ecf611d",
            "0f7d517cf5d84b858995adecb2b0943f",
            "b7f1bec0b96349ad8c9cdb75b2973b7a",
            "8642fe3db2ca40279eb09c318db05816",
            "6f1eb6a6f9fb46ccb1f5ceda3b053840",
            "db3a253ae9c74a649f149ca0057b07ff",
            "b01cc7d734984ac6972dc8a06444a7d7",
            "9f305762a36544a3bfa777276cf8c592",
            "e17c3fff296d4a9dbbd35e42329bf94c",
            "84883e78979742ff899dfdaf90eb5477",
            "5d52ac8c76814f6894b5f54bc24902d9",
            "a0da3068774842ed8df0a3ae0c7cc360"
          ]
        },
        "outputId": "9a303d42-03cf-4f08-d25e-ac8da8332ada"
      },
      "source": [
        "model = train(col_name, no_of_classes, train_epochs, train_df , val_df, img_transformations, bert_tokenizer, vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old data length : 6382\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 6710\n",
            "Old data length : 1596\n",
            "minority class is 1. Duplicating minority class data!\n",
            "New data length : 1702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d401a7b56ed4939893179e16b4f6d0f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fresh! Previous model state dict load unsuccessful\n",
            "using FocalLoss() loss\n",
            "Training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4bf642263614a25a9c70a446b86001a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1677.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0512\n",
            "Train Losses : [0.14035172760486603, 0.37193116545677185, 0.7138417959213257, 1.8466997146606445, 0.505464494228363, 1.6012463569641113, 1.3402514457702637, 0.4082871675491333, 0.24075525999069214, 0.19696460664272308, 0.27065229415893555, 0.14880387485027313, 0.11551708728075027, 0.19301746785640717, 0.2606574296951294, 0.1529109627008438, 0.12148351967334747, 0.08708969503641129, 0.12382733076810837, 0.14105530083179474, 0.12865211069583893, 0.08555344492197037, 0.060973890125751495, 0.34453192353248596, 0.04911381006240845, 0.04302876442670822, 0.2608028054237366, 0.02578503079712391, 0.02205159142613411, 0.017431456595659256, 0.011884181760251522, 0.00943478848785162, 0.008286593481898308, 0.006971144583076239, 0.07253667712211609, 0.006494481582194567, 0.09329243749380112, 0.0037163987290114164, 0.13037176430225372, 0.02667812816798687, 0.00797076802700758, 0.004790406208485365, 0.45747995376586914, 0.0686984583735466, 0.006729388143867254, 0.013075238093733788, 0.002332559321075678, 0.312114953994751, 0.006690305192023516, 0.05690045654773712, 0.008359046652913094, 0.002763208234682679, 0.0040549240075051785, 0.12280925363302231, 0.001990334130823612, 0.004425660241395235, 0.0020183713641017675, 0.0022525242529809475, 0.014261800795793533, 0.004059323109686375, 0.003010106272995472, 0.31395065784454346, 0.005720092914998531, 0.12881194055080414, 0.05292081832885742, 0.0036394265480339527, 0.00519515061751008, 0.008191917091608047, 0.44645997881889343, 0.6860226988792419, 0.0053199827671051025, 0.0066153486259281635, 0.03023006208240986, 0.008883560076355934, 0.006557703483849764, 0.0037451705429702997, 0.015217667445540428, 0.03348616883158684, 0.01561816781759262, 0.016801729798316956, 0.005131609737873077, 0.008601274341344833, 0.005478442646563053, 0.007500494364649057, 0.14558365941047668, 0.00707986718043685, 0.007760174106806517, 0.003364050993695855, 0.07988615334033966, 0.004091164562851191, 0.046556271612644196, 0.00469124736264348, 0.0032439350616186857, 0.3496994078159332, 0.004357536323368549, 0.6995545029640198, 0.0038428811822086573, 0.29072314500808716, 0.005171883851289749, 0.0646190196275711, 0.005144095979630947, 0.0045378077775239944, 0.003703185124322772, 0.00381680391728878, 0.04775127023458481, 0.005564469378441572, 0.004388983361423016, 0.08384406566619873, 0.008193557150661945, 0.031786538660526276, 0.006785138975828886, 0.14333584904670715, 0.21133708953857422, 0.008580969646573067, 0.007526843808591366, 0.010393595322966576, 0.008356492035090923, 0.006793777458369732, 0.006901852320879698, 0.018091972917318344, 0.09658079594373703, 0.010962226428091526, 0.009106989949941635, 0.011931175366044044, 0.010281752794981003, 0.013070246204733849, 0.010119743645191193, 0.005257716402411461, 0.00784219242632389, 0.00912139005959034, 0.0075475131161510944, 0.05027463659644127, 0.0715547725558281, 0.0041949511505663395, 0.3416752815246582, 0.0033810073509812355, 0.0032500913366675377, 0.07134976983070374, 0.08950124680995941, 0.006139261648058891, 0.0064658913761377335, 0.006606244947761297, 0.03933211788535118, 0.0032518170773983, 0.003961394540965557, 0.006228072103112936, 0.006344588007777929, 0.02086637169122696, 0.009260888211429119, 0.004273070953786373, 0.007762587629258633, 0.2929147183895111, 0.0038493280299007893, 0.0067304945550858974, 0.20710904896259308, 0.004151774570345879, 0.0024960145819932222, 0.0026698086876422167, 0.08289135992527008, 0.1959819346666336, 0.39047423005104065, 0.027753012254834175, 0.058235201984643936, 0.010424550622701645, 0.006284297909587622, 0.1654680073261261, 0.08315536379814148, 0.004883169662207365, 0.013991860672831535, 0.10181251913309097, 0.011775877326726913, 0.015048934146761894, 0.16552948951721191, 0.8611199855804443, 0.010319694876670837, 0.01657581329345703, 0.01690964214503765, 0.011292072013020515, 0.017703499644994736, 0.02143896371126175, 0.010014294646680355, 0.014788370579481125, 0.49332350492477417, 0.009429626166820526, 0.010661998763680458, 0.061758458614349365, 0.010961326770484447, 0.007347197271883488, 0.052319590002298355, 0.00728823384270072, 0.41647273302078247, 0.06845053285360336, 0.07033879309892654, 0.008250041864812374, 0.2844181954860687, 0.011800657026469707, 0.007619568612426519, 0.007897574454545975, 0.00878163892775774, 0.14004561305046082, 0.010179556906223297, 0.011890091933310032, 0.0076457723043859005, 0.0100666843354702, 0.006970904767513275, 0.006945288740098476, 0.0061493124812841415, 0.006556751672178507, 0.15298663079738617, 0.0056587085127830505, 0.006653474643826485, 0.0794442668557167, 0.005784706212580204, 0.007396090775728226, 0.11343806982040405, 0.004821673966944218, 0.005490787792950869, 0.1971885710954666, 0.19280317425727844, 0.0052248639985919, 0.16711096465587616, 0.005531055387109518, 0.34967994689941406, 0.006389839109033346, 0.007344696205109358, 0.08266392350196838, 0.008383999578654766, 0.007161307148635387, 0.007337664254009724, 0.008029730059206486, 0.19814558327198029, 0.010060759261250496, 0.009651439264416695, 0.007543346844613552, 0.009363160468637943, 0.007987369783222675, 0.007248043082654476, 0.13686765730381012, 0.10268823057413101, 0.08155474811792374, 0.007240890525281429, 0.1514299064874649, 0.009349130094051361, 0.008085490204393864, 0.008505010977387428, 0.008841552771627903, 0.13485929369926453, 0.0756642296910286, 0.009033981710672379, 0.008144166320562363, 0.09083463251590729, 0.0070872497744858265, 0.008193472400307655, 0.007357487920671701, 0.009401983581483364, 0.008501616306602955, 0.007321249693632126, 0.007834449410438538, 0.007566029671579599, 0.005789829418063164, 0.005619823466986418, 0.005170865450054407, 0.14743508398532867, 0.00518572423607111, 0.0068120406940579414, 0.0062815044075250626, 0.005398689769208431, 0.005761566571891308, 0.16103947162628174, 0.004806816577911377, 0.005544544663280249, 0.005196805112063885, 0.00458720326423645, 0.23861224949359894, 0.0037425372283905745, 0.004855932202190161, 0.003561026882380247, 0.004099226091057062, 0.13966389000415802, 0.1478603482246399, 0.0036299314815551043, 0.1793547123670578, 0.003499835031107068, 0.5211026668548584, 0.00420039938762784, 0.004852189216762781, 0.11695678532123566, 0.00655512185767293, 0.00620872899889946, 0.006579691078513861, 0.0065733627416193485, 0.006815364584326744, 0.0069892252795398235, 0.007345318328589201, 0.00729841273277998, 0.007910949178040028, 0.00729820691049099, 0.38721364736557007, 0.007547201123088598, 0.09266838431358337, 0.10263130813837051, 0.009174116887152195, 0.009987072087824345, 0.009363256394863129, 0.01058519259095192, 0.010271643288433552, 0.009884004481136799, 0.07446504384279251, 0.009623389691114426, 0.009184529073536396, 0.00968208909034729, 0.009100308641791344, 0.15257953107357025, 0.009252030402421951, 0.008113237097859383, 0.14462897181510925, 0.1617060899734497, 0.007625351659953594, 0.09429142624139786, 0.13197551667690277, 0.00768171576783061, 0.007963506504893303, 0.007826877757906914, 0.007681211922317743, 0.007377136033028364, 0.10649728029966354, 0.007157528307288885, 0.08241922408342361, 0.00667929369956255, 0.007098128087818623, 0.007389973383396864, 0.1703636795282364, 0.006501590367406607, 0.006724504288285971, 0.15812183916568756, 0.006240301765501499, 0.006236423272639513, 0.006139863282442093, 0.005936402827501297, 0.006020741071552038, 0.005967167671769857, 0.005512784700840712, 0.11870159953832626, 0.005349638871848583, 0.14191511273384094, 0.005502109881490469, 0.006047373171895742, 0.0054553719237446785, 0.005143801216036081, 0.005274008493870497, 0.13463468849658966, 0.11784975230693817, 0.0055967154912650585, 0.0048965285532176495, 0.11674711108207703, 0.005130755715072155, 0.0821477472782135, 0.10994711518287659, 0.09953131526708603, 0.0059227426536381245, 0.005991050973534584, 0.0059305899776518345, 0.006171003449708223, 0.005756167694926262, 0.005984653253108263, 0.16291482746601105, 0.006128866691142321, 0.005970976315438747, 0.00712746474891901, 0.007370070554316044, 0.006298871245235205, 0.23223178088665009, 0.006033364683389664, 0.005850255489349365, 0.09184302389621735, 0.005553020164370537, 0.006340062245726585, 0.005632483400404453, 0.005500519648194313, 0.005407427437603474, 0.005254351068288088, 0.005910941865295172, 0.004850342404097319, 0.004949911031872034, 0.006248422898352146, 0.0057283123023808, 0.004659595433622599, 0.004563299939036369, 0.004604599438607693, 0.1725403219461441, 0.004243827424943447, 0.004665483720600605, 0.003923003561794758, 0.003798041259869933, 0.003697954583913088, 0.003422896843403578, 0.0033085637260228395, 0.003666872624307871, 0.0031456889118999243, 0.003065203782171011, 0.0035554009955376387, 0.135101780295372, 0.16669917106628418, 0.31913694739341736, 0.003670596517622471, 0.0036509917117655277, 0.0041632573120296, 0.004286644980311394, 0.004808715078979731, 0.00590150011703372, 0.004967135842889547, 0.09180746972560883, 0.005050289444625378, 0.10847344994544983, 0.006186177022755146, 0.006506668403744698, 0.006658398080617189, 0.006095378194004297, 0.10416246205568314, 0.005903930403292179, 0.0065451678819954395, 0.11120603233575821, 0.007463053334504366, 0.006786796264350414, 0.06761091947555542, 0.006259523332118988, 0.006993549410253763, 0.006279993802309036, 0.007239812519401312, 0.006951889023184776, 0.00680824788287282, 0.007008866872638464, 0.0070140487514436245, 0.006272113416343927, 0.007105318363755941, 0.006709951441735029, 0.11911266297101974, 0.004615272860974073, 0.005080997943878174, 0.005958348046988249, 0.004510306287556887, 0.00436046440154314, 0.004234377760440111, 0.004144430160522461, 0.004484756384044886, 0.004096871707588434, 0.003886282444000244, 0.003365042619407177, 0.19294697046279907, 0.004321172367781401, 0.0033048854675143957, 0.5951346158981323, 0.07290719449520111, 0.004239285364747047, 0.004271205049008131, 0.0043413653038442135, 0.005483648739755154, 0.004903893917798996, 0.1347876638174057, 0.0055572097189724445, 0.00537071842700243, 0.005560663528740406, 0.0057344138622283936, 0.005410317797213793, 0.005790217779576778, 0.007187293842434883, 0.005937628448009491, 0.008418590761721134, 0.12295494228601456, 0.005918198265135288, 0.06864083558320999, 0.005541480146348476, 0.005343134980648756, 0.007287173066288233, 0.004896600265055895, 0.005587718449532986, 0.004877428058534861, 0.0052644312381744385, 0.004972934257239103, 0.05482131615281105, 0.1129191517829895, 0.005233804229646921, 0.0964876338839531, 0.004864141345024109, 0.004804625641554594, 0.006636128295212984, 0.004456967581063509, 0.0056207687593996525, 0.06119093671441078, 0.10196321457624435, 0.004785712342709303, 0.005442710127681494, 0.144706130027771, 0.16772033274173737, 0.005250449758023024, 0.007183087058365345, 0.009140944108366966, 0.07913690060377121, 0.12738245725631714, 0.006174433045089245, 0.005797470919787884, 0.006938120350241661, 0.006970703136175871, 0.005291245877742767, 0.007148773409426212, 0.008505387231707573, 0.19652433693408966, 0.007019628304988146, 0.005235319957137108, 0.0066020190715789795, 0.12468120455741882, 0.00557082099840045, 0.006345890462398529, 0.007739591877907515, 0.004871336277574301, 0.07463345676660538, 0.08878193795681, 0.5319069027900696, 0.005114993546158075, 0.005658876616507769, 0.1742475926876068, 0.00635513523593545, 0.0076223136857151985, 0.007119736634194851, 0.40261155366897583, 0.00896820891648531, 0.009101836942136288, 0.05416746810078621, 0.11398497223854065, 0.010215766727924347, 0.013181526213884354, 0.012163895182311535, 0.012798062525689602, 0.013224857859313488, 0.011360668577253819, 0.01285877451300621, 0.013734063133597374, 0.009959620423614979, 0.011863810941576958, 0.011139597743749619, 0.11977476626634598, 0.009767222218215466, 0.009163969196379185, 0.007872715592384338, 0.008893942460417747, 0.007841555401682854, 0.0642937496304512, 0.09822148084640503, 0.00739049119874835, 0.007282781880348921, 0.007661973126232624, 0.04865624010562897, 0.006640311796218157, 0.008006230928003788, 0.005929937586188316, 0.05966684967279434, 0.005747031420469284, 0.00582945765927434, 0.005185216665267944, 0.09422013908624649, 0.0062038530595600605, 0.005579980555921793, 0.004851961042732, 0.0056075709871947765, 0.0690746158361435, 0.005073125474154949, 0.0050233276560902596, 0.005088253878057003, 0.00452736672013998, 0.2778189778327942, 0.0053539699874818325, 0.0048063453286886215, 0.0043551130220294, 0.0038911551237106323, 0.07558061927556992, 0.004095158539712429, 0.00459160003811121, 0.004606302827596664, 0.11444780975580215, 0.1182546392083168, 0.004693513736128807, 0.005004024598747492, 0.13884375989437103, 0.08198563754558563, 0.004583848640322685, 0.0059349425137043, 0.006222537253051996, 0.0049270810559391975, 0.005232084542512894, 0.005387085024267435, 0.005784577690064907, 0.004917430691421032, 0.2105831801891327, 0.005625659134238958, 0.06441809982061386, 0.14453332126140594, 0.007416539825499058, 0.006949674803763628, 0.09819933772087097, 0.005587962921708822, 0.006375382654368877, 0.18861925601959229, 0.07631898671388626, 0.006047024391591549, 0.006627444177865982, 0.005945557728409767, 0.3108772337436676, 0.006028035189956427, 0.006788054946810007, 0.007915080524981022, 0.006867919582873583, 0.008882676251232624, 0.009277704171836376, 0.00734263751655817, 0.22405894100666046, 0.00776111101731658, 0.00865253247320652, 0.00943917129188776, 0.011107510887086391, 0.05015919730067253, 0.09230588376522064, 0.00809377059340477, 0.008351773954927921, 0.007458082865923643, 0.3511698842048645, 0.16764789819717407, 0.05399834364652634, 0.008703602477908134, 0.008788279257714748, 0.008553072810173035, 0.009014328010380268, 0.31931644678115845, 0.1317644864320755, 0.009924477897584438, 0.01276750210672617, 0.015960130840539932, 0.07540980726480484, 0.013514373451471329, 0.012907271273434162, 0.012960699386894703, 0.05620227009057999, 0.011863760650157928, 0.013867560774087906, 0.012070145457983017, 0.04357219487428665, 0.012160011567175388, 0.012238509953022003, 0.0112147256731987, 0.012324326671659946, 0.011498000472784042, 0.011546991765499115, 0.012016218155622482, 0.009280157275497913, 0.007688568439334631, 0.007594018243253231, 0.007396681234240532, 0.008340053260326385, 0.27270081639289856, 0.005826163571327925, 0.00698506273329258, 0.005842241458594799, 0.005410521756857634, 0.006026416085660458, 0.005790413822978735, 0.004854927770793438, 0.004588245879858732, 0.004823160357773304, 0.0038017062470316887, 0.0041588470339775085, 0.0033925259485840797, 0.003761288244277239, 0.0036589568480849266, 0.00307425856590271, 0.10837715119123459, 0.0027386813890188932, 0.0026403027586638927, 0.00306233623996377, 0.002823487389832735, 0.002688162261620164, 0.002681456273421645, 0.1184011697769165, 0.18016521632671356, 0.002383097307756543, 0.0029197975527495146, 0.0032075606286525726, 0.0033138790167868137, 0.13950859010219574, 0.0025820424780249596, 0.6238397359848022, 0.003235697979107499, 0.0034478690940886736, 0.29281115531921387, 0.00402824766933918, 0.07601946592330933, 0.005140554625540972, 0.005897462833672762, 0.006526835262775421, 0.06519977748394012, 0.007369742263108492, 0.11632578819990158, 0.008285781368613243, 0.009149504825472832, 0.01025381963700056, 0.010216177441179752, 0.10821186006069183, 0.010094919241964817, 0.011219835840165615, 0.010182165540754795, 0.01054384931921959, 0.010138150304555893, 0.012884384021162987, 0.15004320442676544, 0.10503872483968735, 0.009810369461774826, 0.009582038968801498, 0.10608559846878052, 0.0929521843791008, 0.010548126883804798, 0.01071721501648426, 0.012294488027691841, 0.008410542272031307, 0.011840103194117546, 0.008145967498421669, 0.008357517421245575, 0.08773596584796906, 0.17496025562286377, 0.007332340814173222, 0.374612420797348, 0.009127458557486534, 0.008196692913770676, 0.008966412395238876, 0.007837288081645966, 0.19171345233917236, 0.48758628964424133, 0.011242840439081192, 0.009304766543209553, 0.011590026319026947, 0.010827974416315556, 0.010570096783339977, 0.12022531032562256, 0.08466386049985886, 0.010718787088990211, 0.12971824407577515, 0.011297503486275673, 0.01065758429467678, 0.010792043060064316, 0.0107426093891263, 0.010731840506196022, 0.010806412436068058, 0.12106721103191376, 0.01094033382833004, 0.009589538909494877, 0.009815971367061138, 0.36056846380233765, 0.009090864099562168, 0.009207763709127903, 0.009759115986526012, 0.1164066269993782, 0.1471479833126068, 0.0095727713778615, 0.11798424273729324, 0.00962059199810028, 0.11067142337560654, 0.009958813898265362, 0.010071848519146442, 0.011018548160791397, 0.010080364532768726, 0.05647944658994675, 0.010048944503068924, 0.009420489892363548, 0.009119486436247826, 0.009823442436754704, 0.009071575477719307, 0.008307160809636116, 0.008434426039457321, 0.00787864439189434, 0.007577124051749706, 0.09486870467662811, 0.006894703954458237, 0.007261618040502071, 0.006799426395446062, 0.006507602985948324, 0.006106565240770578, 0.0058031463995575905, 0.005646073259413242, 0.0056251282803714275, 0.005195568315684795, 0.005513114854693413, 0.1337631642818451, 0.004862544592469931, 0.14691783487796783, 0.004872523248195648, 0.37485557794570923, 0.13468711078166962, 0.005837087985128164, 0.005363935604691505, 0.7524833679199219, 0.07954240590333939, 0.007788006216287613, 0.14793087542057037, 0.10974303632974625, 0.134027898311615, 0.3789841830730438, 0.09272844344377518, 0.1033424660563469, 0.01865963265299797, 0.09464935213327408, 0.020392509177327156, 0.02162657491862774, 0.022733265534043312, 0.023303965106606483, 0.023484038189053535, 0.023968057706952095, 0.10559912025928497, 0.02378573827445507, 0.10966216772794724, 0.11812297999858856, 0.0833624005317688, 0.021194957196712494, 0.020595358684659004, 0.09849587082862854, 0.020238680765032768, 0.019540399312973022, 0.018580162897706032, 0.017250018194317818, 0.016665445640683174, 0.01682422310113907, 0.09287643432617188, 0.08037624508142471, 0.013623164035379887, 0.012617416679859161, 0.012428282760083675, 0.01194462925195694, 0.11637641489505768, 0.0111614428460598, 0.010094333440065384, 0.009502135217189789, 0.009159253910183907, 0.0088078947737813, 0.008346314541995525, 0.12999281287193298, 0.007720818743109703, 0.0076635149307549, 0.10695115476846695, 0.0066913762129843235, 0.09703812003135681, 0.4300680458545685, 0.006993787828832865, 0.0069336071610450745, 0.007198534905910492, 0.0074341255240142345, 0.007428598590195179, 0.007594391703605652, 0.007325521670281887, 0.007694670464843512, 0.07068084925413132, 0.007652307860553265, 0.00724215991795063, 0.008069515228271484, 0.007915630005300045, 0.00798124074935913, 0.007737406529486179, 0.09085897356271744, 0.006688016466796398, 0.4811209440231323, 0.007495860103517771, 0.007503202185034752, 0.007235382683575153, 0.007191136479377747, 0.007470311596989632, 0.007590801455080509, 0.0075657181441783905, 0.008332216180860996, 0.0075716557912528515, 0.007608044892549515, 0.0733717530965805, 0.007287757005542517, 0.06719612330198288, 0.007315441966056824, 0.007553491275757551, 0.00722942128777504, 0.0068902382627129555, 0.0066188122145831585, 0.006607996299862862, 0.0067819757387042046, 0.006802916992455721, 0.005956102628260851, 0.4582771956920624, 0.006428244523704052, 0.00652601383626461, 0.006410032510757446, 0.0066856578923761845, 0.006679846439510584, 0.006408224813640118, 0.14816054701805115, 0.13060957193374634, 0.006396948359906673, 0.006519712973386049, 0.006767923012375832, 0.006792822852730751, 0.006447477266192436, 0.4643031358718872, 0.0951172262430191, 0.007270131725817919, 0.007620498072355986, 0.007981248199939728, 0.008273247629404068, 0.0081520676612854, 0.008560200221836567, 0.008853464387357235, 0.09186550229787827, 0.008299806155264378, 0.008810002356767654, 0.008737464435398579, 0.008352400735020638, 0.10349159687757492, 0.007983836345374584, 0.007858389988541603, 0.008022482506930828, 0.007688358426094055, 0.13175992667675018, 0.007795693818479776, 0.007332049775868654, 0.007021644152700901, 0.00683868583291769, 0.006924079731106758, 0.006572226528078318, 0.07306547462940216, 0.006318008527159691, 0.006394220981746912, 0.006197950802743435, 0.005957287736237049, 0.005987993907183409, 0.005665503907948732, 0.005528963636606932, 0.0055535403080284595, 0.14883194863796234, 0.005229605827480555, 0.1350460797548294, 0.00496405316516757, 0.004916544072329998, 0.0047622364945709705, 0.004945477936416864, 0.004859872628003359, 0.004668357782065868, 0.1556083858013153, 0.004490794613957405, 0.004431619308888912, 0.00453190365806222, 0.004370733164250851, 0.004381402395665646, 0.14190270006656647, 0.004305787850171328, 0.004263373091816902, 0.004410814493894577, 0.0042295814491808414, 0.004108374007046223, 0.15283749997615814, 0.004050909541547298, 0.004156310111284256, 0.004124605096876621, 0.00398992421105504, 0.003933110740035772, 0.004126154817640781, 0.08085844665765762, 0.0039681666530668736, 0.003862694138661027, 0.0039381710812449455, 0.0038196861278265715, 0.0038518235087394714, 0.0038515375927090645, 0.09552479535341263, 0.003673933446407318, 0.1077316477894783, 0.003797710407525301, 0.0037348230835050344, 0.0038827601820230484, 0.46136465668678284, 0.0039998493157327175, 0.3939426839351654, 0.005102517548948526, 0.005428299307823181, 0.1441449075937271, 0.1178409531712532, 0.007112208288162947, 0.007698383182287216, 0.008076611906290054, 0.07564897835254669, 0.008973829448223114, 0.11556912958621979, 0.1370723694562912, 0.009862547740340233, 0.13249675929546356, 0.10856962949037552, 0.09748384356498718, 0.13166016340255737, 0.10531698912382126, 0.012080463580787182, 0.11368639767169952, 0.012949121184647083, 0.012575390748679638, 0.012896660715341568, 0.012866727076470852, 0.012899167835712433, 0.10899479687213898, 0.012515679001808167, 0.012182191014289856, 0.011854445561766624, 0.011643164791166782, 0.01176399365067482, 0.09238801896572113, 0.010850252583622932, 0.01047384925186634, 0.010035359300673008, 0.00987530592828989, 0.24662356078624725, 0.00964580662548542, 0.009399418719112873, 0.08684775978326797, 0.09288235753774643, 0.009674753993749619, 0.009640534408390522, 0.009428653866052628, 0.110064797103405, 0.009301424957811832, 0.00928827840834856, 0.009114236570894718, 0.07412390410900116, 0.009053112007677555, 0.008575696498155594, 0.09770072996616364, 0.008703750558197498, 0.008205891586840153, 0.008276774547994137, 0.008070310577750206, 0.007829447276890278, 0.007422929164022207, 0.29855480790138245, 0.08344786614179611, 0.008182338438928127, 0.008208043873310089, 0.13046695291996002, 0.008147298358380795, 0.009057714603841305, 0.008507789112627506, 0.008781777694821358, 0.008717957884073257, 0.009122662246227264, 0.009106727316975594, 0.008345097303390503, 0.007721645757555962, 0.008394598960876465, 0.007465452421456575, 0.0071167550049722195, 0.10779307782649994, 0.006725241430103779, 0.008194646798074245, 0.09356484562158585, 0.006552477367222309, 0.17282947897911072, 0.006667336914688349, 0.0070757195353507996, 0.006803170312196016, 0.006112872622907162, 0.006921764463186264, 0.10518351942300797, 0.005871670786291361, 0.005767845548689365, 0.0059723639860749245, 0.006471587345004082, 0.005799505859613419, 0.13571321964263916, 0.005609361920505762, 0.005463499575853348, 0.1417924165725708, 0.11776245385408401, 0.0054546925239264965, 0.005349195096641779, 0.11114604771137238, 0.005320348776876926, 0.005405867472290993, 0.08467257022857666, 0.0057628159411251545, 0.08580595254898071, 0.006087549962103367, 0.1308148354291916, 0.006277758628129959, 0.006050824653357267, 0.006188563071191311, 0.006111289840191603, 0.005696517415344715, 0.006063212174922228, 0.0055749500170350075, 0.005501344334334135, 0.005508312024176121, 0.13630078732967377, 0.45173484086990356, 0.005767993163317442, 0.006368489004671574, 0.006010128650814295, 0.09706534445285797, 0.006616593338549137, 0.12028395384550095, 0.09901408851146698, 0.10674632340669632, 0.007455496117472649, 0.007671681232750416, 0.007963527925312519, 0.007889840751886368, 0.00877619069069624, 0.16425105929374695, 0.008049175143241882, 0.09781638532876968, 0.008276887238025665, 0.008106840774416924, 0.008257400244474411, 0.008081956766545773, 0.008208719082176685, 0.09050159156322479, 0.008619919419288635, 0.007863257080316544, 0.0083271823823452, 0.007746819872409105, 0.007966605946421623, 0.0073792943730950356, 0.007796889171004295, 0.0069043077528476715, 0.0068176924251019955, 0.006480940151959658, 0.006322923116385937, 0.006243756040930748, 0.006152653601020575, 0.005861023906618357, 0.005475434474647045, 0.10910148918628693, 0.005543261766433716, 0.0056284405291080475, 0.005170819349586964, 0.0049080136232078075, 0.005172471050173044, 0.004686555825173855, 0.0045314752496778965, 0.004384225700050592, 0.004351498559117317, 0.0042224423959851265, 0.3509542644023895, 0.1616916060447693, 0.004764039069414139, 0.004729495383799076, 0.0051405467092990875, 0.14009198546409607, 0.005268042907118797, 0.005351910833269358, 0.005354393273591995, 0.0054764943197369576, 0.0056281560100615025, 0.005624821875244379, 0.06282981485128403, 0.09510961920022964, 0.006142201367765665, 0.005724198184907436, 0.005878189112991095, 0.006513381376862526, 0.07199029624462128, 0.10061711817979813, 0.0063944910652935505, 0.0061769564636051655, 0.008599016815423965, 0.561974287033081, 0.0071386308409273624, 0.006943913642317057, 0.007810340728610754, 0.15258356928825378, 0.007672271691262722, 0.008846055716276169, 0.007428328040987253, 0.21727587282657623, 0.07409924268722534, 0.00857699103653431, 0.07417795062065125, 0.008424008265137672, 0.11421141773462296, 0.008306879550218582, 0.0091062281280756, 0.008389292284846306, 0.15038570761680603, 0.008518735878169537, 0.008643900975584984, 0.008976257406175137, 0.008729794062674046, 0.008331350050866604, 0.008251672610640526, 0.008519917726516724, 0.007657499052584171, 0.007933903485536575, 0.008739427663385868, 0.007964675314724445, 0.16306088864803314, 0.007000932935625315, 0.006573026534169912, 0.006404964718967676, 0.11506279557943344, 0.11088952422142029, 0.11955957114696503, 0.12140890955924988, 0.006296572741121054, 0.006660466082394123, 0.5029724836349487, 0.0068672639317810535, 0.00717892637476325, 0.0075158835388720036, 0.007776955142617226, 0.007869149558246136, 0.008049098774790764, 0.007976527325809002, 0.11802785843610764, 0.11005207896232605, 0.008305593393743038, 0.0086139515042305, 0.008745472878217697, 0.008784922771155834, 0.008170686662197113, 0.0887020155787468, 0.13105648756027222, 0.0083938492462039, 0.008161736652255058, 0.008458521217107773, 0.13205726444721222, 0.007862275466322899, 0.007790459785610437, 0.13042142987251282, 0.007816260680556297, 0.007738014217466116, 0.12403785437345505, 0.007728545926511288, 0.06859146803617477, 0.12058772146701813, 0.0077369678765535355, 0.007772612851113081, 0.007713565602898598, 0.007810416165739298, 0.00746531318873167, 0.0076145282946527, 0.007723987102508545, 0.0070648519322276115, 0.007724754977971315, 0.007129218894988298, 0.006716309580951929, 0.006817327346652746, 0.0065431068651378155, 0.006573955528438091, 0.00604024576023221, 0.005754274781793356, 0.006049466319382191, 0.3881497085094452, 0.006406627129763365, 0.10566819459199905, 0.005868856329470873, 0.10025235265493393, 0.006462186109274626, 0.09973664581775665, 0.006471182685345411, 0.0076003652065992355, 0.007134109269827604, 0.007287569344043732, 0.16529442369937897, 0.007050729356706142, 0.007475269492715597, 0.006805570796132088, 0.007147554773837328, 0.007261035032570362, 0.0066985758021473885, 0.006872038822621107, 0.11493824422359467, 0.16548538208007812, 0.1473834365606308, 0.7562246322631836, 0.00770053593441844, 0.008377937600016594, 0.008950597606599331, 0.009989292360842228, 0.010079930536448956, 0.010617954656481743, 0.011426088400185108, 0.012320843525230885, 0.011944843456149101, 0.011928226798772812, 0.08912751078605652, 0.011980832554399967, 0.012336239218711853, 0.12833015620708466, 0.012604822404682636, 0.0122922258451581, 0.012582874856889248, 0.011577867902815342, 0.010869454592466354, 0.010675973258912563, 0.10146009176969528, 0.08853728324174881, 0.009866436943411827, 0.1294453889131546, 0.09904105216264725, 0.009779902175068855, 0.08550902456045151, 0.009404884651303291, 0.34756508469581604, 0.009841250255703926, 0.01049457024782896, 0.010405070148408413, 0.010328768752515316, 0.14293573796749115, 0.010502662509679794, 0.09416406601667404, 0.010873041115701199, 0.1316903680562973, 0.010972363874316216, 0.010615791194140911, 0.010715646669268608, 0.010356731712818146, 0.010561862029135227, 0.010228237137198448, 0.010411228984594345, 0.009509948082268238, 0.08605923503637314, 0.08438372611999512, 0.009013892151415348, 0.10813962668180466, 0.009236701764166355, 0.00902497861534357, 0.008574052713811398, 0.00814075581729412, 0.008251744322478771, 0.007833380252122879, 0.00749068520963192, 0.0074148173443973064, 0.1253470778465271, 0.08877786248922348, 0.007062364835292101, 0.0068021053448319435, 0.006646489258855581, 0.0064762914553284645, 0.10203500092029572, 0.006373682990670204, 0.006592541467398405, 0.006682268343865871, 0.006062538828700781, 0.0061821043491363525, 0.0062437504529953, 0.10298733413219452, 0.005748335737735033, 0.15500827133655548, 0.005604741629213095, 0.00564325088635087, 0.0053755235858261585, 0.005642724689096212, 0.1492982655763626, 0.005454422440379858, 0.005199810490012169, 0.005411038640886545, 0.005324336234480143, 0.004991831257939339, 0.005152952391654253, 0.005094532854855061, 0.42609119415283203, 0.004967036657035351, 0.09171409159898758, 0.0056545971892774105, 0.005749866832047701, 0.006226203870028257, 0.006166115868836641, 0.005951134953647852, 0.09413319826126099, 0.0062376465648412704, 0.10736257582902908, 0.006436889059841633, 0.10297097265720367, 0.006766600999981165, 0.00694257440045476, 0.1451960653066635, 0.00684092054143548, 0.006832323037087917, 0.006890567019581795, 0.006800538394600153, 0.00684056943282485, 0.006698616314679384, 0.007445728871971369, 0.006697317119687796, 0.12928742170333862, 0.006598671432584524, 0.006457437761127949, 0.006647712085396051, 0.006247210782021284, 0.0063202036544680595, 0.006101817358285189, 0.005922931712120771, 0.1300528645515442, 0.006044706329703331, 0.0055862474255263805, 0.00563846668228507, 0.005396714434027672, 0.005436320323497057, 0.005267120897769928, 0.0679866224527359, 0.005479799117892981, 0.11006961762905121, 0.11612346023321152, 0.1161433607339859, 0.11891812831163406, 0.0052388450130820274, 0.005416059400886297, 0.00573974521830678, 0.005536307115107775, 0.005534794181585312, 0.005709891673177481, 0.005576374940574169, 0.005649677477777004, 0.005484314635396004, 0.005333598703145981, 0.005539059638977051, 0.005629340186715126, 0.14181190729141235, 0.005175226368010044, 0.005054214037954807, 0.005382147151976824, 0.0050376541912555695, 0.005002777557820082, 0.0048981900326907635, 0.08780121058225632, 0.1676393747329712, 0.1208883598446846, 0.0049518863670527935, 0.13668115437030792, 0.1209951713681221, 0.005375961307436228, 0.005267180036753416, 0.005635850131511688, 0.005356290843337774, 0.12478192895650864, 0.005801967345178127, 0.005786852911114693, 0.12674830853939056, 0.006141939200460911, 0.13098080456256866, 0.006059199571609497, 0.1534077674150467, 0.006469005718827248, 0.006261989939957857, 0.0060938941314816475, 0.006200670730322599, 0.006461104843765497, 0.006495293229818344, 0.10680129379034042, 0.13354657590389252, 0.006210553925484419, 0.1257144808769226, 0.09916507452726364, 0.006420055869966745, 0.006551404017955065, 0.32559725642204285, 0.007579196244478226, 0.13283520936965942, 0.008172613568603992, 0.1169760450720787, 0.15383920073509216, 0.008912185207009315, 0.11899702996015549, 0.009711929596960545, 0.010223466902971268, 0.00997525081038475, 0.3478552997112274, 0.010756070725619793, 0.011272035539150238, 0.011377896182239056, 0.01167698297649622, 0.09234430640935898, 0.012266762554645538, 0.012262317351996899, 0.012542971409857273, 0.01222517155110836, 0.012512258253991604, 0.012743180617690086, 0.012063195928931236, 0.01144374068826437, 0.011293931864202023, 0.011178654618561268, 0.011080202646553516, 0.01055994350463152, 0.010152640752494335, 0.009673237800598145, 0.009273285046219826, 0.008754896931350231, 0.1175559014081955, 0.00835287757217884, 0.008044269867241383, 0.007886412553489208, 0.007748876698315144, 0.0073921047151088715, 0.12424613535404205, 0.13764545321464539, 0.006637606769800186, 0.0066009946167469025, 0.006546736229211092, 0.0066351755522191525, 0.10433267056941986, 0.10597213357686996, 0.12580452859401703, 0.006131540518254042, 0.11173490434885025, 0.006275031715631485, 0.00647536339238286, 0.006201148498803377, 0.29711639881134033, 0.006449630483984947, 0.303128719329834, 0.11215173453092575, 0.08816717565059662, 0.008528389967978, 0.009593754075467587, 0.009869069792330265, 0.3525625169277191, 0.0106389494612813, 0.012131274677813053, 0.012200689874589443, 0.01253875344991684, 0.013658002950251102, 0.01329727377742529, 0.013976708054542542, 0.013901963829994202, 0.1422836184501648, 0.013519493862986565, 0.11284779757261276, 0.013218866661190987, 0.013025636784732342, 0.01335199922323227, 0.07412948459386826, 0.09113705158233643, 0.012197245843708515, 0.012331932783126831, 0.012398041784763336, 0.011974511668086052, 0.01135184708982706, 0.0110676484182477, 0.010506520979106426, 0.010123206302523613, 0.1537841409444809, 0.010000540874898434, 0.009257263503968716, 0.009060047566890717, 0.009000669233500957, 0.008405845612287521, 0.00807266402989626, 0.008139406330883503, 0.0075453463941812515, 0.007971474900841713, 0.007370439358055592, 0.1629163771867752, 0.007017334457486868, 0.006358291953802109, 0.006366281770169735, 0.006571590900421143, 0.005816365126520395, 0.005742295645177364, 0.09825856238603592, 0.1345607489347458, 0.1105450689792633, 0.005421170499175787, 0.11349223554134369, 0.005348563194274902, 0.005624041892588139, 0.005369084887206554, 0.0054997606202960014, 0.12999524176120758, 0.005537781864404678, 0.005306214094161987, 0.005348515696823597, 0.132881760597229, 0.13889048993587494, 0.005732269957661629, 0.005411818623542786, 0.1041046679019928, 0.005708393640816212, 0.14361587166786194, 0.1341966837644577, 0.005946834105998278, 0.005888208281248808, 0.11704042553901672, 0.006011877674609423, 0.00617867149412632, 0.1414649486541748, 0.0970003604888916, 0.10823046416044235, 0.006951670628041029, 0.00680320430546999, 0.1250050961971283, 0.007031995803117752, 0.007165293209254742, 0.007242160849273205, 0.007083549629896879, 0.007200067862868309, 0.007296609226614237, 0.007002186495810747, 0.09513073414564133, 0.11105053871870041, 0.08477455377578735, 0.09886744618415833, 0.007147719152271748, 0.007137259468436241, 0.007251803297549486, 0.09619348496198654, 0.007536463439464569, 0.0073059904389083385, 0.007168353535234928, 0.007319370284676552, 0.13680525124073029, 0.007016564253717661, 0.0984010100364685, 0.007222031708806753, 0.007174487225711346, 0.007072921376675367, 0.007077779155224562, 0.0069122714921832085, 0.006700458936393261, 0.006659957114607096, 0.006699077319353819, 0.006396234966814518, 0.00630863755941391, 0.006303220987319946, 0.006195101421326399, 0.005976782646030188, 0.00590005936101079, 0.005595123395323753, 0.005585737060755491, 0.10895434767007828, 0.0051036435179412365, 0.09643849730491638, 0.005089280195534229, 0.005079829599708319, 0.004957375582307577, 0.004793280269950628, 0.004662222694605589, 0.004696464631706476, 0.004587983712553978, 0.004430121276527643, 0.004645287990570068, 0.00429238798096776, 0.0044417292810976505, 0.004057855345308781, 0.003989914432168007, 0.0039894673973321915, 0.004146302584558725, 0.003858911106362939, 0.0036597554571926594, 0.12400276958942413, 0.0034911800175905228, 0.11353632062673569, 0.11367007344961166, 0.09675955772399902, 0.12595593929290771, 0.00376068614423275, 0.11528095602989197, 0.003910087514668703, 0.004186463076621294, 0.004196276422590017, 0.004350003786385059, 0.10250406712293625, 0.08790134638547897, 0.11726658046245575, 0.0046569122932851315, 0.15190863609313965, 0.0051651992835104465, 0.005330794490873814, 0.0053929528221488, 0.005476168356835842, 0.12835274636745453, 0.1081128790974617, 0.11091213673353195, 0.005937967449426651]\n",
            "Val loss 0.05378448044990792\n",
            "Val auc roc 0.4861398503789502\n",
            "Saved model state dict for epoch 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "856c5666bdb24e4387dc29857403fb47",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1677.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0424\n",
            "Train Losses : [0.006160060875117779, 0.09490014612674713, 0.10898087173700333, 0.10133994370698929, 0.11195577681064606, 0.006824813783168793, 0.007052377797663212, 0.13048963248729706, 0.007547806482762098, 0.007943161763250828, 0.007500171661376953, 0.10100752860307693, 0.06645388901233673, 0.007756042759865522, 0.007898618467152119, 0.14735692739486694, 0.00828095804899931, 0.00852896086871624, 0.008541177958250046, 0.008362402208149433, 0.07238392531871796, 0.09838815778493881, 0.008281026966869831, 0.06978761404752731, 0.008240623399615288, 0.008171428926289082, 0.008237635716795921, 0.007992313243448734, 0.008156642317771912, 0.40385743975639343, 0.009374408051371574, 0.00829483661800623, 0.008196616545319557, 0.009248103946447372, 0.009068065322935581, 0.4125407934188843, 0.008640758693218231, 0.009523539803922176, 0.009409550577402115, 0.009979824535548687, 0.07310379296541214, 0.010562471114099026, 0.01084056869149208, 0.08129676431417465, 0.010136746801435947, 0.010042518377304077, 0.010642965324223042, 0.11956903338432312, 0.009869430214166641, 0.011657753959298134, 0.009800480678677559, 0.08705433458089828, 0.01056994590908289, 0.010271085426211357, 0.009756906889379025, 0.009853609837591648, 0.12400990724563599, 0.008421489037573338, 0.009033103473484516, 0.009434615261852741, 0.05372609943151474, 0.008489953354001045, 0.009993304498493671, 0.31090807914733887, 0.009155765175819397, 0.009348342195153236, 0.008287779055535793, 0.1170852780342102, 0.008696336299180984, 0.008238335140049458, 0.13097864389419556, 0.008134705014526844, 0.11371610313653946, 0.008357173763215542, 0.14185267686843872, 0.00812085997313261, 0.15114659070968628, 0.010020065121352673, 0.008275403641164303, 0.1492658257484436, 0.008819959126412868, 0.009438158012926579, 0.008244429714977741, 0.09660591930150986, 0.11060259491205215, 0.00911873858422041, 0.008394917473196983, 0.00827291700989008, 0.008850766345858574, 0.13394474983215332, 0.007929237559437752, 0.12253818660974503, 0.007724422961473465, 0.09137973189353943, 0.00894961692392826, 0.007952230051159859, 0.11988890916109085, 0.09419219195842743, 0.007623882032930851, 0.007862593047320843, 0.09232086688280106, 0.00880686566233635, 0.007756756152957678, 0.007937086746096611, 0.007784932851791382, 0.008072874508798122, 0.007817373611032963, 0.007255799137055874, 0.00738288089632988, 0.00699797784909606, 0.006757946684956551, 0.16698868572711945, 0.006605240050703287, 0.006911635398864746, 0.006775209214538336, 0.006639792583882809, 0.006663832813501358, 0.38075557351112366, 0.0062127262353897095, 0.4531170427799225, 0.32350674271583557, 0.008434700779616833, 0.008203448727726936, 0.00891069881618023, 0.009714190848171711, 0.11080696433782578, 0.011873900890350342, 0.1813054084777832, 0.013212387450039387, 0.34293073415756226, 0.09105725586414337, 0.37820395827293396, 0.016122907400131226, 0.016864113509655, 0.1823522001504898, 0.01908823661506176, 0.017562847584486008, 0.12666648626327515, 0.02018531784415245, 0.09090863168239594, 0.019650625064969063, 0.019871873781085014, 0.020056242123246193, 0.11003171652555466, 0.08036284148693085, 0.018883757293224335, 0.019951580092310905, 0.018218327313661575, 0.018379462882876396, 0.0178862065076828, 0.01685652881860733, 0.016970591619610786, 0.01563967764377594, 0.015319043770432472, 0.015624666586518288, 0.013799336738884449, 0.013339068740606308, 0.01354924775660038, 0.012749881483614445, 0.09927421808242798, 0.011317561380565166, 0.010507162660360336, 0.1454549878835678, 0.06470342725515366, 0.009611043147742748, 0.009296616539359093, 0.11705263704061508, 0.00847605336457491, 0.008294796571135521, 0.09610448777675629, 0.008038033731281757, 0.08572249859571457, 0.00825907476246357, 0.007442120462656021, 0.008001045323908329, 0.10079801827669144, 0.007226431742310524, 0.006913292221724987, 0.007911378517746925, 0.0070592607371509075, 0.006769471801817417, 0.1603986769914627, 0.0063908882439136505, 0.006541271228343248, 0.11759717017412186, 0.006218702998012304, 0.006043965928256512, 0.09849813580513, 0.14722684025764465, 0.006323294714093208, 0.08408354222774506, 0.0064428760670125484, 0.006160285789519548, 0.006125219631940126, 0.006367785390466452, 0.006208234466612339, 0.07753966003656387, 0.00612290482968092, 0.005950125399976969, 0.41037696599960327, 0.00653810752555728, 0.09930656105279922, 0.006816742941737175, 0.006782061420381069, 0.007085121236741543, 0.12566567957401276, 0.007302870042622089, 0.007869953289628029, 0.10920239239931107, 0.007714161649346352, 0.007724079303443432, 0.12859085202217102, 0.00779962632805109, 0.08384671062231064, 0.008109298534691334, 0.007941754534840584, 0.008143053390085697, 0.13142208755016327, 0.10785368084907532, 0.09969660639762878, 0.008123597130179405, 0.008173933252692223, 0.008668779395520687, 0.00836828164756298, 0.008060183376073837, 0.00815496500581503, 0.008260002359747887, 0.1521005481481552, 0.00806822907179594, 0.00809069350361824, 0.007880555465817451, 0.12408149242401123, 0.007906484417617321, 0.007615159265697002, 0.007236870471388102, 0.007145098876208067, 0.16687503457069397, 0.007138160988688469, 0.10966259241104126, 0.13172291219234467, 0.1069016233086586, 0.007260337006300688, 0.007044618017971516, 0.007179925683885813, 0.007133122067898512, 0.007107112091034651, 0.006899546831846237, 0.13012008368968964, 0.0069190505892038345, 0.00758921355009079, 0.007133362349122763, 0.1126246303319931, 0.09437564015388489, 0.11964783072471619, 0.007291940972208977, 0.006743851117789745, 0.11658164858818054, 0.006612525321543217, 0.10600990056991577, 0.1702902764081955, 0.15513671934604645, 0.00737422751262784, 0.007313874084502459, 0.007100522518157959, 0.11256430298089981, 0.1141778752207756, 0.0073075564578175545, 0.007290735840797424, 0.0073986416682600975, 0.007545938715338707, 0.007604822050780058, 0.007349570281803608, 0.007303518243134022, 0.007256462238729, 0.13729502260684967, 0.007071876898407936, 0.007296718191355467, 0.007153401151299477, 0.00697189848870039, 0.006717718206346035, 0.12787356972694397, 0.11409535259008408, 0.006562001537531614, 0.006495315581560135, 0.006428197026252747, 0.006444910075515509, 0.006313918624073267, 0.006232799030840397, 0.006198067683726549, 0.006047836970537901, 0.005845138803124428, 0.005835510324686766, 0.0058804587461054325, 0.12380433827638626, 0.12268457561731339, 0.005551363341510296, 0.10753902047872543, 0.005524196662008762, 0.005422218702733517, 0.005437996704131365, 0.0054262010380625725, 0.0053480686619877815, 0.0054537891410291195, 0.1291475147008896, 0.0052176001481711864, 0.005294009577482939, 0.11584724485874176, 0.005208582151681185, 0.08989416062831879, 0.005259467754513025, 0.005306677892804146, 0.005231608636677265, 0.005317389499396086, 0.005292978603392839, 0.00523343775421381, 0.005074142478406429, 0.005145809147506952, 0.005125283729285002, 0.0050866673700511456, 0.005046588834375143, 0.004752672277390957, 0.3909699022769928, 0.004818991292268038, 0.00522735808044672, 0.005127862561494112, 0.005271796137094498, 0.005339271388947964, 0.13095805048942566, 0.005552810151129961, 0.005468909628689289, 0.005531164351850748, 0.005591261200606823, 0.00595287187024951, 0.00554994959384203, 0.0055329445749521255, 0.11958780884742737, 0.005539451260119677, 0.0940198227763176, 0.005912595894187689, 0.12092002481222153, 0.005648215301334858, 0.0056455605663359165, 0.005723502486944199, 0.36153164505958557, 0.105288065969944, 0.006308319512754679, 0.006817017216235399, 0.007060342933982611, 0.006890968419611454, 0.00706173712387681, 0.1030135452747345, 0.007519586943089962, 0.089523546397686, 0.1288335770368576, 0.008048450574278831, 0.009107418358325958, 0.007957800291478634, 0.007894661277532578, 0.008321241475641727, 0.05654587969183922, 0.008227652870118618, 0.007875621318817139, 0.008600391447544098, 0.00824793428182602, 0.008102677762508392, 0.007476926315575838, 0.00827823206782341, 0.007639126852154732, 0.0076537542045116425, 0.00842201802879572, 0.13078396022319794, 0.0070232488214969635, 0.006597749888896942, 0.0064641921781003475, 0.006980720441788435, 0.0060817888006567955, 0.0061022392474114895, 0.005973814986646175, 0.006813897285610437, 0.11295098066329956, 0.00570724718272686, 0.005747354589402676, 0.005406889133155346, 0.005226715002208948, 0.005273710936307907, 0.005083866883069277, 0.005010976456105709, 0.004922807682305574, 0.004786426201462746, 0.005005821585655212, 0.004437102936208248, 0.004591664299368858, 0.11382634937763214, 0.00423192884773016, 0.004457347560673952, 0.004046163987368345, 0.11708807200193405, 0.1299278438091278, 0.12943828105926514, 0.004308079369366169, 0.14886070787906647, 0.004381183069199324, 0.004490267019718885, 0.004774743691086769, 0.004513822961598635, 0.004690235480666161, 0.12031394988298416, 0.004529444966465235, 0.4435517489910126, 0.004888366907835007, 0.005438928492367268, 0.0054583195596933365, 0.3558834493160248, 0.006441769655793905, 0.006634862627834082, 0.006854770239442587, 0.00739811547100544, 0.007917261682450771, 0.008045105263590813, 0.008010810241103172, 0.008073801174759865, 0.009110583923757076, 0.00833952333778143, 0.2183309942483902, 0.008609851822257042, 0.009035021997988224, 0.009532548487186432, 0.009549083188176155, 0.009706312790513039, 0.08548813313245773, 0.009511780925095081, 0.07114484906196594, 0.009544002823531628, 0.009934956207871437, 0.0662919208407402, 0.00975765660405159, 0.2990545332431793, 0.010028290562331676, 0.09110657125711441, 0.011179788038134575, 0.011574176140129566, 0.010809794999659061, 0.011143608018755913, 0.1433931589126587, 0.013347317464649677, 0.012024838477373123, 0.011408284306526184, 0.011264909990131855, 0.01109994761645794, 0.010172517970204353, 0.01003231480717659, 0.10683782398700714, 0.009482473134994507, 0.1385343074798584, 0.01100947055965662, 0.1552758663892746, 0.11230036616325378, 0.14874964952468872, 0.008903739042580128, 0.07427999377250671, 0.010650422424077988, 0.3966417610645294, 0.009637766517698765, 0.15402084589004517, 0.010631250217556953, 0.09970995038747787, 0.10511140525341034, 0.27870282530784607, 0.010875385254621506, 0.012426643632352352, 0.012381134554743767, 0.012232616543769836, 0.012430616654455662, 0.013688607141375542, 0.12577678263187408, 0.3317074775695801, 0.10997534543275833, 0.097043976187706, 0.014035461470484734, 0.12087304145097733, 0.015024657361209393, 0.015132543630897999, 0.5374999642372131, 0.095049649477005, 0.06266788393259048, 0.01898101717233658, 0.019095780327916145, 0.019553914666175842, 0.09290175139904022, 0.02087390422821045, 0.11662192642688751, 0.020897643640637398, 0.11132126301527023, 0.021428484469652176, 0.022859768941998482, 0.02068246155977249, 0.2577251195907593, 0.021029604598879814, 0.020369570702314377, 0.020083438605070114, 0.019760193303227425, 0.020280981436371803, 0.019562188535928726, 0.019015314057469368, 0.018057262524962425, 0.0179844219237566, 0.01770363561809063, 0.017326971516013145, 0.015579977072775364, 0.0154237886890769, 0.1328490972518921, 0.013765044510364532, 0.013213805854320526, 0.0128484470769763, 0.012648473493754864, 0.011657850816845894, 0.10950527340173721, 0.011559993028640747, 0.010663566179573536, 0.15164706110954285, 0.009907691739499569, 0.010089286603033543, 0.009283416904509068, 0.12475540488958359, 0.008699563331902027, 0.1412201225757599, 0.008258435875177383, 0.008123727515339851, 0.008466687984764576, 0.007958942092955112, 0.008249539881944656, 0.11513011157512665, 0.007308670785278082, 0.007730665151029825, 0.0072881863452494144, 0.007078127469867468, 0.007040617987513542, 0.006710388697683811, 0.006610240787267685, 0.006306841969490051, 0.08321452885866165, 0.006038142368197441, 0.00608580419793725, 0.09964607656002045, 0.005851940251886845, 0.0056541431695222855, 0.005586997605860233, 0.005623531527817249, 0.07808803021907806, 0.00537645909935236, 0.005272028502076864, 0.005861402489244938, 0.005124441348016262, 0.005502080544829369, 0.005245163571089506, 0.005184802692383528, 0.004841887857764959, 0.004733327776193619, 0.004790568258613348, 0.004704238846898079, 0.09997391700744629, 0.004944032058119774, 0.004612288903445005, 0.004381473641842604, 0.004235847387462854, 0.16703534126281738, 0.09839744120836258, 0.15764527022838593, 0.0044441064819693565, 0.0804297998547554, 0.004492891952395439, 0.004753215704113245, 0.004520778078585863, 0.004846985451877117, 0.004496987909078598, 0.004446346312761307, 0.004668056033551693, 0.00450810045003891, 0.004667545668780804, 0.1883992999792099, 0.0043987007811665535, 0.004716959316283464, 0.1700630635023117, 0.004546470940113068, 0.004629889037460089, 0.11417445540428162, 0.10571432113647461, 0.004830036778002977, 0.09917385876178741, 0.46569809317588806, 0.00512038916349411, 0.0053944834508001804, 0.005737024825066328, 0.0060440958477556705, 0.10663478821516037, 0.006256868131458759, 0.12188940495252609, 0.15313495695590973, 0.006919538136571646, 0.0071192458271980286, 0.0073663112707436085, 0.007627455517649651, 0.007606419734656811, 0.007720475550740957, 0.0770697295665741, 0.12912213802337646, 0.008011828176677227, 0.1284462809562683, 0.008172951638698578, 0.007858175784349442, 0.007945635356009007, 0.10883340984582901, 0.12129122763872147, 0.11924402415752411, 0.1300026923418045, 0.008155910298228264, 0.008599777705967426, 0.00824650563299656, 0.008593292906880379, 0.10788778215646744, 0.008377088233828545, 0.008538955822587013, 0.008398935198783875, 0.008156674914062023, 0.008099643513560295, 0.008334104903042316, 0.008026976138353348, 0.007885053753852844, 0.007609446067363024, 0.007575306110084057, 0.007379606366157532, 0.13430503010749817, 0.007384373806416988, 0.007081160321831703, 0.006930455099791288, 0.0067558917216956615, 0.007067461498081684, 0.006804532837122679, 0.006781751289963722, 0.0062666661106050014, 0.006204698234796524, 0.00596120348200202, 0.005918491166085005, 0.005803817417472601, 0.08636989444494247, 0.005549082066863775, 0.005373693071305752, 0.005396614782512188, 0.005384655669331551, 0.005374750588089228, 0.11886933445930481, 0.3785083293914795, 0.005113096442073584, 0.005362487398087978, 0.005477874539792538, 0.0058996230363845825, 0.005795361008495092, 0.005626081023365259, 0.1450953185558319, 0.0064425840973854065, 0.005974551197141409, 0.005890398286283016, 0.005904306657612324, 0.005805475637316704, 0.005821130704134703, 0.08633723855018616, 0.15492242574691772, 0.005904457066208124, 0.11424341052770615, 0.006093522999435663, 0.006116450298577547, 0.006185656413435936, 0.0060014971531927586, 0.09151659905910492, 0.14602093398571014, 0.006366446614265442, 0.006216344889253378, 0.10298990458250046, 0.006479206029325724, 0.11901616305112839, 0.00626204302534461, 0.0063366093672811985, 0.0064154984429478645, 0.006395537871867418, 0.006426861509680748, 0.006485828198492527, 0.1141725406050682, 0.09868621826171875, 0.09396519511938095, 0.006532435771077871, 0.006492206361144781, 0.006573088001459837, 0.006350971758365631, 0.08102535456418991, 0.006782411132007837, 0.09993753582239151, 0.11343470960855484, 0.006855054292827845, 0.006662680767476559, 0.006563322152942419, 0.006602645386010408, 0.006734788883477449, 0.006581886205822229, 0.006590227596461773, 0.006416098680347204, 0.37113600969314575, 0.137457475066185, 0.006640888284891844, 0.10960867255926132, 0.12672773003578186, 0.007358917500823736, 0.007963351905345917, 0.007571167778223753, 0.008035863749682903, 0.007836192846298218, 0.007810506504029036, 0.00810452364385128, 0.0843312069773674, 0.008145513944327831, 0.00783122144639492, 0.007785164285451174, 0.00822575856000185, 0.007861819118261337, 0.007556736934930086, 0.00787451770156622, 0.007313080597668886, 0.0075800493359565735, 0.007452136371284723, 0.007025517988950014, 0.006778332870453596, 0.006852538324892521, 0.006580382119864225, 0.006425553932785988, 0.006457195617258549, 0.11927025765180588, 0.11710866540670395, 0.06936907768249512, 0.005914872977882624, 0.006117541808634996, 0.0060694050043821335, 0.09318318963050842, 0.005943897645920515, 0.006100745871663094, 0.006106206215918064, 0.00607869541272521, 0.0055932290852069855, 0.005786298308521509, 0.005468789488077164, 0.005658797919750214, 0.005446980707347393, 0.005460343323647976, 0.005101579241454601, 0.1276898980140686, 0.005151249468326569, 0.0053955307230353355, 0.12867537140846252, 0.005088480189442635, 0.10099545866250992, 0.1343718022108078, 0.18506774306297302, 0.005533080548048019, 0.005346273072063923, 0.00529722822830081, 0.005552220623940229, 0.37778881192207336, 0.005465668626129627, 0.14497804641723633, 0.006061567924916744, 0.16029466688632965, 0.0063180928118526936, 0.11161444336175919, 0.006877622101455927, 0.007138425018638372, 0.18620125949382782, 0.12194862961769104, 0.007483345456421375, 0.007698549423366785, 0.007809387519955635, 0.008105961605906487, 0.008130096830427647, 0.008090210147202015, 0.00883430801331997, 0.008024211041629314, 0.007868289016187191, 0.00784256774932146, 0.09242077171802521, 0.11232618987560272, 0.007923613302409649, 0.007859637960791588, 0.0077421958558261395, 0.0873745009303093, 0.11421173065900803, 0.007424172479659319, 0.007680381648242474, 0.007596277631819248, 0.007417147513478994, 0.10057906061410904, 0.007236331235617399, 0.00727832829579711, 0.007533129304647446, 0.11115182936191559, 0.0992090106010437, 0.11587310582399368, 0.007032644469290972, 0.007236038334667683, 0.007006754633039236, 0.0074154892936348915, 0.007114733569324017, 0.10241042077541351, 0.10675018280744553, 0.007200616877526045, 0.007123064249753952, 0.007060757372528315, 0.006853611208498478, 0.00680639548227191, 0.00676096323877573, 0.006755008827894926, 0.006468673702329397, 0.006511345040053129, 0.10907215625047684, 0.00655699335038662, 0.006312050390988588, 0.006098682060837746, 0.006032686680555344, 0.14434608817100525, 0.005978541914373636, 0.09269428253173828, 0.005886883474886417, 0.005827054847031832, 0.005957374349236488, 0.005919046234339476, 0.1011265367269516, 0.005672906991094351, 0.005642126314342022, 0.005643250420689583, 0.0054689678363502026, 0.10441876947879791, 0.005478270817548037, 0.005447964649647474, 0.15319573879241943, 0.005391424056142569, 0.12489638477563858, 0.09366537630558014, 0.005572378635406494, 0.005730180069804192, 0.0057814037427306175, 0.005843300838023424, 0.35925787687301636, 0.005782339721918106, 0.006007332354784012, 0.0060950075276196, 0.006308511830866337, 0.006483166944235563, 0.3835752606391907, 0.13417284190654755, 0.007091861683875322, 0.007434382103383541, 0.008378487080335617, 0.007808866444975138, 0.00824704673141241, 0.008294660598039627, 0.08261080831289291, 0.008496674709022045, 0.008749687112867832, 0.008848284371197224, 0.00858732033520937, 0.008516864851117134, 0.00858832336962223, 0.008649115450680256, 0.0084615433588624, 0.12367210537195206, 0.008426353335380554, 0.008472033776342869, 0.008128870278596878, 0.008116760291159153, 0.007831296883523464, 0.12248602509498596, 0.09387147426605225, 0.173078715801239, 0.08457732200622559, 0.00773784751072526, 0.007876072078943253, 0.007460310589522123, 0.007444850634783506, 0.007670963183045387, 0.0073989988304674625, 0.0072267246432602406, 0.10809051990509033, 0.007165034767240286, 0.07764226943254471, 0.007138408720493317, 0.10008454322814941, 0.006966388784348965, 0.00709249172359705, 0.007131146267056465, 0.006778400857001543, 0.006997755728662014, 0.006782871205359697, 0.006720534525811672, 0.14823758602142334, 0.00681960629299283, 0.12936170399188995, 0.0063368892297148705, 0.006265587173402309, 0.006369207054376602, 0.0064979661256074905, 0.0061851744540035725, 0.006173670757561922, 0.005966161843389273, 0.09275228530168533, 0.13714054226875305, 0.005887892562896013, 0.15345637500286102, 0.07826294004917145, 0.006034187972545624, 0.005882051307708025, 0.006204323843121529, 0.006126428488641977, 0.7107360363006592, 0.13105741143226624, 0.006872613914310932, 0.007439735345542431, 0.007364329416304827, 0.007668072823435068, 0.008188710547983646, 0.008386041037738323, 0.13393396139144897, 0.10261951386928558, 0.00907906610518694, 0.009100292809307575, 0.00902640726417303, 0.009722704999148846, 0.12529633939266205, 0.009911893866956234, 0.009291051886975765, 0.10891839116811752, 0.010552995838224888, 0.009794016368687153, 0.00910673663020134, 0.1257028579711914, 0.008985976688563824, 0.10348920524120331, 0.13365760445594788, 0.00903414934873581, 0.00913937482982874, 0.12703759968280792, 0.009115448221564293, 0.009274736046791077, 0.30603131651878357, 0.009308467619121075, 0.10363484174013138, 0.13322237133979797, 0.00952978990972042, 0.009821737185120583, 0.009745685383677483, 0.010102408938109875, 0.01010904461145401, 0.010397296398878098, 0.009872292168438435, 0.009680765680968761, 0.00969478115439415, 0.009668453596532345, 0.00947460439056158, 0.009366645477712154, 0.009128059260547161, 0.00940121989697218, 0.009073355235159397, 0.135138139128685, 0.00859756488353014, 0.13705694675445557, 0.1311095952987671, 0.008484847843647003, 0.008219005540013313, 0.11721870303153992, 0.12127813696861267, 0.008052458055317402, 0.0083934860303998, 0.007970493286848068, 0.09777301549911499, 0.007836217060685158, 0.007782910950481892, 0.007909848354756832, 0.0078510707244277, 0.007747378200292587, 0.1182733103632927, 0.007521576713770628, 0.007474534213542938, 0.0933184027671814, 0.08378265053033829, 0.09541007876396179, 0.007272571790963411, 0.0072641693986952305, 0.007358524017035961, 0.007359534036368132, 0.007036000024527311, 0.10878860950469971, 0.007033584639430046, 0.10094928741455078, 0.0072250752709805965, 0.10058365762233734, 0.00696732709184289, 0.006939207669347525, 0.006960323080420494, 0.006803419440984726, 0.006817249581217766, 0.0067698219791054726, 0.11749949306249619, 0.006618454586714506, 0.11875098943710327, 0.1188015267252922, 0.006596795283257961, 0.11602436006069183, 0.006548431236296892, 0.006558882538229227, 0.13027699291706085, 0.006599138490855694, 0.08786727488040924, 0.006856083869934082, 0.006710297428071499, 0.0065912287682294846, 0.006739865522831678, 0.006753464229404926, 0.006502960808575153, 0.006418679375201464, 0.006454583257436752, 0.006357858423143625, 0.006337616592645645, 0.0063247946090996265, 0.006092126946896315, 0.005918778479099274, 0.09305237233638763, 0.005776731297373772, 0.0059267692267894745, 0.0056914533488452435, 0.0057626748457551, 0.005568730179220438, 0.146978497505188, 0.005483695771545172, 0.005375593435019255, 0.005618798080831766, 0.005309215281158686, 0.005263078026473522, 0.005410885438323021, 0.00523850042372942, 0.0051626404747366905, 0.004980774130672216, 0.005023978650569916, 0.1280849128961563, 0.004907811991870403, 0.0046900599263608456, 0.004637809470295906, 0.004623115994036198, 0.004507402889430523, 0.004581179469823837, 0.00452445587143302, 0.004350493662059307, 0.004367436282336712, 0.0042777941562235355, 0.004501232877373695, 0.004107558634132147, 0.004037355538457632, 0.0040549119003117085, 0.14202895760536194, 0.003990871366113424, 0.10425636172294617, 0.1412254124879837, 0.00415321160107851, 0.004054253455251455, 0.004453228320926428, 0.10128290206193924, 0.004187722224742174, 0.004171336069703102, 0.004415114410221577, 0.004196065478026867, 0.004337175749242306, 0.0041223312728106976, 0.14631226658821106, 0.1319672167301178, 0.10287271440029144, 0.13211284577846527, 0.0043428014032542706, 0.1773187220096588, 0.0047925785183906555, 0.004989508539438248, 0.1029590368270874, 0.005084990058094263, 0.005147718824446201, 0.09452448785305023, 0.005198723170906305, 0.0050836848095059395, 0.005390996113419533, 0.005286393687129021, 0.005420350003987551, 0.0053423321805894375, 0.00541425496339798, 0.005803647916764021, 0.0052544730715453625, 0.005777344573289156, 0.005199484061449766, 0.005145790986716747, 0.005207610782235861, 0.14821606874465942, 0.005238056648522615, 0.005183626897633076, 0.005219237878918648, 0.00496970908716321, 0.004798184148967266, 0.004974029492586851, 0.004945151973515749, 0.12426777929067612, 0.004813377279788256, 0.004869773052632809, 0.004795213229954243, 0.0941862016916275, 0.09146010130643845, 0.005040406249463558, 0.004732639063149691, 0.1610063910484314, 0.10233648866415024, 0.11478328704833984, 0.11915434151887894, 0.1338856816291809, 0.5074612498283386, 0.005402015056461096, 0.15338444709777832, 0.00605271989479661, 0.07042640447616577, 0.1139402911067009, 0.0069836219772696495, 0.007124484516680241, 0.007325960323214531, 0.008139939047396183, 0.10986164212226868, 0.007960421033203602, 0.1168457493185997, 0.1124764233827591, 0.008738826960325241, 0.3873128294944763, 0.008968932554125786, 0.009732760488986969, 0.11196939647197723, 0.009794678539037704, 0.010686071589589119, 0.010144074447453022, 0.01115046814084053, 0.010697010904550552, 0.01061839610338211, 0.08716608583927155, 0.01072653103619814, 0.15541741251945496, 0.011612514965236187, 0.010517075657844543, 0.010568463243544102, 0.010200772434473038, 0.010912078432738781, 0.16092561185359955, 0.11444419622421265, 0.010470621287822723, 0.010000559501349926, 0.009945081546902657, 0.11464545130729675, 0.1597461849451065, 0.009483483619987965, 0.009487872011959553, 0.009525381959974766, 0.009394621476531029, 0.009060315787792206, 0.009171765297651291, 0.12746068835258484, 0.008673833683133125, 0.008731575682759285, 0.11714749783277512, 0.008604812435805798, 0.009094865061342716, 0.008422470651566982, 0.008180595003068447, 0.008027547039091587, 0.00785827822983265, 0.09440475702285767, 0.4242728650569916, 0.00795736350119114, 0.007926968857645988, 0.008219773881137371, 0.11750371754169464, 0.008421380072832108, 0.008211835287511349, 0.009043016470968723, 0.08556126803159714, 0.09745538979768753, 0.008218967355787754, 0.008360560983419418, 0.00831859651952982, 0.0942174643278122, 0.008721398189663887, 0.008441566489636898, 0.008150892332196236, 0.008265153504908085, 0.008176181465387344, 0.008135685697197914, 0.008176127448678017, 0.008091599680483341, 0.0076190331019461155, 0.0076243155635893345, 0.007372002582997084, 0.0073385280556976795, 0.007124277763068676, 0.007090799976140261, 0.007179433945566416, 0.006751884240657091, 0.006809557322412729, 0.006473243236541748, 0.11676481366157532, 0.006322280969470739, 0.006617751903831959, 0.006245446857064962, 0.005919269751757383, 0.005814863834530115, 0.005664236843585968, 0.10241147130727768, 0.005545139778405428, 0.08875327557325363, 0.005444609094411135, 0.0054230703972280025, 0.005348417442291975, 0.00533844530582428, 0.409697026014328, 0.00544710410758853, 0.005502365529537201, 0.0057734898291528225, 0.005748771131038666, 0.12412052601575851, 0.006051687523722649, 0.006028574425727129, 0.006277758162468672, 0.09755714237689972, 0.1478695422410965, 0.006400215905159712, 0.006308663170784712, 0.0067694042809307575, 0.06646353006362915, 0.00653319014236331, 0.00632919417694211, 0.08700654655694962, 0.006366189569234848, 0.006571563892066479, 0.006497745867818594, 0.006696169264614582, 0.006450706627219915, 0.006305869203060865, 0.006282430607825518, 0.006165873724967241, 0.006089024245738983, 0.006251916289329529, 0.005970762576907873, 0.006264165509492159, 0.006213813554495573, 0.00580534478649497, 0.39808496832847595, 0.006045664194971323, 0.07921519875526428, 0.0875103622674942, 0.006670213770121336, 0.09015636146068573, 0.006222932133823633, 0.006542767398059368, 0.0063863638788461685, 0.0067723034881055355, 0.006482197903096676, 0.0874994769692421, 0.1409606635570526, 0.0067886048927903175, 0.006921985652297735, 0.006809798534959555, 0.12392451614141464, 0.006997480057179928, 0.006973956245929003, 0.1009233370423317, 0.006914404686540365, 0.12642070651054382, 0.10409771651029587, 0.007104467134922743, 0.007011634763330221, 0.0075203548185527325, 0.11615025997161865, 0.007199157029390335, 0.007428443990647793, 0.09351883083581924, 0.007140215020626783, 0.007450663018971682, 0.076013945043087, 0.12556539475917816, 0.16794395446777344, 0.007315559312701225, 0.3292335271835327, 0.11794757843017578, 0.1316346824169159, 0.008359632454812527, 0.008367838338017464, 0.008926826529204845, 0.00876554660499096, 0.008901780471205711, 0.12027377635240555, 0.009651020169258118, 0.1156068965792656, 0.10122071206569672, 0.10576201230287552, 0.009645412676036358, 0.009954175911843777, 0.010105757042765617, 0.009643180295825005, 0.010078493505716324, 0.07773735374212265, 0.009843428619205952, 0.00953213032335043, 0.07050595432519913, 0.13669632375240326, 0.009809466078877449, 0.009358638897538185, 0.009720627218484879, 0.009122046642005444, 0.00943619105964899, 0.009108110330998898, 0.008838552981615067, 0.008913897909224033, 0.008636384271085262, 0.10576178133487701, 0.008295095525681973, 0.008176370523869991, 0.11471451818943024, 0.008382966741919518, 0.007790670730173588, 0.00776401674374938, 0.007660954724997282, 0.007705226074904203, 0.08683009445667267, 0.007548634894192219, 0.007405915297567844, 0.10734057426452637, 0.007041280623525381, 0.007016908843070269, 0.00697320606559515, 0.0067894901148974895, 0.0067209783010184765, 0.10303325206041336, 0.006591701414436102, 0.0064969975501298904, 0.00649552745744586, 0.006375134456902742, 0.12356488406658173, 0.006138667464256287, 0.006595327984541655, 0.006178474053740501, 0.1366318017244339, 0.006059605628252029, 0.005998566746711731, 0.005853819660842419, 0.005907793063670397, 0.1190137192606926, 0.005926875397562981, 0.0058441790752112865, 0.0056799473240971565, 0.005593002308160067, 0.005467790644615889, 0.005607612431049347, 0.11187788099050522, 0.005353864748030901, 0.0055780536495149136, 0.005371700506657362, 0.0052163260988891125, 0.005243093706667423, 0.005381686147302389, 0.14286556839942932, 0.0053361086174845695, 0.10191456228494644, 0.005046358332037926, 0.09202928096055984, 0.10745906829833984, 0.005017215386033058, 0.12319543957710266, 0.0051031881012022495, 0.10193681716918945, 0.005564059130847454, 0.0052776518277823925, 0.36233028769493103, 0.005550367292016745, 0.005657501053065062, 0.005862862803041935, 0.0061163813807070255, 0.006080297287553549, 0.0062230355106294155, 0.006419810000807047, 0.006395525764673948, 0.006482528522610664, 0.09382285922765732, 0.006485681980848312, 0.006592163350433111, 0.006654251366853714, 0.0065486980602145195, 0.006492312997579575, 0.09324724227190018, 0.006767856422811747, 0.006694923620671034, 0.12200862914323807, 0.006248791702091694, 0.00665398919954896, 0.006606950890272856, 0.006808989681303501, 0.006141101475805044, 0.11407846957445145, 0.0063646393828094006, 0.1271064132452011, 0.0061447350308299065, 0.006299406290054321, 0.13123010098934174, 0.006213497836142778, 0.09696386754512787, 0.2815781235694885, 0.006329862866550684, 0.0065316869877278805, 0.11854719370603561, 0.007276137825101614, 0.0072020674124360085, 0.006962963379919529, 0.007529424503445625, 0.007250096648931503, 0.007265824358910322, 0.007251535542309284, 0.00746613834053278, 0.007578226737678051, 0.007550423964858055, 0.1425780951976776, 0.007398409303277731, 0.006947295740246773, 0.007305881008505821, 0.16800494492053986, 0.007307919207960367, 0.10153298825025558, 0.0070453668013215065, 0.12784194946289062, 0.006943786982446909, 0.006983703933656216, 0.13309530913829803, 0.00719650462269783, 0.007077681832015514, 0.007318335119634867, 0.0837768018245697, 0.00685235345736146, 0.0069437590427696705, 0.0068932524882256985, 0.00709640933200717, 0.006807937752455473, 0.37002187967300415, 0.006833902560174465, 0.007159859407693148, 0.007097773253917694, 0.007108938414603472, 0.09243815392255783, 0.4004248082637787, 0.10112152248620987, 0.008053908124566078, 0.007896225899457932, 0.00871614646166563, 0.00856040883809328, 0.008465193212032318, 0.008692678064107895, 0.00887212622910738, 0.008768982253968716, 0.00873527117073536, 0.008865256793797016, 0.102785125374794, 0.008690405637025833, 0.008668667636811733, 0.09688448905944824, 0.11582476645708084, 0.008616372011601925, 0.11601510643959045, 0.00925611425191164, 0.008726616390049458, 0.06825881451368332, 0.008562014438211918, 0.008694453164935112, 0.008456794545054436, 0.14051900804042816, 0.008810987696051598, 0.00830559991300106, 0.00822050217539072, 0.14035426080226898, 0.11660647392272949, 0.008109990507364273, 0.00814126804471016, 0.008022959344089031, 0.09377135336399078, 0.007905744947493076, 0.007965784519910812, 0.007845655083656311, 0.007791902869939804, 0.007746581453830004, 0.007567457389086485, 0.007510533090680838, 0.007515454199165106, 0.007433847524225712, 0.0072454484179615974, 0.00714979600161314, 0.007125692442059517, 0.006892889738082886, 0.134666308760643, 0.0067718238569796085, 0.006611218210309744, 0.11833351850509644, 0.00638679089024663, 0.006361396983265877, 0.09427842497825623, 0.1175927221775055, 0.006237476132810116, 0.10513085126876831, 0.0062428852543234825, 0.006297027226537466, 0.10205360502004623, 0.09494499117136002, 0.006326780654489994, 0.006342194974422455, 0.006305191200226545, 0.006342118605971336, 0.12641647458076477, 0.006302257068455219, 0.006295814178884029, 0.006351201329380274, 0.11070812493562698, 0.13957810401916504, 0.0063746920786798, 0.0063097006641328335, 0.006361980456858873, 0.006410994566977024, 0.006445769686251879, 0.14373284578323364, 0.006339720916002989, 0.0063404059037566185, 0.006323052570223808, 0.006190462037920952, 0.00622789841145277, 0.11421818286180496, 0.006222230847924948, 0.1245504692196846, 0.10947278887033463, 0.006055835634469986, 0.006062475498765707, 0.0061144959181547165, 0.00601366488263011, 0.13557778298854828, 0.0060549830086529255, 0.006184599827975035, 0.11092250049114227, 0.006100281607359648, 0.006097610108554363, 0.006081387400627136, 0.006109488196671009, 0.005947886500507593, 0.005954463966190815, 0.1077486053109169, 0.005860850680619478, 0.005992611404508352, 0.005785064306110144, 0.11208872497081757, 0.005884284619241953, 0.005864350590854883, 0.005777422804385424, 0.10673000663518906, 0.005791958421468735, 0.005671342369168997, 0.00561490748077631, 0.005587268155068159, 0.005612262990325689, 0.11594268679618835, 0.0055738636292517185, 0.005948221310973167, 0.005593731068074703, 0.00543972197920084, 0.005429252982139587, 0.005330289714038372, 0.005318600684404373, 0.0052775125950574875, 0.1129997968673706, 0.0051140496507287025, 0.00510212779045105, 0.0051436647772789, 0.005017315968871117, 0.00496086198836565, 0.12522007524967194, 0.12472915649414062, 0.004988492000848055, 0.004908397328108549, 0.004973255097866058, 0.005020900629460812, 0.004966301377862692, 0.005012247711420059, 0.00487153884023428, 0.104217030107975, 0.004769312217831612, 0.11114165186882019, 0.004834945313632488, 0.004784935619682074, 0.004766405560076237, 0.004767260514199734, 0.004873434081673622, 0.004741420038044453, 0.004674907773733139, 0.004749167710542679, 0.004648002330213785, 0.11522660404443741, 0.004644317552447319, 0.004530200269073248, 0.004528859630227089, 0.004534995649009943, 0.11362892389297485, 0.004570716992020607, 0.004484213888645172, 0.12827561795711517, 0.004487722646445036, 0.00448628282174468, 0.004468230996280909, 0.004519434180110693, 0.11482014507055283, 0.004512346815317869, 0.004494239576160908, 0.004427751991897821, 0.004520785994827747, 0.13380226492881775, 0.00443701958283782, 0.37820327281951904, 0.004606539383530617, 0.00478907348588109, 0.004826290998607874, 0.004932076670229435, 0.1335056722164154, 0.005117223598062992, 0.005329557694494724, 0.005341529846191406, 0.0054007540456950665, 0.005353210028260946, 0.005443200469017029, 0.12102388590574265, 0.005459825973957777, 0.0054986062459647655, 0.10284719616174698, 0.12977159023284912, 0.09113248437643051, 0.0057014646008610725, 0.00576675683259964, 0.005815259646624327, 0.005826269276440144, 0.005888917949050665, 0.0058584134094417095, 0.11966484040021896, 0.006006026640534401, 0.1346960812807083, 0.005978324916213751, 0.11623793095350266, 0.006084118504077196, 0.006184202153235674, 0.0060337623581290245, 0.006122604478150606, 0.006045308895409107, 0.006035244092345238, 0.006107311695814133, 0.006088682916015387, 0.005939563270658255, 0.0058586630038917065, 0.11448555439710617, 0.0058287037536501884, 0.005842570681124926, 0.12325220555067062, 0.005771927069872618, 0.005762437824159861, 0.0057913376949727535, 0.005661385133862495, 0.005683764815330505, 0.13376420736312866]\n",
            "Val loss 0.051654407727148605\n",
            "Val auc roc 0.5005468963631392\n",
            "Saved model state dict for epoch 1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f1eb6a6f9fb46ccb1f5ceda3b053840",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1677.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Loss: 0.0427\n",
            "Train Losses : [0.005570713896304369, 0.005657806061208248, 0.0055635590106248856, 0.005514740012586117, 0.005479714833199978, 0.11374316364526749, 0.0054911356419324875, 0.005378706846386194, 0.005368628539144993, 0.005389087367802858, 0.13423168659210205, 0.12488752603530884, 0.005344630219042301, 0.0054041678085923195, 0.00530605623498559, 0.005320046562701464, 0.005292776972055435, 0.005289441905915737, 0.005260382313281298, 0.005241974722594023, 0.005265221931040287, 0.005147026851773262, 0.005054857581853867, 0.005018128082156181, 0.10238828510046005, 0.004931394010782242, 0.1214580163359642, 0.004959589336067438, 0.004984140861779451, 0.005066249519586563, 0.004880428779870272, 0.004873314872384071, 0.1476745903491974, 0.004907301161438227, 0.00484477449208498, 0.004862773697823286, 0.004805379081517458, 0.0049131945706903934, 0.004728715401142836, 0.004762161523103714, 0.004645337350666523, 0.004633106756955385, 0.004711054265499115, 0.004546890035271645, 0.10108700394630432, 0.00448572589084506, 0.004447062034159899, 0.004482656717300415, 0.12484516203403473, 0.004390347748994827, 0.004400682635605335, 0.00434939144179225, 0.004433488007634878, 0.11682690680027008, 0.004347033798694611, 0.004324794746935368, 0.004367374815046787, 0.004355844110250473, 0.11962143331766129, 0.0042818645015358925, 0.004410909954458475, 0.13106147944927216, 0.004285458009690046, 0.004343423992395401, 0.004311314318329096, 0.0044347671791911125, 0.004408746492117643, 0.00427323579788208, 0.004286385606974363, 0.004234631080180407, 0.12850195169448853, 0.004210278391838074, 0.004258438944816589, 0.0042399014346301556, 0.11694210767745972, 0.004193905740976334, 0.00424413476139307, 0.11903375387191772, 0.004211698658764362, 0.004316049162298441, 0.39115139842033386, 0.13564066588878632, 0.004572458565235138, 0.004721132107079029, 0.004860761109739542, 0.004939013160765171, 0.10825062543153763, 0.005155978724360466, 0.005192257463932037, 0.005401187110692263, 0.0053427922539412975, 0.11464466154575348, 0.005575842224061489, 0.0055040111765265465, 0.005512610077857971, 0.005614092573523521, 0.09195079654455185, 0.0055696661584079266, 0.12412090599536896, 0.11602728813886642, 0.005734630860388279, 0.1209908053278923, 0.005820025224238634, 0.11496326327323914, 0.005991993937641382, 0.09769820421934128, 0.006133667193353176, 0.11278629302978516, 0.0061799148097634315, 0.006264232099056244, 0.006270936224609613, 0.006309216842055321, 0.006353318691253662, 0.0063321711495518684, 0.006360176019370556, 0.12830057740211487, 0.006292958278208971, 0.10052324086427689, 0.12686394155025482, 0.006299491040408611, 0.006342730484902859, 0.006349554285407066, 0.006402438506484032, 0.006483634002506733, 0.006298011634498835, 0.006342915818095207, 0.006242698989808559, 0.11560695618391037, 0.12796910107135773, 0.36667218804359436, 0.006331183947622776, 0.006487671285867691, 0.006612302269786596, 0.12013737112283707, 0.38693180680274963, 0.11198350787162781, 0.007487324997782707, 0.007693890947848558, 0.00794724840670824, 0.008086241781711578, 0.008210747502744198, 0.10713446885347366, 0.008487078361213207, 0.008526173420250416, 0.00865787174552679, 0.10282619297504425, 0.008762950077652931, 0.00877572875469923, 0.008859632536768913, 0.10500116646289825, 0.008808232843875885, 0.008761041797697544, 0.11650608479976654, 0.008746840991079807, 0.008777829818427563, 0.00877863634377718, 0.008640758693218231, 0.008680539205670357, 0.11681318283081055, 0.12290740758180618, 0.00849370751529932, 0.008415807038545609, 0.008359991945326328, 0.11728786677122116, 0.30688849091529846, 0.3383643627166748, 0.09773939847946167, 0.009136061184108257, 0.009390984661877155, 0.009611515328288078, 0.009831364266574383, 0.010004263371229172, 0.01006498746573925, 0.010142847895622253, 0.01018779817968607, 0.10041543841362, 0.010240662842988968, 0.01028507761657238, 0.010305522941052914, 0.010185264982283115, 0.010160951875150204, 0.010084165260195732, 0.10595450550317764, 0.11137031763792038, 0.009868082590401173, 0.00978291779756546, 0.009714558720588684, 0.009702382609248161, 0.00963426474481821, 0.00943898968398571, 0.11099856346845627, 0.009181691333651543, 0.00916352029889822, 0.009051929228007793, 0.008877166546881199, 0.008800653740763664, 0.3426974415779114, 0.0086628757417202, 0.00871939305216074, 0.008764799684286118, 0.10334610939025879, 0.009004762396216393, 0.008774827234447002, 0.35021188855171204, 0.009038315154612064, 0.3395763337612152, 0.00945676676928997, 0.10891129076480865, 0.010079548694193363, 0.11591245979070663, 0.010444379411637783, 0.010617186315357685, 0.11134377866983414, 0.010890686884522438, 0.010995661839842796, 0.01114605087786913, 0.011265088804066181, 0.011132310144603252, 0.011156649328768253, 0.01108931191265583, 0.011048109270632267, 0.10945715755224228, 0.01083823386579752, 0.010754351504147053, 0.11360631138086319, 0.09223022311925888, 0.010653050616383553, 0.010500980541110039, 0.010440584272146225, 0.0955096185207367, 0.010221649892628193, 0.010162396356463432, 0.1077495589852333, 0.00999427493661642, 0.010000201873481274, 0.109035924077034, 0.009719030931591988, 0.3356788158416748, 0.009863555431365967, 0.00982133112847805, 0.009882624261081219, 0.009937167167663574, 0.00992013793438673, 0.00987392570823431, 0.009846020489931107, 0.00988068152219057, 0.009804424829781055, 0.009674612432718277, 0.12379709631204605, 0.09394989162683487, 0.1266660988330841, 0.1123594343662262, 0.009419809095561504, 0.009420793503522873, 0.009448369964957237, 0.009322235360741615, 0.09981851279735565, 0.11081605404615402, 0.009213065728545189, 0.00919082947075367, 0.009119385853409767, 0.009055877104401588, 0.00905210617929697, 0.009027429856359959, 0.008844391442835331, 0.008738960139453411, 0.00865953043103218, 0.008558199740946293, 0.008374396711587906, 0.09729623049497604, 0.008204647339880466, 0.008103694766759872, 0.007977201603353024, 0.11042389273643494, 0.11047832667827606, 0.14159654080867767, 0.10184858739376068, 0.09947910904884338, 0.09097389131784439, 0.007826083339750767, 0.00792637001723051, 0.11157030612230301, 0.007910247892141342, 0.007891803048551083, 0.00791372824460268, 0.007870582863688469, 0.00783207081258297, 0.007788896560668945, 0.007764076814055443, 0.007701731286942959, 0.11831407994031906, 0.10043229162693024, 0.007598577067255974, 0.007575877942144871, 0.007547756657004356, 0.0074575250037014484, 0.007444219663739204, 0.0073494678363204, 0.007269229739904404, 0.1111566424369812, 0.007256632205098867, 0.007084843702614307, 0.10876594483852386, 0.007009731139987707, 0.0069473376497626305, 0.00691255321726203, 0.006942812353372574, 0.006850139703601599, 0.006738246884196997, 0.006765040103346109, 0.006601918954402208, 0.10260935127735138, 0.006477091461420059, 0.006540381815284491, 0.0063636102713644505, 0.006389337591826916, 0.00635179178789258, 0.006217891350388527, 0.3333817422389984, 0.006198214367032051, 0.0062806010246276855, 0.0063788373954594135, 0.006342732347548008, 0.0063618686981499195, 0.09658315777778625, 0.006389628630131483, 0.006446384824812412, 0.0064141103066504, 0.006405445747077465, 0.006488708313554525, 0.00640404038131237, 0.006332669872790575, 0.12004969269037247, 0.006378920283168554, 0.006260218098759651, 0.006234952248632908, 0.006215616595000029, 0.12566223740577698, 0.373264878988266, 0.11228816956281662, 0.006432740017771721, 0.006539044436067343, 0.006709006614983082, 0.006724216975271702, 0.0067809708416461945, 0.11439524590969086, 0.11098480969667435, 0.007185615599155426, 0.007067037746310234, 0.007051517721265554, 0.11258463561534882, 0.007106212433427572, 0.11070942878723145, 0.007199631072580814, 0.10743477195501328, 0.007222081534564495, 0.00727923633530736, 0.007314236368983984, 0.1364966481924057, 0.007310823071748018, 0.007381480187177658, 0.007295744493603706, 0.007330828811973333, 0.0072256941348314285, 0.007215769030153751, 0.007189346011728048, 0.007097454275935888, 0.007033812813460827, 0.006965439300984144, 0.00698254955932498, 0.006871678866446018, 0.006807407829910517, 0.11052268743515015, 0.006638574413955212, 0.006580450106412172, 0.00656595453619957, 0.006488231010735035, 0.0064360881224274635, 0.006366537418216467, 0.006266687996685505, 0.0062316786497831345, 0.11070483922958374, 0.35447415709495544, 0.0061900923028588295, 0.006264854688197374, 0.006356867030262947, 0.10783872753381729, 0.006446346174925566, 0.006505502853542566, 0.006538114510476589, 0.10319225490093231, 0.006612334866076708, 0.10108096897602081, 0.11842793226242065, 0.0067454553209245205, 0.12245970219373703, 0.006803419440984726, 0.0068218884989619255, 0.006860731169581413, 0.006847734563052654, 0.006963656283915043, 0.006870417855679989, 0.006838442757725716, 0.0068845259957015514, 0.006834663450717926, 0.12010052055120468, 0.09282631427049637, 0.0067093586549162865, 0.0067104133777320385, 0.1070757806301117, 0.006696347147226334, 0.006699331104755402, 0.006672920659184456, 0.00664934329688549, 0.006666692905128002, 0.006586775649338961, 0.1396891325712204, 0.006515929009765387, 0.006520395632833242, 0.006453297100961208, 0.10691648721694946, 0.10712561011314392, 0.006403479725122452, 0.006410995498299599, 0.12672603130340576, 0.006380106322467327, 0.37025710940361023, 0.0065416134893894196, 0.1142260879278183, 0.0067139556631445885, 0.006863712333142757, 0.0068737235851585865, 0.006959294434636831, 0.00701981782913208, 0.007035634946078062, 0.007027577608823776, 0.007061864249408245, 0.33940771222114563, 0.007137308828532696, 0.007304060272872448, 0.007420804351568222, 0.11030053347349167, 0.007559767458587885, 0.007636501453816891, 0.007658624555915594, 0.007612518034875393, 0.09234863519668579, 0.007650925777852535, 0.007730522658675909, 0.007737509906291962, 0.00769573962315917, 0.007640860974788666, 0.11681264638900757, 0.007580177392810583, 0.007558851968497038, 0.0999695286154747, 0.007509385701268911, 0.31844091415405273, 0.007686778903007507, 0.007742443587630987, 0.0077521721832454205, 0.007838757708668709, 0.11495815217494965, 0.007887217216193676, 0.007944479584693909, 0.007948216050863266, 0.008015003055334091, 0.007968038320541382, 0.007931394502520561, 0.007933458313345909, 0.007846901193261147, 0.007772271521389484, 0.007757962215691805, 0.0077055334113538265, 0.007594429422169924, 0.11793562024831772, 0.007554109673947096, 0.007451154757291079, 0.007371283136308193, 0.36580702662467957, 0.007392150815576315, 0.007451504468917847, 0.007531645707786083, 0.007538893260061741, 0.11684782058000565, 0.007544802036136389, 0.007617667317390442, 0.09910507500171661, 0.007581066340208054, 0.00761424470692873, 0.0075640324503183365, 0.007569789886474609, 0.00761041697114706, 0.007544269785284996, 0.007483556400984526, 0.34985509514808655, 0.0076069007627666, 0.007689060643315315, 0.007702520117163658, 0.0076475623063743114, 0.007798362988978624, 0.007732631638646126, 0.007696847431361675, 0.007664404343813658, 0.007624407298862934, 0.007606165949255228, 0.007610283326357603, 0.10705854743719101, 0.00747464457526803, 0.0074556441977620125, 0.13195142149925232, 0.007404766045510769, 0.007411307655274868, 0.007333101239055395, 0.00733089167624712, 0.007232608273625374, 0.007235268596559763, 0.007154460996389389, 0.007232592441141605, 0.007011261768639088, 0.006947603076696396, 0.0069016460329294205, 0.006887287367135286, 0.006813554093241692, 0.08635375648736954, 0.00658393744379282, 0.006619587540626526, 0.006506996229290962, 0.11327863484621048, 0.006397486664354801, 0.006386416964232922, 0.00635085953399539, 0.006270912941545248, 0.0061937542632222176, 0.0061315023340284824, 0.006161819212138653, 0.006090281065553427, 0.006000207271426916, 0.09924918413162231, 0.12600436806678772, 0.10895688831806183, 0.00590196019038558, 0.005978046450763941, 0.0058349971659481525, 0.13170914351940155, 0.005838070064783096, 0.0059806955978274345, 0.0059560141526162624, 0.09557153284549713, 0.005804839078336954, 0.005850628018379211, 0.10313770920038223, 0.10751983523368835, 0.12169179320335388, 0.005970698781311512, 0.005892111919820309, 0.005879370961338282, 0.005897568538784981, 0.005886318162083626, 0.1140584945678711, 0.005991628393530846, 0.1065078154206276, 0.005924787372350693, 0.0059050098061561584, 0.005935230292379856, 0.005973255727440119, 0.005973260849714279, 0.005896672140806913, 0.005967100150883198, 0.09538641571998596, 0.005811268929392099, 0.005836245138198137, 0.12661944329738617, 0.0057961419224739075, 0.005769320763647556, 0.005784676410257816, 0.0058706970885396, 0.005761291831731796, 0.005701317917555571, 0.005714906845241785, 0.005652780644595623, 0.0960797518491745, 0.005651336163282394, 0.005520845763385296, 0.005720616318285465, 0.1034732311964035, 0.0055391062051057816, 0.11885462701320648, 0.005580772180110216, 0.005596786271780729, 0.09024510532617569, 0.1326178014278412, 0.005573540925979614, 0.0054936218075454235, 0.005487387999892235, 0.0055315387435257435, 0.1084510087966919, 0.12117036432027817, 0.1225622370839119, 0.005579451564699411, 0.10958725959062576, 0.3755173683166504, 0.005979353096336126, 0.005946966353803873, 0.006099368911236525, 0.006112088914960623, 0.006225072778761387, 0.0063949632458388805, 0.006435459479689598, 0.006431180518120527, 0.006427827291190624, 0.00638370867818594, 0.006352605298161507, 0.08624167740345001, 0.006615721620619297, 0.006489309947937727, 0.09641554951667786, 0.00654313201084733, 0.13501513004302979, 0.11402590572834015, 0.006451559253036976, 0.00659828120842576, 0.12674762308597565, 0.0064871646463871, 0.09066365659236908, 0.32179608941078186, 0.0067675113677978516, 0.0068757240660488605, 0.0070163593627512455, 0.007138366810977459, 0.007114107254892588, 0.007165837567299604, 0.0071341171860694885, 0.0071261171251535416, 0.32307636737823486, 0.0936121940612793, 0.007521953899413347, 0.00758375646546483, 0.12936562299728394, 0.008062474429607391, 0.11567576974630356, 0.007905079983174801, 0.00805487111210823, 0.00794854387640953, 0.0801023542881012, 0.008112342096865177, 0.00811153557151556, 0.008114426396787167, 0.008235078305006027, 0.008160567842423916, 0.008219054900109768, 0.008147326298058033, 0.008252987638115883, 0.008005745708942413, 0.008255315013229847, 0.00804614182561636, 0.007814466021955013, 0.008049963973462582, 0.0076588732190430164, 0.007722665090113878, 0.1284894496202469, 0.007564445026218891, 0.007571380585432053, 0.11593416333198547, 0.3142321705818176, 0.007502047810703516, 0.007420300506055355, 0.007709071971476078, 0.007636696100234985, 0.11792244017124176, 0.09044721722602844, 0.13274545967578888, 0.00767647847533226, 0.007871459238231182, 0.007796668913215399, 0.3204513490200043, 0.008079346269369125, 0.007958137430250645, 0.00805568229407072, 0.008174723014235497, 0.08955883234739304, 0.008250164799392223, 0.14384432137012482, 0.008404339663684368, 0.00834215059876442, 0.09986654669046402, 0.13738428056240082, 0.09767036885023117, 0.1131555512547493, 0.008727815933525562, 0.008614720776677132, 0.0938560962677002, 0.008747488260269165, 0.3351902961730957, 0.11713004857301712, 0.00912058912217617, 0.10087266564369202, 0.009250353090465069, 0.00930915866047144, 0.009555434808135033, 0.11064708977937698, 0.009497622027993202, 0.00958982016891241, 0.09003882855176926, 0.10361045598983765, 0.009649170562624931, 0.009780263528227806, 0.009818588383495808, 0.009684579446911812, 0.009740914218127728, 0.009948085993528366, 0.00952841155230999, 0.009647003374993801, 0.009492882527410984, 0.009487606585025787, 0.009291179478168488, 0.009430205449461937, 0.009297063574194908, 0.009057463146746159, 0.07582972943782806, 0.3345702886581421, 0.008949567563831806, 0.009161535650491714, 0.009135376662015915, 0.009158146567642689, 0.00897947233170271, 0.009186484850943089, 0.009271955117583275, 0.008939109742641449, 0.008840959519147873, 0.009074823930859566, 0.009208520874381065, 0.008879374712705612, 0.00882397685199976, 0.109572634100914, 0.008890004828572273, 0.1114521399140358, 0.008491862565279007, 0.008440063335001469, 0.008271829225122929, 0.3531641662120819, 0.008269339799880981, 0.008439735509455204, 0.008513049222528934, 0.10587211698293686, 0.1001025065779686, 0.008584223687648773, 0.008750743232667446, 0.008646337315440178, 0.09783562272787094, 0.008770334534347057, 0.32370203733444214, 0.008646896108984947, 0.008832097053527832, 0.008954617194831371, 0.1191294714808464, 0.009017344564199448, 0.008928843773901463, 0.008919068612158298, 0.00910001341253519, 0.009047466330230236, 0.008963663130998611, 0.00896218791604042, 0.008873840793967247, 0.11292269080877304, 0.1017957255244255, 0.10418310761451721, 0.12275430560112, 0.00902021024376154, 0.008971850387752056, 0.00897184107452631, 0.008841856382787228, 0.008848144672811031, 0.008797119371592999, 0.008783501572906971, 0.008701556362211704, 0.008681158535182476, 0.1061817854642868, 0.00851472932845354, 0.008650858886539936, 0.008763636462390423, 0.008385111577808857, 0.008540800772607327, 0.008444246836006641, 0.008110355585813522, 0.00803209189325571, 0.1303308606147766, 0.00803159736096859, 0.007842173799872398, 0.007796966005116701, 0.09880007058382034, 0.007825846783816814, 0.007784412242472172, 0.007800312712788582, 0.00774452555924654, 0.0074944645166397095, 0.007708306889981031, 0.00757561856880784, 0.10491982847452164, 0.007293996401131153, 0.007436603773385286, 0.13581222295761108, 0.007193224970251322, 0.1384221911430359, 0.10418542474508286, 0.007216837722808123, 0.3733643591403961, 0.007343251258134842, 0.007427654229104519, 0.11881064623594284, 0.29119938611984253, 0.007695454638451338, 0.1396760493516922, 0.007848524488508701, 0.007972029969096184, 0.00831716787070036, 0.008256795816123486, 0.008274272084236145, 0.008232624270021915, 0.0882163718342781, 0.0083917286247015, 0.008370617404580116, 0.008380700834095478, 0.008641627617180347, 0.00834914855659008, 0.008336338214576244, 0.00859476625919342, 0.008300152607262135, 0.008306555449962616, 0.008384492248296738, 0.08610434085130692, 0.11760694533586502, 0.09996344894170761, 0.008222118951380253, 0.008134977892041206, 0.31980717182159424, 0.1182267814874649, 0.09676828235387802, 0.008414429612457752, 0.10434615612030029, 0.008454921655356884, 0.008451382629573345, 0.008671823889017105, 0.008817685768008232, 0.111727774143219, 0.008622602559626102, 0.008697567507624626, 0.09270545840263367, 0.008628811687231064, 0.008613075129687786, 0.008809770457446575, 0.008714773692190647, 0.008586399257183075, 0.008609830401837826, 0.008668797090649605, 0.00851409137248993, 0.008529873564839363, 0.008333425968885422, 0.008551502600312233, 0.008329602889716625, 0.08705944567918777, 0.008290223777294159, 0.00822632946074009, 0.008260788396000862, 0.007968269288539886, 0.09098941087722778, 0.1270902007818222, 0.007815266959369183, 0.13499674201011658, 0.008054021745920181, 0.33364900946617126, 0.00783446803689003, 0.00799036119133234, 0.007894342765212059, 0.1015903428196907, 0.09035880863666534, 0.008078414015471935, 0.008094336837530136, 0.008291780948638916, 0.008127967827022076, 0.00808144360780716, 0.008359933272004128, 0.008419393561780453, 0.008021821267902851, 0.11229749768972397, 0.007973003201186657, 0.008045700378715992, 0.007998027838766575, 0.008056712336838245, 0.008129850961267948, 0.007800660561770201, 0.007825159467756748, 0.1327376514673233, 0.14881373941898346, 0.0076585812494158745, 0.0076847802847623825, 0.007638908457010984, 0.008098062127828598, 0.007607660721987486, 0.007491896394640207, 0.007592661771923304, 0.13879287242889404, 0.09427760541439056, 0.11616868525743484, 0.007542143110185862, 0.14135301113128662, 0.007423095405101776, 0.3902668356895447, 0.13367222249507904, 0.007736751809716225, 0.09871035814285278, 0.007735149003565311, 0.0078516136854887, 0.3122720420360565, 0.008052514865994453, 0.008192158304154873, 0.008239495567977428, 0.008665632456541061, 0.08464163541793823, 0.12343525141477585, 0.008500934578478336, 0.008757181465625763, 0.10505116730928421, 0.008575665764510632, 0.008702599443495274, 0.008716332726180553, 0.008861374109983444, 0.1376112848520279, 0.10722529143095016, 0.10828319191932678, 0.008801227435469627, 0.1209249347448349, 0.09311474859714508, 0.008947672322392464, 0.09933991730213165, 0.008974221535027027, 0.008863752707839012, 0.10935258120298386, 0.008950301446020603, 0.008921073749661446, 0.2808636724948883, 0.008957775309681892, 0.32837578654289246, 0.009248324669897556, 0.009505829773843288, 0.0094916308298707, 0.07896920293569565, 0.009621851146221161, 0.009741137735545635, 0.00994246918708086, 0.009680258110165596, 0.009783396497368813, 0.009759494103491306, 0.11184679716825485, 0.00979903619736433, 0.3011339008808136, 0.0099419467151165, 0.010051766410470009, 0.009947211481630802, 0.010174460709095001, 0.12314291298389435, 0.010073895566165447, 0.010331747122108936, 0.010213706642389297, 0.09810348600149155, 0.009972178377211094, 0.08738287538290024, 0.01008585374802351, 0.10822183638811111, 0.009914207272231579, 0.09737365692853928, 0.00996472779661417, 0.08810795843601227, 0.010172015056014061, 0.01007963065057993, 0.009973637759685516, 0.009996581822633743, 0.009896486066281796, 0.009860814549028873, 0.009790854528546333, 0.13973401486873627, 0.07866399735212326, 0.009688807651400566, 0.07848841696977615, 0.009645822457969189, 0.12709519267082214, 0.10695794969797134, 0.1347842663526535, 0.009736556559801102, 0.009561826474964619, 0.009544291533529758, 0.00948163028806448, 0.009400703944265842, 0.6845727562904358, 0.10276132822036743, 0.009814713150262833, 0.09161796420812607, 0.08833438903093338, 0.010112127289175987, 0.010039888322353363, 0.10240257531404495, 0.010060909204185009, 0.010265651158988476, 0.010230451822280884, 0.010341765359044075, 0.0102162454277277, 0.010359248146414757, 0.010241774842143059, 0.12791807949543, 0.010388543829321861, 0.6505799889564514, 0.010521860793232918, 0.11098101735115051, 0.32605740427970886, 0.010727358981966972, 0.01100338064134121, 0.011034895665943623, 0.011101732961833477, 0.13386870920658112, 0.011394474655389786, 0.011576077900826931, 0.11472627520561218, 0.011834503151476383, 0.011748229153454304, 0.011625904589891434, 0.011775613762438297, 0.10154955089092255, 0.011735591106116772, 0.011898486874997616, 0.011678334325551987, 0.011524615809321404, 0.011552447453141212, 0.01155338529497385, 0.011520866304636002, 0.27760404348373413, 0.011325490660965443, 0.011338677257299423, 0.011413809843361378, 0.01132692489773035, 0.13188400864601135, 0.011383887380361557, 0.011340266093611717, 0.31456854939460754, 0.011281360872089863, 0.01132225152105093, 0.011507377028465271, 0.11058799177408218, 0.09236481785774231, 0.011444536037743092, 0.011376109905540943, 0.011499284766614437, 0.11675840616226196, 0.011444607749581337, 0.011331489309668541, 0.01138150691986084, 0.30246713757514954, 0.011400243267416954, 0.01151980459690094, 0.01155775599181652, 0.011518684215843678, 0.011470994912087917, 0.11012563109397888, 0.011562288738787174, 0.011405902914702892, 0.011522202752530575, 0.011635417118668556, 0.011295377276837826, 0.011509863659739494, 0.011143647134304047, 0.011116375215351582, 0.01106460951268673, 0.3360043466091156, 0.011069707572460175, 0.33500248193740845, 0.011185838840901852, 0.12862572073936462, 0.011238755658268929, 0.011306052096188068, 0.011548390612006187, 0.011474750004708767, 0.011668350547552109, 0.101542167365551, 0.09751676023006439, 0.011566614732146263, 0.08366832882165909, 0.0114769097417593, 0.011411521583795547, 0.011385143734514713, 0.11005599051713943, 0.011320938356220722, 0.10411632806062698, 0.01129624992609024, 0.011219737119972706, 0.1018814891576767, 0.011113007552921772, 0.011394999921321869, 0.10687939822673798, 0.011142263188958168, 0.09432265162467957, 0.010991886258125305, 0.10640520602464676, 0.11457474529743195, 0.010941289365291595, 0.011075853370130062, 0.010972321964800358, 0.01080850325524807, 0.010894720442593098, 0.01070175226777792, 0.010732925496995449, 0.010829834267497063, 0.010620305314660072, 0.010690072551369667, 0.11361196637153625, 0.0969264879822731, 0.11533968895673752, 0.010675343684852123, 0.01060275174677372, 0.010299364104866982, 0.010192394256591797, 0.010174809023737907, 0.010324380360543728, 0.11298687756061554, 0.010050468146800995, 0.010047771967947483, 0.010073318146169186, 0.009906836785376072, 0.00984694343060255, 0.009846457280218601, 0.009747754782438278, 0.009886279702186584, 0.10610171407461166, 0.09717833250761032, 0.0095168836414814, 0.009517117403447628, 0.009484383277595043, 0.009428723715245724, 0.009481499902904034, 0.009272350929677486, 0.009347555227577686, 0.009137238375842571, 0.09987729787826538, 0.10804449766874313, 0.009093286469578743, 0.009180659428238869, 0.008988176472485065, 0.008932230994105339, 0.00898079201579094, 0.1238117665052414, 0.008901990950107574, 0.008863084949553013, 0.008775189518928528, 0.008932207711040974, 0.08609026670455933, 0.008673426695168018, 0.10828910768032074, 0.00861745048314333, 0.008716579526662827, 0.008536122739315033, 0.008534129709005356, 0.008544751442968845, 0.09965488314628601, 0.008442729711532593, 0.008395363576710224, 0.09874145686626434, 0.008307837881147861, 0.08866893500089645, 0.008417036384344101, 0.09086354821920395, 0.008247659541666508, 0.008275163359940052, 0.11816050857305527, 0.008177847601473331, 0.008165274746716022, 0.008361742831766605, 0.11961891502141953, 0.00824232678860426, 0.10541953891515732, 0.11370716243982315, 0.008085429668426514, 0.00813778955489397, 0.008139589801430702, 0.008209602907299995, 0.008019949309527874, 0.09584449231624603, 0.007970546372234821, 0.008089151233434677, 0.007981662638485432, 0.10117810219526291, 0.09186356514692307, 0.008012275211513042, 0.008059464395046234, 0.11615945398807526, 0.11031191796064377, 0.007905833423137665, 0.007973218336701393, 0.1194145679473877, 0.007884110324084759, 0.007983670569956303, 0.09191656857728958, 0.007896635681390762, 0.007838794961571693, 0.13470205664634705, 0.007920878008008003, 0.008043783716857433, 0.007922596298158169, 0.007826825603842735, 0.008059589192271233, 0.007898361422121525, 0.3397798240184784, 0.007841893471777439, 0.007774715311825275, 0.007888291031122208, 0.007931794039905071, 0.007974951528012753, 0.007930425927042961, 0.007781950291246176, 0.007865498773753643, 0.007887087762355804, 0.007772858254611492, 0.007801236119121313, 0.007818692363798618, 0.007845091633498669, 0.09789343923330307, 0.007787514943629503, 0.00765334302559495, 0.0077238529920578, 0.09325020760297775, 0.007814307697117329, 0.0911727175116539, 0.007641852367669344, 0.007817705161869526, 0.0804549902677536, 0.007512838579714298, 0.11192842572927475, 0.00754280760884285, 0.11130732297897339, 0.007749529089778662, 0.00780117604881525, 0.007544283289462328, 0.007477836217731237, 0.007579685654491186, 0.08906948566436768, 0.007517185527831316, 0.1056826263666153, 0.007603566162288189, 0.12272220849990845, 0.007362759672105312, 0.007385910023003817, 0.007443847134709358, 0.007503973785787821, 0.007444068323820829, 0.08675948530435562, 0.007370815612375736, 0.007565497420728207, 0.13460074365139008, 0.007273415569216013, 0.11312392354011536, 0.13463538885116577, 0.0073847584426403046, 0.11593077331781387, 0.007299799006432295, 0.007411068305373192, 0.12526105344295502, 0.007414322346448898, 0.007502444554120302, 0.13470381498336792, 0.0074173929169774055, 0.0072379400953650475, 0.007261826191097498, 0.0073262532241642475, 0.0072747631929814816, 0.3565685451030731, 0.007231798488646746, 0.00725789787247777, 0.007275761570781469, 0.007357887923717499, 0.007371632382273674, 0.12430950254201889, 0.00736357131972909, 0.00739598972722888, 0.10689478367567062, 0.0073835658840835094, 0.007373129483312368, 0.007381223142147064, 0.12320785224437714, 0.007468694355338812, 0.0075286515057086945, 0.3405781090259552, 0.007458832114934921, 0.10267677903175354, 0.0075067137368023396, 0.0074925716035068035, 0.00759688438847661, 0.007758419495075941, 0.007559909950941801, 0.007532138377428055, 0.0076763685792684555, 0.0074919285252690315, 0.007590481545776129, 0.007490267977118492, 0.08536660671234131, 0.007539911661297083, 0.007524622604250908, 0.007513538934290409, 0.007508929818868637, 0.007486576214432716, 0.007392259314656258, 0.11453015357255936, 0.007493441924452782, 0.0073563773185014725, 0.007345357444137335, 0.007425639778375626, 0.007463566958904266, 0.007271275855600834, 0.007364147342741489, 0.007371668238192797, 0.007367880083620548, 0.007340651471167803, 0.007171035744249821, 0.007177285850048065, 0.11623509228229523, 0.12297914922237396, 0.00716410344466567, 0.11259820312261581, 0.007172426674515009, 0.007137315813452005, 0.09792545437812805, 0.007082399912178516, 0.0070884255692362785, 0.10013996809720993, 0.007069064769893885, 0.007212434429675341, 0.09998291730880737, 0.3790605068206787, 0.007077470887452364, 0.0071586924605071545, 0.00713921245187521, 0.11223342269659042, 0.007146415766328573, 0.007176344282925129, 0.007199395447969437, 0.0072610205970704556, 0.00721335643902421, 0.007242017891258001, 0.007230870425701141, 0.09660910069942474, 0.007183094974607229, 0.0072499047964811325, 0.09615863859653473, 0.007181704510003328, 0.08346716314554214, 0.007190359756350517, 0.007223967462778091, 0.007183087058365345, 0.007236273493617773, 0.09848416596651077, 0.007371904794126749, 0.00728989252820611, 0.0072562736459076405, 0.007177270948886871, 0.35492268204689026, 0.007106624078005552, 0.1361098289489746, 0.007210754789412022, 0.00715998001396656, 0.0071729752235114574, 0.09688820689916611, 0.007313057314604521, 0.10301991552114487, 0.007303737569600344, 0.007292271591722965, 0.007361763156950474, 0.007323702797293663, 0.007401148322969675, 0.007223175838589668, 0.00734676280990243, 0.00728929229080677, 0.11817580461502075, 0.007270448375493288, 0.007338485214859247, 0.007273896597325802, 0.007354781962931156, 0.11212514340877533, 0.007310613989830017, 0.09071971476078033, 0.007229616399854422, 0.08968425542116165, 0.007167664356529713, 0.007109697442501783, 0.007139937020838261, 0.007135631516575813, 0.007233797572553158, 0.09400620311498642, 0.007318757940083742, 0.1305815428495407, 0.007138742599636316, 0.007222640328109264, 0.1334236115217209, 0.0930723026394844, 0.007044709287583828, 0.12202026695013046, 0.007143758237361908, 0.007104892283678055, 0.08732084929943085, 0.11027344316244125, 0.3612028658390045, 0.007115400396287441, 0.0071148038841784, 0.00727422721683979, 0.0071808588691055775, 0.007231353782117367, 0.007191394455730915, 0.007231186144053936, 0.007364879362285137, 0.007300917990505695, 0.007199967745691538, 0.12416868656873703, 0.0073744505643844604, 0.10925202816724777, 0.007259363308548927, 0.007279119919985533, 0.36917200684547424, 0.00740407221019268, 0.007344000972807407, 0.0074495580047369, 0.007327207364141941, 0.00737658329308033, 0.007461565546691418, 0.007351724896579981, 0.007330550812184811, 0.007521194405853748, 0.13463076949119568, 0.007301380392163992, 0.007307043299078941, 0.007356724701821804, 0.007345871068537235, 0.00742320017889142, 0.0852414220571518, 0.007343301549553871, 0.007487583439797163, 0.007274933159351349, 0.007335713133215904, 0.007306667976081371, 0.007349008694291115, 0.10074819624423981, 0.0073348539881408215, 0.12069038301706314, 0.007269950117915869, 0.007231138180941343, 0.007393695414066315, 0.007314685266464949, 0.0074055390432477, 0.007218327838927507, 0.007237653713673353, 0.007282010745257139, 0.007221980020403862, 0.00716417608782649, 0.11960622668266296, 0.007239897269755602, 0.007360805757343769, 0.40133440494537354, 0.007112286984920502, 0.007149762939661741, 0.3293439447879791, 0.007178820203989744, 0.10671531409025192, 0.007355926092714071, 0.007204995956271887, 0.007301785051822662, 0.13034147024154663, 0.0073679531924426556, 0.00728699890896678, 0.0074205705896019936, 0.0074320631101727486, 0.007467234041541815, 0.007369173690676689, 0.00731299864128232, 0.007300891913473606, 0.007434389553964138, 0.007404291536659002, 0.007276259362697601, 0.0072976406663656235, 0.007355701178312302, 0.00723650399595499, 0.0072705065831542015, 0.007352369837462902, 0.10376804322004318, 0.007291787303984165, 0.007285742554813623, 0.11038745939731598, 0.00718852411955595, 0.007184264715760946, 0.007293591275811195, 0.1368434876203537, 0.007228055968880653, 0.0073472196236252785, 0.007248078938573599, 0.007154565770179033, 0.12684637308120728, 0.10299499332904816, 0.007125535514205694, 0.0886261910200119, 0.007179282605648041, 0.00718459440395236, 0.007281484082341194, 0.11801639199256897, 0.007199552841484547, 0.09859436750411987, 0.0071276589296758175, 0.3677361309528351, 0.12570145726203918, 0.007192318793386221, 0.007224332075566053, 0.00737495394423604, 0.007281518075615168, 0.007273676339536905, 0.00723553542047739, 0.007250105496495962, 0.007341398857533932, 0.007199508138000965, 0.007298304699361324, 0.007245795335620642, 0.10711017996072769, 0.11793126910924911, 0.007276743184775114, 0.11509990692138672, 0.1125243604183197, 0.007203220389783382, 0.007184152025729418, 0.10953227430582047, 0.007211804389953613, 0.14465969800949097, 0.007255928125232458, 0.12398212403059006, 0.007284490391612053, 0.007286268752068281, 0.007428986020386219, 0.0073647210374474525, 0.0073196301236748695, 0.007319603580981493, 0.12186900526285172, 0.007235810160636902, 0.007279530633240938, 0.09864430874586105, 0.007314384914934635, 0.007249666377902031, 0.0072408271953463554, 0.00730885798111558, 0.0071952929720282555, 0.007212287746369839, 0.0073452843353152275, 0.118110790848732, 0.0071602435782551765, 0.007159600965678692, 0.11272907257080078, 0.0072095319628715515, 0.1357763558626175, 0.007137357257306576, 0.007148074917495251, 0.007147241849452257, 0.13909773528575897, 0.007236991077661514, 0.007217611186206341, 0.0072039649821817875, 0.007246175315231085, 0.11755257844924927, 0.007158141117542982, 0.00713771115988493, 0.11236732453107834, 0.3075994849205017, 0.007124299183487892, 0.34114089608192444, 0.0812806785106659, 0.007348599843680859, 0.007302853278815746, 0.007275308948010206, 0.007300248835235834, 0.007231411058455706, 0.007217230275273323, 0.007215253543108702, 0.39545589685440063, 0.007468545343726873, 0.007276972755789757, 0.007273427676409483, 0.007346101105213165, 0.007371121551841497, 0.007394094485789537, 0.00741376169025898, 0.0074586705304682255, 0.09926296025514603, 0.1376924067735672, 0.007494779769331217, 0.007330362219363451, 0.36038345098495483, 0.12260395288467407, 0.00731893815100193, 0.007598028518259525, 0.1012265756726265, 0.007363121025264263, 0.007384708151221275, 0.007547665853053331, 0.007392441853880882, 0.007479967549443245, 0.007494473364204168, 0.0073793609626591206, 0.007364700082689524, 0.007360128685832024, 0.10149300843477249, 0.007377894129604101, 0.007443671580404043, 0.007445084396749735, 0.00737506989389658, 0.00736404350027442, 0.007444609887897968, 0.007438915781676769, 0.1150263100862503, 0.39745384454727173, 0.10090462118387222, 0.007353299297392368, 0.0074142469093203545, 0.007383652031421661, 0.00758989667519927, 0.007451401557773352, 0.007465115748345852, 0.09413964301347733, 0.007726713083684444, 0.007444306276738644, 0.007580128964036703, 0.007418247405439615, 0.007529851980507374, 0.007370119448751211, 0.00747640011832118, 0.1001320481300354, 0.0074268970638513565, 0.007363610435277224, 0.09515269100666046, 0.007392114493995905, 0.007435549516230822, 0.00752685172483325, 0.007532505784183741, 0.0074904500506818295, 0.007440319284796715, 0.0073863607831299305, 0.007376697845757008, 0.007419300731271505, 0.007379588205367327, 0.007418567780405283, 0.007339279633015394, 0.007374567911028862, 0.007359978277236223, 0.007378270849585533, 0.1107444316148758, 0.007432619109749794, 0.007355047389864922, 0.11528224498033524, 0.11342161148786545, 0.007370954379439354, 0.007364748511463404, 0.09021385759115219, 0.007457929663360119, 0.007304370868951082, 0.13065914809703827, 0.007380998227745295, 0.007393089588731527, 0.007518305908888578, 0.007496330887079239, 0.1023452952504158, 0.007318262942135334, 0.007438331376761198, 0.007353066932410002, 0.007336006034165621, 0.007353329565376043, 0.007416453678160906, 0.007337223272770643, 0.007355837617069483, 0.007312202826142311, 0.007338186260312796]\n",
            "Val loss 0.0522896233902258\n",
            "Val auc roc 0.5147988523339005\n",
            "Saved model state dict for epoch 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFm0nuBLjo-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2e23e7-5f48-45bc-a91f-2a46d6961883"
      },
      "source": [
        "model = MultiModalBertClf(no_of_classes, bert_tokenizer)\n",
        "try:\n",
        "    model.load_state_dict(torch.load('./model_state_dict.pth'))\n",
        "    print('Loaded previous model state successfully!')\n",
        "except:\n",
        "    print('Starting fresh! Previous model state dict load unsuccessful')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded previous model state successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yXL1gy1tRZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5diJj175Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './model_'+col_name+'_'+str(datetime.datetime.now())+'.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm6SH297H5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_data = pd.read_csv('./final_test3_unpreprocessed.csv')\n",
        "test_submission_dataset=SubmissionDataset(test_submission_data, './test_images', img_transformations, bert_tokenizer, vocab)\n",
        "test_submission_dataloader=torch.utils.data.DataLoader(test_submission_dataset, batch_size=4, collate_fn=collate_function_for_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9PDREj1A1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "357c2392-bc11-45e1-f848-c50db680606f"
      },
      "source": [
        "len(test_submission_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ez1sufJ7oqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, tweet_ids = model_predict(test_submission_dataloader, model, chosen_criteria, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOclNQGRFWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    predictions[i]=(predictions[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJHqglG5s0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.array(predictions).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKcQfDh7NCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "437c1435-63d2-418e-e4de-ff1e629b5b9c"
      },
      "source": [
        "tids = []\n",
        "for i in range(len(tweet_ids)):\n",
        "    tids+=[[str(tweet_ids[i][0])]]\n",
        "tids_arr = np.array(tids)\n",
        "tids_arr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1995, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QGf7qcW897U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TweetIds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OWDbQnT4yfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tweet_ids = np.array(tweet_ids).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo4r_mE56ujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(tweet_ids.shape[0]):\n",
        "#     tweet_ids[i][0]=str(tweet_ids[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQ8IOaG62RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(tweet_ids[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id5X5Pmb1geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = pd.DataFrame(np.concatenate((tids_arr, predictions), axis=1), columns=['TweetId', col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHbyBTW5A2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "7923ecbb-7f8e-4f8c-d336-447f315eae5e"
      },
      "source": [
        "submit_df[submit_df[col_name]==0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Generalized_Hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TweetId, Generalized_Hate]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQemOi-I6K0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df.to_csv(col_name+' '+str(datetime.datetime.now())+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt3drOM94rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ec32c9b8-06be-4aa3-b409-dac1a64be2f3"
      },
      "source": [
        "str(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-07-28 11:14:53.792686'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSTypu-_r5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}